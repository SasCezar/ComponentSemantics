{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiset\n",
    "\n",
    "from utils import load_embeddings, load_projects, load_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "projects, imapping = load_projects('.', 'java-projects - java-projects (1).csv')\n",
    "labels = {k:v for k,v in zip(projects['names'], projects['labels_id'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = \"resources/java/stopwords.txt\"\n",
    "stopwords = load_stopwords(path)\n",
    "path = \"resources/en/stopwords.txt\"\n",
    "stopwords.update(load_stopwords(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "terms_path = '../data/embeddings/terms-count/'\n",
    "mapping = {v:k for k,v in imapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/asm.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/infinispan.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/infer.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/source.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/org.aspectj.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/JGroups.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/checker-framework.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/libgdx.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/eclipse.platform.swt.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/reflectasm.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/flink.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/Smack.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/Sysmon.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/cogcomp-nlp.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/CoreNLP.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/kryonet.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/commons-classscan.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/gs-core.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/jgraphx.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/lucene-solr.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/xmlunit.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/jgit.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/webprotege.vec'\n",
      "[Errno 2] No such file or directory: '../data/embeddings/terms-count/nutch.apache.org.vec'\n"
     ]
    }
   ],
   "source": [
    "from textblob import  Word\n",
    "\n",
    "category_terms_count = defaultdict(lambda: Counter())\n",
    "category_terms_occ = defaultdict(lambda: Counter())\n",
    "text = []\n",
    "lab = []\n",
    "for project in labels:\n",
    "    category = mapping[labels[project]]\n",
    "    try:\n",
    "        terms_count = load_embeddings(os.path.join(terms_path, f\"{project}.vec\"))\n",
    "        terms = []\n",
    "        for x, y in terms_count.items():\n",
    "            lemma = Word(x).lemmatize()\n",
    "            if lemma not in stopwords and len(x) > 1 and x not in stopwords:\n",
    "                tokens = [lemma] * int(y[0])\n",
    "                terms.extend(tokens)\n",
    "        #terms = [[Word(x).lemmatize()] * int(y[0]) for x, y in terms_count.items() if Word(x).lemmatize() not in stopwords and len(x) > 1]\n",
    "        text.append(\" \".join(terms))\n",
    "        lab.append(category)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.DataFrame({'text': text, 'label': lab})\n",
    "df = df[~df['label'].isin(['NA', 'Miscellaneous'])]\n",
    "\n",
    "y = df['label'].to_frame()\n",
    "X = df['text']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,stratify=y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "category_terms_occ = defaultdict(lambda: multiset.Multiset())\n",
    "\n",
    "for label in set(y['label'].tolist()):\n",
    "    corpus = X_train[y_train['label']==label].tolist()\n",
    "\n",
    "    for sample in corpus:\n",
    "        terms = sample.split(\" \")\n",
    "        category_terms_occ[label].update(terms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "X_t_mat = vectorizer.transform(X_train)\n",
    "X_s_mat = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=300)\n",
    "X_t_mat_pca = pca.fit_transform(X_t_mat.todense())\n",
    "X_s_mat_pca = pca.transform(X_s_mat.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-1cc042e4af8d>:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  neigh.fit(X_t_mat, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(X_t_mat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions = neigh.predict(X_s_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  0,  1,  3,  0,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  5,  4,  0,  0,  3,  0,  0,  0,  1],\n",
       "       [ 3,  0,  1, 26,  0,  0,  2,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 4,  0,  0,  1,  0,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  1,  5,  0,  0,  4,  1,  0,  0,  0],\n",
       "       [ 4,  0,  0,  4,  1,  1,  0,  2,  0,  0,  0],\n",
       "       [ 3,  0,  0,  2,  0,  2,  0,  0,  3,  0,  1],\n",
       "       [ 3,  0,  0,  3,  0,  1,  0,  0,  1,  4,  1],\n",
       "       [ 5,  0,  0,  2,  0,  0,  0,  0,  0,  0,  5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                A-Find       0.16      0.50      0.24        10\n",
      "                   CLI       1.00      0.50      0.67         2\n",
      "                  Data       0.62      0.33      0.43        15\n",
      "           Development       0.52      0.81      0.63        32\n",
      "             Graphical       0.50      0.67      0.57         3\n",
      "            Networking       0.33      0.29      0.31         7\n",
      "                Parser       0.40      0.33      0.36        12\n",
      "Scientific/Engineering       0.67      0.17      0.27        12\n",
      "                Server       0.75      0.27      0.40        11\n",
      "               Testing       1.00      0.31      0.47        13\n",
      "                   Web       0.62      0.42      0.50        12\n",
      "\n",
      "              accuracy                           0.46       129\n",
      "             macro avg       0.60      0.42      0.44       129\n",
      "          weighted avg       0.58      0.46      0.45       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000007"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import autosklearn.classification\n",
    "#\n",
    "# automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "#     n_jobs=1,\n",
    "#     memory_limit=140072,\n",
    "#     per_run_time_limit=30,\n",
    "#     tmp_folder='/tmp/autosklearn_parallel_1_example_tmp',\n",
    "#     output_folder='/tmp/autosklearn_parallel_1_example_out',\n",
    "#     ensemble_size=1,\n",
    "#     include_preprocessors=[\"no_preprocessing\"],\n",
    "#     exclude_estimators=['liblinear_svc', 'libsvm_svc', 'mlp']\n",
    "# )\n",
    "# automl.fit(X_t_mat, y_train)\n",
    "# y_hat = automl.predict(X_s_mat)\n",
    "# print(\"Accuracy score\", classification_report(y_test, y_hat))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from tpot import TPOTClassifier\n",
    "# tpot = TPOTClassifier(\n",
    "#     generations=5,\n",
    "#     population_size=50,\n",
    "#     verbosity=2, random_state=42)\n",
    "# tpot.fit(X_t_mat.todense(), y_train)\n",
    "# print(tpot.score(X_s_mat.todense(), y_test))\n",
    "# tpot.export('tpot_terms_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                A-Find       0.00      0.00      0.00        10\n",
      "                   CLI       0.00      0.00      0.00         2\n",
      "                  Data       0.67      0.13      0.22        15\n",
      "           Development       0.36      0.90      0.52        31\n",
      "             Graphical       1.00      0.33      0.50         3\n",
      "            Networking       0.00      0.00      0.00         8\n",
      "                Parser       0.16      0.42      0.23        12\n",
      "Scientific/Engineering       1.00      0.08      0.15        12\n",
      "                Server       0.00      0.00      0.00        11\n",
      "               Testing       0.00      0.00      0.00        13\n",
      "                   Web       0.50      0.58      0.54        12\n",
      "\n",
      "              accuracy                           0.34       129\n",
      "             macro avg       0.34      0.22      0.20       129\n",
      "          weighted avg       0.34      0.34      0.25       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=.01,\n",
    "                                 max_depth=3, random_state=0)\n",
    "clf.fit(X_t_mat_pca, y_train)\n",
    "predictions = clf.predict(X_s_mat_pca)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 228.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring criteria: accuracy\n",
      "--------------- model 1/11 ---------------\n",
      "SGDClassifier\n",
      "--------------- model 2/11 ---------------\n",
      "LogisticRegression\n",
      "--------------- model 3/11 ---------------\n",
      "Perceptron\n",
      "--------------- model 4/11 ---------------\n",
      "PassiveAggressiveClassifier\n",
      "--------------- model 5/11 ---------------\n",
      "KMeans\n",
      "--------------- model 6/11 ---------------\n",
      "KNeighborsClassifier\n",
      "--------------- model 7/11 ---------------\n",
      "NearestCentroid\n",
      "--------------- model 8/11 ---------------\n",
      "RadiusNeighborsClassifier\n",
      "--------------- model 9/11 ---------------\n",
      "RandomForestClassifier\n",
      "--------------- model 10/11 ---------------\n",
      "DecisionTreeClassifier\n",
      "--------------- model 11/11 ---------------\n",
      "ExtraTreesClassifier\n",
      "============================================================\n",
      "Model                          accuracy    Time/clf (s)\n",
      "---------------------------  ----------  --------------\n",
      "SGDClassifier                      -inf             inf\n",
      "LogisticRegression                 -inf             inf\n",
      "Perceptron                         -inf             inf\n",
      "PassiveAggressiveClassifier        -inf             inf\n",
      "KMeans                             -inf             inf\n",
      "KNeighborsClassifier               -inf             inf\n",
      "NearestCentroid                    -inf             inf\n",
      "RadiusNeighborsClassifier          -inf             inf\n",
      "RandomForestClassifier             -inf             inf\n",
      "DecisionTreeClassifier             -inf             inf\n",
      "ExtraTreesClassifier               -inf             inf\n",
      "============================================================\n",
      "The winner is: SGDClassifier with score -inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hunga_bunga.classification.HungaBungaClassifier at 0x7f56c9c74070>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_t_mat_pca, y_train['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This SGDClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-37-832cb5484af6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_t_mat_pca\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/gML/lib/python3.8/site-packages/hunga_bunga/classification.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    200\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormalize_x\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnormalize_x\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrid_search\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrid_search\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 202\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mHungaBungaClassifier\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    203\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/gML/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    305\u001B[0m             \u001B[0mPredicted\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mlabel\u001B[0m \u001B[0mper\u001B[0m \u001B[0msample\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m         \"\"\"\n\u001B[0;32m--> 307\u001B[0;31m         \u001B[0mscores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecision_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    308\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscores\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m             \u001B[0mindices\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mscores\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/gML/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001B[0m in \u001B[0;36mdecision_function\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    278\u001B[0m             \u001B[0;32mclass\u001B[0m \u001B[0mwould\u001B[0m \u001B[0mbe\u001B[0m \u001B[0mpredicted\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    279\u001B[0m         \"\"\"\n\u001B[0;32m--> 280\u001B[0;31m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    281\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    282\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'csr'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/gML/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     70\u001B[0m                           FutureWarning)\n\u001B[1;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     73\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/gML/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_is_fitted\u001B[0;34m(estimator, attributes, msg, all_or_any)\u001B[0m\n\u001B[1;32m   1017\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1018\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mattrs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1019\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mNotFittedError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'name'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1020\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1021\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNotFittedError\u001B[0m: This SGDClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "clf.predict(X_t_mat_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_t_mat, y_train['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  0,  1,  3,  0,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  5,  4,  0,  0,  3,  0,  0,  0,  1],\n",
       "       [ 3,  0,  1, 26,  0,  0,  2,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 4,  0,  0,  1,  0,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  1,  5,  0,  0,  4,  1,  0,  0,  0],\n",
       "       [ 4,  0,  0,  4,  1,  1,  0,  2,  0,  0,  0],\n",
       "       [ 3,  0,  0,  2,  0,  2,  0,  0,  3,  0,  1],\n",
       "       [ 3,  0,  0,  3,  0,  1,  0,  0,  1,  4,  1],\n",
       "       [ 5,  0,  0,  2,  0,  0,  0,  0,  0,  0,  5]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = neigh.predict(X_s_mat)\n",
    "confusion_matrix(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                A-Find       0.16      0.50      0.24        10\n",
      "                   CLI       1.00      0.50      0.67         2\n",
      "                  Data       0.62      0.33      0.43        15\n",
      "           Development       0.52      0.81      0.63        32\n",
      "             Graphical       0.50      0.67      0.57         3\n",
      "            Networking       0.33      0.29      0.31         7\n",
      "                Parser       0.40      0.33      0.36        12\n",
      "Scientific/Engineering       0.67      0.17      0.27        12\n",
      "                Server       0.75      0.27      0.40        11\n",
      "               Testing       1.00      0.31      0.47        13\n",
      "                   Web       0.62      0.42      0.50        12\n",
      "\n",
      "              accuracy                           0.46       129\n",
      "             macro avg       0.60      0.42      0.44       129\n",
      "          weighted avg       0.58      0.46      0.45       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}