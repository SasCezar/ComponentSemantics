b'# Toward Convolutional Blind Denoising of Real Photographs\n\n### Paper versions\n[**CVPR 2019 version**](http://www4.comp.polyu.edu.hk/~cslzhang/paper/CVPR19-CBDNet.pdf)\n\n[**CVPR 2019 supp**](http://www4.comp.polyu.edu.hk/~cslzhang/paper/CVPR19-CBDNet-supp.pdf)\n\n### Python implement of ISP/inverse ISP operators and some materials\n[**Python Code, includimng ISP operators implement, real-world sRGB/RAW noisy image generation and noise map generation**](https://github.com/GuoShi28/CBDNet/blob/master/SomeISP_operator_python/ISP_implement.py)(Not totally the same with Matlab Code)\n\n[**Introduction and examples of the formal code**](https://github.com/GuoShi28/CBDNet/blob/master/SomeISP_operator_python/isp_implement.md)\n\n[**Some simple materials of ISP**](https://github.com/GuoShi28/CBDNet/blob/master/Other_material/some_introduction_material_of_ISP.md)\n\n## 1. Abstract\nDespite their success in Gaussian denoising, deep convolutional neural networks (CNNs) are still very limited on real noisy photographs, and may even perform worse than BM3D. In order to improve the robustness and practicability of deep denoising models, this paper presents a convolutional blind denoising network (CBDNet) by incorporating network architecture, asymmetric learning and noise modeling. Our CBDNet is comprised of a noise estimation subnetwork and a denoising subnetwork. Motivated by the asymmetric sensitivity of BM3D to noise estimation error, the asymmetric learning is presented on the noise estimation subnetwork to suppress more on under-estimation of noise\nlevel. To make the learned model applicable to real photographs, both synthetic images based on signal dependent noise model and real photographs with ground-truth images are incorporated to train our CBDNet. The results on two datasets of real noisy photographs clearly demonstrate the superiority of our CBDNet over the state-of-the-art denoisers in terms of quantitative metrics and perceptual quaility. The data, code and model will be publicly available.\n\n## 2. Network Structure\n\n![Image of Network](figs/CBDNet_v13.png)\n\n## 3. Realistic Noise Model\nGiven a clean image `x`, the realistic noise model can be represented as:\n\n![](http://latex.codecogs.com/gif.latex?\\\\textbf{y}=f(\\\\textbf{DM}(\\\\textbf{L}+n(\\\\textbf{L}))))\n\n![](http://latex.codecogs.com/gif.latex?n(\\\\textbf{L})=n_s(\\\\textbf{L})+n_c)\n\nWhere `y` is the noisy image, `f(.)` is the CRF function and the irradiance ![](http://latex.codecogs.com/gif.latex?\\\\textbf{L}=\\\\textbf{M}f^{-1}(\\\\textbf{x})) , `M(.)` represents the function that convert sRGB image to Bayer image and `DM(.)` represents the demosaicing function.\n\nIf considering denosing on compressed images, \n\n![](http://latex.codecogs.com/gif.latex?\\\\textbf{y}=JPEG(f(\\\\textbf{DM}(\\\\textbf{L}+n(\\\\textbf{L})))))\n\n## 4. Testing\n* "Test_Patches.m" is the testing code for small images or image patches. If the tesing image is too large (e.g., 5760*3840), we recommend to use "Test_fullImage.m"\n*  "Test_fullImage.m" is the testing code for large images. \n*  "Test_Realistic_Noise_Model.m" is the testing code for the realistic noise mode in our paper. And it\'s very convinent to utilize [AddNoiseMosai.m](https://github.com/GuoShi28/CBDNet/blob/master/utils/AddNoiseMosai.m) to train your own denoising model for real photographs.\n\n## 5. CBDNet Models\n* "CBDNet.mat" is the testing model for DND dataset and NC12 dataset for not considering the JPEG compression.\n*  "CBDNet_JPEG.mat" is the testing model for Nam dataset and other noisy images with JPEG format.\n\n## 6. Implement Perceptual Loss Using MatConvnet\nThe perceptual loss is the MSE loss between the [Perceptual Layer](https://github.com/GuoShi28/CBDNet/tree/master/utils/Perceptual_Layer) outputs of results and labels.\nThe pretrained vgg model, [fast-rcnn-vgg16-pascal07-dagnn](http://www.vlfeat.org/matconvnet/pretrained/) is needed. \n\n## 7. Real Images Denoising Results\n### 7.1 DND dataset\nFollowing the guided of [DND Online submission system](https://noise.visinf.tu-darmstadt.de/).\n\n![Image of DND](figs/DND_results.png)\n\n### 7.2 Nam dataset\n\n![Image of Nam](figs/Nam_results.png)\n\n## 8. Requirements and Dependencies\n* Matlab 2015b\n* Cuda-8.0 & cuDNN v-5.1\n* [MatConvNet](http://www.vlfeat.org/matconvnet/).\n\n## 9. Citation\n\n```\n@article{Guo2019Cbdnet,\n  title={Toward convolutional blind denoising of real photographs},\n  author={Guo, Shi and Yan, Zifei and Zhang, Kai and Zuo, Wangmeng and Zhang, Lei},\n  journal={2019 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n  year={2019}\n}\n```\n\n------------------------------------------------------------------------------------------------------------------------------\n\n### Q&A: Why CBDNet can not process some high-noisy photos captured by my own?\n\nA: The main reason is the JPEG compression. For uncompression images even with really high noise under low light condition, CBDNet can remove noise very effectively. Even though we consider JPEG compression on CBDNet, our CBDNet(JPEG) model can only handle jpeg images with normal noise level, e.g., Nam or JPEG compression quality is high.   \n\nI capture some high-noisy images using DLSR camera. Images are stored in both *uncompressed* and *JPEG* format. The denoising results are shown below. \n![](figs/results.png)\n'