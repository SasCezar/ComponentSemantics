b"[![Build Status](https://travis-ci.com/petercorke/machinevision-toolbox-matlab.svg?branch=master)](https://travis-ci.com/petercorke/robotics-toolbox-matlab)\n![Coverage](https://codecov.io/gh/petercorke/machinevision-toolbox-matlab/branch/master/graph/badge.svg)\n[![License: LGPL v3](https://img.shields.io/badge/License-LGPL%20v3-blue.svg)](https://www.gnu.org/licenses/lgpl-3.0)\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/petercorke/machine-toolbox-matlab/graphs/commit-activity)\n[![GitHub stars](https://img.shields.io/github/stars/petercorke/machinevision-toolbox-matlab.svg?style=social&label=Star&maxAge=2592000)](https://GitHub.com/petercorke/machinevision-toolbox-matlab/stargazers/)\n\n## Synopsis\n\nMachine Vision Toolbox for MATLAB&reg; release 4.\n\nThe Machine Vision Toolbox (MVTB) provides many functions that are useful in machine vision and vision-based control.  It is a somewhat eclectic collection reflecting my personal interest in areas of photometry, photogrammetry, colorimetry.  It includes over 100 functions spanning operations such as image file reading and writing, acquisition, display, filtering, blob, point and line feature extraction,  mathematical morphology, homographies, visual Jacobians, camera calibration and color space conversion. With input from a web camera and output to a robot (not provided) it would be possible to implement a visual servo system entirely in MATLAB.\n\nAn image is usually treated as a rectangular array of scalar values representing intensity or perhaps range.  The matrix is the natural datatype for MATLAB and thus makes the manipulation of images easily expressible in terms of arithmetic statements in MATLAB language.  Many image operations such as thresholding, filtering and statistics can be achieved with existing MATLAB functions.\n\nAdvantages of the Toolbox are that:\n\n  * the code is mature and provides a point of comparison for other implementations of the same algorithms;\n  * the routines are generally written in a straightforward manner which allows for easy understanding, perhaps at the expense of computational efficiency. If you feel strongly about computational efficiency then you can always rewrite the function to be more efficient, compile the M-file using the MATLAB compiler, or create a MEX version;\n  * since source code is available there is a benefit for understanding and teaching.\n\n## Code Examples\n\n### Binary blobs\n\n```matlab\n>> im = iread('shark2.png');   % read a binary image of two sharks\n>> idisp(im);   % display it with interactive viewing tool\n>> f = iblobs(im, 'class', 1)  % find all the white blobs\nf =\n(1) area=7827, cent=(172.3,156.1), theta=-0.21, b/a=0.585, color=1, label=2, touch=0, parent=1\n(2) area=7827, cent=(372.3,356.1), theta=-0.21, b/a=0.585, color=1, label=3, touch=0, parent=1\n>> f.plot_box('g')  % put a green bounding box on each blob\n>> f.plot_centroid('o');  % put a circle+cross on the centroid of each blob\n>> f.plot_centroid('x');\n```\n![Binary image showing bounding boxes and centroids](doc/misc/shark2+boxes.png)\n\n### Binary blob hierarchy\n\nWe can load a binary image with nested objects\n\n```matlab\n>> im = iread('multiblobs.png');\n>> idisp(im)\n```\n![Binary image showing bounding boxes and centroids](doc/figs/multi.png)\n\nand request the blob label image which we then display\n\n```matlab\n>> [label, m] = ilabel(im);\n>> idisp(label, 'colormap', jet, 'bar')\n```\n![Binary image showing bounding boxes and centroids](doc/figs/multi_labelled.png)\n\n### Camera modelling\n\n```matlab\n>> cam = CentralCamera('focal', 0.015, 'pixel', 10e-6, ...\n    'resolution', [1280 1024], 'centre', [640 512], 'name', 'mycamera')\ncam = \nname: mycamera [central-perspective]                    \n  focal length:   0.015                                 \n  pixel size:     (1e-05, 1e-05)                        \n  principal pt:   (640, 512)                            \n  number pixels:  1280 x 1024                           \n  pose:           t = (0, 0, 0), RPY/yxz = (0, 0, 0) deg\n```\nand its intrinsic parameters are\n\n```matlab \n>> cam.K\nans =\n   1.0e+03 *\n\n    1.5000         0    0.6400\n         0    1.5000    0.5120\n         0         0    0.0010\n```\nWe can define an arbitrary point in the world\n\n```matlab \n>> P = [0.3, 0.4, 3.0]';\n```\nand then project it into the camera\n\n```matlab\n>> cam.project(P)\nans =\n   790\n   712\n```\nwhich is the corresponding coordinate in pixels.  If we shift the camera slightly the image plane coordiante will also change\n\n```matlab \n>> cam.project(P, 'pose', SE3(0.1, 0, 0) )\nans =\n   740\n   712\n```\n\nWe can define an edge-based cube model and project it into the camera's image plane\n\n```matlab \n>> [X,Y,Z] = mkcube(0.2, 'pose', SE3(0, 0, 1), 'edge');\n>> cam.mesh(X, Y, Z);\n```\n![Perspective camera view](doc/figs/cube.png)\n\nor with a fisheye camera\n\n```matlab\n>> cam = FishEyeCamera('name', 'fisheye', ...\n'projection', 'equiangular', ...\n'pixel', 10e-6, ...\n'resolution', [1280 1024]);\n>> [X,Y,Z] = mkcube(0.2, 'centre', [0.2, 0, 0.3], 'edge');\n>> cam.mesh(X, Y, Z);\n```\n![Fisheye lens camera view](doc/figs/cube_fisheye.png)\n\n\n### Bundle adjustment\n\n### Color space\nPlot the CIE chromaticity space\n\n```matlab\nshowcolorspace('xy')\nlambda = [460:10:540 560:20:600];\n[x,y]=lambda2xy(lambda*1e-9);\nhold on\nplot_point([x y]', 'printf', {' %d', lambda}, 'ko', 'MarkerFaceColor', 'k', 'MarkerSize', 6)\n```\n![CIE chromaticity space](doc/figs/colorspace.png)\n\nLoad the spectrum of sunlight at the Earth's surface and compute the CIE xy chromaticity coordinates\n\n```matlab\nlambda = [400:5:700] * 1e-9; % visible light\nsun_at_ground = loadspectrum(lambda, 'solar');\n>> lambda2xy(lambda, sun_at_ground)\nans =\n    0.3327    0.3454\n>> colorname(ans, 'xy')\nloading rgb.txt\nans =\n    'antiquewhite4'\n```\n\n### Hough transform\n\n```matlab\nim = iread('church.png', 'grey', 'double');\nedges = icanny(im);\nh = Hough(edges, 'suppress', 10);\nlines = h.lines();\n\nidisp(im, 'dark');\nlines(1:10).plot('g');\n\nlines = lines.seglength(edges);\n\nlines(1)\n\nk = find( lines.length > 80);\n\nlines(k).plot('b--')\n```\n![Hough transform](doc/figs/hough.png)\n\n### SURF features\n\nWe load two images and compute a set of SURF features for each\n\n```matlab\n>> im1 = iread('eiffel2-1.jpg', 'mono', 'double');\n>> im2 = iread('eiffel2-2.jpg', 'mono', 'double');\n>> sf1 = isurf(im1);\n>> sf2 = isurf(im2);\n```\nWe can match features between images based purely on the similarity of the features, and display the correspondences found\n\n```matlab\n>> m = sf1.match(sf2)\nm = \n644 corresponding points (listing suppressed)\n>> m(1:5)\nans = \n \n(819.56, 358.557) <-> (708.008, 563.342), dist=0.002137\n(1028.3, 231.748) <-> (880.14, 461.094), dist=0.004057 \n(1027.6, 571.118) <-> (885.147, 742.088), dist=0.004297\n(927.724, 509.93) <-> (800.833, 692.564), dist=0.004371\n(854.35, 401.633) <-> (737.504, 602.187), dist=0.004417\n>> idisp({im1, im2})\n>> m.subset(100).plot('w')\n```\n![Feature matching](doc/figs/matching.png)\n\nClearly there are some bad matches here, but we we can use RANSAC and the epipolar constraint implied by the fundamental matrix to estimate the fundamental matrix and classify correspondences as inliers or outliers\n\n```matlab\n>> F = m.ransac(@fmatrix, 1e-4, 'verbose')\n617 trials\n295 outliers\n0.000145171 final residual\nF =\n    0.0000   -0.0000    0.0087\n    0.0000    0.0000   -0.0135\n   -0.0106    0.0116    3.3601\n>> m.inlier.subset(100).plot('g')\n>> hold on\n>> m.outlier.subset(100).plot('r')\n>> hold off\n```\nwhere green lines show correct correspondences (inliers) and red lines show bad correspondences (outliers) \n![Feature matching after RANSAC](doc/figs/matching_ransac.png)\n\n### Fundamental matrix\n\n## What's new\n\n* Travis CI is now running on the code base\n* All code related to pose representation has been split out into the [Spatial Math Toolbox](https://github.com/petercorke/spatial-math). This repo is now a dependency.\n\n## Installation\n\n### Install from shared MATLAB Drive folder\n\nThis will work for MATLAB Online or MATLAB Desktop provided you have [MATLAB drive](https://www.mathworks.com/products/matlab-drive.html) setup.\n\n1. Click on the appropriate link below and an invitation to share will be emailed to the address associated with your MATLAB account:\n\n  * [RVC 2nd edition RTB10+MVTB4 (2017)](https://drive.matlab.com/sharing/e5e3ffef-f3d4-4f70-88a4-1ea0db0efb1a)\n  * [RVC 1st edition: RTB9+MVTB3 (2011)](https://drive.matlab.com/sharing/0442fc1b-5b9e-45c8-abf9-54cbbd00082a)\n  \n2. Accept the invitation.\n3. A folder named RVC1  or RVC2 will appear in your MATLAB drive folder.\n4. Use the MATLAB file browser and navigate to the folder RVCx/rvctools and double-click the script named startup_rvc.m\n\nNote that this is a combo-installation that includes the Robotics Toolbox (RTB) as well.\n\n### Install from github\n\nYou need to have a recent version of MATLAB, R2016b or later.\n\nThe Machine Vision Toolbox for MATLAB has dependency on two other GitHub repositories: [`spatial-math`](https://github.com/petercorke/spatial-math) and [`toolbox-common-matlab`](https://github.com/petercorke/toolbox-common-matlab).  \n\nTo install the Toolbox on your computer from github follow these simple instructions.\n\nFrom the shell:\n\n```shell\nmkdir rvctools\ncd rvctools\ngit clone https://github.com/petercorke/machinevision-toolbox-matlab.git vision\ngit clone https://github.com/petercorke/spatial-math.git smtb\ngit clone https://github.com/petercorke/toolbox-common-matlab.git common\nmake -C vision\n```\nThe last command builds the MEX files. Then, from within MATLAB\n\n```matlab\n>> addpath rvctools/common  %  rvctools is the same folder as above\n>> startup_rvc\n```\nThe second line sets up the MATLAB path appropriately but it's only for the current session.  You can either:\n1. Repeat this everytime you start MATLAB\n2. Add the MATLAB commands above to your `startup.m` file\n3. Once you have run startup_rvc, run `pathtool` and push the `Save` button, this will save the path settings for subsequent sessions.\n\n## Downloading the example images\n\nThe Robotics, Vision & Control book (2nd edition) uses a number of example images and image sequences.  These are bulky and not really appropriate to keep on Github but you can download them.\nThere are two zip archives:\n\n| Archive        | Size | Contents |\n| -------------- | ----:| -------- |\nimages-RVC2a.zip | 74M  | All images, seq/\\*, mosaic/\\*, campus/\\* |\nimages-RVC2a.zip | 255M | Chapter 14: bridge-l/\\*, bridge-r/\\* |\n\nEach will expand into the `./images` folder which is the default location that MVTB searches for images and sequences.\n\nTo download the main (and smaller) archive\n```shell\ncd rvctools/vision\nwget petercorke.com/files/MVTB/images-RVC2a.zip\nunzip images-RVC2a\n```\n\nTo download the second (and larger) archive\n```shell\ncd rvctools/vision\nwget petercorke.com/files/MVTB/images-RVC2b.zip\nunzip images-RVC2b\n```\n\n## Download the contributed code\n\nSome MVTB functions are wrappers of third-party open-source software.  Working versions, some patched, can be downloaded below.  If you are not using MacOS you will need to rebuild the code.\n\n| Archive        | Size | Contents |\n| -------------- | ----:| -------- |\ncontrib.zip | 16M  | vl_feat, graphseg, EPnP, camera calibration |\ncontrib2.zip | 5M | SIFT, SURF |\n\nThe packages, and their home pages are\n\n| Tool        | Author |  MVTB function | \n| -------------- | -------- | -------- |\n[OpenSurf]() | | `isurf` |\n[SIFT]() | | `isift` |\n[vl_feat](http://www.vlfeat.org) | A. Vedaldi and B. Fulkerson| `imser`, `isift`, `BagOfWords`|\n[graphseg](http://cs.brown.edu/people/pfelzens/segment/) | P. Felzenszwalb, D. Huttenlocher | `igraphseg` |\n[Efficient perspective-n-point camera pose estimation (EPnP)](https://cvlab.epfl.ch/software/multi-view-stereo/epnp/) | V. Lepetit, F. Moreno-Noguer, P. Fua | `CentralCamera.estpose` |\n[Camera Calibration Toolbox for MATLAB](http://www.vision.caltech.edu/bouguetj/calib_doc) | Jean-Yves Bouget | `calib_gui` |\n\n## Online resources:\n\n* [Home page](http://www.petercorke.com)\n* [Discussion group](http://groups.google.com/group/robotics-tool-box?hl=en)\n\nPlease email bug reports, comments or code contribtions to me at rvc@petercorke.com\n  \n\n## Contributors\n\nContributions welcome.  There's a user forum at http://tiny.cc/rvcforum\n\n## License\n\nThis toolbox is released under GNU LGPL.\n"