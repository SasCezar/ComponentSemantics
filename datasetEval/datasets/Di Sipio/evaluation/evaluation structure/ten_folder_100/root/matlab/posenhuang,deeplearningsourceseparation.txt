b'# Deep Learning For Monaural Source Separation\n\n## Demo\nWebpage: https://sites.google.com/site/deeplearningsourceseparation/\n\n\n## Experiments\n### MIR-1K experiment (singing voice separation)\n\n1. Training code: ```codes/mir1k/train_mir1k_demo.m```\n \n2. Demo\n - Download a trained model ```http://www.ifp.illinois.edu/~huang146/DNN_separation/model_400.mat```\n - Put the model at ```codes/mir1k/demo``` and go to the folder\n - Run: ```codes/mir1k/demo/run_test_single_model.m```\n\n\n### TIMIT experiment (speech separation)\n1. Training code: ```codes/timit/train_timit_demo.m``` and ```codes/timit/train_timit_demo_mini_clip.m```\n\n2. Demo \n - Download a trained model ```http://www.ifp.illinois.edu/~huang146/DNN_separation/timit_model_70.mat```\n - Put the model at ```codes/timit/demo``` and go to the folder\n - Run: ```codes/timit/demo/run_test_single_model.m```\n\n\n### TSP experiment (speech separation)\n\n1. Training code: ```codes/TSP/train_TSP_demo_mini_clip.m```\n\n2. Demo\n - Download a trained model ```http://www.ifp.illinois.edu/~huang146/DNN_separation/TSP_model_RNN1_win1_h300_l2_r0_64ms_1000000_softabs_linearout_RELU_logmel_trn0_c1e-10_c0.001_bsz100000_miter10_bf50_c0_d0_7650.mat```\n - Put the model at ```codes/TSP/demo``` and go to the folder\n - Run the demo code at ```codes/TSP/demo/run_test_single_model.m```\n\n### Denosing experiment\n1. Put original ```FCJF0, FDAW0\', FDML0, FECD0, \'FETB0\', \'FJSP0\', \'FKFB0\', \'FMEM0\', \'FSAH0\', \'FSJK1\', \'FSMA0\', \'FTBR0\', \'FVFB0\' \'FVMH0``` of the original TIMIT data under ```codes/denoising/Data/timit/```\n\n2. Training code: ```codes/denoising/train_denoising_demo.m```\n\n3. Demo\n - Download a trained model ```http://www.ifp.illinois.edu/~huang146/DNN_separation/denoising_model_870.mat```\n - Put the model at ```codes/denoising/demo``` and go to the folder\n - Run the demo code at ```codes/denoising/demo/run_test_single_model.m```\n\n\n## Dependencies\n1. The package is modified based on [rnn-speech-denoising](https://github.com/amaas/rnn-speech-denoising)\n\n2. The software depends on Mark Schmidt\'s [minFunc](http://www.di.ens.fr/~mschmidt/Software/minFunc.html) package for convex optimization.\n\n3. Additionally, we have included Mark Hasegawa-Johnson\'s [HTK write and read functions](http://www.isle.illinois.edu/sst/software)\nthat are used to handle the MFCC files.\n\n4. We use [HTK](http://htk.eng.cam.ac.uk) for computing features (MFCC, logmel) (HCopy).\n\n5. We use signal processing functions from [labrosa](http://labrosa.ee.columbia.edu/).\n\n6. We use [BSS Eval](http://bass-db.gforge.inria.fr/bss_eval/) toolbox Version 2.0, 3.0 for evaluation.\n\n7. We use [MIR-1K](https://sites.google.com/site/unvoicedsoundseparation/mir-1k) for singing voice separation task.\n\n8. We use [TSP](http://www-mmsp.ece.mcgill.ca/Documents/Data/) for speech separation task.\n\n\n## Work on your data:\n1. To try the codes on your data, see mir1k, TSP settings - put your data into ```codes/mir1k/Wavfile``` or ```codes/TSP/Data/``` accordingly.\n \n2. Look at the unit test parameters below ```codes/mir1k/train_mir1k_demo.m```, ```codes/TSP/train_TSP_demo_mini_clip.m``` (with minibatch lbfgs, gradient clipping)\n\n3. Tune the parameters on the dev set and check the results.\n \n## Reference\n1. P.-S. Huang, M. Kim, M. Hasegawa-Johnson, P. Smaragdis, "[Joint Optimization of Masks and Deep Recurrent Neural Networks for Monaural Source Separation](http://posenhuang.github.io/papers/Joint_Optimization_of_Masks_and_Deep%20Recurrent_Neural_Networks_for_Monaural_Source_Separation_TASLP2015.pdf)", IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 23, no. 12, pp. 2136\xe2\x80\x932147, Dec. 2015\n\n2. P.-S. Huang, M. Kim, M. Hasegawa-Johnson, P. Smaragdis, "[Singing-Voice Separation From Monaural Recordings Using Deep Recurrent Neural Networks](http://posenhuang.github.io/papers/DRNN_ISMIR2014.pdf)," in International Society for Music Information Retrieval Conference (ISMIR) 2014.\n\n3. P.-S. Huang, M. Kim, M. Hasegawa-Johnson, P. Smaragdis, "[Deep Learning for Monaural Speech Separation](http://posenhuang.github.io/papers/DNN_Separation_ICASSP2014.pdf)," in IEEE International Conference on Acoustic, Speech and Signal Processing 2014.\n\n### Notes \nThe codes are tested using MATLAB R2015a\n\n## Related Implementations\n[source_separaton_ml_jeju](https://andabi.github.io/music-source-separation/)\n'