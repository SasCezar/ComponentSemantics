b"# panorama  \n![img](https://github.com/yihui-he/panorama/blob/master/results/intersection.jpg)  \n![img](https://github.com/yihui-he/panorama/blob/master/results/GrandCanyon2.jpg)  \n![img](https://github.com/yihui-he/panorama/blob/master/results/redrock.jpg)  \n### features  \n- able to handle 360 panorama.\n- Random sequence of images input is welcomed.\n- use color blending and smoothing to make the image more continuous.  \n\n### how to run  \nPrerequisite: matlab 2014b or higher  \nimages sets are already in ./imgs  \n- If you want to see results directly, go to ./results folder\n- If you want to test all images sets with only one click,run RunAllDatasets.m.(10 image sets, about 1 minute)  \n- If you want to specify the image folder, run main.m with path to images folder as argument as follow:  \n` main('./imgs/redrock');`  \n**Note that**, this currently support image sets in `imgs` folder. If you use your own image set, you need to set focus length and other parameters in `main.m`.\n\n######details of my algorithms are shown below:  \n\n### 360 panorama\n- [x] mapping image to cylindrical coordinate  \n*warp.m*  \n\n### recognize panorama(random inputs)\nI select two random sequence images set:family\\_house, and west\\_campus1  \nThey are already shuffled. You can see them in imgs folder.  \nOr you can run shuffle.bash to shuffle them again.  \nAs described in Brown's paper, I use $N\\_inlier>k\\*N\\_pairs+b$ to compute whether a pair of images match or not  \nk,b are const. Set to 5.9 and 0.22 respectively.  \nSee [recognizing panorama](https://github.com/yihui-he/panorama/blob/master/resource/recognizing_panorama.pdf) for details  \n\n*imorder.m*  \n\n### merging and blending  \n- [x] Alpha  \n- [ ] Pyramid  \n- [x] Noblend\n\n*merge.m*  \n\n### transformation\n- [x] homography transformation.\n- [x] translation transformation.( This is more robust)\n\n*computeTrans.m*  \n\n### matching\n- [x] RANSAC\n- [ ] exposure matching  \n\n*RANSAC.m*  \n\n### global adjustment\n- [x] end to end adjustment(comput shift and subtract shift/n to each image)  \n- [ ] bundle adjustment(difficult way)  \n\n*create.m*  \n\n### getting features\n- [x] use SIFT features(using VLFeat library, professor allowed)  \n- [x] SURF features, (SIFT is better)  \n\n*getSIFTFeatures.m, getMatches.m*  \n  \n### resize  \n- [x] I resize image larger than 400 pixel in width  \n  \n*main.m*  \n  \n### References  \n[A nice tutorial](https://github.com/yihui-he/panorama/blob/master/resource/stitching%20tutorial.pdf) on panorama I find useful.  \n\n"