b'\n## \xf0\x9f\x86\x95 Are you looking for a new YOLOv3 implemented by TF2.0 ?\n\n>If you hate the fucking tensorflow1.x very much, no worries! I have implemented **a new YOLOv3 repo with TF2.0**, and also made a chinese blog on how to implement YOLOv3 object detector from scratch. <br>\n[code](https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3) | [blog](https://github.com/YunYang1994/cv-notebooks/blob/master/ai_algorithm/YOLOv3.md)  | [issue](https://github.com/YunYang1994/tensorflow-yolov3/issues/39)\n\n## part 1. Quick start\n1. Clone this file\n```bashrc\n$ git clone https://github.com/YunYang1994/tensorflow-yolov3.git\n```\n2.  You are supposed  to install some dependencies before getting out hands with these codes.\n```bashrc\n$ cd tensorflow-yolov3\n$ pip install -r ./docs/requirements.txt\n```\n3. Exporting loaded COCO weights as TF checkpoint(`yolov3_coco.ckpt`)\xe3\x80\x90[BaiduCloud](https://pan.baidu.com/s/11mwiUy8KotjUVQXqkGGPFQ&shfl=sharepset)\xe3\x80\x91\n```bashrc\n$ cd checkpoint\n$ wget https://github.com/YunYang1994/tensorflow-yolov3/releases/download/v1.0/yolov3_coco.tar.gz\n$ tar -xvf yolov3_coco.tar.gz\n$ cd ..\n$ python convert_weight.py\n$ python freeze_graph.py\n```\n4. Then you will get some `.pb` files in the root path.,  and run the demo script\n```bashrc\n$ python image_demo.py\n$ python video_demo.py # if use camera, set video_path = 0\n```\n<p align="center">\n    <img width="100%" src="https://user-images.githubusercontent.com/30433053/68088581-9255e700-fe9b-11e9-8672-2672ab398abe.jpg" style="max-width:100%;">\n    </a>\n</p>\n\n## part 2. Train your own dataset\nTwo files are required as follows:\n\n- [`dataset.txt`](https://raw.githubusercontent.com/YunYang1994/tensorflow-yolov3/master/data/dataset/voc_train.txt): \n\n```\nxxx/xxx.jpg 18.19,6.32,424.13,421.83,20 323.86,2.65,640.0,421.94,20 \nxxx/xxx.jpg 48,240,195,371,11 8,12,352,498,14\n# image_path x_min, y_min, x_max, y_max, class_id  x_min, y_min ,..., class_id \n# make sure that x_max < width and y_max < height\n```\n\n- [`class.names`](https://github.com/YunYang1994/tensorflow-yolov3/blob/master/data/classes/coco.names):\n\n```\nperson\nbicycle\ncar\n...\ntoothbrush\n```\n\n### 2.1 Train on VOC dataset\nDownload VOC PASCAL trainval  and test data\n```bashrc\n$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n```\nExtract all of these tars into one directory and rename them, which should have the following basic structure.\n\n```bashrc\n\nVOC           # path:  /home/yang/dataset/VOC\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 test\n|    \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80VOCdevkit\n|        \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80VOC2007 (from VOCtest_06-Nov-2007.tar)\n\xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 train\n     \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80VOCdevkit\n         \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80VOC2007 (from VOCtrainval_06-Nov-2007.tar)\n         \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80VOC2012 (from VOCtrainval_11-May-2012.tar)\n                     \n$ python scripts/voc_annotation.py --data_path /home/yang/test/VOC\n```\nThen edit your `./core/config.py` to make some necessary configurations\n\n```bashrc\n__C.YOLO.CLASSES                = "./data/classes/voc.names"\n__C.TRAIN.ANNOT_PATH            = "./data/dataset/voc_train.txt"\n__C.TEST.ANNOT_PATH             = "./data/dataset/voc_test.txt"\n```\nHere are two kinds of training method: \n\n##### (1) train from scratch:\n\n```bashrc\n$ python train.py\n$ tensorboard --logdir ./data\n```\n##### (2) train from COCO weights(recommend):\n\n```bashrc\n$ cd checkpoint\n$ wget https://github.com/YunYang1994/tensorflow-yolov3/releases/download/v1.0/yolov3_coco.tar.gz\n$ tar -xvf yolov3_coco.tar.gz\n$ cd ..\n$ python convert_weight.py --train_from_coco\n$ python train.py\n```\n### 2.2 Evaluate on VOC dataset\n\n```\n$ python evaluate.py\n$ cd mAP\n$ python main.py -na\n```\n\nthe mAP on the VOC2012 dataset:\n\n<p align="center">\n    <img width="50%" src="https://user-images.githubusercontent.com/33013904/58227054-dd4fc800-7d5b-11e9-85aa-67854292fbe0.png" style="max-width:50%;">\n    </a>\n</p>\n\n\n## part 3. Stargazers over time\n\n[![Stargazers over time](https://starcharts.herokuapp.com/YunYang1994/tensorflow-yolov3.svg)](https://starcharts.herokuapp.com/YunYang1994/tensorflow-yolov3)\n\n## part 4. Other Implementations\n\n[-**`YOLOv3\xe7\x9b\xae\xe6\xa0\x87\xe6\xa3\x80\xe6\xb5\x8b\xe6\x9c\x89\xe4\xba\x86TensorFlow\xe5\xae\x9e\xe7\x8e\xb0\xef\xbc\x8c\xe5\x8f\xaf\xe7\x94\xa8\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe6\x9d\xa5\xe8\xae\xad\xe7\xbb\x83`**](https://mp.weixin.qq.com/s/cq7g1-4oFTftLbmKcpi_aQ)<br>\n\n[-**`Stronger-yolo`**](https://github.com/Stinky-Tofu/Stronger-yolo)<br>\n\n[- **`Implementing YOLO v3 in Tensorflow (TF-Slim)`**](https://itnext.io/implementing-yolo-v3-in-tensorflow-tf-slim-c3c55ff59dbe)\n\n[- **`YOLOv3_TensorFlow`**](https://github.com/wizyoung/YOLOv3_TensorFlow)\n\n[- **`Object Detection using YOLOv2 on Pascal VOC2012`**](https://fairyonice.github.io/Part_1_Object_Detection_with_Yolo_for_VOC_2014_data_anchor_box_clustering.html)\n\n[-**`Understanding YOLO`**](https://hackernoon.com/understanding-yolo-f5a74bbc7967)\n\n'