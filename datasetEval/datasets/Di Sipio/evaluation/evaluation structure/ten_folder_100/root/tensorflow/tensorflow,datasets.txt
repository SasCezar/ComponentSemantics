b'# TensorFlow Datasets\n\nTensorFlow Datasets provides many public datasets as `tf.data.Datasets`.\n\n[![Kokoro](https://storage.googleapis.com/tfds-kokoro-public/kokoro-build.svg)](https://storage.googleapis.com/tfds-kokoro-public/kokoro-build.html)\n[![PyPI version](https://badge.fury.io/py/tensorflow-datasets.svg)](https://badge.fury.io/py/tensorflow-datasets)\n\n* [List of datasets](https://www.tensorflow.org/datasets/catalog/overview)\n* [Try it in Colab](https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/overview.ipynb)\n* [API docs](https://www.tensorflow.org/datasets/api_docs/python/tfds)\n* Guides\n  * [Overview](https://www.tensorflow.org/datasets/overview)\n  * [Datasets versioning](https://www.tensorflow.org/datasets/datasets_versioning)\n  * [Using splits and slicing API](https://www.tensorflow.org/datasets/splits)\n  * [Add a dataset](https://www.tensorflow.org/datasets/add_dataset)\n  * [Add a huge dataset (>>100GiB)](https://www.tensorflow.org/datasets/beam_datasets)\n\n\n**Table of Contents**\n\n* [Installation](#installation)\n* [Usage](#usage)\n* [`DatasetBuilder`](#datasetbuilder)\n* [NumPy usage](#numpy-usage-with-tfdsas-numpy)\n* [Want a certain dataset?](#want-a-certain-dataset)\n* [Disclaimers](#disclaimers)\n\n### Installation\n\n```sh\npip install tensorflow-datasets\n\n# Requires TF 1.15+ to be installed.\n# Some datasets require additional libraries; see setup.py extras_require\npip install tensorflow\n# or:\npip install tensorflow-gpu\n```\n\nJoin [our Google group](https://groups.google.com/forum/#!forum/tensorflow-datasets-public-announce)\nto receive updates on the project.\n\n### Usage\n\n```python\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\n# tfds works in both Eager and Graph modes\ntf.compat.v1.enable_eager_execution()\n\n# See available datasets\nprint(tfds.list_builders())\n\n# Construct a tf.data.Dataset\nds_train = tfds.load(name="mnist", split="train", shuffle_files=True)\n\n# Build your input pipeline\nds_train = ds_train.shuffle(1000).batch(128).prefetch(10)\nfor features in ds_train.take(1):\n  image, label = features["image"], features["label"]\n```\n\nTry it interactively in a\n[Colab notebook](https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/overview.ipynb).\n\n### `DatasetBuilder`\n\nAll datasets are implemented as subclasses of\n[`DatasetBuilder`](https://www.tensorflow.org/datasets/api_docs/python/tfds/core/DatasetBuilder.md)\nand\n[`tfds.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load.md)\nis a thin convenience wrapper.\n[`DatasetInfo`](https://www.tensorflow.org/datasets/api_docs/python/tfds/core/DatasetInfo.md)\ndocuments the dataset.\n\n```python\nimport tensorflow_datasets as tfds\n\n# The following is the equivalent of the `load` call above.\n\n# You can fetch the DatasetBuilder class by string\nmnist_builder = tfds.builder(\'mnist\')\n\n# Download the dataset\nmnist_builder.download_and_prepare()\n\n# Construct a tf.data.Dataset\nds = mnist_builder.as_dataset(split=\'train\')\n\n# Get the `DatasetInfo` object, which contains useful information about the\n# dataset and its features\ninfo = mnist_builder.info\nprint(info)\n\n    tfds.core.DatasetInfo(\n        name=\'mnist\',\n        version=1.0.0,\n        description=\'The MNIST database of handwritten digits.\',\n        homepage=\'http://yann.lecun.com/exdb/mnist/\',\n        features=FeaturesDict({\n            \'image\': Image(shape=(28, 28, 1), dtype=tf.uint8),\n            \'label\': ClassLabel(shape=(), dtype=tf.int64, num_classes=10)\n        },\n        total_num_examples=70000,\n        splits={\n            \'test\': <tfds.core.SplitInfo num_examples=10000>,\n            \'train\': <tfds.core.SplitInfo num_examples=60000>\n        },\n        supervised_keys=(\'image\', \'label\'),\n        citation=\'"""\n            @article{lecun2010mnist,\n              title={MNIST handwritten digit database},\n              author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n              journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},\n              volume={2},\n              year={2010}\n            }\n      """\',\n  )\n```\n\nYou can also get details about the classes (number of classes and their names).\n\n```python\ninfo = tfds.builder(\'cats_vs_dogs\').info\n\ninfo.features[\'label\'].num_classes  # 2\ninfo.features[\'label\'].names  # [\'cat\', \'dog\']\ninfo.features[\'label\'].int2str(1)  # "dog"\ninfo.features[\'label\'].str2int(\'cat\')  # 0\n```\n\n### NumPy Usage with `tfds.as_numpy`\n\nAs a convenience for users that want simple NumPy arrays in their programs, you\ncan use\n[`tfds.as_numpy`](https://www.tensorflow.org/datasets/api_docs/python/tfds/as_numpy.md)\nto return a generator that yields NumPy array\nrecords out of a `tf.data.Dataset`. This allows you to build high-performance\ninput pipelines with `tf.data` but use whatever you\'d like for your model\ncomponents.\n\n```python\ntrain_ds = tfds.load("mnist", split=tfds.Split.TRAIN)\ntrain_ds = train_ds.shuffle(1024).batch(128).repeat(5).prefetch(10)\nfor example in tfds.as_numpy(train_ds):\n  numpy_images, numpy_labels = example["image"], example["label"]\n```\n\nYou can also use `tfds.as_numpy` in conjunction with `batch_size=-1` to\nget the full dataset in NumPy arrays from the returned `tf.Tensor` object:\n\n```python\ntrain_ds = tfds.load("mnist", split=tfds.Split.TRAIN, batch_size=-1)\nnumpy_ds = tfds.as_numpy(train_ds)\nnumpy_images, numpy_labels = numpy_ds["image"], numpy_ds["label"]\n```\n\nNote that the library still requires `tensorflow` as an internal dependency.\n\n## Want a certain dataset?\n\nAdding a dataset is really straightforward by following\n[our guide](https://github.com/tensorflow/datasets/tree/master/docs/add_dataset.md).\n\nRequest a dataset by opening a\n[Dataset request GitHub issue](https://github.com/tensorflow/datasets/issues/new?assignees=&labels=dataset+request&template=dataset-request.md&title=%5Bdata+request%5D+%3Cdataset+name%3E).\n\nAnd vote on the current\n[set of requests](https://github.com/tensorflow/datasets/labels/dataset%20request)\nby adding a thumbs-up reaction to the issue.\n\n#### *Disclaimers*\n\n*This is a utility library that downloads and prepares public datasets. We do*\n*not host or distribute these datasets, vouch for their quality or fairness, or*\n*claim that you have license to use the dataset. It is your responsibility to*\n*determine whether you have permission to use the dataset under the dataset\'s*\n*license.*\n\n*If you\'re a dataset owner and wish to update any part of it (description,*\n*citation, etc.), or do not want your dataset to be included in this*\n*library, please get in touch through a GitHub issue. Thanks for your*\n*contribution to the ML community!*\n\n*If you\'re interested in learning more about responsible AI practices, including*\n*fairness, please see Google AI\'s [Responsible AI Practices](https://ai.google/education/responsible-ai-practices).*\n\n*`tensorflow/datasets` is Apache 2.0 licensed. See the `LICENSE` file.*\n'