b'<br>\n<div>\n  <a href="https://github.com/Qihoo360/XLearning">\n    <img width="400" heigth="400" src="./doc/img/logo.jpg">\n  </a>\n</div>\n  \n[![license](https://img.shields.io/badge/license-Apache2.0-blue.svg?style=flat)](./LICENSE)\n[![Release Version](https://img.shields.io/badge/release-1.4-red.svg)]()\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)]()\n\n**XLearning** is a convenient and efficient scheduling platform combined with the big data and artificial intelligence, support for a variety of machine learning, deep learning frameworks. XLearning is running on the Hadoop Yarn and has integrated deep learning frameworks such as TensorFlow, MXNet, Caffe, Theano, PyTorch, Keras, XGBoost. XLearning has the satisfactory scalability and compatibility.\n\n[**\xe4\xb8\xad\xe6\x96\x87\xe6\x96\x87\xe6\xa1\xa3**](./README_CN.md)  \n\n\n## Architecture\n![architecture](./doc/img/xlearning.png)  \nThere are three essential components in XLearning:  \n\n- **Client**: start and get the state of the application.  \n- **ApplicationMaster(AM)**: the role for the internal schedule and lifecycle manager, including the input data distribution and containers management.  \n- **Container**: the actual executor of the application to start the progress of Worker or PS(Parameter Server), monitor and report the status of the progress to AM, and save the output, especially start the TensorBoard service for TensorFlow application.  \n\n\n## Functions\n### 1 Support Multiple Deep Learning Frameworks  \nBesides the distributed mode of TensorFlow and MXNet frameworks, XLearning supports the standalone mode of all deep learning frameworks such as Caffe, Theano, PyTorch. Moreover, XLearning allows the custom versions and multi-version of frameworks flexibly.  \n\n\n### 2 Unified Data Management Based On HDFS  \nXLearning is enable to specify the input strategy for the input data `--input` by setting the `--input-strategy` parameter or `xlearning.input.strategy` configuration. XLearning support three ways to read the HDFS input data:  \n\n- **Download**: AM traverses all files under the specified HDFS path and distributes data to workers in files. Each worker download files from the remote to local.  \n- **Placeholder**: The difference with Download mode is that AM send the related HDFS file list to workers. The process in worker read the data from HDFS directly.   \n- **InputFormat**: Integrated the InputFormat function of MapReduce, XLearning allows the user to specify any of the implementation of InputFormat for the input data. AM splits the input data and assigns fragments to the different workers. Each worker passes the assigned fragments through the pipeline to the execution progress.   \n\nSimilar with the read strategy, XLearning allows to specify the output strategy for the output data `--output` by setting the `--output-strategy` parameter or `xlearning.output.strategy` configuration. There are two kinds of result output modes:  \n\n- **Upload**: After the program finished, each worker upload the local directory of the output to specified HDFS path directly. The button, "Saved Model", on the web interface allows user to upload the intermediate result to remote during the execution.  \n- **OutputFormat**: Integrated the OutputFormat function of MapReduce, XLearning allows the user to specify any of the implementation of OutputFormat for saving the result to HDFS.    \n\nMore detail see [**data management**](./doc/datamanage_cn.md)    \n\n### 3 Visualization Display  \nThe application interface can be divided into four parts:  \n\n- **All Containers**\xef\xbc\x9adisplay the container list and corresponding information, including the container host, container role, current state of container, start time, finish time, current progress.\n- **View TensorBoard**\xef\xbc\x9aIf set to start the service of TensorBoard when the type of application is TensorFlow, provide the link to enter the TensorBoard for real-time view.  \n- **Save Model**\xef\xbc\x9aIf the application has the output, user can upload the intermediate output to specified HDFS path during the execution of the application through the button of "Save Model". After the upload finished, display the list of the intermediate saved path.   \n- **Worker Metrix**\xef\xbc\x9adisplay the resource usage information metrics of each worker.   \nAs shown below:   \n\n![yarn1](./doc/img/yarn1.png) \n\n\n### 4 Compatible With The Code At Native Frameworks  \nExcept the automatic construction of the ClusterSpec at the distributed mode TensorFlow framework, the program at standalone mode TensorFlow and other deep learning frameworks can be executed at XLearning directly.  \n\n\n## Compilation & Deployment Instructions\n\n### 1 Compilation Environment Requirements \n\n- jdk >= 1.7\n- Maven >= 3.3\n\n### 2 Compilation Method \n\nRun the following command in the root directory of the source code:  \n\n`mvn package`    \n\nAfter compiling, a distribution package named `xlearning-1.1-dist.tar.gz` will be generated under `target` in the root directory.   \nUnpacking the distribution package, the following subdirectories will be generated under the root directory:\n\n- bin: scripts for application commit  \n- lib: jars for XLearning and dependencies  \n- conf: configuration files  \n- sbin: scripts for history service  \n- data: data and files for examples\n- examples: XLearning examples\n\n\n### 3 Deployment Environment Requirements  \n\n- CentOS 7.2  \n- Java >= 1.7\n- Hadoop = 2.6, 2.7, 2.8\n- [optional] Dependent environment for deep learning frameworks at the cluster nodes, such as TensorFlow, numpy, Caffe.  \n\n\n### 4 XLearning Client Deployment Guide  \nUnder the "conf" directory of the unpacking distribution package "$XLEARNING_HOME", configure the related files:  \n\n- xlearning-env.sh: set the environment variables, such as:  \n  + JAVA\\_HOME  \n  + HADOOP\\_CONF\\_DIR    \n\n- xlearning-site.xml: configure related properties. Note that the properties associated with the history service needs to be consistent with what has configured when the history service started.For more details, please see the [**Configuration**](./doc/configure.md) part\xe3\x80\x82  \n  \n- log4j.properties\xef\xbc\x9aconfigure the log level  \n\n\n### 5 Start Method of XLearning History Service [Optional]     \n\n- run `$XLEARNING_HOME/sbin/start-history-server.sh`.  \n\n\n## Quick Start\n\nUse `$XLEARNING_HOME/bin/xl-submit` to submit the application to cluster in the XLearning client.   \nHere are the submit example for the TensorFlow application.\n### 1 upload data to hdfs  \nupload the "data" directory under the root of unpacking distribution package to HDFS  \n\n    cd $XLEARNING_HOME  \n    hadoop fs -put data /tmp/ \n    \n### 2 submit\n    cd $XLEARNING_HOME/examples/tensorflow\n    $XLEARNING_HOME/bin/xl-submit \\\n       --app-type "tensorflow" \\\n       --app-name "tf-demo" \\\n       --input /tmp/data/tensorflow#data \\\n       --output /tmp/tensorflow_model#model \\\n       --files demo.py,dataDeal.py \\\n       --launch-cmd "python demo.py --data_path=./data --save_path=./model --log_dir=./eventLog --training_epochs=10" \\\n       --worker-memory 10G \\\n       --worker-num 2 \\\n       --worker-cores 3 \\\n       --ps-memory 1G \\\n       --ps-num 1 \\\n       --ps-cores 2 \\\n       --queue default \\\n\n\nThe meaning of the parameters are as follows:  \n\nProperty Name | Meaning  \n---------------- | ---------------  \napp-name | application name as "tf-demo"  \napp-type | application type as "tensorflow"  \ninput | input file, HDFS path is "/tmp/data/tensorflow" related to local dir "./data"  \noutput | output file\xef\xbc\x8cHDFS path is "/tmp/tensorflow_model" related to local dir "./model"  \nfiles | application program and required local files, including demo.py, dataDeal.py \nlaunch-cmd | execute command  \nworker-memory | amount of memory to use for the worker process is 10GB  \nworker-num | number of worker containers to use for the application is 2  \nworker-cores | number of cores to use for the worker process is 3  \nps-memory | amount of memory to use for the ps process is 1GB  \nps-num | number of ps containers to use for the application is 1  \nps-cores | number of cores to use for the ps process is 2  \nqueue | the queue that application submit to  \n\n\nFor more details, set the [**Submit Parameter**](./doc/submit.md) part\xe3\x80\x82  \n\n\n## FAQ\n[**XLearning FAQ**](./doc/faq.md)\n\n\n## Authors\n\n`XLearning` is designed, authored, reviewed and tested by the team at the github:  \n\n  [@Yuance Li](http://github.com/liyuance), [@Wen OuYang](http://github.com/ouyangwen-it), [@Runying Jia](http://github.com/jiarunying), [@YuHan Jia](http://github.com/jiayuhan-it), [@Lei Wang](http://github.com/wangleibefree)  \n\n\n## Contact us\nMail\xef\xbc\x9a <g-xlearning-dev@360.cn>     \nQQ\xe7\xbe\xa4\xef\xbc\x9a588356340  \n![qq](./doc/img/qq.jpg)\n\n'