b'# Tensorflow Project Template\nA simple and well designed structure is essential for any Deep Learning project, so after a lot of practice and contributing in tensorflow projects here\'s a tensorflow project template that combines   **simplcity**, **best practice for folder structure** and **good OOP design**.\nThe main idea is that there\'s much stuff you do every time you start your tensorflow project, so wrapping all this shared stuff will help you to change just the core idea every time you start a new tensorflow project.\n\n**So, here\'s a simple tensorflow template that help you get into your main project faster and just focus on your core (Model, Training, ...etc)**\n# Table Of Contents\n\n-  [In a Nutshell](#in-a-nutshell)\n-  [In Details](#in-details)\n    -  [Project architecture](#project-architecture)\n    -  [Folder structure](#folder-structure)\n    -  [ Main Components](#main-components)\n        -  [Models](#models)\n        -  [Trainer](#trainer)\n        -  [Data Loader](#data-loader)\n        -  [Logger](#logger)\n        -  [Configuration](#configuration)\n        -  [Main](#main)\n -  [Future Work](#future-work)\n -  [Contributing](#contributing)\n -  [Acknowledgments](#acknowledgments)\n\n# In a Nutshell   \nIn a nutshell here\'s how to use this template, so **for example** assume you want to implement VGG model so you should do the following:\n-  In models folder create a class named VGG that inherit the "base_model" class\n\n```python\n\n    class VGGModel(BaseModel):\n        def __init__(self, config):\n            super(VGGModel, self).__init__(config)\n            #call the build_model and init_saver functions.\n            self.build_model() \n            self.init_saver() \n  ```\n- Override these two functions "build_model" where you implement the vgg model, and "init_saver" where you define a tensorflow saver, then call them in the initalizer.\n    \n```python\n     def build_model(self):\n        # here you build the tensorflow graph of any model you want and also define the loss.\n        pass\n            \n     def init_saver(self):\n        # here you initalize the tensorflow saver that will be used in saving the checkpoints.\n        self.saver = tf.train.Saver(max_to_keep=self.config.max_to_keep)\n\n  ```\n   \n- In trainers folder create a VGG trainer that inherit from "base_train" class\n```python\n\n    class VGGTrainer(BaseTrain):\n        def __init__(self, sess, model, data, config, logger):\n            super(VGGTrainer, self).__init__(sess, model, data, config, logger)\n```\n- Override these two functions "train_step", "train_epoch" where you write the logic of the training process\n```python\n\n    def train_epoch(self):\n        """\n       implement the logic of epoch:\n       -loop on the number of iterations in the config and call the train step\n       -add any summaries you want using the summary\n        """\n        pass\n\n    def train_step(self):\n        """\n       implement the logic of the train step\n       - run the tensorflow session\n       - return any metrics you need to summarize\n       """\n        pass\n\n```\n- In main file, you create the session and instances of the following objects "Model", "Logger", "Data_Generator", "Trainer", and config\n```python\n    sess = tf.Session()\n    # create instance of the model you want\n    model = VGGModel(config)\n    # create your data generator\n    data = DataGenerator(config)\n    # create tensorboard logger\n    logger = Logger(sess, config)\n```\n- Pass the all these objects to the trainer object, and start your training by calling "trainer.train()" \n```python\n    trainer = VGGTrainer(sess, model, data, config, logger)\n\n    # here you train your model\n    trainer.train()\n\n```\n**You will find a template file and a simple example in the model and trainer folder that shows you how to try your first model simply.**\n\n\n# In Details\n\nProject architecture \n--------------\n\n<div align="center">\n\n<img align="center" hight="600" width="600" src="https://github.com/Mrgemy95/Tensorflow-Project-Templete/blob/master/figures/diagram.png?raw=true">\n\n</div>\n\n\nFolder structure\n--------------\n\n```\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80  base\n\xe2\x94\x82   \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 base_model.py   - this file contains the abstract class of the model.\n\xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 base_train.py   - this file contains the abstract class of the trainer.\n\xe2\x94\x82\n\xe2\x94\x82\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 model               - this folder contains any model of your project.\n\xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 example_model.py\n\xe2\x94\x82\n\xe2\x94\x82\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 trainer             - this folder contains trainers of your project.\n\xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 example_trainer.py\n\xe2\x94\x82   \n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80  mains              - here\'s the main(s) of your project (you may need more than one main).\n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 example_main.py  - here\'s an example of main that is responsible for the whole pipeline.\n\n\xe2\x94\x82  \n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80  data _loader  \n\xe2\x94\x82    \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 data_generator.py  - here\'s the data_generator that is responsible for all data handling.\n\xe2\x94\x82 \n\xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 utils\n     \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 logger.py\n     \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 any_other_utils_you_need\n\n```\n\n\n## Main Components\n\n### Models\n--------------\n- #### **Base model**\n    \n    Base model is an abstract class that must be Inherited by any model you create, the idea behind this is that there\'s much shared stuff between all models.\n    The base model contains:\n    - ***Save*** -This function to save a checkpoint to the desk. \n    - ***Load*** -This function to load a checkpoint from the desk.\n    - ***Cur_epoch, Global_step counters*** -These variables to keep track of the current epoch and global step.\n    - ***Init_Saver*** An abstract function to initialize the saver used for saving and loading the checkpoint, ***Note***: override this function in the model you want to implement.\n    - ***Build_model*** Here\'s an abstract function to define the model, ***Note***: override this function in the model you want to implement.\n- #### **Your model**\n    Here\'s where you implement your model.\n    So you should :\n    - Create your model class and inherit the base_model class\n    - override "build_model" where you write the tensorflow model you want\n    - override "init_save" where you create a tensorflow saver to use it to save and load checkpoint\n    - call the "build_model" and "init_saver" in the initializer.\n\n### Trainer\n--------------\n- #### **Base trainer**\n    Base trainer is an abstract class that just wrap the training process.\n    \n- #### **Your trainer**\n     Here\'s what you should implement in your trainer.\n    1. Create your trainer class and inherit the base_trainer class.\n    2. override these two functions "train_step", "train_epoch" where you implement the training process of each step and each epoch.\n### Data Loader\nThis class is responsible for all data handling and processing and provide an easy interface that can be used by the trainer.\n### Logger\nThis class is responsible for the tensorboard summary, in your trainer create a dictionary of all tensorflow variables you want to summarize then pass this dictionary to logger.summarize().\n\n\nThis class also supports reporting to **Comet.ml** which allows you to see all your hyper-params, metrics, graphs, dependencies and more including real-time metric.\nAdd your API key [in the configuration file](configs/example.json#L9):\n\nFor example: "comet_api_key": "your key here"\n\n\n### Comet.ml Integration\nThis template also supports reporting to Comet.ml which allows you to see all your hyper-params, metrics, graphs, dependencies and more including real-time metric. \n\nAdd your API key [in the configuration file](configs/example.json#L9):\n\n\nFor example:  `"comet_api_key": "your key here"` \n\nHere\'s how it looks after you start training:\n<div align="center">\n\n<img align="center" width="800" src="https://comet-ml.nyc3.digitaloceanspaces.com/CometDemo.gif">\n\n</div>\n\nYou can also link your Github repository to your comet.ml project for full version control. \n[Here\'s a live page showing the example from this repo](https://www.comet.ml/gidim/tensorflow-project-template/caba580d8d1547ccaed982693a645507/chart)\n\n\n\n### Configuration\nI use Json as configuration method and then parse it, so write all configs you want then parse it using "utils/config/process_config" and pass this configuration object to all other objects.\n### Main\nHere\'s where you combine all previous part.\n1. Parse the config file.\n2. Create a tensorflow session.\n2. Create an instance of "Model", "Data_Generator" and "Logger" and parse the config to all of them.\n3. Create an instance of "Trainer" and pass all previous objects to it.\n4. Now you can train your model by calling "Trainer.train()"\n\n\n# Future Work\n- Replace the data loader part with new tensorflow dataset API.\n\n\n# Contributing\nAny kind of enhancement or contribution is welcomed.\n\n\n# Acknowledgments\nThanks for my colleague  [Mo\'men Abdelrazek](https://github.com/moemen95) for contributing in this work.\nand thanks for [Mohamed Zahran](https://github.com/moh3th1) for the review.\n**Thanks for Jtoy for including the repo in  [Awesome Tensorflow](https://github.com/jtoy/awesome-tensorflow).** \n'