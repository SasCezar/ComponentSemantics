b'# [Deep Reinforcement Learning Course](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)\n# \xe2\x9a\xa0\xef\xb8\x8f I\'m currently updating the implementations (January and February (some delay due to job interviews)) with Tensorflow and PyTorch.\n<img src="https://raw.githubusercontent.com/simoninithomas/Deep_reinforcement_learning_Course/master/docs/assets/img/DRLC%20Environments.png" alt="Deep Reinforcement Course with Tensorflow" style="width: 500px;"/>\n\n<p>  Deep Reinforcement Learning Course is a free series of blog posts and videos \xf0\x9f\x86\x95 about Deep Reinforcement Learning, where we\'ll <b>learn the main algorithms, and how to implement them with Tensorflow.</b>\n\n\xf0\x9f\x93\x9cThe articles explain the concept from the big picture to the mathematical details behind it.\n\n\xf0\x9f\x93\xb9 The videos explain how to create the agent with Tensorflow </b></p>\n\n# <a href="https://simoninithomas.github.io/Deep_reinforcement_learning_Course/">Syllabus</a><br>\n## \xf0\x9f\x93\x9c Part 1: Introduction to Reinforcement Learning [ARTICLE](https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419) <br><br>\n\n## Part 2: Q-learning with FrozenLake <br>\n### \xf0\x9f\x93\x9c [ARTICLE](https://medium.freecodecamp.org/diving-deeper-into-reinforcement-learning-with-q-learning-c18d0db58efe) // [FROZENLAKE IMPLEMENTATION](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Q%20learning/FrozenLake/Q%20Learning%20with%20FrozenLake.ipynb)<br>\n### \xf0\x9f\x93\xb9 [Implementing a Q-learning agent that plays Taxi-v2 \xf0\x9f\x9a\x95](https://youtu.be/q2ZOEFAaaI0) <br><br>\n\n## Part 3: Deep Q-learning with Doom <br>\n### \xf0\x9f\x93\x9c [ARTICLE](https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8)  //  [DOOM IMPLEMENTATION](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Deep%20Q%20Learning/Doom/Deep%20Q%20learning%20with%20Doom.ipynb)<br>\n### \xf0\x9f\x93\xb9 [Create a DQN Agent that learns to play Atari Space Invaders \xf0\x9f\x91\xbe](https://youtu.be/gCJyVX98KJ4) <br><br>\n\n## Part 4: Policy Gradients with Doom <br>\n### \xf0\x9f\x93\x9c [ARTICLE](https://medium.freecodecamp.org/an-introduction-to-policy-gradients-with-cartpole-and-doom-495b5ef2207f) //  [CARTPOLE IMPLEMENTATION](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Policy%20Gradients/Cartpole/Cartpole%20REINFORCE%20Monte%20Carlo%20Policy%20Gradients.ipynb) // [DOOM IMPLEMENTATION](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Policy%20Gradients/Doom/Doom%20REINFORCE%20Monte%20Carlo%20Policy%20gradients.ipynb) <br>\n### \xf0\x9f\x93\xb9 [Create an Agent that learns to play Doom deathmatch](https://www.youtube.com/watch?v=wLTQRuizVyE) <br><br>\n\n## Part 3+: Improvments in Deep Q-Learning <br>\n### \xf0\x9f\x93\x9c [ARTICLE](https://medium.freecodecamp.org/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682)//  [Doom Deadly corridor IMPLEMENTATION](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Dueling%20Double%20DQN%20with%20PER%20and%20fixed-q%20targets/Dueling%20Deep%20Q%20Learning%20with%20Doom%20(%2B%20double%20DQNs%20and%20Prioritized%20Experience%20Replay).ipynb) <br>\n### \xf0\x9f\x93\xb9 [Create an Agent that learns to play Doom Deadly corridor](https://youtu.be/-Ynjw0Vl3i4) <br><br>\n\n## Part 5: Advantage Advantage Actor Critic (A2C) <br>\n### \xf0\x9f\x93\x9c [ARTICLE](https://medium.freecodecamp.org/an-intro-to-advantage-actor-critic-methods-lets-play-sonic-the-hedgehog-86d6240171d) <br>\n### \xf0\x9f\x93\xb9 [Create an Agent that learns to play Sonic](https://youtu.be/GCfUdkCL7FQ) <br><br>\n\n## Part 6: Proximal Policy Gradients <br>\n### \xf0\x9f\x93\x9c [ARTICLE](https://towardsdatascience.com/proximal-policy-optimization-ppo-with-sonic-the-hedgehog-2-and-3-c9c21dbed5e)<br>\n### \xf0\x9f\x91\xa8\xe2\x80\x8d\xf0\x9f\x92\xbb [Create an Agent that learns to play Sonic the Hedgehog 2 and 3 ](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/tree/master/PPO%20with%20Sonic%20the%20Hedgehog) <br><br>\n\n## Part 7: Curiosity Driven Learning made easy Part I <br> <br>\n### \xf0\x9f\x93\x9c [ARTICLE](https://towardsdatascience.com/curiosity-driven-learning-made-easy-part-i-d3e5a2263359) <br> <br>\n    \n## Part 8: Random Network Distillation with PyTorch  <br>\n## \xf0\x9f\x91\xa8\xe2\x80\x8d\xf0\x9f\x92\xbb [A trained RND agent that learned to play Montezuma\'s revenge (21 hours of training with a Tesla K80](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/tree/master/RND%20Montezuma\'s%20revenge%20PyTorch)  <br> <br>\n\n## Any questions \xf0\x9f\x91\xa8\xe2\x80\x8d\xf0\x9f\x92\xbb\n<p> If you have any questions, feel free to ask me: </p>\n<p> \xf0\x9f\x93\xa7: <a href="mailto:hello@simoninithomas.com">hello@simoninithomas.com</a>  </p>\n<p> Github: https://github.com/simoninithomas/Deep_reinforcement_learning_Course </p>\n<p> \xf0\x9f\x8c\x90 : https://simoninithomas.github.io/Deep_reinforcement_learning_Course/ </p>\n<p> Twitter: <a href="https://twitter.com/ThomasSimonini">@ThomasSimonini</a> </p>\n<p> Don\'t forget to <b> follow me on <a href="https://twitter.com/ThomasSimonini">twitter</a>, <a href="https://github.com/simoninithomas/Deep_reinforcement_learning_Course">github</a> and <a href="https://medium.com/@thomassimonini">Medium</a> to be alerted of the new articles that I publish </b></p>\n\n## How to help  \xf0\x9f\x99\x8c\n3 ways:\n\n- **Clap our articles and like our videos a lot**:Clapping in Medium means that you really like our articles. And the more claps we have, the more our article is shared Liking our videos help them to be much more visible to the deep learning community.\n- **Share and speak about our articles and videos**: By sharing our articles and videos you help us to spread the word. \n- **Improve our notebooks**: if you found a bug or **a better implementation** you can send a pull request.\n<br>\n'