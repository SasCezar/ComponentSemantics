b'# Computer Vision Annotation Tool (CVAT)\n\n[![Build Status](https://travis-ci.org/opencv/cvat.svg?branch=develop)](https://travis-ci.org/opencv/cvat)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/840351da141e4eaeac6476fd19ec0a33)](https://app.codacy.com/app/cvat/cvat?utm_source=github.com&utm_medium=referral&utm_content=opencv/cvat&utm_campaign=Badge_Grade_Dashboard)\n[![Gitter chat](https://badges.gitter.im/opencv-cvat/gitter.png)](https://gitter.im/opencv-cvat)\n[![Coverage Status](https://coveralls.io/repos/github/opencv/cvat/badge.svg?branch=)](https://coveralls.io/github/opencv/cvat?branch=develop)\n[![DOI](https://zenodo.org/badge/139156354.svg)](https://zenodo.org/badge/latestdoi/139156354)\n\nCVAT is free, online, interactive video and image annotation tool for computer vision. It is being used by our team to annotate million of objects with different properties. Many UI and UX decisions are based on feedbacks from professional data annotation team.\n\n![CVAT screenshot](cvat/apps/documentation/static/documentation/images/cvat.jpg)\n\n## Documentation\n\n- [Installation guide](cvat/apps/documentation/installation.md)\n- [User\'s guide](cvat/apps/documentation/user_guide.md)\n- [Django REST API documentation](#rest-api)\n- [Command line interface](utils/cli/)\n- [XML annotation format](cvat/apps/documentation/xml_format.md)\n- [AWS Deployment Guide](cvat/apps/documentation/AWS-Deployment-Guide.md)\n- [Questions](#questions)\n\n## Screencasts\n\n- [Introduction](https://youtu.be/L9_IvUIHGwM)\n- [Annotation mode](https://youtu.be/6h7HxGL6Ct4)\n- [Interpolation mode](https://youtu.be/U3MYDhESHo4)\n- [Attribute mode](https://youtu.be/UPNfWl8Egd8)\n- [Segmentation mode](https://youtu.be/Fh8oKuSUIPs)\n- [Tutorial for polygons](https://www.youtube.com/watch?v=XTwfXDh4clI)\n- [Semi-automatic segmentation](https://www.youtube.com/watch?v=vnqXZ-Z-VTQ)\n\n## Supported annotation formats\n\nFormat selection is possible after clicking on the Upload annotation / Dump annotation button.\n\n| Annotation format                                                                  | Dumper | Loader |\n| ---------------------------------------------------------------------------------- | ------ | ------ |\n| [CVAT XML v1.1 for images](cvat/apps/documentation/xml_format.md#annotation)       | X      | X      |\n| [CVAT XML v1.1 for a video](cvat/apps/documentation/xml_format.md#interpolation)   | X      | X      |\n| [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/)                              | X      | X      |\n| [YOLO](https://pjreddie.com/darknet/yolo/)                                         | X      | X      |\n| [MS COCO Object Detection](http://cocodataset.org/#format-data)                    | X      | X      |\n| PNG mask                                                                           | X      |        |\n| [TFrecord](https://www.tensorflow.org/tutorials/load_data/tf_records)              | X      | X      |\n| [MOT](https://motchallenge.net/)                                                   | X      | X      |\n| [LabelMe](http://labelme.csail.mit.edu/Release3.0)                                 | X      | X      |\n\n## Links\n- [Intel AI blog: New Computer Vision Tool Accelerates Annotation of Digital Images and Video](https://www.intel.ai/introducing-cvat)\n- [Intel Software: Computer Vision Annotation Tool: A Universal Approach to Data Annotation](https://software.intel.com/en-us/articles/computer-vision-annotation-tool-a-universal-approach-to-data-annotation)\n- [VentureBeat: Intel open-sources CVAT, a toolkit for data labeling](https://venturebeat.com/2019/03/05/intel-open-sources-cvat-a-toolkit-for-data-labeling/)\n\n## Online Demo\n\n[Onepanel](https://www.onepanel.io/) has added CVAT as an environment into their platform and a running demo of CVAT can be accessed at [CVAT Public Demo](https://c.onepanel.io/onepanel-demo/projects/cvat-public-demo/workspaces).\n\nAfter you click the link above:\n\n- Click on "GO TO WORKSPACE" and the CVAT environment will load up\n- The environment is backed by a K80 GPU\n\nIf you have any questions, please contact Onepanel directly at support@onepanel.io. If you are in the Onepanel application, you can also use the chat icon in the bottom right corner.\n\n## REST API\n\nAutomatically generated Swagger documentation for Django REST API is\navailable on ``<cvat_origin>/api/swagger`` (default: ``localhost:8080/api/swagger``).\n\n## LICENSE\n\nCode released under the [MIT License](https://opensource.org/licenses/MIT).\n\n## Questions\n\nCVAT usage related questions or unclear concepts can be posted in our\n[Gitter chat](https://gitter.im/opencv-cvat) for **quick replies** from\ncontributors and other users.\n\nHowever, if you have a feature request or a bug report that can reproduced,\nfeel free to open an issue (with steps to reproduce the bug if it\'s a bug\nreport) on [GitHub* issues](https://github.com/opencv/cvat/issues).\n\nIf you are not sure or just want to browse other users common questions,\n[Gitter chat](https://gitter.im/opencv-cvat) is the way to go.\n\nOther ways to ask questions and get our support:\n* [\\#cvat](https://stackoverflow.com/search?q=%23cvat) tag on StackOverflow*\n* [Forum on Intel Developer Zone](https://software.intel.com/en-us/forums/computer-vision)\n'