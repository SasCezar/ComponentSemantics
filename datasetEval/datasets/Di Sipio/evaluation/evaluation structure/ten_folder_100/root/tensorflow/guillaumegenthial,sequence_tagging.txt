b'# Named Entity Recognition with Tensorflow\n\nThis repo implements a NER model using Tensorflow (LSTM + CRF + chars embeddings).\n\n__A [better implementation is available here, using `tf.data` and `tf.estimator`, and achieves an F1 of 91.21](https://github.com/guillaumegenthial/tf_ner)__\n\nState-of-the-art performance (F1 score between 90 and 91).\n\nCheck the [blog post](https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html)\n\n## Task\n\nGiven a sentence, give a tag to each word. A classical application is Named Entity Recognition (NER). Here is an example\n\n```\nJohn   lives in New   York\nB-PER  O     O  B-LOC I-LOC\n```\n\n\n## Model\n\nSimilar to [Lample et al.](https://arxiv.org/abs/1603.01360) and [Ma and Hovy](https://arxiv.org/pdf/1603.01354.pdf).\n\n- concatenate final states of a bi-lstm on character embeddings to get a character-based representation of each word\n- concatenate this representation to a standard word vector representation (GloVe here)\n- run a bi-lstm on each sentence to extract contextual representation of each word\n- decode with a linear chain CRF\n\n\n\n## Getting started\n\n\n1. Download the GloVe vectors with\n\n```\nmake glove\n```\n\nAlternatively, you can download them manually [here](https://nlp.stanford.edu/projects/glove/) and update the `glove_filename` entry in `config.py`. You can also choose not to load pretrained word vectors by changing the entry `use_pretrained` to `False` in `model/config.py`.\n\n2. Build the training data, train and evaluate the model with\n```\nmake run\n```\n\n\n## Details\n\n\nHere is the breakdown of the commands executed in `make run`:\n\n1. [DO NOT MISS THIS STEP] Build vocab from the data and extract trimmed glove vectors according to the config in `model/config.py`.\n\n```\npython build_data.py\n```\n\n2. Train the model with\n\n```\npython train.py\n```\n\n\n3. Evaluate and interact with the model with\n```\npython evaluate.py\n```\n\n\nData iterators and utils are in `model/data_utils.py` and the model with training/test procedures is in `model/ner_model.py`\n\nTraining time on NVidia Tesla K80 is 110 seconds per epoch on CoNLL train set using characters embeddings and CRF.\n\n\n\n## Training Data\n\n\nThe training data must be in the following format (identical to the CoNLL2003 dataset).\n\nA default test file is provided to help you getting started.\n\n\n```\nJohn B-PER\nlives O\nin O\nNew B-LOC\nYork I-LOC\n. O\n\nThis O\nis O\nanother O\nsentence\n```\n\n\nOnce you have produced your data files, change the parameters in `config.py` like\n\n```\n# dataset\ndev_filename = "data/coNLL/eng/eng.testa.iob"\ntest_filename = "data/coNLL/eng/eng.testb.iob"\ntrain_filename = "data/coNLL/eng/eng.train.iob"\n```\n\n\n\n\n## License\n\nThis project is licensed under the terms of the apache 2.0 license (as Tensorflow and derivatives). If used for research, citation would be appreciated.\n\n'