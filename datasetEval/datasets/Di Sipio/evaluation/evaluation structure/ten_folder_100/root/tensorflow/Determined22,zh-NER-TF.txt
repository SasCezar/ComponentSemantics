b"# A simple BiLSTM-CRF model for Chinese Named Entity Recognition\n\nThis repository includes the code for buliding a very simple __character-based BiLSTM-CRF sequence labeling model__ for Chinese Named Entity Recognition task. Its goal is to recognize three types of Named Entity: PERSON, LOCATION and ORGANIZATION.\n\nThis code works on __Python 3 & TensorFlow 1.2__ and the following repository [https://github.com/guillaumegenthial/sequence_tagging](https://github.com/guillaumegenthial/sequence_tagging) gives me much help.\n\n## Model\n\nThis model is similar to the models provided by paper [1] and [2]. Its structure looks just like the following illustration:\n\n![Network](./pics/pic1.png)\n\nFor one Chinese sentence, each character in this sentence has / will have a tag which belongs to the set {O, B-PER, I-PER, B-LOC, I-LOC, B-ORG, I-ORG}.\n\nThe first layer, __look-up layer__, aims at transforming each character representation from one-hot vector into *character embedding*. In this code I initialize the embedding matrix randomly and I know it looks too simple. We could add some language knowledge later. For example, do tokenization and use pre-trained word-level embedding, then every character in one token could be initialized with this token's word embedding. In addition, we can get the character embedding by combining low-level features (please see paper[2]'s section 4.1 and paper[3]'s section 3.3 for more details).\n\nThe second layer, __BiLSTM layer__, can efficiently use *both past and future* input information and extract features automatically.\n\nThe third layer, __CRF layer__,  labels the tag for each character in one sentence. If we use a Softmax layer for labeling, we might get ungrammatic tag sequences beacuse the Softmax layer labels each position independently. We know that 'I-LOC' cannot follow 'B-PER' but Softmax doesn't know. Compared to Softmax, a CRF layer can use *sentence-level tag information* and model the transition behavior of each two different tags.\n\n## Dataset\n\n|    | #sentence | #PER | #LOC | #ORG |\n| :----: | :---: | :---: | :---: | :---: |\n| train  | 46364 | 17615 | 36517 | 20571 |\n| test   | 4365  | 1973  | 2877  | 1331  |\n\nIt looks like a portion of [MSRA corpus](http://sighan.cs.uchicago.edu/bakeoff2006/). I downloaded the dataset from the link in `./data_path/original/link.txt`\n\n### data files\n\nThe directory `./data_path` contains:\n\n- the preprocessed data files, `train_data` and `test_data` \n- a vocabulary file `word2id.pkl` that maps each character to a unique id  \n\nFor generating vocabulary file, please refer to the code in `data.py`. \n\n### data format\n\nEach data file should be in the following format:\n\n```\n\xe4\xb8\xad\tB-LOC\n\xe5\x9b\xbd\tI-LOC\n\xe5\xbe\x88\tO\n\xe5\xa4\xa7\tO\n\n\xe5\x8f\xa5\tO\n\xe5\xad\x90\tO\n\xe7\xbb\x93\tO\n\xe6\x9d\x9f\tO\n\xe6\x98\xaf\tO\n\xe7\xa9\xba\tO\n\xe8\xa1\x8c\tO\n\n```\n\nIf you want to use your own dataset, please: \n\n- transform your corpus to the above format\n- generate a new vocabulary file\n\n## How to Run\n\n### train\n\n`python main.py --mode=train `\n\n### test\n\n`python main.py --mode=test --demo_model=1521112368`\n\nPlease set the parameter `--demo_model` to the model that you want to test. `1521112368` is the model trained by me. \n\nAn official evaluation tool for computing metrics: [here (click 'Instructions')](http://sighan.cs.uchicago.edu/bakeoff2006/)\n\nMy test performance:\n\n| P     | R     | F     | F (PER)| F (LOC)| F (ORG)|\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 0.8945 | 0.8752 | 0.8847 | 0.8688 | 0.9118 | 0.8515\n\n### demo\n\n`python main.py --mode=demo --demo_model=1521112368`\n\nYou can input one Chinese sentence and the model will return the recognition result:\n\n![demo_pic](./pics/pic2.png)\n\n## References\n\n\\[1\\] [Bidirectional LSTM-CRF Models for Sequence Tagging](https://arxiv.org/pdf/1508.01991v1.pdf)\n\n\\[2\\] [Neural Architectures for Named Entity Recognition](http://aclweb.org/anthology/N16-1030)\n\n\\[3\\] [Character-Based LSTM-CRF with Radical-Level Features for Chinese Named Entity Recognition](https://link.springer.com/chapter/10.1007/978-3-319-50496-4_20)\n\n\\[4\\] [https://github.com/guillaumegenthial/sequence_tagging](https://github.com/guillaumegenthial/sequence_tagging)  \n"