b"# Tensorflow Speech Recognition\nSpeech recognition using google's [tensorflow](https://github.com/tensorflow/tensorflow/) deep learning framework, [sequence-to-sequence](https://www.tensorflow.org/versions/master/tutorials/seq2seq/index.html) neural networks.\n\nReplaces [caffe-speech-recognition](https://github.com/pannous/caffe-speech-recognition), see there for some background.\n\n\n## Update **Mozilla** released [DeepSpeech](https://github.com/mozilla/DeepSpeech)\nThey achieve good [error rates](http://doyouunderstand.me). Free Speech is in good hands, go *there* if you are an end user.\nFor now *this* project is only maintained for educational purposes.\n\n\n## Ultimate goal\nCreate a decent standalone speech recognition for Linux etc.\nSome people say we have the models but not enough training data.\nWe disagree: There is plenty of training data (100GB [here](http://www.openslr.org/12) and 21GB [here on openslr.org](http://www.openslr.org/7/) , synthetic Text to Speech snippets, Movies with transcripts, Gutenberg, YouTube with captions etc etc) we just need a simple yet powerful model. It's only a question of time...\n\n![Sample spectrogram, That's what she said, too laid?](images/0_Karen_160.png)\n\nSample spectrogram, Karen uttering 'zero' with 160 words per minute.\n## Installation\n### clone code\n```\ngit clone https://github.com/pannous/tensorflow-speech-recognition\ncd tensorflow-speech-recognition\ngit clone https://github.com/pannous/layer.git\ngit clone https://github.com/pannous/tensorpeers.git\n```\n\n### pyaudio\n#### requirements portaudio from http://www.portaudio.com/\n```\ngit clone  https://git.assembla.com/portaudio.git\n./configure --prefix=/path/to/your/local\nmake\nmake install\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/path/to/your/local/lib\nexport LIDRARY_PATH=$LIBRARY_PATH:/path/to/your/local/lib\nexport CPATH=$CPATH:/path/to/your/local/include\nsource ~/.bashrc\n```\n#### install pyaudio\n```\npip install pyaudio\n```\n\n## Getting started\n\nToy examples:\n`./number_classifier_tflearn.py`\n`./speaker_classifier_tflearn.py`\n\nSome less trivial architectures:\n`./densenet_layer.py`\n\nLater:\n`./train.sh`\n`./record.py`\n\n![Sample spectrogram or record.py](images/spectrogram.demo.png)\n\n<!-- \xe2\x95\xae\xe2\x9a\x86\xe1\xb4\xa5\xe2\x9a\x86\xe2\x95\xad -->\n\nUpdate: Nervana [demonstrated](https://www.youtube.com/watch?v=NaqZkV_fBIM) that it is possible for 'independents' to build speech recognizers that are state of the art. \n<!-- \xe1\x96\x97*\xef\xb9\x8f*\xe1\x96\x98 -->\n\n### Fun tasks for newcomers\n* Watch video : https://www.youtube.com/watch?v=u9FPqkuoEJ8\n* Understand and correct the corresponding code: [lstm-tflearn.py](/lstm-tflearn.py) \n* Data Augmentation :  create on-the-fly modulation of the data: increase the speech frequency, add background noise, alter the pitch etc,...\n<!-- \xe1\x95\xae\xe2\x97\x94\xe2\x80\xbf\xe2\x97\x94\xe1\x95\xad -->\n\n### Extensions \n**Extensions** to current tensorflow which are probably needed:\n* [WarpCTC on the GPU](https://github.com/baidu-research/warp-ctc/tree/master/tensorflow_binding) see [issue](https://github.com/tensorflow/tensorflow/issues/2146)\n* Incremental collaborative snapshots ('[P2P learning](https://github.com/pannous/tensorpeers)') !\n* Modular graphs/models + persistance\n<!-- \xe2\xa4\x9c(\xe2\xa8\xb1\xe1\xb4\xa5\xe2\xa8\xb1)\xe2\xa4\x8f -->\n\nEven though this project is far from finished we hope it gives you some starting points.\n\nLooking for a tensorflow collaboration / consultant / deep learning contractor? Reach out to [info@pannous.com](mailto:info@pannous.com?subject=contractor)\n<!--\n Notes\nSTT https://github.com/sotelo/parrot/blob/master/model.py t\n parrot\n\n-->\n"