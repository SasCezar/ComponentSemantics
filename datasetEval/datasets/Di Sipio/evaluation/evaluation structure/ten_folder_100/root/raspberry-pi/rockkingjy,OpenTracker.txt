b'\n<p align="center">\n    <img src="images/Opentracker.png", width="480">\n</p>\n\n# What is OpenTracker?\nOpenTracker is an open sourced repository for Visual Tracking. It\'s written in C++, high speed, easy to use, and easy to be implemented in embedded system.\n```diff\n- AND this is not only boring Codes, \n+ It also has Maths and Implement Notes!\n```\nIf you don\'t exactly know what this means:\n\n<p align="center">\n    <img src="images/equation.png", width="480">\n</p>\n\n**Don\'t worry**, it will be explained fully in the [Notes](https://github.com/rockkingjy/OpenTracker/tree/master/notes). All the maths details of the Not-that-easy algorithms are explaned fully from the very beginning. If **you have headache of reading the papers**(as most of us have), this is a good tutorial. \n(Check [Notes](https://github.com/rockkingjy/OpenTracker/tree/master/notes)(draft now)). \n\nOr, **if you have problems with the implementation of a complicate cutting-edge algorithms, check this! You will get something!**\n\n<p align="center">\n    <img src="images/Crossing.gif", width="480">\n</p>\n<p align="center">\n    <img src="images/trackingdemo.gif", width="480">\n</p>\n\n**Attention!** OpenTracker is **NOT** designed just for tracking human beings as the demo images, it can track **everything**, even some special points!\n\n**For Multiple Object Tracker**, check: [OpenMultiTracker](https://github.com/rockkingjy/OpenMultiTracker).\n\n\n**2018/11/06 -- New features** add CMake compile support for ECO tracker. (Thanks to [ou-zhi-hui](https://github.com/ou-zhi-hui/OpenTracker))\n\n**2018/09/19 -- New features** Performance tested on VOT2017 dataset!\n\n**2018/09/13 -- New features** CN feature added!\n\n**2018/08/30 -- New features** Support Initialize by Object Detection using [Darknet](https://github.com/rockkingjy/darknet) and track.\n\n**2018/08/27 -- New features** Support ECO API.\n\n**2018/08/24 -- New features** Now ECO runs "almost" real-time on Raspberry Pi 3!\n\n**2018/08/24 -- New features** Support [FFTW](http://www.fftw.org/).\n\n**2018/08/13 -- New features** Speed up by multi-thread.\n\n**2018/08/09 -- New features** Now it supports **Raspberry Pi 3**, and speed up with NEON!\n\n**2018/08/08 -- New features** Speed up with NEON, speed up from ~32FPS to ~42FPS on Jetson TX2 with scale one.\n\n**2018/08/06 -- New features** Speed up with SSE, speed up from ~86FPS to ~102FPS(quicker than matlab version) with scale one.\n\n**2018/07/07 -- New features** OpenTracker Implement Notes draft published! Check **notes/OpenTrackerNotes.pdf**. Complete version is comming!\n\n**2018/07/06 -- New features** Now it supports **Nvidia Jetson TX1/2**!\n\n**2018/07/05 -- New features** Now it supports **macOS**!\n\n**2018/06/28 -- New features** Now it supports automatic initialization with Web camera using **OpenPose**!\n\n\n## Supported tracker (more in progressing):\nIncluded                                   | Tracker    \n-------------------------------------------|---------------\n:ballot_box_with_check:                    | CSK          \n:ballot_box_with_check:                    | KCF          \n:ballot_box_with_check:                    | DSST          \n:ballot_box_with_check:                    | GOTURN         \n :hammer:                    | ECO         \n\n## Supported Dataset (more in progressing):\n\nIncluded                                   | Dataset      | Reference\n-------------------------------------------|--------------|-----------\n:ballot_box_with_check:                    | VOT-2017     | [Web](http://votchallenge.net/vot2017/dataset.html)\n:ballot_box_with_check:                    | TB-2015      | [Web](http://cvlab.hanyang.ac.kr/tracker_benchmark/index.html)\n:ballot_box_with_check:                    | TLP          | [Web](https://amoudgl.github.io/tlp/)\n:ballot_box_with_check:                    | UAV123       | [Web](https://ivul.kaust.edu.sa/Pages/Dataset-UAV123.aspx)\n\n## Supported Autodetection with Web Camera\nIncluded                                   | Dataset    | Reference\n-------------------------------------------|--------------|-----------\n:ballot_box_with_check:                    | OpenPose     | [Web](https://github.com/CMU-Perceptual-Computing-Lab/openpose)\n\n## Tested Operating Systems / Platform\nIncluded                   | OS / Platform   \n---------------------------|-------------\n:ballot_box_with_check:    | Ubuntu 16.04\n:ballot_box_with_check:    | macOS Sierra\n:ballot_box_with_check:    | NVIDIA Jetson TX1/2\n:ballot_box_with_check:    | Rasperberry PI 3 \n :hammer:                  | Windows10\n\n## Performance Analysis\n<p align="center">\n    <img src="images/vot2017.png", width="">\n</p>\n\n"ECOHCMATLAB" is the original matlab full version ECO-HC.\n\n"ECOHCMATLABHOGCN" is the matlab version ECO-HC without fDSST scale filter.\n\n"ECOHCMATLABHOG" is the matlab version ECO-HC without fDSST scale filter and CN feature.\n\n"ECOCPPHOGCN" is the c++ ECO tracker in OpenTracker without fDSST scale filter.\n\n"ECOCPPHOG" is the c++ ECO tracker in OpenTracker without CN feature and fDSST scale filter.\n\n"KCFCPP" is the c++ KCF tracker in OpenTracker.\n\n"NCC" is a demo tracker in vot-toolkit.\n\nThe test is on dataset VOT2017, and parameters are set exactly the same as "VOT2016_HC_settings" in matlab version. This is just for proof of validation of c++ version code, thus the parameters are not tuned for VOT2017.\n\nYou can see from the plot that, full-featured "ECOHCMATLAB" has the highest performance, "ECOCPPHOGCN" has almost the same performance with "ECOHCMATLABHOGCN", and "ECOCPPHOG" quite similar to "ECOHCMATLABHOG". And "KCFCPP" perform even better than the HOG-only ECO version, so it seems that CN feature matters.\n\n## Speed-up(without CN feature)\nIncluded                | Method(single thread)   | FPS(scale=1) | FPS(scale=7)\n------------------------|-------------------------|--------------|-------------\n:ballot_box_with_check: | Matlab ECO-HOG(Intel i9)| ~73          | ~45\n:ballot_box_with_check: | no speed-up(Intel i9)   | ~86          | ~36\n:ballot_box_with_check: | SSE(Intel i9)           |~260:cherries:| ~95:cherries:\n:ballot_box_with_check: | no speed-up(MacBook Air Intel i5)| ~60        | ~22 \n:ballot_box_with_check: | SSE(MacBook Air Intel i5)|~140:cherries:|~55:cherries:\n:ballot_box_with_check: | no speed-up(Jestson TX2)| ~32          | ~10\n:ballot_box_with_check: | NEON(Jetson TX2)        | ~60:cherries:| ~34:cherries:\n:ballot_box_with_check: | no speed-up(Raspberrypi)| ~11          | ~3\n:ballot_box_with_check: | NEON(Raspberrypi)       | ~24:cherries:| ~7.5\n:hammer:                | GPU                     | :hammer:     | :hammer:\n\n## Speed Analysis(without CN feature)\n<p align="center">\n    <img src="images/speedanalysis.png", width="">\n</p>\n\n# Quick start\n--------------------------------\nWith quick start, you can have a quick first taste of this repository, without any panic. No need to install Caffe, CUDA etc. (**But of course you have to install OpenCV 3.0 first**).\n\nOpenCV 3.0 Install on Ubuntu check this [[Tutorial](https://www.learnopencv.com/install-opencv3-on-ubuntu/)].\n\n## Quick Run ECO Tracker:\nIn `eco/runecotracker.cc`, make sure to choose the dataset `Demo`:\n``` \n    string databaseType = databaseTypes[0];\n```\n### Quick start -- Ubuntu\n```\ngit clone https://github.com/rockkingjy/OpenTracker\ncd OpenTracker/eco\nmake -j`nproc`\nsudo make install\n./runecotracker.bin\n```\n### Quick start -- macOS\n```\nbrew install tesseract\ngit clone https://github.com/rockkingjy/OpenTracker\ncd OpenTracker/eco\nmake  -j`nproc`\nsudo make install\n./runecotracker.bin\n```\n\n## Quick Run KCF and DSST Tracker:\nIn file `kcf/runkcftracker.cc`, make sure to choose the dataset `Demo`:\n``` \n    string databaseType = databaseTypes[0];\n```\n### Quick start -- Ubuntu\n```\ngit clone https://github.com/rockkingjy/OpenTracker\ncd OpenTracker/kcf\nmake \n./runkcftracker.bin\n```\n### Quick start -- macOS\n```\nbrew install tesseract\ngit clone https://github.com/rockkingjy/OpenTracker\ncd OpenTracker/kcf\nmake\n./runkcftracker.bin\n```\n\n## Quick Run (almost) all the tracker:\n```\ngit clone https://github.com/rockkingjy/OpenTracker\ncd OpenTracker\nmake \nsudo make install\n./trackerscompare.bin\n```\n\n# Compile and Run \n--------------------------------\nFor the **environment settings** and detailed procedures (with all the packages from the very beginning), refer to: [[My DeeplearningSettings](https://github.com/rockkingjy/DeepLearningSettings)].\n\nThe only extra-package is: **Opencv3.x** (already installed if you follow the environment settings above).\n\nOf course, for trackers that use Deep features, you need to install [[**caffe**](https://github.com/rockkingjy/caffe)] (maybe I will use Darknet with C in the future, I like Darknet :lips: ), and change the **makefile** according to your path. Compile of caffe refer to : [[Install caffe by makefile](https://github.com/rockkingjy/DeepLearningSettings/blob/master/caffe.md)].\n\nIf you want to autodetection the people with web camera, you need to install [[OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose)]. \n\n\n## Parameters setting\nIf you want to use Openpose, in `./makefile`, set `OPENPOSE=1`, else set `OPENPOSE=0`.\n\nChange the datasets, in `inputs/readdatasets.hpp`, change the number of `string databaseType = databaseTypes[1];`\n\nChange the path of datasets, in `inputs/readdatasets.cc`, change the `path` to your path of data.\n\n## To use web camera with openpose\nBy raising your two arms higher than your nose, it will atomatically detect the person and start the tracking programme.\n\n\n## Run to compare all the trackers at the same time\n```\nmake all\nsudo make install\n./trackerscompare.bin\n```\n\n## Run ECO\n### Compile without Caffe\nIf you don\'t want to compile with Caffe, that means you cannot use Deep features, set in **eco/makefile**: `USE_CAFFE=0`.\n\nIf you don\'t want to compile with CUDA, that means you cannot use Deep features, set in **eco/makefile**: `USE_CUDA=0`.\n\n### Compile with Caffe\nIf you want to compile with Caffe, set in **makefile** and **eco/makefile**: `USE_CAFFE=1 USE_CUDA=1`, and set the according caffe path of your system in **eco/makefile**:\n```\nCAFFE_PATH=<YOUR_CAFFE_PATH>\n```\n\nDownload a pretrained [[VGG_CNN_M_2048.caffemodel (370 MB)](https://drive.google.com/file/d/1-kYYCcTR7gBZyHM5oVChNvu0Q9XPdva3/view?usp=sharing)], put it into folder: **eco/model**\n\nIf you could not download through the link above (especially for the people from Mainland China), check this [[link](https://gist.github.com/ksimonyan/78047f3591446d1d7b91#file-readme-md)] and download. \n\nIn **eco/parameters.hpp**, change the path to your path:\n```\nstruct CnnParameters\n{\n\tstring proto = "<YOUR_PATH>/OpenTracker/eco/model/imagenet-vgg-m-2048.prototxt";\n\tstring model = "<YOUR_PATH>/OpenTracker/eco/model/VGG_CNN_M_2048.caffemodel";\n\tstring mean_file = "<YOUR_PATH>/OpenTracker/eco/model/VGG_mean.binaryproto";\n```\n\n### Use CN feature\nIn **eco/runecotracker.cc**, change the path:\n```\n    parameters.useCnFeature = true;\n    parameters.cn_features.fparams.tablename = "<YOUR_PATH>/OpenTracker/eco/look_tables/CNnorm.txt"\n```\n\n### Speed-up with SIMD\nIf you are using Intel computer, in `eco\\makefile`, set:\n```\nUSE_SIMD=1\n```\nIf you are using ARM like Jetson TX1/2, in `eco\\makefile`, set:\n```\nUSE_SIMD=2\n```\nIf you are using ARM like Rasberrypi 3, in `eco\\makefile`, set:\n```\nUSE_SIMD=3\n```\n\n### Speed-up with multi-thread\nIn `eco\\makefile`, set:\n```\nUSE_MULTI_THREAD=1\n```\n\n### Speed-up with GPU (not yet implemented)\nIf you have a GPU, it can speed-up with gpu.\n\nFirst don\'t forget to install Opencv with CUDA supported:\n```\ncmake -D OPENCV_EXTRA_MODULE_PATH=/media/elab/sdd/Amy/opencv_contrib/modules \\\n    -D CMAKE_BUILD_TYPE=RELEASE \\\n    -D CMAKE_INSTALL_PREFIX=/usr/local \\\n    -D CMAKE_BUILD_TYPE=RELEASE \\\n    -D CMAKE_INSTALL_PREFIX=/usr/local \\\n    -D WITH_CUDA=ON \\\n    -D ENABLE_FAST_MATH=1 \\\n    -D CUDA_FAST_MATH=1 \\\n    -D WITH_CUBLAS=1 \\\n    ..\nmake -j`nproc` \nsudo make install\n```\nin `eco/makefile`, set:\n```\nUSE_CUDA=1\n```\n\n### Datasets settings\nChange the path of your test images in **eco/runecotracker.cc**.\n\nChange the datasets, in **eco/runecotracker.cc**, change the number of `string databaseType = databaseTypes[1];`.\n\n### Show heatmap\nIf you want to show the heatmap of the tracking, in **eco/parameters.cc**, change to `#define DEBUG 1`.\n\n### Compile and Run:\n```\ncd eco\nmake -j`nproc`\n./runecotracker.bin\n```\n\n## Run Opencv trackers\nChange the path of your test images in **kcf/opencvtrackers.cc**.\n```\ncd opencvtrackers\nmake \n./opencvtrackers.bin\n```\n\n## Run KCF / DSST\nChange the path of your test images in **kcf/runkcftracker.cc**.\n```\ncd kcf\nmake -j`nproc`\n./runkcftracker.bin\n```\n\n## Run GOTURN\nChange the path of your test images in **goturn/rungoturntracker.cc**.\n\n### Pretrained model\nYou can download a pretrained [[goturun_tracker.caffemodel (434 MB)](https://drive.google.com/file/d/1uc9k8sTqug_EY9kv1v_QnrDxjkrTJejR/view?usp=sharing)], put it into folder: **goturn/nets**\n\n```\ncd goturn\nmake -j`nproc`\n./rungoturntracker.bin\n```\n\n### Run caffe classification for simple test\n```\n./classification.bin   /media/elab/sdd/caffe/models/bvlc_reference_caffenet/deploy.prototxt   /media/elab/sdd/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel   /media/elab/sdd/caffe/data/ilsvrc12/imagenet_mean.binaryproto   /media/elab/sdd/caffe/data/ilsvrc12/synset_words.txt   /media/elab/sdd/caffe/examples/images/cat.jpg\n```\n\n## Run all trackers\n**ATTENTION!** Make sure that the parameter settings in `makefile` and `eco/makefile` are the same, else it will be errors!\n\n# How to use the API of the OpenTracker?\nTo use the API of the trackers is really simple, just two steps. Check `example/readme.md`.\n\n# References \n--------------------------------\n(not complete, tell me if I forgot you)\n\n## GOTURN Tracker\n**[Learning to Track at 100 FPS with Deep Regression Networks](http://davheld.github.io/GOTURN/GOTURN.html)**,\n<br>\n[David Held](http://davheld.github.io/),\n[Sebastian Thrun](http://robots.stanford.edu/),\n[Silvio Savarese](http://cvgl.stanford.edu/silvio/),\n<br>\nEuropean Conference on Computer Vision (ECCV), 2016 (In press)\n\n## KCF Tracker\nJ. F. Henriques, R. Caseiro, P. Martins, J. Batista,   \n"High-Speed Tracking with Kernelized Correlation Filters", TPAMI 2015.\n\n## CSK Tracker\nJ. F. Henriques, R. Caseiro, P. Martins, J. Batista,   \n"Exploiting the Circulant Structure of Tracking-by-detection with Kernels", ECCV 2012.\n\n## ECO Tracker\nMartin Danelljan, Goutam Bhat, Fahad Khan, Michael Felsberg.  \n<a href="https://arxiv.org/abs/1611.09224">ECO: Efficient Convolution Operators for Tracking</a>.  \nIn Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017. \n\n## C-COT Tracker\nMartin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg.  \n    Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking.  \n    In Proceedings of the European Conference on Computer Vision (ECCV), 2016.  \n    http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/index.html\n    \n## SRDCF Tracker\nMartin Danelljan, Gustav H\xc3\xa4ger, Fahad Khan, Michael Felsberg.  \n    Learning Spatially Regularized Correlation Filters for Visual Tracking.  \n    In Proceedings of the International Conference in Computer Vision (ICCV), 2015.  \n    http://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/index.html\n\n## SRDCF-Deep Tracker\nMartin Danelljan, Gustav H\xc3\xa4ger, Fahad Khan, Michael Felsberg.  \n    Convolutional Features for Correlation Filter Based Visual Tracking.  \n    ICCV workshop on the Visual Object Tracking (VOT) Challenge, 2015.  \n    http://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/index.html\n\t\n## DSST Tracker\nMartin Danelljan, Gustav H\xc3\xa4ger, Fahad Khan and Michael Felsberg.  \n    Accurate Scale Estimation for Robust Visual Tracking.  \n    In Proceedings of the British Machine Vision Conference (BMVC), 2014.  \n    http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/index.html\n    \n\nMartin Danelljan, Gustav H\xc3\xa4ger, Fahad Khan, Michael Felsberg.  \n    Discriminative Scale Space Tracking.  \n    Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017.  \n    http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/index.html\n\n## HOG feature\nN. Dalal and B. Triggs.  \n    Histograms of oriented gradients for human detection.  \n    In CVPR, 2005. \n\n## Color Names feature\nJ. van de Weijer, C. Schmid, J. J. Verbeek, and D. Larlus.  \n    Learning color names for real-world applications.  \n    TIP, 18(7):1512\xe2\x80\x931524, 2009.  \n\n## OBT database\n Y. Wu, J. Lim, and M.-H. Yang.  \n    Online object tracking: A benchmark.  \n    TPAMI 37(9), 1834-1848 (2015).  \n    https://sites.google.com/site/trackerbenchmark/benchmarks/v10\n\n Y. Wu, J. Lim, and M.-H. Yang.  \n    Object tracking benchmark.  \n    In CVPR, 2013.  \n\n## VOT database\nhttp://votchallenge.net/\n\n\n## Some code references\n\nKCF: [joaofaro/KCFcpp](https://github.com/joaofaro/KCFcpp).\n\nDSST: [liliumao/KCF-DSST](https://github.com/liliumao/KCF-DSST), the max_scale_factor and min_scale_factor is set to 10 and 0.1 in case of divergence error (Tested on UAV123 dataset when the object is quite small, ex.uav2/3/4...).\n\nGOTURN: [davheld/GOTURN](https://github.com/davheld/GOTURN).\n\nECO: [martin-danelljan/ECO](https://github.com/martin-danelljan/ECO).\n\n\n\n\n'