b"# Self-Driving Pi Car \n\n[![Build Status](https://travis-ci.org/felipessalvatore/self_driving_pi_car.svg?branch=python3)](https://travis-ci.org/felipessalvatore/self_driving_pi_car)\n[![License](https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000)](https://github.com/felipessalvatore/self_driving_pi_car/blob/master/LICENSE)\n\n## Introduction\n\nSelf-Driving Pi Car is a deep neural network based self-driving car, that combines Lego Mindstorms NXT with the computational power of a Raspberry Pi 3.\n\nThis repository was created by [Paula Moraes](https://github.com/paulaksm) and [Felipe Salvatore](https://github.com/felipessalvatore).\n\n<p align = 'center'>\n<img src = 'images/track.png' height = '270px'>\n</p>\n<p align = 'center'>\nRobot driving on a track\n</p>\n\nYou can read more about the project on [Medium](https://medium.com/@project_m/self-drives-me-crazy-from-0-to-self-driving-car-in-150-hours-bf4f68d50d8a)\n\n## Getting Started\n\n### Install\n\nThe first thing you need to do is to install all the libraries for the Raspberry Pi. To do so, open a terminal in Raspberry Pi and run:\n\n```\n$ cd raspi_utils/\n$ bash install.sh\n```\n\nIn the computer that you will perform the training -- protip: don't train the model in the Raspberry Pi! -- install all the requirements by runnig:\n\n```\n$ pip install -r requirements.txt\n```\n\n## Usage\n\n**Attention:**\nin the master branch all python code is written for Python 2. If you would like to run this project in Python 3, please switch to the python3 branch of this repository.\n\n\n### Collecting data\n\nBefore doing any kind of training you need to collect the track data. So in the Raspberry Pi -- with the assembled robot -- run the data collection script:\n```\n  $ cd self_driving/data_collection/ \n  $ python DataCollector.py -n <images_folder_name>\n```\n\nPressing `q` will stop execution and save all images and pickle file.\n\nInside the folder `<images_folder_name>` there will be subdirectories organized by timestamps similar to `2018-02-17-23-27-02` with the collected `*.png` images. All the associated labels are saved in a pickle file `2018-02-17-23-27-02_pickle` in `<images_folder_name>`.\n\nCompress `<images_folder_name>` directory and export it from Raspberry Pi to other computer (using scp command, cloud, email, etc).\n```\n  $ tar cvf <images_folder_name>.tar <images_folder_name>\n```\n\n\n**Attention:**\nplease continue following the instructions in the computer that will be use for training.\n\n\n### Generating npy and tfrecords\n\nBefore generating tfrecords, you need to transform the untar `<images_folder_name>` containing all folders of images and pickles into a tuple of np.arrays. Running the following script will result in the creation of `<npy_files_name>_90_160_3_data.npy` and `<npy_files_name>_90_160_3_labels.npy` files:\n```\n  $ cd self_driving/data_manipulation/\n  $ python img2array.py <images_folder_path> <npy_folder_path> <npy_files_name>\n```\n\nTo generate tfrecords from `*.npy` and augment or manipulate (e.g. binarize) the data, run:\n ```\n  $ cd ../ml_training/ \n  $ python generate_tfrecords.py <npy_data_path> <npy_labels_path> -n <name_tfrecords> \n```\n\nResulting in `<name_tfrecords>_train.tfrecords`, `<name_tfrecords>_test.tfrecords` and `<name_tfrecords>_valid.tfrecords` files.\n\n\n\n### Hyperparameters optimization\n\n**Attention:**\nall code in this section can be runned on both Python 2 and 3 with TensorFlow 1.2.1 (and above) and with GPU support, if possible.\n\nNow it's time to test different architectures, learning rates and optimizers, in the hopes of improving accuracy. \n\n\n#### Best architecture search\n\nRunning the following script will create `architecture_results.txt` file with the results for a given configuration passed through optional arguments.\n ```\n  $ python best_architecture.py -n <name_tfrecords>\n```\n\n\n#### Best learning rate search\n\nRunning the following script will create `learning_rate_results.txt` file with the results for a given configuration passed through optional arguments.\n ```\n  $ python best_learning_rate.py -n <name_tfrecords>\n```\n\n\n#### Best optimizer search\n\nRunning the following script will create `optimizer_results.txt` file with the results for a given configuration passed through optional arguments.\n ```\n  $ python best_optimizer.py -n <name_tfrecords>\n```\n\n\n### Training the model \n\n**Attention:**\nback to Python 2\n\nAfter searching for an appropriate combination of hyperparameters, you must train the model running this script with additional arguments relative to the model:\n\n```\n  $ python train.py -n <name_tfrecords> -v\n```\n\nThe result will be a `checkpoints` directory with all files needed to deploy the model.\n\n\n#### Accuracy test\n\nYou can test for accuracy with the script:\n\n```\n  $ python acc_test.py -n <name_tfrecords>\n```\n\n\n#### Simulation\n\nBefore going live, it's possible to simulate the model in action with track images. This simulation script uses `checkpoints` and `<images_folder_path>` to generate new images, saved on `<output_images_folder_path>`, with a stamp of the probabilities for each class.\n\n```\n  $ cd ../\n  $ python simulation.py <images_folder_path> <output_images_folder_path>\n```\n\nExample:\n<p align = 'left'>\n<img src = 'images/run_readme.gif'>\n</p>\n\n\n### Self-driving \n\n**Attention:**\nthis section must be run on Raspberry Pi.\n\nAfter training the model and loading its `checkpoints` to Raspberry Pi, there will be two modes available: **regular** and **debug**. \n\nOn ___regular mode___, the car will take an action based on the model's prediction given an image took by the camera. Pressing `q` will stop the execution:\n\n```\n$ python DiffController.py \n```\n\nThe __debug mode__ works in the same way as regular, but also creates a `debug-run` directory containing all images taken during execution with a stamp of the probabilities for each class. Pressing `q` will stop the execution:\n\n```\n$ python DiffController.py -d\n```\n\n\n\n### Running the tests\n\nThere is two kind of tests: the ones from the Raspberry Pi and the ones for the training computer.\nIn the Raspberry Pi run\n\n```\n$ python setup.py test \n```\nThese tests serve to check if the conection with the NXT robot is working.\n\nAnd in the training computer\n```\n  $ bash test_script.sh \n```\nThese last tests check if the image manipulation functions and the tensorflow model are doing what they suppose to be doing.\n\n\n\n## Built With\n\n* [Tensorflow](https://www.tensorflow.org/)\n* [NXT-Python](https://github.com/Eelviny/nxt-python)\n\n\n### Citation\n```\n  @misc{self_driving_pi_car2018,\n    author = {Paula Moraes and Felipe Salvatore},\n    title = {Self-Driving Pi Car},\n    year = {2018},\n    howpublished = {\\url{https://github.com/felipessalvatore/self_driving_pi_car}},\n    note = {commit xxxxxxx}\n  }\n```\n"