b'# ImageAI (v2.1.5)\n\n![Discourse status](https://img.shields.io/discourse/https/forum.imageai.org/status) [![Build Status](https://travis-ci.com/OlafenwaMoses/ImageAI.svg?branch=master)](https://travis-ci.com/OlafenwaMoses/ImageAI)  [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/OlafenwaMoses/ImageAI/blob/master/LICENSE) [![PyPI version](https://badge.fury.io/py/imageai.svg)](https://badge.fury.io/py/imageai)   [![Downloads](https://pepy.tech/badge/imageai/month)](https://pepy.tech/project/imageai/month) [![Downloads](https://pepy.tech/badge/imageai/week)](https://pepy.tech/project/imageai/week) [![codecov](https://codecov.io/gh/TechnionYP5777/project-name/branch/master/graph/badge.svg)](https://codecov.io/gh/OlafenwaMoses/ImageAI) \n\nAn open-source python library built to empower developers to build applications and systems with self-contained Deep Learning and Computer Vision capabilities using simple\n and few lines of code.\n \n If you will like to back this project, kindly visit the <strong>Patreon</strong> page by clicking the badge below.\n \n <span class="badge-patreon"><a href="https://patreon.com/OlafenwaMoses" title="Donate to this project using Patreon"><img src="https://img.shields.io/badge/patreon-donate-yellow.svg" alt="Patreon donate button" /></a></span> \n \n![](logo1.png)\n\nAn **DeepQuest AI** (A Brand of AI Commons Global Limited)  project [deepquestai.com](https://deepquestai.com).\n\nDeveloped and Maintained by [Moses Olafenwa](https://twitter.com/OlafenwaMoses) and [John Olafenwa](https://twitter.com/johnolafenwa), brothers, creators of [TorchFusion](https://github.com/johnolafenwa/TorchFusion), Authors of [Introduction to Deep Computer Vision](https://john.aicommons.science/deepvision) and creators of [DeepStack AI Server](https://deepstack.cc).\n\n---\n\nBuilt with simplicity in mind, **ImageAI** \n    supports a list of state-of-the-art Machine Learning algorithms for image prediction, custom image prediction, object detection, video detection, video object tracking\n    and image predictions trainings. **ImageAI** currently supports image prediction and training using 4 different Machine Learning algorithms \n    trained on the ImageNet-1000 dataset. **ImageAI** also supports object detection, video detection and object tracking  using RetinaNet, YOLOv3 and TinyYOLOv3 trained on COCO dataset. Finally, **ImageAI** allows you to train custom models for performing detection and recognition of new objects. \n   \nEventually, **ImageAI** will provide support for a wider\n    and more specialized aspects of Computer Vision including and not limited to image \n    recognition in special environments and special fields.\n\n\n**New Release : ImageAI 2.1.5**\n\nWhat\'s new:\n\n- **Tensorboard** logging for all prediction and detection model training.\n- **Progress bar** for detection training\n- Allow prediction and detection in multi-threaded code\n- Automatic **Multi-GPU** utilization for detection training\n- Custom detection model **metrics** retrieval\n- Bug fix: change custom model probability from **string to float**\n\n\n### TABLE OF CONTENTS\n- <a href="#dependencies" > :white_square_button: Dependencies</a>\n- <a href="#installation" > :white_square_button: Installation</a>\n- <a href="#prediction" > :white_square_button: Image Prediction</a>\n- <a href="#detection" > :white_square_button: Object Detection</a><br>\n- <a href="#videodetection" > :white_square_button: Video Object Detection, Tracking & Analysis</a>\n- <a href="#customtraining" > :white_square_button: Custom Model Training</a>\n- <a href="#customprediction" > :white_square_button: Custom Image Prediction</a>\n- <a href="#customdetectiontraining" > :white_square_button: Custom Detection Model Training</a>\n- <a href="#customdetection" > :white_square_button: Custom Object Detection</a>\n- <a href="#customvideodetection" > :white_square_button: Custom Video Object Detection & Analysis</a>\n- <a href="#documentation" > :white_square_button: Documentation</a>\n- <a href="#sample" > :white_square_button: Projects Built on ImageAI</a>\n- <a href="#real-time-and-high-performance-implementation" > :white_square_button: High Performance Implementation</a>\n- <a href="#recommendation" > :white_square_button: AI Practice Recommendations</a>\n- <a href="#contact" > :white_square_button: Contact Developers</a>\n- <a href="#citation" > :white_square_button: Citation</a>\n- <a href="#contributors" > :white_square_button: Contributors</a>\n- <a href="#ref" > :white_square_button: References</a>\n\n\n\n### Dependencies\n<div id="dependencies"></div>\n\nTo use **ImageAI** in your application developments, you must have installed the following \n dependencies before you install **ImageAI** : \n \n - Python 3.5.1 (and later versions)\n - Tensorflow 1.4.0 (and later versions) **(Tensorflow 2.0 coming soon)**\n - OpenCV \n - Keras 2.x \n \n ```bash\npip install -U tensorflow keras opencv-python\n```\n\n### Installation\n<div id="installation"></div>\n \nTo install ImageAI, run the python installation instruction below in the command line:\n\n```bash\npip3 install imageai --upgrade\n```\n\n### Image Prediction\n<div id="prediction"></div>\n\n![](./data-images/1.jpg)\n \n```\nconvertible : 52.459555864334106\nsports_car : 37.61284649372101\npickup : 3.1751200556755066\ncar_wheel : 1.817505806684494\nminivan : 1.7487050965428352\n```\n\n**ImageAI** provides 4 different algorithms and model types to perform image prediction, trained on the ImageNet-1000 dataset.\nThe 4 algorithms provided for image prediction include **SqueezeNet**, **ResNet**, **InceptionV3** and **DenseNet**. \n\nClick the link below to see the full sample codes, explanations and best practices guide.\n\n[>>> Tutorial & Guide](imageai/Prediction/README.md)\n\n\n### Object Detection\n<div id="detection"></div>\n\n![Input Image](./data-images/image2.jpg)\n![Output Image](./data-images/image2new.jpg)\n\n```\nperson : 91.946941614151\n--------------------------------\nperson : 73.61021637916565\n--------------------------------\nlaptop : 90.24320840835571\n--------------------------------\nlaptop : 73.6881673336029\n--------------------------------\nlaptop : 95.16398310661316\n--------------------------------\nperson : 87.10319399833679\n--------------------------------\n```\n\n**ImageAI** provides very convenient and powerful methods to perform object detection on images and extract each object from the image.\nThe object detection class provides support for RetinaNet, YOLOv3 and TinyYOLOv3, with options to adjust for state of the art performance or real time processing.\n\nClick the link below to see the full sample codes, explanations and best practices guide.\n\n\n[>>> Tutorial & Guide](imageai/Detection/README.md)\n\n\n### Video Object Detection and Tracking\n<div id="videodetection"></div>\n\n**Video Object Detection & Analysis**\n\n_Below is a snapshot of a video with objects detected._\n\n![](./data-images/video1.jpg)\n          \n**Video Custom Object Detection (Object Tracking)**\n\n_Below is a snapshot of a video with only person, bicycle and motorcyle detected._\n\n![](./data-images/video2.jpg)\n\n**Video Analysis Visualization**\n\n_Below is a visualization of video analysis returned by **ImageAI** into a \'per_second\' function._\n\n![](./data-images/video_analysis_visualization.jpg)\n\n**ImageAI** provides very convenient and powerful methods to perform object detection in videos and track specific object(s).\nThe video object detection class provided only supports  the current state-of-the-art RetinaNet, but with options to adjust for state of the art performance or real time processing.\nClick the link to see the full videos, sample codes, explanations and best practices guide.\n\n\n[>>> Tutorial & Guide](imageai/Detection/VIDEO.md)\n\n### Custom Model Training\n<div id="customtraining"></div>\n\n_A sample from the IdenProf Dataset used to train a Model for predicting professionals._\n\n![](./data-images/idenprof.jpg)\n\n\n**ImageAI** provides classes and methods for you to train a new model that can be used to perform prediction on your own custom objects.\nYou can train your custom models using SqueezeNet, ResNet50, InceptionV3 and DenseNet in  **5** lines of code.\nClick the link below to see the guide to preparing training images, sample training codes, explanations and best practices.\n\n[>>> Tutorials & Documentation](imageai/Prediction/CUSTOMTRAINING.md)\n\n\n### Custom Image Prediction\n<div id="customprediction"></div>\n\n_Prediction from a sample model trained on IdenProf, for predicting professionals_\n\n![](./data-images/4.jpg)\n\n```\nmechanic : 76.82620286941528\nchef : 10.106072574853897\nwaiter : 4.036874696612358\npolice : 2.6663416996598244\npilot : 2.239348366856575\n```\n\n**ImageAI** provides classes and methods for you to run image prediction your own custom objects using your own model trained with **ImageAI** Model Training class.\nYou can use your custom models trained with SqueezeNet, ResNet50, InceptionV3 and DenseNet and the JSON file containing the mapping of the custom object names.\nClick the link below to see the guide to sample training codes, explanations, and best practices guide.\n\n\n[>>> Tutorials & Documentation](imageai/Prediction/CUSTOMPREDICTION.md)\n\n\n\n### Custom Detection Model Training\n<div id="customdetectiontraining"></div>\n\n_Training detection models to detect and recognize new objects._\n\n![](./data-images/headsets.jpg)\n\n**ImageAI** provides classes and methods for you to train new **YOLOv3** object detection models on your **custom dataset**.\nThis means you can train a model to detect literally any object of interest by providing the images, the annotations and training with ImageAI.\nClick the link below to see the guide to sample training codes, explanations, and best practices guide.\n\n\n[>>> Tutorials & Documentation](imageai/Detection/Custom/CUSTOMDETECTIONTRAINING.md)\n\n\n### Custom Object Detection\n<div id="customdetection"></div>\n\n_Detection result from a custom YOLOv3 model trained to detect the Hololens headset._\n\n![](./data-images/holo2-detected.jpg)\n\n```\nhololens  :  39.69653248786926  :  [611, 74, 751, 154]\nhololens  :  87.6643180847168  :  [23, 46, 90, 79]\nhololens  :  89.25175070762634  :  [191, 66, 243, 95]\nhololens  :  64.49641585350037  :  [437, 81, 514, 133]\nhololens  :  91.78624749183655  :  [380, 113, 423, 138]\n```\n\n**ImageAI** now provides classes and methods for you detect and recognize your own custom objects in images using your own model trained with the **DetectionModelTraining** class.\nYou can use your custom trained **YOLOv3** mode and the **detection_config.json** file generated during the training.\nClick the link below to see the guide to sample training codes, explanations, and best practices guide.\n\n\n[>>> Tutorials & Documentation](imageai/Detection/Custom/CUSTOMDETECTION.md)\n\n\n\n\n### Custom Video Object Detection & Analysis \n<div id="customvideodetection"></div>\n\n\n_Video Detection result from a custom YOLOv3 model trained to detect the Hololens headset in a video._\n\n![](./data-images/customvideodetection.gif)\n      \n    \n\nNow you can use your custom trained **YOLOv3** model to detect, recognize and analyze objects in videos.\nClick the link below to see the guide to sample training codes, explanations, and best practices guide.\n\n\n\n[>>> Tutorials & Documentation](imageai/Detection/Custom/CUSTOMVIDEODETECTION.md)\n\n\n\n### Documentation\n<div id="documentation"></div>\n\nWe have provided full documentation for all **ImageAI** classes and functions in 2 major languages. Find links below:\n\n- Documentation - **English Version**  [https://imageai.readthedocs.io](https://imageai.readthedocs.io)\n- Documentation - **Chinese Version**  [https://imageai-cn.readthedocs.io](https://imageai-cn.readthedocs.io)\n- Documentation - **French Version**  [https://imageai-fr.readthedocs.io](https://imageai-fr.readthedocs.io)\n\n\n\n### Real-Time and High Performance Implementation\n<div id="performance"></div>\n\n**ImageAI** provides abstracted and convenient implementations of state-of-the-art Computer Vision technologies. All of **ImageAI** implementations and code can work on any computer system with moderate CPU capacity. However, the speed of processing for operations like image prediction, object detection and others on CPU is slow and not suitable for real-time applications. To perform real-time Computer Vision operations with high performance, you need to use GPU enabled technologies.\n\n**ImageAI** uses the Tensorflow backbone for it\'s Computer Vision operations. Tensorflow supports both CPUs and GPUs ( Specifically NVIDIA GPUs.  You can get one for your PC or get a PC that has one) for machine learning and artificial intelligence algorithms\' implementations. To use Tensorflow that supports the use of GPUs, follow the link below :\n\n\n* FOR WINDOWS - [install_windows](https://www.tensorflow.org/install/install_windows)\n* FOR macOS - [install_mac](https://www.tensorflow.org/install/install_mac)\n* FOR UBUNTU - [install_linux](https://www.tensorflow.org/install/install_linux)\n\n\n### Projects Built on ImageAI\n<div id="sample"></div>\n\n\n<u> [BatBot](https://github.com/LeeHounshell/BatBot) :</u> BatBot is an open source Intelligent Research Robot with image and speech recognition. It comes with an Android App which allows you to speak voice commands and instruct the robot to find objects using its camera and an AI engine powered by **ImageAI**. It also allows you to re-train and improve the AI capabilities from new images captured by the robot. Learn more about the incredible capabilities and components of **BatBot** via the [GitHub repository](https://github.com/LeeHounshell/BatBot) . It is developed and maintained by [Lee Hounshell](https://github.com/LeeHounshell)\n\n\n\n We also welcome submissions of applications and systems built by you and powered by ImageAI for listings here.\n Should you want your ImageAI powered developments listed here, you can reach to us via our <a href="#contact" >Contacts</a> below.\n\n\n\n ### AI Practice Recommendations\n<div id="recommendation"></div>\n\nFor anyone interested in building AI systems and using them for business, economic,  social and research purposes, it is critical that the person knows the likely positive, negative and unprecedented impacts the use of such technologies will have.\nThey must also be aware of approaches and practices recommended by experienced industry experts to ensure every use of AI brings overall benefit to mankind.\nWe therefore recommend to everyone that wishes to use ImageAI and other AI tools and resources to read Microsoft\'s January 2018 publication on AI titled "The Future Computed : Artificial Intelligence and its role in society".\nKindly follow the link below to download the publication.\n\n[https://blogs.microsoft.com/blog/2018/01/17/future-computed-artificial-intelligence-role-society](https://blogs.microsoft.com/blog/2018/01/17/future-computed-artificial-intelligence-role-society/)\n\n### Contact Developer\n<div id="contact"></div>\n\n- **Moses Olafenwa**\n    * _Email:_ guymodscientist@gmail.com\n    * _Website:_ [http://olafenwamoses.me](http://olafenwamoses.me)\n    * _Twitter:_ [@OlafenwaMoses](https://twitter.com/OlafenwaMoses)\n    * _Medium:_ [@guymodscientist](https://medium.com/@guymodscientist)\n    * _Facebook:_ [moses.olafenwa](https://facebook.com/moses.olafenwa)\n- **Moses Olafenwa**\n    * _Email:_ johnolafenwa@gmail.com\n    * _Website:_ [https://john.aicommons.science](https://john.aicommons.science)\n    * _Twitter:_ [@johnolafenwa](https://twitter.com/johnolafenwa)\n    * _Medium:_ [@johnolafenwa](https://medium.com/@johnolafenwa)\n    * _Facebook:_ [olafenwajohn](https://facebook.com/olafenwajohn)\n\n\n### Contributors\n<div id="contact"></div>\n\nWe are inviting anyone who wishes to contribute to the **ImageAI** project to reach to us. We primarily need contributions in translating the documentation of the project\'s code to major languages that includes but not limited to French, Spanish, Portuguese, Arabian and more. We want every developer and researcher around the world to benefit from this project irrespective of their native languages.\n\nWe give special thanks to **[Kang vcar](https://github.com/kangvcar/)** for his incredible and excellent work in translating **ImageAI**\'s documentation to the Chinese language. Find below the contact details of those who have contributed immensely to the **ImageAI** project.\n\n- **Kang vcar**\n    * _Email:_ kangvcar@mail.com\n    * _Website:_ [http://www.kangvcar.com](http://www.kangvcar.com)\n    * _Twitter:_ [@kangvcar](https://twitter.com/kangvcar)\n \n\n\n\n### Citation\n<div id="citation"></div>\n\nYou can cite **ImageAI** in your projects and research papers via the **BibTeX** entry below.  \n  \n```\n@misc {ImageAI,\n    author = "Moses and John Olafenwa",\n    title  = "ImageAI, an open source python library built to empower developers to build applications and systems  with self-contained Computer Vision capabilities",\n    url    = "https://github.com/OlafenwaMoses/ImageAI",\n    month  = "mar",\n    year   = "2018--"\n}\n```\n\n\n ### References\n <div id="ref"></div>\n\n 1. Somshubra Majumdar, DenseNet Implementation of the paper, Densely Connected Convolutional Networks in Keras\n[https://github.com/titu1994/DenseNet](https://github.com/titu1994/DenseNet)\n 2. Broad Institute of MIT and Harvard, Keras package for deep residual networks\n[https://github.com/broadinstitute/keras-resnet](https://github.com/broadinstitute/keras-resnet)\n 3. Fizyr, Keras implementation of RetinaNet object detection\n[https://github.com/fizyr/keras-retinanet](https://github.com/fizyr/keras-retinanet)\n 4. Francois Chollet, Keras code and weights files for popular deeplearning models\n[https://github.com/fchollet/deep-learning-models](https://github.com/fchollet/deep-learning-models)\n 5. Forrest N. et al, SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size\n[https://arxiv.org/abs/1602.07360](https://arxiv.org/abs/1602.07360)\n 6. Kaiming H. et al, Deep Residual Learning for Image Recognition\n[https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)\n 7. Szegedy. et al, Rethinking the Inception Architecture for Computer Vision\n[https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567)\n 8. Gao. et al, Densely Connected Convolutional Networks\n[https://arxiv.org/abs/1608.06993](https://arxiv.org/abs/1608.06993)\n 9. Tsung-Yi. et al, Focal Loss for Dense Object Detection\n[https://arxiv.org/abs/1708.02002](https://arxiv.org/abs/1708.02002)\n 10. O Russakovsky et al, ImageNet Large Scale Visual Recognition Challenge\n[https://arxiv.org/abs/1409.0575](https://arxiv.org/abs/1409.0575)\n 11. TY Lin et al, Microsoft COCO: Common Objects in Context\n[https://arxiv.org/abs/1405.0312](https://arxiv.org/abs/1405.0312)\n 12. Moses & John Olafenwa, A collection of images of identifiable professionals.\n[https://github.com/OlafenwaMoses/IdenProf](https://github.com/OlafenwaMoses/IdenProf)\n 13. Joseph Redmon and Ali Farhadi, YOLOv3: An Incremental Improvement.\n[https://arxiv.org/abs/1804.02767](https://arxiv.org/abs/1804.02767)\n 14. Experiencor, Training and Detecting Objects with YOLO3\n[https://github.com/experiencor/keras-yolo3](https://github.com/experiencor/keras-yolo3)\n'