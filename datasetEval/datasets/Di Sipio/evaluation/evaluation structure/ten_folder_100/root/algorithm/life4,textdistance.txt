b'# TextDistance\n\n![TextDistance logo](logo.png)\n\n[![Build Status](https://travis-ci.org/life4/textdistance.svg?branch=master)](https://travis-ci.org/life4/textdistance) [![PyPI version](https://img.shields.io/pypi/v/textdistance.svg)](https://pypi.python.org/pypi/textdistance) [![Status](https://img.shields.io/pypi/status/textdistance.svg)](https://pypi.python.org/pypi/textdistance) [![Code size](https://img.shields.io/github/languages/code-size/life4/textdistance.svg)](https://github.com/life4/textdistance) [![License](https://img.shields.io/pypi/l/textdistance.svg)](LICENSE)\n\n**TextDistance** -- python library for comparing distance between two or more sequences by many algorithms.\n\nFeatures:\n\n* 30+ algorithms\n* Pure python implementation\n* Simple usage\n* More than two sequences comparing\n* Some algorithms have more than one implementation in one class.\n* Optional numpy usage for maximum speed.\n\n## Algorithms\n\n### Edit based\n\n| Algorithm                                                                                 | Class                | Functions              |\n|-------------------------------------------------------------------------------------------|----------------------|------------------------|\n| [Hamming](https://en.wikipedia.org/wiki/Hamming_distance)                                 | `Hamming`            | `hamming`              |\n| [MLIPNS](http://www.sial.iias.spb.su/files/386-386-1-PB.pdf)                              | `Mlipns`             | `mlipns`               |\n| [Levenshtein](https://en.wikipedia.org/wiki/Levenshtein_distance)                         | `Levenshtein`        | `levenshtein`          |\n| [Damerau-Levenshtein](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance) | `DamerauLevenshtein` | `damerau_levenshtein`  |\n| [Jaro-Winkler](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance)               | `JaroWinkler`        | `jaro_winkler`, `jaro` |\n| [Strcmp95](http://cpansearch.perl.org/src/SCW/Text-JaroWinkler-0.1/strcmp95.c)            | `StrCmp95`           | `strcmp95`             |\n| [Needleman-Wunsch](https://en.wikipedia.org/wiki/Needleman%E2%80%93Wunsch_algorithm)      | `NeedlemanWunsch`    | `needleman_wunsch`     |\n| [Gotoh](https://www.cs.umd.edu/class/spring2003/cmsc838t/papers/gotoh1982.pdf)            | `Gotoh`              | `gotoh`                |\n| [Smith-Waterman](https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm)          | `SmithWaterman`      | `smith_waterman`       |\n\n### Token based\n\n| Algorithm                                                                                 | Class                | Functions     |\n|-------------------------------------------------------------------------------------------|----------------------|---------------|\n| [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index)                              | `Jaccard`            | `jaccard`     |\n| [S\xc3\xb8rensen\xe2\x80\x93Dice coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient) | `Sorensen`   | `sorensen`, `sorensen_dice`, `dice` |\n| [Tversky index](https://en.wikipedia.org/wiki/Tversky_index)                              | `Tversky`            | `tversky`    |\n| [Overlap coefficient](https://en.wikipedia.org/wiki/Overlap_coefficient)                  | `Overlap`            | `overlap`    |\n| [Tanimoto distance](https://en.wikipedia.org/wiki/Jaccard_index#Tanimoto_similarity_and_distance) | `Tanimoto`   | `tanimoto`   |\n| [Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity)                      | `Cosine`             | `cosine`     |\n| [Monge-Elkan](https://www.academia.edu/200314/Generalized_Monge-Elkan_Method_for_Approximate_Text_String_Comparison) | `MongeElkan` | `monge_elkan` |\n| [Bag distance](https://github.com/Yomguithereal/talisman/blob/master/src/metrics/distance/bag.js) | `Bag`        | `bag`        |\n\n### Sequence based\n\n| Algorithm | Class | Functions |\n|-----------|-------|-----------|\n| [longest common subsequence similarity](https://en.wikipedia.org/wiki/Longest_common_subsequence_problem)          | `LCSSeq` | `lcsseq` |\n| [longest common substring similarity](https://docs.python.org/2/library/difflib.html#difflib.SequenceMatcher)      | `LCSStr` | `lcsstr` |\n| [Ratcliff-Obershelp similarity](http://collaboration.cmc.ec.gc.ca/science/rpn/biblio/ddj/Website/articles/DDJ/1988/8807/8807c/8807c.htm) | `RatcliffObershelp` | `ratcliff_obershelp` |\n\n### Compression based\n\n[Normalized compression distance](https://en.wikipedia.org/wiki/Normalized_compression_distance#Normalized_compression_distance) with different compression algorithms.\n\nClassic compression algorithms:\n\n| Algorithm                                                                  | Class       | Function     |\n|----------------------------------------------------------------------------|-------------|--------------|\n| [Arithmetic coding](https://en.wikipedia.org/wiki/Arithmetic_coding)       | `ArithNCD`  | `arith_ncd`  |\n| [RLE](https://en.wikipedia.org/wiki/Run-length_encoding)                   | `RLENCD`    | `rle_ncd`    |\n| [BWT RLE](https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform) | `BWTRLENCD` | `bwtrle_ncd` |\n\nNormal compression algorithms:\n\n| Algorithm                                                                  | Class        | Function      |\n|----------------------------------------------------------------------------|--------------|---------------|\n| Square Root                                                                | `SqrtNCD`    | `sqrt_ncd`    |\n| [Entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory))      | `EntropyNCD` | `entropy_ncd` |\n\nWork in progress algorithms that compare two strings as array of bits:\n\n| Algorithm                                  | Class     | Function   |\n|--------------------------------------------|-----------|------------|\n| [BZ2](https://en.wikipedia.org/wiki/Bzip2) | `BZ2NCD`  | `bz2_ncd`  |\n| [LZMA](https://en.wikipedia.org/wiki/LZMA) | `LZMANCD` | `lzma_ncd` |\n| [ZLib](https://en.wikipedia.org/wiki/Zlib) | `ZLIBNCD` | `zlib_ncd` |\n\nSee [blog post](https://articles.life4web.ru/other/ncd/) for more details about NCD.\n\n### Phonetic\n\n| Algorithm                                                                    | Class    | Functions |\n|------------------------------------------------------------------------------|----------|-----------|\n| [MRA](https://en.wikipedia.org/wiki/Match_rating_approach)                   | `MRA`    | `mra`     |\n| [Editex](https://anhaidgroup.github.io/py_stringmatching/v0.3.x/Editex.html) | `Editex` | `editex`  |\n\n### Simple\n\n| Algorithm           | Class      | Functions  |\n|---------------------|------------|------------|\n| Prefix similarity   | `Prefix`   | `prefix`   |\n| Postfix similarity  | `Postfix`  | `postfix`  |\n| Length distance     | `Length`   | `length`   |\n| Identity similarity | `Identity` | `identity` |\n| Matrix similarity   | `Matrix`   | `matrix`   |\n\n\n## Installation\n\n### Stable\n\nOnly pure python implementation:\n\n```bash\npip install textdistance\n```\n\nWith extra libraries for maximum speed:\n\n```bash\npip install "textdistance[extras]"\n```\n\nWith all libraries (required for [benchmarking](#benchmarks) and [testing](#test)):\n\n```bash\npip install "textdistance[benchmark]"\n```\n\nWith algorithm specific extras:\n\n```bash\npip install "textdistance[Hamming]"\n```\n\nAlgorithms with available extras: `DamerauLevenshtein`, `Hamming`, `Jaro`, `JaroWinkler`, `Levenshtein`.\n\n### Dev\n\nVia pip:\n\n```bash\npip install -e git+https://github.com/life4/textdistance.git#egg=textdistance\n```\n\nOr clone repo and install with some extras:\n\n```bash\ngit clone https://github.com/life4/textdistance.git\npip install -e ".[benchmark]"\n```\n\n\n## Usage\n\nAll algorithms have 2 interfaces:\n\n1. Class with algorithm-specific params for customizing.\n2. Class instance with default params for quick and simple usage.\n\nAll algorithms have some common methods:\n\n1. `.distance(*sequences)` -- calculate distance between sequences.\n2. `.similarity(*sequences)` -- calculate similarity for sequences.\n3. `.maximum(*sequences)` -- maximum possible value for distance and similarity. For any sequence: `distance + similarity == maximum`.\n4. `.normalized_distance(*sequences)` -- normalized distance between sequences. The return value is a float between 0 and 1, where 0 means equal, and 1 totally different.\n5. `.normalized_similarity(*sequences)` -- normalized similarity for sequences. The return value is a float between 0 and 1, where 0 means totally different, and 1 equal.\n\n\nMost common init arguments:\n\n1. `qval` -- q-value for split sequences into q-grams. Possible values:\n    * 1 (default) -- compare sequences by chars.\n    * 2 or more -- transform sequences to q-grams.\n    * None -- split sequences by words.\n2. `as_set` -- for token-based algorithms:\n    * True -- `t` and `ttt` is equal.\n    * False (default) -- `t` and `ttt` is different.\n\n## Example\n\nFor example, [Hamming distance](https://en.wikipedia.org/wiki/Hamming_distance):\n\n```python\nimport textdistance\n\ntextdistance.hamming(\'test\', \'text\')\n# 1\n\ntextdistance.hamming.distance(\'test\', \'text\')\n# 1\n\ntextdistance.hamming.similarity(\'test\', \'text\')\n# 3\n\ntextdistance.hamming.normalized_distance(\'test\', \'text\')\n# 0.25\n\ntextdistance.hamming.normalized_similarity(\'test\', \'text\')\n# 0.75\n\ntextdistance.Hamming(qval=2).distance(\'test\', \'text\')\n# 2\n\n```\n\nAny other algorithms have same interface.\n\n\n## Articles\n\nA few articles with examples how to use textdistance in the real world:\n\n- [Guide to Fuzzy Matching with Python](http://theautomatic.net/2019/11/13/guide-to-fuzzy-matching-with-python/)\n- [String similarity \xe2\x80\x94 the basic know your algorithms guide!](https://itnext.io/string-similarity-the-basic-know-your-algorithms-guide-3de3d7346227)\n- [Normalized compression distance](https://articles.life4web.ru/other/ncd/)\n\n\n## Extra libraries\n\nFor main algorithms textdistance try to call known external libraries (fastest first) if available (installed in your system) and possible (this implementation can compare this type of sequences). [Install](#installation) textdistance with extras for this feature.\n\nYou can disable this by passing `external=False` argument on init:\n\n```python3\nimport textdistance\nhamming = textdistance.Hamming(external=False)\nhamming(\'text\', \'testit\')\n# 3\n```\n\nSupported libraries:\n\n1. [abydos](https://github.com/chrislit/abydos)\n1. [Distance](https://github.com/doukremt/distance)\n1. [jellyfish](https://github.com/jamesturk/jellyfish)\n1. [py_stringmatching](https://github.com/anhaidgroup/py_stringmatching)\n1. [pylev](https://github.com/toastdriven/pylev)\n1. [python-Levenshtein](https://github.com/ztane/python-Levenshtein)\n1. [pyxDamerauLevenshtein](https://github.com/gfairchild/pyxDamerauLevenshtein)\n\nAlgorithms:\n\n1. DamerauLevenshtein\n1. Hamming\n1. Jaro\n1. JaroWinkler\n1. Levenshtein\n\n\n## Benchmarks\n\nWithout extras installation:\n\n| algorithm | library | function | time |\n|-----------|---------|----------|------|\n| DamerauLevenshtein | jellyfish | damerau_levenshtein_distance | 0.00965294 |\n| DamerauLevenshtein | pyxdameraulevenshtein | damerau_levenshtein_distance | 0.151378 |\n| DamerauLevenshtein | pylev | damerau_levenshtein | 0.766461 |\n| DamerauLevenshtein | **textdistance** | DamerauLevenshtein | 4.13463 |\n| DamerauLevenshtein | abydos | damerau_levenshtein | 4.3831 |\n| Hamming | Levenshtein | hamming | 0.0014428 |\n| Hamming | jellyfish | hamming_distance | 0.00240262 |\n| Hamming | distance | hamming | 0.036253 |\n| Hamming | abydos | hamming | 0.0383933 |\n| Hamming | **textdistance** | Hamming | 0.176781 |\n| Jaro | Levenshtein | jaro | 0.00313561 |\n| Jaro | jellyfish | jaro_distance | 0.0051885 |\n| Jaro | py_stringmatching | jaro | 0.180628 |\n| Jaro | **textdistance** | Jaro | 0.278917 |\n| JaroWinkler | Levenshtein | jaro_winkler | 0.00319735 |\n| JaroWinkler | jellyfish | jaro_winkler | 0.00540443 |\n| JaroWinkler | **textdistance** | JaroWinkler | 0.289626 |\n| Levenshtein | Levenshtein | distance | 0.00414404 |\n| Levenshtein | jellyfish | levenshtein_distance | 0.00601647 |\n| Levenshtein | py_stringmatching | levenshtein | 0.252901 |\n| Levenshtein | pylev | levenshtein | 0.569182 |\n| Levenshtein | distance | levenshtein | 1.15726 |\n| Levenshtein | abydos | levenshtein | 3.68451 |\n| Levenshtein | **textdistance** | Levenshtein | 8.63674 |\n\nTotal: 24 libs.\n\nYeah, so slow. Use TextDistance on production only with extras.\n\nTextdistance use benchmark\'s results for algorithm\'s optimization and try to call fastest external lib first (if possible).\n\nYou can run benchmark manually on your system:\n\n```bash\npip install textdistance[benchmark]\npython3 -m textdistance.benchmark\n```\n\nTextDistance show benchmarks results table for your system and save libraries priorities into `libraries.json` file in TextDistance\'s folder. This file will be used by textdistance for calling fastest algorithm implementation. Default [libraries.json](textdistance/libraries.json) already included in package.\n\n\n## Test\n\nYou can run tests via [tox](https://tox.readthedocs.io/en/latest/):\n\n```bash\nsudo pip3 install tox\ntox\n```\n'