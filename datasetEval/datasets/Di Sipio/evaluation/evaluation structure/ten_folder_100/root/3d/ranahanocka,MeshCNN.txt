b'<img src=\'docs/imgs/alien.gif\' align="right" width=325>\n<br><br><br>\n\n# MeshCNN in PyTorch\n\n\n### SIGGRAPH 2019 [[Paper]](https://bit.ly/meshcnn) [[Project Page]](https://ranahanocka.github.io/MeshCNN/)<br>\n\nMeshCNN is a general-purpose deep neural network for 3D triangular meshes, which can be used for tasks such as 3D shape classification or segmentation. This framework includes convolution, pooling and unpooling layers which are applied directly on the mesh edges.\n\n<img src="docs/imgs/meshcnn_overview.png" align="center" width="750px"> <br>\n\nThe code was written by [Rana Hanocka](https://www.cs.tau.ac.il/~hanocka/) and [Amir Hertz](http://pxcm.org/) with support from [Noa Fish](http://www.cs.tau.ac.il/~noafish/).\n\n# Getting Started\n\n### Installation\n- Clone this repo:\n```bash\ngit clone https://github.com/ranahanocka/MeshCNN.git\ncd MeshCNN\n```\n- Install dependencies: [PyTorch](https://pytorch.org/) version 1.2. <i> Optional </i>: [tensorboardX](https://github.com/lanpa/tensorboardX) for training plots.\n  - Via new conda environment `conda env create -f environment.yml` (creates an environment called meshcnn)\n  \n### 3D Shape Classification on SHREC\nDownload the dataset\n```bash\nbash ./scripts/shrec/get_data.sh\n```\n\nRun training (if using conda env first activate env e.g. ```source activate meshcnn```)\n```bash\nbash ./scripts/shrec/train.sh\n```\n\nTo view the training loss plots, in another terminal run ```tensorboard --logdir runs``` and click [http://localhost:6006](http://localhost:6006).\n\nRun test and export the intermediate pooled meshes:\n```bash\nbash ./scripts/shrec/test.sh\n```\n\nVisualize the network-learned edge collapses:\n```bash\nbash ./scripts/shrec/view.sh\n```\n\nAn example of collapses for a mesh:\n\n<img src="/docs/imgs/T252.png" width="450px"/> \n\nNote, you can also get pre-trained weights using bash ```./scripts/shrec/get_pretrained.sh```. \n\nIn order to use the pre-trained weights, run ```train.sh``` which will compute and save the mean / standard deviation of the training data. \n\n\n### 3D Shape Segmentation on Humans\nThe same as above, to download the dataset / run train / get pretrained / run test / view\n```bash\nbash ./scripts/human_seg/get_data.sh\nbash ./scripts/human_seg/train.sh\nbash ./scripts/human_seg/get_pretrained.sh\nbash ./scripts/human_seg/test.sh\nbash ./scripts/human_seg/view.sh\n```\n\nSome segmentation result examples:\n\n<img src="/docs/imgs/shrec__10_0.png" height="150px"/> <img src="/docs/imgs/shrec__14_0.png" height="150px"/> <img src="/docs/imgs/shrec__2_0.png" height="150px"/> \n\n### Additional Datasets\nThe same scripts also exist for COSEG segmentation in ```scripts/coseg_seg``` and cubes classification in ```scripts/cubes```. \n\n# More Info\nCheck out the [MeshCNN wiki](https://github.com/ranahanocka/MeshCNN/wiki) for more details. Specifically, see info on [segmentation](https://github.com/ranahanocka/MeshCNN/wiki/Segmentation) and [data processing](https://github.com/ranahanocka/MeshCNN/wiki/Data-Processing).\n\n# Citation\nIf you find this code useful, please consider citing our paper\n```\n@article{hanocka2019meshcnn,\n  title={MeshCNN: A Network with an Edge},\n  author={Hanocka, Rana and Hertz, Amir and Fish, Noa and Giryes, Raja and Fleishman, Shachar and Cohen-Or, Daniel},\n  journal={ACM Transactions on Graphics (TOG)},\n  volume={38},\n  number={4},\n  pages = {90:1--90:12},\n  year={2019},\n  publisher={ACM}\n}\n```\n\n\n# Questions / Issues\nIf you have questions or issues running this code, please open an issue so we can know to fix it.\n  \n# Acknowledgments\nThis code design was adopted from [pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix).\n'