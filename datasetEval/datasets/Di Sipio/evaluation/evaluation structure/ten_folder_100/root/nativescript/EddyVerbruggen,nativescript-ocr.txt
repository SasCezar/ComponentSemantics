b'# NativeScript OCR\n\n[![Build Status][build-status]][build-url]\n[![NPM version][npm-image]][npm-url]\n[![Downloads][downloads-image]][npm-url]\n[![Twitter Follow][twitter-image]][twitter-url]\n\n[build-status]:https://travis-ci.org/EddyVerbruggen/nativescript-ocr.svg?branch=master\n[build-url]:https://travis-ci.org/EddyVerbruggen/nativescript-ocr\n[npm-image]:http://img.shields.io/npm/v/nativescript-ocr.svg\n[npm-url]:https://npmjs.org/package/nativescript-ocr\n[downloads-image]:http://img.shields.io/npm/dm/nativescript-ocr.svg\n[twitter-image]:https://img.shields.io/twitter/follow/eddyverbruggen.svg?style=social&label=Follow%20me\n[twitter-url]:https://twitter.com/eddyverbruggen\n\n> \xe2\x9a\xa0\xef\xb8\x8f This repo is hardly maintained - if you want an OCR solution in NativeScript, please consider using [Firebase MLKit](https://github.com/EddyVerbruggen/nativescript-plugin-firebase/blob/master/docs/ML_KIT.md#text-recognition).\n\n<img src="https://github.com/EddyVerbruggen/nativescript-ocr/raw/master/demo/app/samples/scanned.png" height="440px"/> <img src="https://github.com/EddyVerbruggen/nativescript-ocr/raw/master/screenshots/ios-scanning.png" height="440px"/> <img src="https://github.com/EddyVerbruggen/nativescript-ocr/raw/master/screenshots/ios-scanned.png" height="440px"/>\n\nOptical Character Recognition - powered by Tesseract\n\n## Installation\n```bash\ntns plugin add nativescript-ocr\n```\n\n## Setup\nYou\'ll need to add language files to help Tesseract recognizing text in the images you feed it.\n\nDownload version 3.04.00 of the tessdata files [here](https://github.com/tesseract-ocr/tessdata/releases/tag/3.04.00) and\nadd your required language to the `app/tesseract/tessdata/` folder of your app.\n\nNote that if your language(s) has multiple files (like English: there\'s 9 files matching `eng.*`), copy _all_ those files to the folder.\n\n### iOS\niOS searches for the tessdata folder in `app/App_Resources/iOS`, but instead of dulicating the folder\nyou can create a symbolic link:\n\n```bash\ncd app/App_Resources/iOS\nln -s ../../tesseract/tessdata\n```\n\n## API\n\n### `retrieveText`\n\n#### JavaScript\nThis is just a basic example using the default settings, look at the TypeScript code below\nfor a more elaborate example.\n\n```js\nvar OCRPlugin = require("nativescript-ocr");\nvar ocr = new OCRPlugin.OCR();\n\nocr.retrieveText({\n  image: myImage\n}).then(\n    function (result) {\n      console.log("Result: " + result.text);\n    },\n    function (error) {\n      console.log("Error: " + error);\n    }\n);\n```\n\n#### TypeScript\nThis example shows how to use all possible (but optional) options you can pass into `retrieveText`:\n\n```js\nimport { OCR, RetrieveTextResult } from "nativescript-ocr";\nimport { ImageSource } from "image-source";\n\nexport Class MyOCRClass {\n  private ocr: OCR;\n  \n  constructor() {\n    this.ocr = new OCR();\n  }\n\n  doRecognize(): void {\n    let img: ImageSource = new ImageSource();\n\n    img.fromFile("~/samples/scanned.png").then((success: boolean) => {\n      if (success) {\n        this.ocr.retrieveText({\n          image: img,\n          whitelist: "ABCDEF",     // you can include only certain characters in the result\n          blacklist: "0123456789", // .. or you can exclude certain characters from the result\n          onProgress: (percentage: number ) => {\n            console.log(`Decoding progress: ${percentage}%`);\n          }\n        }).then(\n            (result: RetrieveTextResult) => {\n              this.set(HelloWorldModel.BUSY_KEY, false);\n              console.log(`Result: ${result.text}`);\n            }, (error: string) => {\n              console.log(`Error: ${err}`);\n            })\n      }\n    });\n  }\n}\n```\n'