b'# NativeScript Speech Recognition\n\n[![Build Status][build-status]][build-url]\n[![NPM version][npm-image]][npm-url]\n[![Downloads][downloads-image]][npm-url]\n[![Twitter Follow][twitter-image]][twitter-url]\n\n[build-status]:https://travis-ci.org/EddyVerbruggen/nativescript-speech-recognition.svg?branch=master\n[build-url]:https://travis-ci.org/EddyVerbruggen/nativescript-speech-recognition\n[npm-image]:http://img.shields.io/npm/v/nativescript-speech-recognition.svg\n[npm-url]:https://npmjs.org/package/nativescript-speech-recognition\n[downloads-image]:http://img.shields.io/npm/dm/nativescript-speech-recognition.svg\n[twitter-image]:https://img.shields.io/twitter/follow/eddyverbruggen.svg?style=social&label=Follow%20me\n[twitter-url]:https://twitter.com/eddyverbruggen\n\nThis is the plugin [demo](https://github.com/EddyVerbruggen/nativescript-speech-recognition/tree/master/demo) in action..\n\n| ..while recognizing Dutch \xf0\x9f\x87\xb3\xf0\x9f\x87\xb1 | .. after recognizing American-English \xf0\x9f\x87\xba\xf0\x9f\x87\xb8 |\n| --- | --- |\n| <img src="https://github.com/EddyVerbruggen/nativescript-speech-recognition/raw/master/screenshots/ios-nl.jpg" width="375px" /> | <img src="https://github.com/EddyVerbruggen/nativescript-speech-recognition/raw/master/screenshots/ios-en.jpg" width="375px" /> |\n\n## Installation\nFrom the command prompt go to your app\'s root folder and execute:\n\n```\ntns plugin add nativescript-speech-recognition\n```\n\n## Testing\nYou\'ll need to test this on a real device as a Simulator/Emulator doesn\'t have speech recognition capabilities.\n\n## API\n\n### `available`\n\nDepending on the OS version a speech engine may not be available.\n\n#### JavaScript\n```js\n// require the plugin\nvar SpeechRecognition = require("nativescript-speech-recognition").SpeechRecognition;\n\n// instantiate the plugin\nvar speechRecognition = new SpeechRecognition();\n\nspeechRecognition.available().then(\n  function(available) {\n    console.log(available ? "YES!" : "NO");\n  }\n);\n```\n\n#### TypeScript\n```typescript\n// import the plugin\nimport { SpeechRecognition } from "nativescript-speech-recognition";\n\nclass SomeClass {\n  private speechRecognition = new SpeechRecognition();\n  \n  public checkAvailability(): void {\n    this.speechRecognition.available().then(\n      (available: boolean) => console.log(available ? "YES!" : "NO"),\n      (err: string) => console.log(err)\n    );\n  }\n}\n```\n\n### `requestPermission`\nYou can either let `startListening` handle permissions when needed, but if you want to have more control\nover when the permission popups are shown, you can use this function:\n\n```typescript\nthis.speechRecognition.requestPermission().then((granted: boolean) => {\n  console.log("Granted? " + granted);\n});\n```\n\n### `startListening`\n\nOn iOS this will trigger two prompts:\n\nThe first prompt requests to allow Apple to analyze the voice input. The user will see a consent screen which you can extend with your own message by adding a fragment like this to `app/App_Resources/iOS/Info.plist`:\n\n```xml\n<key>NSSpeechRecognitionUsageDescription</key>\n<string>My custom recognition usage description. Overriding the default empty one in the plugin.</string>\n```\n\nThe second prompt requests access to the microphone:\n\n```xml\n<key>NSMicrophoneUsageDescription</key>\n<string>My custom microphone usage description. Overriding the default empty one in the plugin.</string>\n```\n\n#### TypeScript\n```typescript\n// import the options\nimport { SpeechRecognitionTranscription } from "nativescript-speech-recognition";\n\nthis.speechRecognition.startListening(\n  {\n    // optional, uses the device locale by default\n    locale: "en-US",\n    // set to true to get results back continuously\n    returnPartialResults: true,\n    // this callback will be invoked repeatedly during recognition\n    onResult: (transcription: SpeechRecognitionTranscription) => {\n      console.log(`User said: ${transcription.text}`);\n      console.log(`User finished?: ${transcription.finished}`);\n    },\n    onError: (error: string | number) => {\n      // because of the way iOS and Android differ, this is either:\n      // - iOS: A \'string\', describing the issue. \n      // - Android: A \'number\', referencing an \'ERROR_*\' constant from https://developer.android.com/reference/android/speech/SpeechRecognizer.\n      //            If that code is either 6 or 7 you may want to restart listening.\n    }\n  }\n).then(\n  (started: boolean) => { console.log(`started listening`) },\n  (errorMessage: string) => { console.log(`Error: ${errorMessage}`); }\n).catch((error: string | number) => {\n  // same as the \'onError\' handler, but this may not return if the error occurs after listening has successfully started (because that resolves the promise,\n  // hence the\' onError\' handler was created.\n});\n```\n\n##### Angular tip\nIf you\'re using this plugin in Angular, then note that the `onResult` callback is not part of Angular\'s lifecycle.\nSo either update the UI in [an `ngZone` as shown here](https://github.com/EddyVerbruggen/nativescript-pluginshowcase/blob/28f65ef98716ad7c4698071b9c394cceb2d9748f/app/speech/speech.component.ts#L154),\nor use [`ChangeDetectorRef` as shown here](https://blog.paulhalliday.io/2017/06/24/nativescript-speech-recognition/).\n\n### `stopListening`\n\n#### TypeScript\n```typescript\nthis.speechRecognition.stopListening().then(\n  () => { console.log(`stopped listening`) },\n  (errorMessage: string) => { console.log(`Stop error: ${errorMessage}`); }\n);\n```\n\n## Demo app (Angular)\nThis plugin is part of the [plugin showcase app](https://github.com/EddyVerbruggen/nativescript-pluginshowcase/tree/master/app/speech) I built using Angular.\n\n### Angular video tutorial\nRather watch a video? Check out [this tutorial on YouTube](https://www.youtube.com/watch?v=C5i_EYjfuTE).\n'