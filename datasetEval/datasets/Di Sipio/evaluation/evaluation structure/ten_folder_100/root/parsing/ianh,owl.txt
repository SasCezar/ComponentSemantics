b'<img src="doc/images/logo.png" width=475>\n\nOwl is a parser generator which targets the class of [visibly pushdown languages](https://en.wikipedia.org/wiki/Nested_word).  It is:\n\n* Efficient \xe2\x80\x94 Owl can parse any syntactically valid grammar in linear time.\n* Understandable \xe2\x80\x94 like regular expressions, its parsing model (and error messages<sup><a name="footnote1up" href="#footnote1">[1]</a></sup>) can be understood without talking about parser states, backtracking, lookahead, or any other implementation details.\n* Easy to use \xe2\x80\x94 using Owl\'s interpreter mode, you can design, test, and debug your grammar without writing any code.  An Owl grammar compiles to a single C header file which provides a straightforward parse tree API.\n\nHere\'s a grammar for a simple programming language with expressions, assignment, and a `print` statement ([see it online with syntax highlighting](https://ianh.github.io/owl/try/#example)).\n\n```\nprogram = stmt*\nstmt =\n   \'print\' expr : print\n   identifier \'=\' expr : assign\nexpr =\n   [ \'(\' expr \')\' ] : parens\n   identifier : variable\n   number : literal\n .operators prefix\n   \'-\' : negative\n .operators infix left\n   \'*\' : times\n   \'/\' : divided-by\n .operators infix left\n   \'+\' : plus\n   \'-\' : minus\n```\n\nMore examples are available in the [example/](example/) directory.\n\n## how to use it\n\nYou can build the `owl` tool from this repository using `make`:\n\n```console\n$ git clone https://github.com/ianh/owl.git\n$ cd owl/\n$ make\n```\n\nRun `make install` to copy the `owl` tool into `/usr/local/bin/owl`.\n\nOn Windows, [MSYS2](http://www.msys2.org/) is the supported way to build `owl`.  In the MSYS shell, run `pacman -S make gcc git` to install the proper dependencies before running the commands above.  To install, use `make PREFIX=/usr install` (which copies to `/usr/bin/owl` instead).\n\nOwl has two modes of operation&mdash;**interpreter mode** and **compilation mode**.\n\nIn **interpreter mode**, Owl reads your grammar file, then parses standard input on the fly, producing a visual representation of the parse tree as soon as you hit `^D`:\n\n```console\n$ owl test/expr.owl\n1 + 2\n^D\n. 1            + 2\n  expr:literal   expr:literal\n  expr:plus------------------\n```\n\nYou can specify a file to use as input with `--input` or `-i`:\n\n```console\n$ echo "8 * 7" > multiply.txt\n$ owl test/expr.owl -i multiply.txt\n. 8            * 7\n  expr:literal   expr:literal\n  expr:times-----------------\n```\n\nYou can also use Owl\'s interpreter [on the web](https://ianh.github.io/owl/try/).\n\nIn **compilation mode**, Owl reads your grammar file, but doesn\'t parse any input right away.  Instead, it generates C code with functions that let you parse the input later.\n\n```console\n$ owl -c test/expr.owl -o parser.h\n```\n\nYou can `#include` this generated parser into a C program:\n\n```C\n#include "parser.h"\n```\n\nWherever you #define `OWL_PARSER_IMPLEMENTATION`, the implementation of the parser will also be included.  Make sure to do this somewhere in your program:\n\n```C\n#define OWL_PARSER_IMPLEMENTATION\n#include "parser.h"\n```\n\nFor more about how to use this header, see the docs on [using the generated parser](doc/generated-parser.md).\n\n## rules and grammars\n\nRules in owl are written like regular expressions with a few extra features.  Here\'s a rule that matches a comma-separated list of numbers:\n\n```\nnumber-list = number (\',\' number)*\n```\n\nNote that Owl operates on tokens (like `\',\'` and `number`), not individual characters like a regular expression would.  Owl comes with the built-in token classes `number`, `identifier`, `integer`, and `string`; keywords `\'like\'` `\'this\'` match their literal text.\n\nTo create a parse tree, you can write rules that refer to each other:\n\n```\nvariable = \'var\' identifier (\':\' type)?\ntype = \'int\' | \'string\'\n```\n\nRules can only refer to later rules, not earlier ones: plain recursion isn\'t allowed.  Only two restricted kinds of recursion are available: *guarded recursion* and *expression recursion*.\n\n*Guarded recursion* is recursion inside `[ guard brackets ]`.  Here\'s a grammar to parse `{"arrays", "that", {"look", "like"}, "this"}`:\n\n```\nelement = array | string\narray = [ \'{\' element (\',\' element)* \'}\' ]\n```\n\nThe symbols just inside the brackets \xe2\x80\x94 `\'{\'` and `\'}\'` here \xe2\x80\x94 are the *begin* and *end tokens* of the guard bracket.  Begin and end tokens can\'t appear anywhere else in the grammar except as other begin and end tokens.  This is what guarantees the language is *visibly pushdown*: all recursion is explicitly delineated by special symbols.\n\n*Expression recursion* lets you define unary and binary operators using the `.operators` keyword:\n\n```\nexpression =\n    identifier | number | parens : value\n  .operators prefix\n    \'-\' : negate\n  .operators infix left\n    \'+\' : add\n    \'-\' : subtract\nparens = [ \'(\' expression \')\' ]\n```\n\nOperators in the same `.operators` clause have the same precedence level; clauses nearer the top of the list are higher in precedence.\n\nThese forms of recursion may seem limiting, but you can go surprisingly far with them.  For example, if you\'re willing to use `?` and `:` as begin and end tokens, the C ternary operator can be written as an infix operator:\n\n```\nexpr =\n    ...\n  .operators infix left\n    [ \'?\' middle \':\' ] : ternary\n```\n\nFor a more thorough guide to Owl\'s grammar format, check out the [grammar reference](doc/grammar-reference.md).  The [example/](example/) directory also has some example grammars.\n\n## what owl isn\'t\n\n### non-goals\n\n* Parsing arbitrary context-free languages or other, more general languages.\n* Constant-space streaming-style parsing \xe2\x80\x94 the way Owl parses operators depends on having a syntax tree representation (plus, see the "memory use" bullet below).\n\n### current limitations\n\n* Large grammars \xe2\x80\x94 Owl uses precomputed DFAs and action tables, which can blow up in size as grammars get more complex.  In the future, it would be nice to build the DFAs incrementally.\n* Memory use \xe2\x80\x94 Owl stores a small (single digit bytes) amount of information for every token while parsing in order to resolve nondeterminism.  If a decision about what to match depends on a token which appears much later in the text, Owl needs to store enough information to go back and make this decision at the point that the token appears.  Instead of analyzing how long to wait before making these decisions, Owl just waits until the end, gathering data for the entire input before creating the parse tree.\n* Error messages \xe2\x80\x94 Owl can show you the token where an error happened<sup><a name="footnote2up" href="#footnote2">[2]</a></sup>, but it doesn\'t suggest how to fix it.\n* Generating code in other languages \xe2\x80\x94 only C is supported right now.\n\n## footnotes\n\n<a name="footnote1">[1]</a> This includes errors caused by ambiguities, where your grammar can match the same text in two different ways.  Owl shows you the text in question alongside its two conflicting matches:\n\n```\nerror: this grammar is ambiguous\n\n. a ( b ) \n\n  can be parsed in two different ways: as\n\n. a ( b )   \n  expr:call \n  stmt:expr \n  program-- \n\n  or as\n\n. a          ( b )       \n  expr:ident expr:parens \n  stmt:expr- stmt:expr-- \n  program--------------- \n```\n\nIf you want more context for why this is important, [LL and LR in Context: Why Parsing Tools Are Hard](http://blog.reverberate.org/2013/09/ll-and-lr-in-context-why-parsing-tools.html) is a good summary.  Ambiguity is an inherent problem with context-free grammars; limiting ourselves to visibly pushdown languages lets us solve this problem (at the expense of excluding some useful grammars).\n\n[**go back up**](#footnote1up)\n\n. . . . . . .\n\n<a name="footnote2">[2]</a> To be precise, Owl reports the token where the input stopped being a valid prefix of the grammar.  It\'s possible that the "real" error location was earlier in the input.\n\n[**go back up**](#footnote2up)\n\n## notes and bibliography\n\nThis article about Rust\'s macro system was what got me thinking about all of this in the first place:\n\n- Daniel Keep. 2017. [A Practical Intro to Macros in Rust 1.0](https://danielkeep.github.io/practical-intro-to-macros.html).\n\nThe question I had was: what would a parser that operated directly on token trees look like?  In particular, could you just use regular expressions to parse each level of the tree?\n\n### visibly pushdown languages\n\nIt turns out there\'s a [body of research](http://madhu.cs.illinois.edu/vpa/) which answers this question.  Combining an ordinary regular language with explicit nesting tokens gives you what\'s called a visibly pushdown language (or VPL):\n\n- Rajeev Alur and P. Madhusudan. 2004. [Visibly Pushdown Languages](http://madhu.cs.illinois.edu/stoc04.pdf). [[doi](https://doi.org/10.1145/1007352.1007390)]\n\nor, as it has been called earlier, an input-driven pushdown language:\n\n- Kurt Mehlhorn. 1980. [Pebbling Mountain Ranges and its Application to DCFL-Recognition](https://pdfs.semanticscholar.org/1c9b/c1ae6b2484b236bf9d674b8d10bdaad95eb1.pdf). [[doi](https://dx.doi.org/10.1007/3-540-10003-2_89)]\n\nThese languages share a lot of nice properties with regular languages, including closure under union and concatenation (which are useful for composing VPL/IDPLs out of atomic pieces).\n\nVPLs are often used for program analysis, where the nesting tokens represent calls and returns in an execution trace.  There haven\'t been many attempts to apply this theory to text parsing, though.  This presentation about visibly pushdown applicative parser combinators in Haskell is the only one I\'ve found:\n\n- Philippa Cowderoy. 2011. [Visibly Powerful Parsing](http://www.flippac.org/talks/VPParsing.pdf).\n\n### automata\n\nTo match (balanced) visibly pushdown languages, Owl uses a pair of finite-state automata\xe2\x80\x94a "base automaton" and a "bracket automaton"\xe2\x80\x94with a few rules for moving between them.  I\'ll describe how these automata work briefly.\n\nThe idea is to treat an entire bracketed group of tokens `( ... )` as a single *bracket symbol*.  The bracket automaton matches these groups, and the bracket automaton\'s accepting state tells us the bracket symbol.\n\nEach symbol is classified as one of the following:\n\n* the **begin symbols** (<sub>1</sub> \xe2\x80\xa6 (<sub>*m*</sub> \xe2\x80\x94 "begin tokens" that appear on the left side of a guard bracket\n* the **end symbols** )<sub>1</sub> \xe2\x80\xa6 )<sub>*n*</sub> \xe2\x80\x94 "end tokens" that appear on the right side of a guard bracket\n* the **regular symbols** *a*<sub>1</sub> \xe2\x80\xa6 *a*<sub>*l*</sub> \xe2\x80\x94 all tokens except the begin and end tokens\n* the **bracket symbols** ()<sub>1</sub> \xe2\x80\xa6 ()<sub>*k*</sub> \xe2\x80\x94 these don\'t appear in the input, but are produced by matching against the bracket automaton.\n\nExecution starts at the start state of the base automaton.  A stack of states is used during execution; it\'s initialized to be empty.  The automaton reads each symbol from the input and acts according to its classification:\n\n* a regular symbol\n    * transitions normally;\n* a begin symbol\n    * pushes the current state onto the stack,\n    * moves to the start state of the bracket automaton,\n    * and transitions normally from that start state;\n* an end symbol\n    * transitions normally,\n    * checks the bracket symbol corresponding to the current accepting bracket automaton state,\n    * pops the current state from the stack,\n    * and transitions normally from the popped state using that bracket symbol.\n\nA sequence of input symbols is recognized if this process leaves us in an accepting state of the base automaton.\n\nHere\'s a quick drawing of what the two automata look like for this [grammar of nested arrays](https://ianh.github.io/owl/try/#nested): `a = [ \'[\' (a (\',\' a)*)? \']\' ]`.\n\n| <img src="doc/images/base-automaton.png" width=162 height=57> | <img src="doc/images/bracket-automaton.png" width=225 height=187> |\n| :---: | :---: |\n| *base automaton* | *bracket automaton* |\n\n\nThe square-shaped state is the labeled accepting state of the bracket automaton.\n\n### determinization\n\n[Owl\'s determinization](src/5-determinize.c) is an iterative version of the usual [subset construction](https://en.wikipedia.org/wiki/Powerset_construction).  The first iteration ignores the bracket symbols, following only transitions involving regular, begin, and end symbols.  Once accepting state sets appear in the determinized bracket automaton, the bracket symbols corresponding to the states in each set are followed simultaneously (since their appearance in a state set means they can occur together) during the next iteration of the subset construction.\n\nBecause these accepting state sets grow monotonically (we only ever find new ways of reaching them) and are bounded above in size, this iterative process eventually stops making progress.  At this point, determinization is finished, and the accepting state sets in the bracket automaton become the new bracket symbols in the deterministic automata.\n\n### parse tree construction\n\nThe next step is to generate a parse tree.  When Owl builds its automata from a grammar, it encodes [parse tree actions](src/construct-actions.h) (like "start operand", "set slot choice", etc.) along certain transitions.  How can Owl preserve this information during determinization so it can reconstruct the list of actions?\n\nThese two papers describe how to do that:\n\n- Danny Dub\xc3\xa9 and Marc Feeley. 2000. [Efficiently building a parse tree from a regular expression](http://www.iro.umontreal.ca/~feeley/papers/DubeFeeleyACTAINFORMATICA00.pdf). [[doi](http://dx.doi.org/10.1007/s002360000037)]\n- Danny Dub\xc3\xa9 and Anass Kadiri. 2006. [Automatic construction of parse trees for lexemes](http://www.schemeworkshop.org/2006/14-dube.pdf).\n\nThe basic idea is: each transition in the deterministic automaton is derived from several transitions in the original automaton (typically with the same symbol).  Collect the original transitions which produce each deterministic transition together in a table.\n\nThen, when you find a path through the deterministic automaton, start from the end and walk backward along the path, using the table for each transition to reconstruct the original path through the original automaton.\n\nAdapting this technique to Owl\'s iterative determinization algorithm is straightfoward: since determinized bracket symbols can represent multiple non-deterministic symbols, the table has an extra field for the non-deterministic symbol, but everything else is the same.\n\nI considered some other approaches too:\n\nA Thompson-style interpreter would sidestep the problem by interpreting the original, non-deterministic automaton.\n\n- Russ Cox. 2009. [Regular Expression Matching: the Virtual Machine Approach](https://swtch.com/~rsc/regexp/regexp2.html).\n\nEach thread would have to store its own action list, which could end up taking a lot of memory for some inputs\xe2\x80\x94that\'s why I avoided this approach in the first place.  But the Dub\xc3\xa9-Feeley-style action maps also take up a lot of memory.  In retrospect, I think this approach could be worth a try.\n\nLaurikari\'s tagged NFAs seem like they would work well for a limited number of sub-matches, but I couldn\'t think of a way to scale them up to a full parse tree:\n\n- Ville Laurikari. 2000. [NFAs with Tagged Transitions, their Conversion to Deterministic Automata and Application to Regular Expressions](https://laurikari.net/ville/spire2000-tnfa.pdf). [[doi](https://doi.org/10.1109/SPIRE.2000.878194)]\n- Ville Laurikari. 2001. [Efficient Submatch Addressing for Regular Expressions](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.6717).\n\n### operator-precedence grammars\n\nA variation of Dijkstra\'s two-stack "shunting-yard" algorithm is used to associate operators with their operands (see [src/x-construct-parse-tree.h](src/x-construct-parse-tree.h) for the implementation).  I mostly just read the [Wikipedia page](https://en.wikipedia.org/wiki/Shunting-yard_algorithm) for this one, though the original reference is apparently:\n\n- E.W. Dijkstra. 1961. [An Algol 60 Translator for the X1](http://www.cs.utexas.edu/~EWD/MCReps/MR35.PDF).\n\n### ambiguity checking\n\nIn order to check the grammar for ambiguity, Owl creates a "product automaton" over pairs of states\xe2\x80\x94a path through the product automaton corresponds to two paths in the original automaton that accept the same input.  This paper was very helpful when I was figuring out how to search the product automaton for ambiguity in a systematic way:\n\n- Cyril Allauzen, Mehryar Mohri, and Ashish Rastogi. 2011. [General Algorithms for Testing the Ambiguity of Finite Automata and the Double-Tape Ambiguity of Finite-State Transducers](https://research.google.com/pubs/archive/37168.pdf). [[doi](http://doi.org/10.1142/S0129054111008477)]\n\nOwl uses a variation of their "epsilon filtering" technique to create the product automaton without introducing bogus ambiguities.\n\n### parse tree formatting\n\nThe way that Owl\'s interpreter and ambiguity checker display parse trees was inspired by the icicle plot visualization in [Ohm](https://nextjournal.com/dubroy/ohm-parsing-made-easy) (a PEG parser):\n\n- Patrick Dubroy, Saketh Kasibatla, Meixian Li, Marko R\xc3\xb6der, and Alex Warth. 2016. [Language Hacking in a Live Programming Environment](https://ohmlang.github.io/pubs/live2016/).\n\nOwl turns the icicles upside down (a stalagmite plot?) on the principle that the text itself forms the leaves of the tree.\n\n. . . . . . .\n\n*Ian Henderson <<ian@ianhenderson.org>><br>\n(Feel free to email me with any questions or comments!)*\n'