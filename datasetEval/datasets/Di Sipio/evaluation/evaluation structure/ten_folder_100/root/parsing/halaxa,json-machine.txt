b'![](img/logo.png)\n# JSON Machine\n\n[![Build Status](https://travis-ci.com/halaxa/json-machine.svg?branch=master)](https://travis-ci.com/halaxa/json-machine)\n---\nJSON Machine is an efficient, easy-to-use and fast JSON stream parser based on generators\ndeveloped for unpredictably long JSON streams or documents. Main features are:\n\n- Constant memory footprint for unpredictably large JSON documents.\n- Ease of use. Just iterate JSON of any size with `foreach`. No events and callbacks.\n- Efficient iteration on any subtree of the document, specified by [Json Pointer](#json-pointer)\n- Speed. Performace critical code contains no unnecessary function calls, no regular expressions\nand uses native `json_decode` to decode JSON document chunks.\n\n## TL;DR;\nJSON Machine is drop-in replacement for non efficient iteration of big JSONs:\n\n```diff\n<?php\n\n- $users = json_decode(file_get_contents(\'500MB-users.json\'));\n+ $users = \\JsonMachine\\JsonMachine::fromFile(\'500MB-users.json\');\n\nforeach ($users as $id => $user) {\n    // just process $user as usual\n}\n```\n\nRandom access like `$users[42]` **is not possible**. However you can scan the collection in `foreach` and find the item.\n\n## Parsing JSON documents\n\n### Simple document\nLet\'s say that `big.json` contains this really big JSON document:\n```json\n// big.json\n{\n    "apple": {\n        "color": "red"\n    },\n    "pear": {\n        "color": "yellow"\n    }\n}\n``` \nIt can be parsed this way:\n```php\n<?php\n\n$jsonStream = \\JsonMachine\\JsonMachine::fromFile(\'big.json\');\n\nforeach ($jsonStream as $name => $data) {\n    // 1st iteration: $name === "apple" and $data === ["color" => "red"]\n    // 2nd iteration: $name === "pear" and $data === ["color" => "yellow"]\n}\n```\n\nParsing an array instead of a dictionary follows the same logic.\nThe key in a foreach will be a numeric index of an item.\n\n### Parsing a subtree\nIf you want to iterate only `fruits-key` subtree in this `fruits.json`:\n```json\n// fruits.json\n{\n    "fruits-key": {\n        "apple": {\n            "color": "red"\n        },\n        "pear": {\n            "color": "yellow"\n        }\n    }\n}\n```\ndo it like this:\n```php\n<?php\n\n$jsonStream = \\JsonMachine\\JsonMachine::fromFile("fruits.json", "/fruits-key" /* <- Json Pointer */);\nforeach ($jsonStream as $name => $data) {\n    // The same as above, which means:\n    // 1st iteration: $name === "apple" and $data === ["color" => "red"]\n    // 2nd iteration: $name === "pear" and $data === ["color" => "yellow"]\n}\n```\n\n> Note:\n>\n> Value of `fruits-key` is not loaded into memory at once, but only one item in\n> `fruits-key` at a time. It is always one item in memory at a time at the level/subtree\n> you are currently iterating. Thus the memory consumption is constant.\n\n<a name="json-pointer"></a>\n#### Few words about Json Pointer\nIt\'s a way of addressing one item in JSON document. See the [Json Pointer RFC 6901](https://tools.ietf.org/html/rfc6901).\nIt\'s very handy, because sometimes the JSON structure goes deeper, and you want to iterate a subtree,\nnot the main level. So you just specify the pointer to the JSON array or object you want to iterate and off you go.\nWhen the parser hits the collection you specified, iteration begins. It is always a second parameter in all\n`JsonMachine::from*` functions. If you specify pointer to scalar value (which logically cannot be iterated)\nor non existent position in the document, an exception is thrown.\n\nSome examples:\n\n| Json Pointer value | Will iterate through                                                                              |\n|--------------------|---------------------------------------------------------------------------------------------------|\n| (empty string)     | `["this", "array"]` or `{"a": "this", "b": "dictionary"}` will be iterated (main level - default) |\n| `/result/items`    | `{"result":{"items":["this","array","will","be","iterated"]}}`                                    |\n| `/0/items`         | `[{"items":["this","array","will","be","iterated"]}]` (supports array indexes)                    |\n| `/` (gotcha! - a slash followed by an empty string, see the [spec](https://tools.ietf.org/html/rfc6901#section-5))      | `{"":["this","array","will","be","iterated"]}`              |\n\n  \n## Parsing API responses\nAPI response or any other JSON stream is parsed exactly the same way as file is. The only difference\nis, you use `JsonMachine::fromStream($streamResource)` for it, where `$streamResource` is the stream\nresource with the JSON document. The rest is the same as with parsing files.\n\n### GuzzleHttp\nGuzzle uses its own streams, but they can be converted back to PHP streams by calling\n`\\GuzzleHttp\\Psr7\\StreamWrapper::getResource()`. Pass the result of this function to\n`JsonMachine::fromStream` function and you\'re set up. See working\n[GuzzleHttp example](src/examples/guzzleHttp.php).\n\n## Efficiency of parsing streams/files\nJSON Machine reads the stream or file 1 JSON item at a time and generates corresponding 1 PHP array at a time.\nThis is the most efficient way, because if you had say 10,000 users in JSON file and wanted to parse it using\n`json_decode(file_get_contents(\'big.json\'))`, you\'d have the whole string in memory as well as all the 10,000\nPHP structures. Following table demonstrates a concept of the difference:\n\n|                            | String items in memory at a time | Decoded PHP items in memory at a time | Total |\n|----------------------------|---------------------------------:|--------------------------------------:|------:|\n| `json_decode`              |                            10000 |                                 10000 | 20000 |\n| `JsonMachine::fromStream`  |                                1 |                                     1 |     2 |\n\nThis means, that `JsonMachine::fromStream` is constantly efficient for any size of processed JSON. 100 GB no problem.\n\n## Efficiency of parsing in-memory JSON strings\nThere is also a method `JsonMachine::fromString()`. You may wonder, why is it there. Why just not use\n`json_decode`? True, when parsing short strings, JSON Machine may be overhead. But if you are\nforced to parse a big string and the stream is not available, JSON Machine may be better than `json_decode`.\nThe reason is that unlike `json_decode` it still traverses the JSON string one item at a time and doesn\'t\nload the whole resulting PHP structure into memory at once.\n\nLet\'s continue with the example with 10,000 users. This time they are all in string in memory.\nWhen decoding that string with `json_decode`, 10,000 arrays (objects) is created in memory and then the result\nis returned. JSON Machine on the other hand creates single array for found item in the string and yields it back\nto you. When you process this item and iterate to the next one, another single array is created. This is the same\nbehaviour as with streams/files. Following table puts the concept into perspective:\n\n|                            | String items in memory at a time | Decoded PHP items in memory at a time | Total |\n|----------------------------|---------------------------------:|--------------------------------------:|------:|\n| `json_decode`              |                            10000 |                                 10000 | 20000 |\n| `JsonMachine::fromString`  |                            10000 |                                     1 | 10001 |\n\nThe reality is even brighter. `JsonMachine::fromString` consumes about **5 times less memory** than `json_decode`.\n\n## Error handling\nWhen any part of the JSON stream is malformed, `SyntaxError` exception is thrown. Better solution is on the way.\n\n## Running tests\n```bash\ntests/run.sh\n```\nThis uses php and composer installation already present in your machine.\n\n### Running tests on all supported PHP platforms\n[Install docker](https://docs.docker.com/install/) to your machine and run\n```bash\ntests/docker-run-all-platforms.sh\n```\nThis needs no php nor composer installation on your machine. Only Docker.\n\n## Installation\n```bash\ncomposer require halaxa/json-machine\n```\nor clone or download this repository (not recommended).\n\n## License\nApache 2.0\n\nCogwheel element: Icons made by [TutsPlus](https://www.flaticon.com/authors/tutsplus)\nfrom [www.flaticon.com](https://www.flaticon.com/)\nis licensed by [CC 3.0 BY](http://creativecommons.org/licenses/by/3.0/)\n'