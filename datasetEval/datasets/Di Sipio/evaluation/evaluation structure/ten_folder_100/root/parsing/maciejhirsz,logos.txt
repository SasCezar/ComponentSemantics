b'<p align="center">\n    <img src="https://raw.githubusercontent.com/maciejhirsz/logos/master/logos.png" width="60%" alt="Logos">\n</p>\n\n## Create ridiculously fast Lexers.\n\n[![Travis shield](https://travis-ci.org/maciejhirsz/logos.svg)](https://travis-ci.org/maciejhirsz/logos)\n[![Crates.io version shield](https://img.shields.io/crates/v/logos.svg)](https://crates.io/crates/logos)\n[![Crates.io license shield](https://img.shields.io/crates/l/logos.svg)](https://crates.io/crates/logos)\n\n**Logos** works by:\n+ Resolving all logical branching of token definitions into a tree.\n+ Optimizing complex patterns into [Lookup Tables](https://en.wikipedia.org/wiki/Lookup_table).\n+ Always using a Lookup Table for the first byte of a token.\n+ Producing code that never backtracks, thus running at linear time or close to it.\n\nIn practice it means that for most grammars the lexing performance is virtually unaffected by the number\nof tokens defined in the grammar. Or, in other words, **it is really fast**.\n\n## Usage\n\n```rust\nuse logos::Logos;\n\n#[derive(Logos, Debug, PartialEq)]\nenum Token {\n    // Logos requires that we define two default variants,\n    // one for end of input source,\n    #[end]\n    End,\n\n    // ...and one for errors. Those can be named anything\n    // you wish as long as the attributes are there.\n    #[error]\n    Error,\n\n    // Tokens can be literal strings, of any length.\n    #[token = "fast"]\n    Fast,\n\n    #[token = "."]\n    Period,\n\n    // Or regular expressions.\n    #[regex = "[a-zA-Z]+"]\n    Text,\n}\n\nfn main() {\n    let mut lexer = Token::lexer("Create ridiculously fast Lexers.");\n\n    assert_eq!(lexer.token, Token::Text);\n    assert_eq!(lexer.slice(), "Create");\n    assert_eq!(lexer.range(), 0..6);\n\n    lexer.advance();\n\n    assert_eq!(lexer.token, Token::Text);\n    assert_eq!(lexer.slice(), "ridiculously");\n    assert_eq!(lexer.range(), 7..19);\n\n    lexer.advance();\n\n    assert_eq!(lexer.token, Token::Fast);\n    assert_eq!(lexer.slice(), "fast");\n    assert_eq!(lexer.range(), 20..24);\n\n    lexer.advance();\n\n    assert_eq!(lexer.token, Token::Text);\n    assert_eq!(lexer.slice(), "Lexers");\n    assert_eq!(lexer.range(), 25..31);\n\n    lexer.advance();\n\n    assert_eq!(lexer.token, Token::Period);\n    assert_eq!(lexer.slice(), ".");\n    assert_eq!(lexer.range(), 31..32);\n\n    lexer.advance();\n\n    assert_eq!(lexer.token, Token::End);\n}\n```\n\n## How fast?\n\nRidiculously fast!\n\n```\ntest identifiers                       ... bench:         675 ns/iter (+/- 3) = 1154 MB/s\ntest keywords_operators_and_punctators ... bench:       1,814 ns/iter (+/- 16) = 1174 MB/s\n```\n\n## License\n\nThis code is distributed under the terms of both the MIT license\nand the Apache License (Version 2.0), choose whatever works for you.\n\nSee [LICENSE-APACHE](LICENSE-APACHE) and [LICENSE-MIT](LICENSE-MIT) for details.\n'