b'#### Table of contents\n1. [Introduction](#introduction)\n2. [Installation](#install)\n2. [Usage for Python users](#python)\n3. [Usage for Java users](#java)\n4. [Experimental results](#exp)\n\n# VnCoreNLP: A Vietnamese natural language processing toolkit <a name="introduction"></a>\n\nVnCoreNLP is an NLP annotation pipeline for Vietnamese, providing rich linguistic annotations through key NLP components of **word segmentation**, **POS tagging**, **named entity recognition** (NER) and **dependency parsing**:\n\n* **ACCURATE** \xe2\x80\x93 VnCoreNLP is the most accurate toolkit for Vietnamese NLP, obtaining state-of-the-art results on standard benchmark datasets.\n* **FAST** \xe2\x80\x93 VnCoreNLP is fast, so it can be used for dealing with large-scale data.\n* **Easy-To-Use** \xe2\x80\x93 Users do not have to install external dependencies. Users can run processing pipelines from either the command-line or the  API.\n\n**The general architecture and experimental results of VnCoreNLP can be found in the following related papers:**\n\n1. Thanh Vu, Dat Quoc Nguyen, Dai Quoc Nguyen, Mark Dras and Mark Johnson. **2018**. [VnCoreNLP: A Vietnamese Natural Language Processing Toolkit](http://aclweb.org/anthology/N18-5012). In  *Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations*, [NAACL 2018](http://naacl2018.org), pages 56-60. [[.bib]](http://aclweb.org/anthology/N18-5012.bib)\n2. Dat Quoc Nguyen, Dai Quoc Nguyen, Thanh Vu, Mark Dras and Mark Johnson. **2018**. [A Fast and Accurate Vietnamese Word Segmenter](http://www.lrec-conf.org/proceedings/lrec2018/summaries/55.html). In *Proceedings of the 11th International Conference on Language Resources and Evaluation*, [LREC 2018](http://lrec2018.lrec-conf.org/en/), pages 2582-2587. [[.bib]](https://dblp.uni-trier.de/rec/bibtex/conf/lrec/NguyenNVDJ18)\n3. Dat Quoc Nguyen, Thanh Vu, Dai Quoc Nguyen, Mark Dras and Mark Johnson. **2017**. [From Word Segmentation to POS Tagging for Vietnamese](http://aclweb.org/anthology/U17-1013). In *Proceedings of the 15th Annual Workshop of the Australasian Language Technology Association*, [ALTA 2017](http://alta2017.alta.asn.au), pages 108-113. [[.bib]](http://aclweb.org/anthology/U17-1013.bib)\n\nPlease **CITE** paper [1] whenever VnCoreNLP is used to produce published results or incorporated into other software. If you are dealing in depth with either word segmentation or POS tagging, you are encouraged to also cite paper [2] or [3], respectively. \n\nIf you are looking for light-weight versions, VnCoreNLP\'s word segmentation and POS tagging components have also been released as independent packages [RDRsegmenter](https://github.com/datquocnguyen/RDRsegmenter)  [2]  and [VnMarMoT](https://github.com/datquocnguyen/VnMarMoT) [3], resepectively.\n\n\n## Installation <a name="install"></a>\n\n- `Python 3.4+` if using  a Python wrapper of VnCoreNLP. To install this wrapper, users have to run the following command:\n\n    ``$ pip3 install vncorenlp`` \n    \n    _A special thanks goes to Khoa Duong ([@dnanhkhoa](https://github.com/dnanhkhoa)) for creating this wrapper!_\n    \n- `Java 1.8+` \n- File  `VnCoreNLP-1.1.1.jar` (27MB) and folder `models` (115MB) are placed in the same working folder.\n\n\n\n## Usage for Python users <a name="python"></a>\n\n**Assume that the Python wrapper of VnCoreNLP is already installed via: ``$ pip3 install vncorenlp``**\n\n### Use as a service (recommended)\n\n1. Run the following command: \n\n    ``$ vncorenlp -Xmx2g <FULL-PATH-to-VnCoreNLP-jar-file> -p 9000 -a "wseg,pos,ner,parse"``\n    \n    The service is now available at ``http://127.0.0.1:9000``.\n\n2. Use the service in your `python` code:\n\n```python\nfrom vncorenlp import VnCoreNLP\nannotator = VnCoreNLP(address="http://127.0.0.1", port=9000) \n\n# Input \ntext = "\xc3\x94ng Nguy\xe1\xbb\x85n Kh\xe1\xba\xafc Ch\xc3\xbac  \xc4\x91ang l\xc3\xa0m vi\xe1\xbb\x87c t\xe1\xba\xa1i \xc4\x90\xe1\xba\xa1i h\xe1\xbb\x8dc Qu\xe1\xbb\x91c gia H\xc3\xa0 N\xe1\xbb\x99i. B\xc3\xa0 Lan, v\xe1\xbb\xa3 \xc3\xb4ng Ch\xc3\xbac, c\xc5\xa9ng l\xc3\xa0m vi\xe1\xbb\x87c t\xe1\xba\xa1i \xc4\x91\xc3\xa2y."\n\n# To perform word segmentation, POS tagging, NER and then dependency parsing\nannotated_text = annotator.annotate(text)   \n\n# To perform word segmentation only\nword_segmented_text = annotator.tokenize(text)\n```\n\n- `print(annotated_text)` # JSON format\n\n```\n{\'sentences\': [[{\'index\': 1, \'form\': \'\xc3\x94ng\', \'posTag\': \'Nc\', \'nerLabel\': \'O\', \'head\': 4, \'depLabel\': \'sub\'}, {\'index\': 2, \'form\': \'Nguy\xe1\xbb\x85n_Kh\xe1\xba\xafc_Ch\xc3\xbac\', \'posTag\': \'Np\', \'nerLabel\': \'B-PER\', \'head\': 1, \'depLabel\': \'nmod\'}, {\'index\': 3, \'form\': \'\xc4\x91ang\', \'posTag\': \'R\', \'nerLabel\': \'O\', \'head\': 4, \'depLabel\': \'adv\'}, {\'index\': 4, \'form\': \'l\xc3\xa0m_vi\xe1\xbb\x87c\', \'posTag\': \'V\', \'nerLabel\': \'O\', \'head\': 0, \'depLabel\': \'root\'}, {\'index\': 5, \'form\': \'t\xe1\xba\xa1i\', \'posTag\': \'E\', \'nerLabel\': \'O\', \'head\': 4, \'depLabel\': \'loc\'}, {\'index\': 6, \'form\': \'\xc4\x90\xe1\xba\xa1i_h\xe1\xbb\x8dc\', \'posTag\': \'N\', \'nerLabel\': \'B-ORG\', \'head\': 5, \'depLabel\': \'pob\'}, {\'index\': 7, \'form\': \'Qu\xe1\xbb\x91c_gia\', \'posTag\': \'N\', \'nerLabel\': \'I-ORG\', \'head\': 6, \'depLabel\': \'nmod\'}, {\'index\': 8, \'form\': \'H\xc3\xa0_N\xe1\xbb\x99i\', \'posTag\': \'Np\', \'nerLabel\': \'I-ORG\', \'head\': 6, \'depLabel\': \'nmod\'}, {\'index\': 9, \'form\': \'.\', \'posTag\': \'CH\', \'nerLabel\': \'O\', \'head\': 4, \'depLabel\': \'punct\'}], [{\'index\': 1, \'form\': \'B\xc3\xa0\', \'posTag\': \'Nc\', \'nerLabel\': \'O\', \'head\': 9, \'depLabel\': \'sub\'}, {\'index\': 2, \'form\': \'Lan\', \'posTag\': \'Np\', \'nerLabel\': \'B-PER\', \'head\': 1, \'depLabel\': \'nmod\'}, {\'index\': 3, \'form\': \',\', \'posTag\': \'CH\', \'nerLabel\': \'O\', \'head\': 1, \'depLabel\': \'punct\'}, {\'index\': 4, \'form\': \'v\xe1\xbb\xa3\', \'posTag\': \'N\', \'nerLabel\': \'O\', \'head\': 1, \'depLabel\': \'nmod\'}, {\'index\': 5, \'form\': \'\xc3\xb4ng\', \'posTag\': \'Nc\', \'nerLabel\': \'O\', \'head\': 4, \'depLabel\': \'nmod\'}, {\'index\': 6, \'form\': \'Ch\xc3\xbac\', \'posTag\': \'Np\', \'nerLabel\': \'B-PER\', \'head\': 5, \'depLabel\': \'nmod\'}, {\'index\': 7, \'form\': \',\', \'posTag\': \'CH\', \'nerLabel\': \'O\', \'head\': 1, \'depLabel\': \'punct\'}, {\'index\': 8, \'form\': \'c\xc5\xa9ng\', \'posTag\': \'R\', \'nerLabel\': \'O\', \'head\': 9, \'depLabel\': \'adv\'}, {\'index\': 9, \'form\': \'l\xc3\xa0m_vi\xe1\xbb\x87c\', \'posTag\': \'V\', \'nerLabel\': \'O\', \'head\': 0, \'depLabel\': \'root\'}, {\'index\': 10, \'form\': \'t\xe1\xba\xa1i\', \'posTag\': \'E\', \'nerLabel\': \'O\', \'head\': 9, \'depLabel\': \'loc\'}, {\'index\': 11, \'form\': \'\xc4\x91\xc3\xa2y\', \'posTag\': \'P\', \'nerLabel\': \'O\', \'head\': 10, \'depLabel\': \'pob\'}, {\'index\': 12, \'form\': \'.\', \'posTag\': \'CH\', \'nerLabel\': \'O\', \'head\': 9, \'depLabel\': \'punct\'}]]}\n```\n\n- `print(word_segmented_text)`\n\n```\n[[\'\xc3\x94ng\', \'Nguy\xe1\xbb\x85n_Kh\xe1\xba\xafc_Ch\xc3\xbac\', \'\xc4\x91ang\', \'l\xc3\xa0m_vi\xe1\xbb\x87c\', \'t\xe1\xba\xa1i\', \'\xc4\x90\xe1\xba\xa1i_h\xe1\xbb\x8dc\', \'Qu\xe1\xbb\x91c_gia\', \'H\xc3\xa0_N\xe1\xbb\x99i\', \'.\'], [\'B\xc3\xa0\', \'Lan\', \',\', \'v\xe1\xbb\xa3\', \'\xc3\xb4ng\', \'Ch\xc3\xbac\', \',\', \'c\xc5\xa9ng\', \'l\xc3\xa0m_vi\xe1\xbb\x87c\', \'t\xe1\xba\xa1i\', \'\xc4\x91\xc3\xa2y\', \'.\']]\n```\n\n\n\n\n### Use without the service\n\n```python\nfrom vncorenlp import VnCoreNLP\nannotator = VnCoreNLP("<FULL-PATH-to-VnCoreNLP-jar-file>", annotators="wseg,pos,ner,parse", max_heap_size=\'-Xmx2g\') \n\n# Input \ntext = "\xc3\x94ng Nguy\xe1\xbb\x85n Kh\xe1\xba\xafc Ch\xc3\xbac  \xc4\x91ang l\xc3\xa0m vi\xe1\xbb\x87c t\xe1\xba\xa1i \xc4\x90\xe1\xba\xa1i h\xe1\xbb\x8dc Qu\xe1\xbb\x91c gia H\xc3\xa0 N\xe1\xbb\x99i. B\xc3\xa0 Lan, v\xe1\xbb\xa3 \xc3\xb4ng Ch\xc3\xbac, c\xc5\xa9ng l\xc3\xa0m vi\xe1\xbb\x87c t\xe1\xba\xa1i \xc4\x91\xc3\xa2y."\n\n# To perform word segmentation, POS tagging, NER and then dependency parsing\nannotated_text = annotator.annotate(text)\n\n# To perform word segmentation only\nword_segmented_text = annotator.tokenize(text) \n\n```\n\n_For more details, we refer users to [https://github.com/dnanhkhoa/python-vncorenlp](https://github.com/dnanhkhoa/python-vncorenlp)._\n\n\n## Usage for Java users <a name="java"></a>\n\n### Using VnCoreNLP from the command line\n\nYou can run VnCoreNLP to annotate an input raw text corpus (e.g. a collection of news content) by using following commands:\n\n    // To perform word segmentation, POS tagging, NER and then dependency parsing\n    $ java -Xmx2g -jar VnCoreNLP-1.1.1.jar -fin input.txt -fout output.txt\n    // To perform word segmentation, POS tagging and then NER\n    $ java -Xmx2g -jar VnCoreNLP-1.1.1.jar -fin input.txt -fout output.txt -annotators wseg,pos,ner\n    // To perform word segmentation and then POS tagging\n    $ java -Xmx2g -jar VnCoreNLP-1.1.1.jar -fin input.txt -fout output.txt -annotators wseg,pos\n    // To perform word segmentation\n    $ java -Xmx2g -jar VnCoreNLP-1.1.1.jar -fin input.txt -fout output.txt -annotators wseg    \n\n\n### Using VnCoreNLP from the API\n\nThe following code is a simple and complete example:\n\n```java\nimport vn.pipeline.*;\nimport java.io.*;\npublic class VnCoreNLPExample {\n    public static void main(String[] args) throws IOException {\n    \n        // "wseg", "pos", "ner", and "parse" refer to as word segmentation, POS tagging, NER and dependency parsing, respectively. \n        String[] annotators = {"wseg", "pos", "ner", "parse"}; \n        VnCoreNLP pipeline = new VnCoreNLP(annotators); \n    \n        String str = "\xc3\x94ng Nguy\xe1\xbb\x85n Kh\xe1\xba\xafc Ch\xc3\xbac  \xc4\x91ang l\xc3\xa0m vi\xe1\xbb\x87c t\xe1\xba\xa1i \xc4\x90\xe1\xba\xa1i h\xe1\xbb\x8dc Qu\xe1\xbb\x91c gia H\xc3\xa0 N\xe1\xbb\x99i. B\xc3\xa0 Lan, v\xe1\xbb\xa3 \xc3\xb4ng Ch\xc3\xbac, c\xc5\xa9ng l\xc3\xa0m vi\xe1\xbb\x87c t\xe1\xba\xa1i \xc4\x91\xc3\xa2y."; \n        \n        Annotation annotation = new Annotation(str); \n        pipeline.annotate(annotation); \n        \n        System.out.println(annotation.toString());\n        // 1    \xc3\x94ng                 Nc  O       4   sub \n        // 2    Nguy\xe1\xbb\x85n_Kh\xe1\xba\xafc_Ch\xc3\xbac    Np  B-PER   1   nmod\n        // 3    \xc4\x91ang                R   O       4   adv\n        // 4    l\xc3\xa0m_vi\xe1\xbb\x87c            V   O       0   root\n        // ...\n        \n        //Write to file\n        PrintStream outputPrinter = new PrintStream("output.txt");\n        pipeline.printToFile(annotation, outputPrinter); \n    \n        // You can also get a single sentence to analyze individually \n        Sentence firstSentence = annotation.getSentences().get(0);\n        System.out.println(firstSentence.toString());\n    }\n}\n```\n\n<img width="1039" alt="vncorenlpexample" src="https://user-images.githubusercontent.com/33695776/37561346-aca1fd68-2aa0-11e8-8bd8-530577b0b5cf.png">\n\nSee VnCoreNLP\'s open-source in folder `src` for API details. \n\n## Experimental results <a name="exp"></a>\n\nWe briefly present experimental setups and obtained results in the following subsections. See details in papers [1,2,3] above or at [NLP-progress](http://nlpprogress.com/vietnamese/vietnamese.html).\n\n### Word segmentation \n\n* Training data: 75k manually word-segmented training sentences from the VLSP 2013 word segmentation shared task.\n* Test data: 2120 test sentences from the VLSP 2013 POS tagging shared task.\n\n<table>\n  <tr>\n    <td><b>Model<b></td>\n    <td><b>F1 (%)</td>\n    <td><b>Speed</b> (words/second)</td>\n  </tr>\n  <tr>\n    <td>VnCoreNLP (i.e. RDRsegmenter)</td>\n    <td><b>97.90</b></td>\n    <td><b>62k</b> / _</td>\n  </tr>\n  <tr>\n    <td>UETsegmenter</td>\n    <td>97.87</td>\n    <td>48k / 33k*</td>\n  </tr>\n   <tr>\n    <td>vnTokenizer</td>\n    <td>97.33</td>\n    <td> _ / 5k*</td>\n  </tr>\n   <tr>\n    <td>JVnSegmenter-Maxent</td>\n    <td>97.00</td>\n    <td> _ / 1k*</td>\n  </tr>\n   <tr>\n    <td>JVnSegmenter-CRFs</td>\n    <td>97.06</td>\n    <td> _ / 1k*</td>\n  </tr>\n   <tr>\n    <td>DongDu</td>\n    <td>96.90</td>\n    <td> _ / 17k*</td>\n  </tr>\n</table>\n\n* Speed is computed on a personal computer of Intel Core i7 2.2 GHz, except when specifically mentioned. \\* denotes that the speed is computed on a personal computer of   Intel Core i5 1.80 GHz.\n* See paper [2] for more details.\n\n### POS tagging \n\n* 27,870 sentences for training and development from the VLSP 2013 POS tagging shared task:\n  *  27k sentences are used for training.\n  *  870 sentences are used for development.\n* Test data: 2120 test sentences from the VLSP 2013 POS tagging shared task.\n\n<table>\n    <tr>\n    <td><b>Model<b></td>\n    <td><b>Accuracy (%)</td>\n    <td><b>Speed</td>\n  </tr>\n  <tr>\n    <td>VnCoreNLP (i.e. VnMarMoT)</td>\n    <td><b>95.88</b></td>\n    <td>25k</td>\n  </tr>\n  <tr>\n    <td>RDRPOSTagger</td>\n    <td>   95.11 </td>\n    <td> <b>  180k</td>\n  </tr>\n   <tr>\n    <td>BiLSTM-CRF</td>\n    <td>95.06</td>\n    <td> 3k</td>\n  </tr>\n   <tr>\n    <td>BiLSTM-CRF + CNN-char</td>\n    <td>95.40</td>\n    <td> 2.5k</td>\n  </tr>\n  <tr>\n    <td>BiLSTM-CRF + LSTM-char</td>\n    <td>95.31</td>\n    <td> 1.5k</td>\n  </tr>\n</table>\n\n* See paper [3] for more details.\n\n### Named entity recognition\n* 16,861 sentences for training and development from the VLSP 2016 NER shared task:\n  *  14,861 sentences are used for training.\n  *  2k sentences are used for development.\n* Test data: 2,831 test sentences from the VLSP 2016 NER  shared task.\n* **NOTE** that in the VLSP 2016 NER data, each word representing a full personal name are separated into syllables that constitute the word. The VLSP 2016 NER data also consists of gold POS and chunking tags as [reconfirmed by VLSP 2016 organizers](https://drive.google.com/file/d/1XzrgPw13N4C_B6yrQy_7qIxl8Bqf7Uqi/view?usp=sharing). This scheme results in an unrealistic scenario for a pipeline evaluation: \n  * The standard annotation for Vietnamese word segmentation and POS tagging forms each full name as a word token, thus all   word segmenters have been trained to output a full name as a word and all POS taggers have been trained to assign a POS label to the entire full-name.\n  * Gold POS and chunking tags are NOT available in a real-world application.\n* For a realistic scenario, contiguous syllables constituting a full name are merged to form a word. Then,  POS tags are predicted by using our tagging component. The results are as follows:\n\n<table>\n    <tr>\n    <td><b>Model<b></td>\n    <td><b>F1</td>\n    <td><b>Speed</td>\n  </tr>\n  <tr>\n    <td>VnCoreNLP</td>\n    <td><b>88.55</td>\n    <td><b>18k</td>\n  </tr>\n  <tr>\n    <td>BiLSTM-CRF</td>\n    <td>86.48</td>\n    <td> 2.8k</td>\n  </tr>\n   <tr>\n    <td>BiLSTM-CRF + CNN-char</td>\n    <td>88.28</td>\n    <td> 1.8k</td>\n  </tr>\n  <tr>\n    <td>BiLSTM-CRF + LSTM-char</td>\n    <td>87.71</td>\n    <td> 1.3k</td>\n  </tr>\n  <tr>\n    <td>BiLSTM-CRF + predicted POS</td>\n    <td>86.12</td>\n    <td> _ </td>\n  </tr>\n   <tr>\n    <td>BiLSTM-CRF + CNN-char + predicted POS </td>\n    <td>88.06</td>\n    <td> _</td>\n  </tr>\n  <tr>\n    <td>BiLSTM-CRF + LSTM-char + predicted POS</td>\n    <td>87.43</td>\n    <td> _ </td>\n  </tr>\n</table>\n\n* Here, for VnCoreNLP, we include the time POS tagging takes in the speed.\n* See paper [1] for more details.\n\n### Dependency parsing\n\n* The last 1020 sentences of the [benchmark Vietnamese dependency treebank VnDT](http://vndp.sourceforge.net) are used for test, while the remaining 9k+ sentences are used for training & development. LAS and UAS scores are computed on all\ntokens (i.e. including punctuation). \n\n<table>\n  <tr>\n    <th colspan="2"><b>Model</b></th>\n    <th> <b>LAS</b> (%)</th>\n    <th><b>UAS</b> (%)</th>\n    <th><b>Speed</th>\n  </tr>\n  <tr>\n    <td rowspan="5">Gold POS</td>\n    <td>VnCoreNLP</td>\n    <td><b>73.39</td>\n    <td>79.02</td>\n    <td>_</td>\n  </tr>\n  <tr>\n    <td>BIST-bmstparser</td>\n    <td>73.17</td>\n    <td><b>79.39</td>\n    <td>_</td>\n  </tr>\n  <tr>\n    <td>BIST-barchybrid</td>\n    <td>72.53</td>\n    <td>79.33</td>\n    <td>_</td>\n  </tr>\n  <tr>\n    <td>MSTparser</td>\n    <td>70.29</td>\n    <td>76.47</td>\n    <td>_</td>\n  </tr>\n  <tr>\n    <td>MaltParser</td>\n    <td>69.10</td>\n    <td>74.91</td>\n    <td>_</td>\n  </tr>\n  <tr>\n    <td rowspan="2">Predicted POS</td>\n    <td>VnCoreNLP</td>\n    <td><b>70.23</td>\n    <td>76.93</td>\n    <td><b>8k</td>\n  </tr>\n  <tr>\n    <td>jPTDP</td>\n    <td>69.49</td>\n    <td><b>77.68</td>\n    <td>700</td>\n  </tr>\n</table>\n\n* See paper [1] for more details.\n'