b'# Jsoniter Scala\n \n[![Actions build](https://github.com/plokhotnyuk/jsoniter-scala/workflows/build/badge.svg)](https://github.com/plokhotnyuk/jsoniter-scala/actions)\n[![TravisCI build](https://travis-ci.org/plokhotnyuk/jsoniter-scala.svg?branch=master)](https://travis-ci.org/plokhotnyuk/jsoniter-scala) \n[![Code coverage](https://codecov.io/gh/plokhotnyuk/jsoniter-scala/branch/master/graph/badge.svg)](https://codecov.io/gh/plokhotnyuk/jsoniter-scala)\n[![Gitter chat](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/plokhotnyuk/jsoniter-scala?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Maven Central](https://img.shields.io/badge/maven--central-2.0.2-blue.svg)](https://search.maven.org/search?q=jsoniter-scala-macros)\n\nScala macros that generate codecs for case classes, standard types, and collections to get maximum performance of JSON \nparsing and serialization.\n\n[**Latest results of benchmarks**](https://plokhotnyuk.github.io/jsoniter-scala/) which compare parsing and serialization\nperformance of Jsoniter Scala with [Borer](https://github.com/sirthias/borer), [Circe](https://github.com/circe/circe),\n[Play-JSON](https://github.com/playframework/play-json), [Spray-JSON](https://github.com/spray/spray-json),\n[Jackson](https://github.com/FasterXML/jackson-module-scala), [uPickle](https://github.com/lihaoyi/upickle),\n[AVSystem\'s scala-commons](https://github.com/AVSystem/scala-commons), [DSL-JSON](https://github.com/ngs-doo/dsl-json)\nand [Jsoniter Java](https://github.com/json-iterator/java) libraries using different JDK and GraalVM versions on the\nfollowing environment: Intel\xc2\xae Core\xe2\x84\xa2 i9-9880H CPU @ 2.3GHz (max 4.8GHz), RAM 16Gb DDR4-2400, macOS Mojave 10.14.6, and \nlatest versions of Amazon Corretto 8/11, [OpenJDK 13](https://docs.google.com/spreadsheets/d/1IxIvLoLlLb0bxUaRgSsaaRuXV0RUQ3I04vFqhDc2Bt8/edit?usp=sharing),\n, and GraalVM CE/EE for Java 8/11\n\n## Acknowledgments\n\nThis library started from macros that reused [Jsoniter Java](https://github.com/json-iterator/java) reader & writer and\ngenerated codecs for them but then evolved to have own core of mechanics for parsing and serialization.\n\nThe idea to generate codecs by Scala macros and main details was borrowed from\n[Kryo Macros](https://github.com/evolution-gaming/kryo-macros) and adapted for needs of the JSON domain.\n  \nOther Scala macros features were peeped in\n[AVSystem Commons Library for Scala](https://github.com/AVSystem/scala-commons/tree/master/commons-macros/src/main/scala/com/avsystem/commons/macros)\n\n## Goals\n\n1. **Safety**: validate JSON format, UTF-8 encoding of strings, and mapped values safely with the fail-fast approach and \nclear reporting, provide configurable limits for suboptimal data structures with safe defaults to be resilient for DoS \nattacks, generate codecs that create instances of a _fixed_ set of classes during parsing to avoid RCE attacks\n2. **Correctness**: parse and serialize numbers without loosing of precision doing half even rounding for too long JSON\nnumbers when they bounded to floats or doubles, do not replace illegally encoded characters of string values by \nplaceholder characters\n3. **Speed**: do parsing and serialization of JSON directly from UTF-8 bytes to your data structures and back, do it \ncrazily fast without using of run-time reflection, intermediate ASTs, strings or hash maps, with minimum allocations and\ncopying\n4. **Productivity**: derive codecs recursively for complex types using one line macro, do it in _compile-time_ to \nminimize the probability of run-time issues, optionally print generated sources as compiler output to be inspected for \nproving safety and correctness or to be reused as a starting point for the implementation of custom codecs, prohibit \nserializing of `null` Scala values and parsing immediately to them in generated codecs\n5. **Ergonomics**: have preconfigured defaults for the safest and common usage that can be easily altered by compile- \nand run-time configuration instances, combined with compile-time annotations and implicits, embrace the textual \nrepresentation of JSON providing a pretty printing option, provide a hex dump in the parse error message to speed up the\nview of an error context\n\nThe library targets JDK 8+ and GraalVM 19+ (including compilation to native images) without any platform restrictions.\n\nSupport of Scala.js and Scala Native is not a goal for the moment. \n\n## Features and limitations\n- JSON parsing from `Array[Byte]`, `java.io.InputStream` or `java.nio.ByteBuffer`\n- JSON serialization to `Array[Byte]`, `java.io.OutputStream` or `java.nio.ByteBuffer`\n- Support of parsing from or writing to part of `Array[Byte]` or `java.nio.ByteBuffer` by specifying of position and \n  limit\n- Parsing of streaming JSON values and JSON arrays from `java.io.InputStream` without the need of holding all parsed\n  values in the memory\n- Only UTF-8 encoding is supported when working with buffered bytes directly but there is a fallback to parse and\n  serialize JSON from/to `String` (while this is much less efficient)\n- Parsing of strings with escaped characters for JSON keys and string values\n- Codecs can be generated for primitives, boxed primitives, enums, tuples, `String`, `BigInt`, `BigDecimal`, `Option`,\n  `Either`, `java.util.UUID`, `java.time.*` (to/from ISO-8601 representation only), Scala collections, arrays, module\n  classes, literal types, value classes, and case classes with values/fields having any of types listed here\n- Classes should be defined with a primary constructor that has one list of arguments for all non-transient fields\n- Non-case Scala classes also supported but they should have getter accessors for all arguments of a primary\n  constructor\n- Types that supported as map keys are primitives, boxed primitives, enums, `String`, `BigInt`, `BigDecimal`,\n  `java.util.UUID`, `java.time.*`, literal types, and value classes for any of them\n- Codecs for sorted maps and sets can be customized by implicit `Ordering[K]` instances for keys that are available at\n  the scope of the `make` macro call\n- Core module support reading and writing byte arrays from/to Base16 and Base64 representations (RFC 4648) for using in \n  custom codecs    \n- Parsing of escaped characters is not supported for strings which are mapped to byte arrays, numeric and `java.time.*` \n  types\n- Support of first-order and higher-kind types\n- Support of 2 representations of ADTs with a sealed trait or a Scala class as a base type and non-abstract Scala \n  classes or objects as leaf classes: 1st representation uses discriminator field with string type of value, 2nd one \n  uses string values for objects and a wrapper JSON object with a discriminator key for case class instances\n- Implicitly resolvable value codecs for JSON values and key codecs for JSON object keys that are mapped to maps allows\n  to inject your custom codecs for adding support of other types or for altering representation in JSON for already\n  supported classes\n- Type aliases are also supported for all types mentioned above\n- Only acyclic graphs of class instances are supported by generated codecs\n- Order of instance fields is preserved during serialization for generated codecs\n- Throws a parsing exception if duplicated keys were detected for a class instance (except maps)\n- Serialization of `null` values is prohibited by throwing of `NullPointerException` errors\n- Parsing of `null` values allowed only for optional of collection types (that means the `None` value or an empty \n  collection accordingly) and for fields which have defined non-null default values\n- Fields with default values that defined in the constructor are optional, other fields are required (no special\n  annotation required)\n- Fields with values that are equals to default values, or are empty options/collections/arrays are not serialized to\n  provide a sparse output\n- Any values that used directly or as part of default values of the constructor parameters should have right\n  implementations of the `equals` method (it mostly concerns non-case classes or other types that have custom codecs)\n- Fields can be annotated as transient or just not defined in the constructor to avoid parsing and serializing at all\n- Field names can be overridden for serialization/parsing by field annotation in the primary constructor of classes\n- Reading and writing of any arbitrary bytes or raw values are possible by using custom codecs\n- Parsing exception always reports a hexadecimal offset of `Array[Byte]`, `java.io.InputStream` or `java.nio.ByteBuffer`\n  where it occurs and an optional hex dump affected by error part of an internal byte buffer\n- Configurable by field annotation ability to read/write numeric fields from/to string values\n- Both key and value codecs are specialized to be work with primitives efficiently without boxing/unboxing\n- No extra buffering is required when parsing from `java.io.InputStream` or serializing to `java.io.OutputStream`\n- Using black box macros only for codec generation ensures that your types will never be changed\n- Ability to print all generated code for codecs using a custom scala compiler option: `-Xmacro-settings:print-codecs`\n- No dependencies on extra libraries in _runtime_ excluding Scala\'s `scala-library`\n- Releases for different Scala versions: 2.11, 2.12, 2.13\n- Support of shading to another package for locking on a particular released version\n- Patch versions are backward and forward compatible \n- Support of compilation to a native image by GraalVM\n  \nThere are configurable options that can be set in compile-time:\n- Ability to read/write numbers from/to string values\n- Skipping of unexpected fields or throwing of parse exceptions\n- Skipping of serialization of fields that have empty collection values can be turned off to force serialization of them\n- Skipping of serialization of fields that have empty optional values can be turned off to force serialization of them\n- Skipping of serialization of fields which values are matched with defaults that are defined in the primary constructor\n  can be turned off to force serialization of that values\n- Mapping function for property names between classes and JSON, including predefined functions which enforce snake_case,\n  kebab-case, camelCase or PascalCase names for all fields in the generated codec\n- An optional name of the discriminator field for ADTs\n- Mapping function for values of a discriminator field that is used for distinguishing classes of ADTs\n- Ability to set precision, scale limit, and the max number of significant digits when parsing `BigDecimal` values\n- Ability to set the max number of significant digits when parsing `BigInt` values\n- Ability to set max allowed value when parsing bit sets\n- Ability to set a limit for the number of inserts when parsing sets or maps\n- Throwing of compilation error for recursive data structures can be turned off\n\nList of options that change parsing and serialization in runtime:\n- Serialization of strings with escaped Unicode characters to be ASCII compatible\n- Indenting of output and its step\n- Throwing of stack-less parsing exceptions by default to greatly reduce the impact on performance, while stack traces\n  can be turned on in development for debugging\n- Turning off hex dumping affected by error part of an internal byte buffer to reduce the impact on performance\n- Preferred size of internal in buffers when parsing from `java.io.InputStream` or `java.nio.DirectByteBuffer`\n- Preferred size of internal out buffers when serializing to `java.io.OutputStream` or `java.nio.DirectByteBuffer`\n- Preferred size of char buffers when parsing string values\n\nFor upcoming features and fixes see [Commits](https://github.com/plokhotnyuk/jsoniter-scala/commits/master)\nand [Issues page](https://github.com/plokhotnyuk/jsoniter-scala/issues).\n\n## How to use\n\nAdd the core library with a "compile" scope and the macros library with a "provided" scope to your dependencies list:\n\n```sbt\nlibraryDependencies ++= Seq(\n  "com.github.plokhotnyuk.jsoniter-scala" %% "jsoniter-scala-core"   % "2.0.2" % Compile,\n  "com.github.plokhotnyuk.jsoniter-scala" %% "jsoniter-scala-macros" % "2.0.2" % Provided // required only in compile-time\n)\n```\n\nGenerate codecs for your Scala classes and collections:\n\n```scala\nimport com.github.plokhotnyuk.jsoniter_scala.macros._\nimport com.github.plokhotnyuk.jsoniter_scala.core._\n\ncase class Device(id: Int, model: String)\n\ncase class User(name: String, devices: Seq[Device])\n\nimplicit val codec: JsonValueCodec[User] = JsonCodecMaker.make[User](CodecMakerConfig)\n```\n\nThat\'s it! You have generated an instance of `com.github.plokhotnyuk.jsoniter_scala.core.JsonValueCodec`.\n\nNow you can use it for parsing and serialization:\n\n```scala\nval user = readFromArray("""{"name":"John","devices":[{"id":1,"model":"HTC One X"}]}""".getBytes("UTF-8"))\nval json = writeToArray(User(name = "John", devices = Seq(Device(id = 2, model = "iPhone X"))))\n```\n\nIf you don\'t know-how to make your data structures from scratch but have a JSON sample then use on-line services\n[1](https://json2caseclass.cleverapps.io/) [2](https://transform.now.sh/json-to-scala-case-class/) to generate an initial\nversion of them.\n\nTo see generated code for codecs add the following line to your sbt build file\n\n```sbt\nscalacOptions ++= Seq("-Xmacro-settings:print-codecs")\n```\n\nFull code see in the [examples](https://github.com/plokhotnyuk/jsoniter-scala/blob/master/jsoniter-scala-examples) directory\n\nFor more use cases, please, check out tests:\n- [JsonCodecMakerSpec](https://github.com/plokhotnyuk/jsoniter-scala/blob/master/jsoniter-scala-macros/src/test/scala/com/github/plokhotnyuk/jsoniter_scala/macros/JsonCodecMakerSpec.scala)\n- [PackageSpec](https://github.com/plokhotnyuk/jsoniter-scala/blob/master/jsoniter-scala-core/src/test/scala/com/github/plokhotnyuk/jsoniter_scala/core/PackageSpec.scala)\n- [JsonReaderSpec](https://github.com/plokhotnyuk/jsoniter-scala/blob/master/jsoniter-scala-core/src/test/scala/com/github/plokhotnyuk/jsoniter_scala/core/JsonReaderSpec.scala)\n- [JsonWriterSpec](https://github.com/plokhotnyuk/jsoniter-scala/blob/master/jsoniter-scala-core/src/test/scala/com/github/plokhotnyuk/jsoniter_scala/core/JsonWriterSpec.scala)\n\nSamples for integration with different web frameworks:\n- [colossus](https://github.com/TechEmpower/FrameworkBenchmarks/blob/b3a39dcd95b207cd2509d7bbf873a0dfb91097f5/frameworks/Scala/colossus/src/main/scala/example/Main.scala)\n- [blaze](https://github.com/TechEmpower/FrameworkBenchmarks/blob/b3a39dcd95b207cd2509d7bbf873a0dfb91097f5/frameworks/Scala/blaze/src/main/scala/Main.scala)\n- [Play (with Netty native transport)](https://github.com/plokhotnyuk/play/tree/master/src/main/scala/microservice)\n- [akka-http](https://github.com/hseeberger/akka-http-json/blob/master/akka-http-jsoniter-scala/src/test/scala/de/heikoseeberger/akkahttpjsoniterscala/ExampleApp.scala)\n- [http4s](https://github.com/TechEmpower/FrameworkBenchmarks/blob/d1f960b2d4d6ea7b5c30a3ef2a8b47670f346f1c/frameworks/Scala/http4s/src/main/scala/WebServer.scala)\n\nFor all dependent projects it is recommended to use [sbt-updates plugin](https://github.com/rtimush/sbt-updates) or\n[Scala steward service](https://github.com/scala-steward) to keep up with using of latest releases.\n\n## Known issues\n\n1. Scalac has a bug that affects case classes which have 2 fields where the name of one is a prefix for another name\nthat contains a character which should be encoded immediately after the prefix (like `o` and `o-o`). You will get \ncompilation or runtime error, depending on the version of the compiler, see details [here](https://github.com/scala/bug/issues/11212).\n\nThe workaround is to move a definition of the field with encoded chars (`o-o` in our case) to be after the field that is\naffected by the exception (after the `o` field)\n\n2. A configuration parameter for the `make` macro is evaluated in compile-time only that require no dependency on other\ncode that uses a result of the macro\'s call. In that case the following compilation error will be reported:\n\n```\n[error] Cannot evaluate a parameter of the \'make\' macro call for type \'full.name.of.YourType\'. It should not depend on\n        code from the same compilation module where the \'make\' macro is called. Use a separated submodule of the project\n        to compile all such dependencies before their usage for generation of codecs.\n```\n\nBut sometime scalac (or zinc) can fail to compile the `make` macro call with the same error message for configuration\nthat has not clear dependencies on other code. For those cases workarounds can be simpler than recommended usage of\nseparated submodule:\n- isolate the `make` macro call(s) in the separated object, like in [this PR](https://github.com/plokhotnyuk/play/pull/5/files)\n- move jsoniter-scala imports to be local, like [here](https://github.com/plokhotnyuk/play/blob/master/src/main/scala/microservice/HelloWorld.scala#L6-L7)\nand [here](https://github.com/plokhotnyuk/play/blob/master/src/main/scala/microservice/HelloWorldController.scala#L12)\n- use `sbt clean compile stage` or `sbt clean test stage` instead of just `sbt clean stage`, like in\n[this repo](https://github.com/hochgi/HTTP-stream-exercise/tree/jsoniter-2nd-round)\n\n3. Scalac can throw the following stack overflow exception on `make` call for ADTs with objects if the call and the ADT\ndefinition are enclosed in the definition of some outer class (for more details see: https://github.com/scala/bug/issues/11157):\n\n```\njava.lang.StackOverflowError\n    ...\n\tat scala.tools.nsc.transform.ExplicitOuter$OuterPathTransformer.outerPath(ExplicitOuter.scala:267)\n\tat scala.tools.nsc.transform.ExplicitOuter$OuterPathTransformer.outerPath(ExplicitOuter.scala:267)\n\tat scala.tools.nsc.transform.ExplicitOuter$OuterPathTransformer.outerPath(ExplicitOuter.scala:267)\n\tat scala.tools.nsc.transform.ExplicitOuter$OuterPathTransformer.outerPath(ExplicitOuter.scala:267)\n\t...\n```\n\nWorkarounds are:\n- don\'t enclose ADTs with an object into outer classes\n- use the outer object (not a class) instead \n\n## How to develop\n\nFeel free to ask questions in [chat](https://gitter.im/plokhotnyuk/jsoniter-scala), open issues, or contribute by \ncreating pull requests (fixes and improvements to docs, code, and tests are highly appreciated)\n\n### Run tests, check coverage and binary compatibility\n\n```sh\nsbt clean coverage test coverageReport\nsbt clean +test +mimaReportBinaryIssues\n```\n\nBEWARE: jsoniter-scala is included into [Scala Community Build](https://github.com/scala/community-builds)\n for 2.11.x, 2.12.x, and 2.13.x versions of Scala.\n \n### Printing of code generated by macros\n\nTo see and check code generated by the `make` macro add the `-Dmacro.settings=print-codecs` option like here:\n```sh\nsbt -Dmacro.settings=print-codecs clean test\n``` \n\nAlso, to print code generated by the `eval` macro use the `-Dmacro.settings=print-expr-results` option.\n\nBoth options can be combined: `-Dmacro.settings=print-codecs,print-expr-results`\n\n### Run benchmarks\n\nBefore benchmark running check if your CPU works in `performance` mode (not a `powersave` one). On Linux use following\ncommands to print current and set the `performance` mode:\n\n```sh\ncat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor\necho performance | sudo tee /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor\n```\n\nSbt plugin for JMH tool is used for benchmarking, to see all their features and options please check\n[Sbt-JMH docs](https://github.com/ktoso/sbt-jmh) and [JMH tool docs](https://openjdk.java.net/projects/code-tools/jmh/\n\nLearn how to write benchmarks in [JMH samples](https://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/)\n and JMH articles posted in [Aleksey Shipil\xd1\x91v\xe2\x80\x99s](https://shipilev.net/) and [Nitsan Wakart\xe2\x80\x99s](https://psy-lob-saw.blogspot.com/p/jmh-related-posts.html)\n blogs.\n\nList of available option can be printed by:\n\n```sh\nsbt \'jsoniter-scala-benchmark/jmh:run -h\'\n```\n\nResults of benchmark can be stored in different formats: *.csv, *.json, etc. All supported formats can be listed by:\n```sh\nsbt \'jsoniter-scala-benchmark/jmh:run -lrf\'\n```\n\nJMH allows to run benchmarks with different profilers, to get a list of supported use (can require entering of user\npassword):\n\n```sh\nsbt \'jsoniter-scala-benchmark/jmh:run -lprof\'\n```\n\nHelp for profiler options can be printed by following command (`<profiler_name>` should be replaced by name of the\nsupported profiler from the command above):\n\n```sh\nsbt \'jsoniter-scala-benchmark/jmh:run -prof <profiler_name>:help\'\n```\n\nFor parametrized benchmarks the constant value(s) for parameter(s) can be set by `-p` option:\n\n```sh\nsbt clean \'jsoniter-scala-benchmark/jmh:run -p size=1,10,100,1000 ArrayOf.*\'\n```\n\nTo see throughput with allocation rate of generated codecs run benchmarks with GC profiler using the following command:\n\n```sh\nsbt clean \'jsoniter-scala-benchmark/jmh:run -prof gc -rf json -rff jdk8.json .*Reading.*\'\n```\n\nResults that are stored in JSON can be easy plotted in [JMH Visualizer](https://jmh.morethan.io/) by drugging & dropping\nof your file to the drop zone or using the `source` parameter with an HTTP link to your file in the URL like\n[here](https://jmh.morethan.io/?source=https://plokhotnyuk.github.io/jsoniter-scala/oraclejdk11.json).\n\nOn Linux the perf profiler can be used to see CPU event statistics normalized per ops:\n\n```sh\nsbt clean \'jsoniter-scala-benchmark/jmh:run -prof perfnorm TwitterAPIReading.jsoniterScala\'\n```\n\nTo get a result for some benchmarks with an in-flight recording file from JFR profiler use command like this:\n\n```sh\nsbt clean \'jsoniter-scala-benchmark/jmh:run -jvmArgsAppend "-XX:+UnlockDiagnosticVMOptions -XX:+DebugNonSafepoints" -prof "jmh.extras.JFR:dir=/tmp/profile-jfr;flameGraphDir=/home/andriy/Projects/com/github/brendangregg/FlameGraph;jfrFlameGraphDir=/home/andriy/Projects/com/github/chrishantha/jfr-flame-graph;verbose=true" -wi 10 -i 60 TwitterAPIReading.jsoniterScala\'\n```\n\nNow you can open files from the `/tmp/profile-jfr` directory:\n```sh\nprofile.jfr                             # JFR profile, open and analyze it using JMC\njfr-collapsed-cpu.txt                   # Data from JFR profile that are extracted for Flame Graph tool\nflame-graph-cpu.svg                     # Flame graph of CPU usage\nflame-graph-cpu-reverse.svg             # Reversed flame graph of CPU usage\nflame-graph-allocation-tlab.svg         # Flame graph of heap allocations in TLAB\nflame-graph-allocation-tlab-reverse.svg # Reversed flame graph of heap allocations in TLAB\n```\n\nTo run benchmarks with recordings by [Async profiler](https://github.com/jvm-profiling-tools/async-profiler), clone its\nrepository and use command like this:\n\n```sh\nsbt -no-colors \'jsoniter-scala-benchmark/jmh:run -jvmArgsAppend "-XX:+UnlockDiagnosticVMOptions -XX:+DebugNonSafepoints" -prof "jmh.extras.Async:event=cpu;dir=/tmp/profile-async;asyncProfilerDir=/home/andriy/Projects/com/github/jvm-profiling-tools/async-profiler;flameGraphDir=/home/andriy/Projects/com/github/brendangregg/FlameGraph;flameGraphOpts=--color,java;verbose=true" -wi 10 -i 60 TwitterAPIReading.jsoniterScala\'\n```\n\nTo see list of available events need to start your app or benchmark, and run `jps` command. I will show list of PIDs and\nnames for currently running Java processes. While your Java process still running launch the Async Profiler with the\n`list` option and ID of your process like here:\n```sh\n$ ~/Projects/com/github/jvm-profiling-tools/async-profiler/profiler.sh list 6924\nBasic events:\n  cpu\n  alloc\n  lock\n  wall\n  itimer\nPerf events:\n  page-faults\n  context-switches\n  cycles\n  instructions\n  cache-references\n  cache-misses\n  branches\n  branch-misses\n  bus-cycles\n  L1-dcache-load-misses\n  LLC-load-misses\n  dTLB-load-misses\n  mem:breakpoint\n  trace:tracepoint\n```\n\nFollowing command can be used to profile and print assembly code of hottest methods, but it requires [a setup of an \nadditional library to make PrintAssembly feature enabled](https://psy-lob-saw.blogspot.com/2013/01/java-print-assembly.html):\n\n```sh\nsbt clean \'jsoniter-scala-benchmark/jmh:run -prof perfasm -wi 10 -i 10 -p size=128 BigIntReading.jsoniterScala\'\n```\n\nMore info about extras, options and ability to generate flame graphs see in [Sbt-JMH docs](https://github.com/ktoso/sbt-jmh)\n\nOther benchmarks with results for jsoniter-scala:\n- [comparison](https://github.com/sirthias/borer/pull/30) with other JSON parser for Scala mostly on samples from real APIs \n- [comparison](https://github.com/dkomanov/scala-serialization/pull/8) with best binary parsers and serializers for Scala\n- [comparison](https://github.com/saint1991/serialization-benchmark) with different binary and text serializers for Scala\n- [comparison](https://github.com/tkrs/json-bench) with JSON serializers for Scala on synthetic samples\n- [comparison](https://github.com/guillaumebort/mison/pull/1) with a state of the art filter that by "building\n  structural indices converts control flow into data flow, thereby largely eliminating inherently unpredictable branches\n  in the program and exploiting the parallelism available in modern processors"\n\n### Publish locally\n\nPublish to local Ivy repo:\n\n```sh\nsbt clean +publishLocal\n```\n\nPublish to local Maven repo:\n\n```sh\nsbt clean +publishM2\n```\n\n### Release\n\nFor version numbering use [Recommended Versioning Scheme](https://docs.scala-lang.org/overviews/core/binary-compatibility-for-library-authors.html#recommended-versioning-scheme)\nthat is used in the Scala ecosystem.\n\nDouble-check binary and source compatibility, including behavior, and release using the following command (credentials \nare required):\n\n```sh\nsbt release\n```\n\nDo not push changes to github until promoted artifacts for the new version are not available for download on\n[Maven Central Repository](https://repo1.maven.org/maven2/com/github/plokhotnyuk/jsoniter-scala)\nto avoid binary compatibility check failures in triggered Travis CI builds.\n\nThe last step is updating of the tag info in a [release list](https://github.com/plokhotnyuk/jsoniter-scala/releases).\n'