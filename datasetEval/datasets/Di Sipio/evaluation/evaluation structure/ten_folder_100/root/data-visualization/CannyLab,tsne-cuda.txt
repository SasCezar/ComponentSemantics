b"# TSNE-CUDA\n[![Build Status](https://travis-ci.org/CannyLab/tsne-cuda.svg?branch=docker-build)](https://travis-ci.org/CannyLab/tsne-cuda) \n\n\nThis repo is an optimized CUDA version of [FIt-SNE algorithm](https://github.com/KlugerLab/FIt-SNE) with associated python modules. We find that our implementation of t-SNE can be up to 1200x faster than Sklearn, or up to 50x faster than Multicore-TSNE when used with the right GPU. The paper describing our approach, as well as the results below, is available at [https://arxiv.org/abs/1807.11824](https://arxiv.org/abs/1807.11824).\n\nYou can install binaries with anaconda for CUDA versions 9.0, 9.2, 10.0, and 10.1 using `conda install cuda<major><minor> tsnecuda -c cannylab`. For more details or to install from source, check out our wiki: [https://github.com/CannyLab/tsne-cuda/wiki/](https://github.com/CannyLab/tsne-cuda/wiki/)\n\n# Benchmarks\n### Simulated Data\n![](docs/simulated_speedup.png)\n\nTime taken compared to other state of the art algorithms on synthetic datasets with 50 dimensions and four clusters for varying numbers of points. Note the log scale on both the points and time axis, and that the scale of the x-axis is in thousands of points (thus, the values on the x-axis range from 1K to 10M points. Dashed lines represent projected times. Projected scaling assumes an O(nlog(n)) implementation.\n\n### MNIST\n![](docs/mnist_speedup.png)\n\nThe performance of t-SNE-CUDA compared to other state-of-the-art implementations on the MNIST dataset. t-SNE-CUDA runs on the raw pixels of the MNIST dataset (60000 images x 768 dimensions) in under 7 seconds.\n\n### CIFAR\n![](docs/cifar_speedup.png)\n\nThe performance of t-SNE-CUDA compared to other state-of-the-art implementations on the CIFAR-10 dataset. t-SNE-CUDA runs on the raw pixels of the CIFAR-10 training set (50000 images x 1024 dimensions x 3 channels) in under 12 seconds.\n\n### Comparison of Embedding Quality\nThe quality of the embeddings produced by t-SNE-CUDA do not differ significantly from the state of the art implementations. See below for a comparison of MNIST cluster outputs.\n\n![](docs/mnist_comparison.jpg)\n\nLeft: MULTICORE-4 (501s), Middle: BH-TSNE (1156s), Right: t-SNE-CUDA (Ours, 6.98s).\n\n# Installation\n\nTo install our library, follow the instructions in the [installation section](https://github.com/CannyLab/tsne-cuda/wiki/Installation) of the wiki.\n\n### Run\n\nLike many of the libraries available, the python wrappers subscribe to the same API as [sklearn.manifold.TSNE](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).\n\nYou can run it as follows:\n\n```\nfrom tsnecuda import TSNE\nX_embedded = TSNE(n_components=2, perplexity=15, learning_rate=10).fit_transform(X)\n```\n\nWe only support `n_components=2`. We currently have no plans to support more dimensions as this requires significant changes to the code to accomodate.\n\nFor more information on running the library, or using it as a C++ library, see the [Python usage](https://github.com/CannyLab/tsne-cuda/wiki/Basic-Usage:-Python) or [C++ Usage](https://github.com/CannyLab/tsne-cuda/wiki/Basic-Usage:-Cxx) sections of the wiki.\n\n# Citation\n\nPlease cite the corresponding paper if it was useful for your research:\n\n```\n@article{chan2019gpu,\n  title={GPU accelerated t-distributed stochastic neighbor embedding},\n  author={Chan, David M and Rao, Roshan and Huang, Forrest and Canny, John F},\n  journal={Journal of Parallel and Distributed Computing},\n  volume={131},\n  pages={1--13},\n  year={2019},\n  publisher={Elsevier}\n}\n```\n\nThis library is built on top of the following technology, without this tech, none of this would be possible!\n\n[L. Van der Maaten's paper](http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf)\n\n[FIt-SNE](https://github.com/KlugerLab/FIt-SNE)\n\n[Multicore-TSNE](https://github.com/DmitryUlyanov/Multicore-TSNE)\n\n[BHTSNE](https://github.com/lvdmaaten/bhtsne/)\n\n[CUDA Utilities/Pairwise Distance](https://github.com/OrangeOwlSolutions)\n\n[LONESTAR-GPU](http://iss.ices.utexas.edu/?p=projects/galois/lonestargpu)\n\n[FAISS](https://github.com/facebookresearch/faiss)\n\n[GTest](https://github.com/google/googletest)\n\n[CXXopts](https://github.com/jarro2783/cxxopts)\n\n\n# License\n\nOur code is built using components from FAISS, the Lonestar GPU library, GTest, CXXopts, and OrangeOwl's CUDA utilities. Each portion of the code is governed by their respective licenses - however our code is governed by the BSD-3 license found in LICENSE.txt\n"