b'![GraphVite logo](asset/logo/logo.png)\n\nGraphVite - graph embedding at high speed and large scale\n=========================================================\n\n[![Install with conda](https://anaconda.org/milagraph/graphvite/badges/installer/conda.svg)][conda]\n[![License](https://anaconda.org/milagraph/graphvite/badges/license.svg)][license]\n\n[conda]: https://anaconda.org/milagraph/graphvite\n[license]: LICENSE\n\n[Docs] | [Tutorials] | [Benchmarks] | [Pre-trained models]\n\n[Docs]: https://graphvite.io/docs/latest/api/application\n[Tutorials]: https://graphvite.io/tutorials\n[Benchmarks]: https://graphvite.io/docs/latest/benchmark\n[Pre-trained Models]: https://graphvite.io/docs/latest/pretrained_model\n\nGraphVite is a general graph embedding engine, dedicated to high-speed and\nlarge-scale embedding learning in various applications.\n\nGraphVite provides complete training and evaluation pipelines for 3 applications:\n**node embedding**, **knowledge graph embedding** and\n**graph & high-dimensional data visualization**. Besides, it also includes 9 popular\nmodels, along with their benchmarks on a bunch of standard datasets.\n\n<table align="center" style="text-align:center">\n    <tr>\n        <th>Node Embedding</th>\n        <th>Knowledge Graph Embedding</th>\n        <th>Graph & High-dimensional Data Visualization</th>\n    </tr>\n    <tr>\n        <td><img src="asset/graph.png" height="240" /></td>\n        <td><img src="asset/knowledge_graph.png" height="240" /></td>\n        <td><img src="asset/visualization.png" height="240" /></td>\n    </tr>\n</table>\n\nHere is a summary of the training time of GraphVite along with the best open-source\nimplementations on 3 applications. All the time is reported based on a server with\n24 CPU threads and 4 V100 GPUs.\n\nTraining time of node embedding on [Youtube] dataset.\n\n| Model      | Existing Implementation       | GraphVite | Speedup |\n|------------|-------------------------------|-----------|---------|\n| [DeepWalk] | [1.64 hrs (CPU parallel)][1]  | 1.19 mins | 82.9x   |\n| [LINE]     | [1.39 hrs (CPU parallel)][2]  | 1.17 mins | 71.4x   |\n| [node2vec] | [24.4 hrs (CPU parallel)][3]  | 4.39 mins | 334x    |\n\n[Youtube]: http://conferences.sigcomm.org/imc/2007/papers/imc170.pdf\n[DeepWalk]: https://arxiv.org/pdf/1403.6652.pdf\n[LINE]: https://arxiv.org/pdf/1503.03578.pdf\n[node2vec]: https://www.kdd.org/kdd2016/papers/files/rfp0218-groverA.pdf\n[1]: https://github.com/phanein/deepwalk\n[2]: https://github.com/tangjianpku/LINE\n[3]: https://github.com/aditya-grover/node2vec\n\nTraining / evaluation time of knowledge graph embedding on [FB15k] dataset.\n\n| Model           | Existing Implementation           | GraphVite          | Speedup       |\n|-----------------|-----------------------------------|--------------------|---------------|\n| [TransE]        | [1.31 hrs / 1.75 mins (1 GPU)][3] | 13.5 mins / 54.3 s | 5.82x / 1.93x |\n| [RotatE]        | [3.69 hrs / 4.19 mins (1 GPU)][4] | 28.1 mins / 55.8 s | 7.88x / 4.50x |\n\n[FB15k]: http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf\n[TransE]: http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf\n[RotatE]: https://arxiv.org/pdf/1902.10197.pdf\n[3]: https://github.com/DeepGraphLearning/KnowledgeGraphEmbedding\n[4]: https://github.com/DeepGraphLearning/KnowledgeGraphEmbedding\n\nTraining time of high-dimensional data visualization on [MNIST] dataset.\n\n| Model        | Existing Implementation       | GraphVite | Speedup |\n|--------------|-------------------------------|-----------|---------|\n| [LargeVis]   | [15.3 mins (CPU parallel)][5] | 13.9 s    | 66.8x   |\n\n[MNIST]: http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n[LargeVis]: https://arxiv.org/pdf/1602.00370.pdf\n[5]: https://github.com/lferry007/LargeVis\n\nRequirements\n------------\n\nGenerally, GraphVite works on any Linux distribution with CUDA >= 9.2.\n\nThe library is compatible with Python 2.7 and 3.6/3.7.\n\nInstallation\n------------\n\n### From Conda ###\n\n```bash\nconda install -c milagraph graphvite cudatoolkit=$(nvcc -V | grep -Po "(?<=V)\\d+.\\d+")\n```\n\nIf you only need embedding training without evaluation, you can use the following\nalternative with minimal dependencies.\n\n```bash\nconda install -c milagraph graphvite-mini cudatoolkit=$(nvcc -V | grep -Po "(?<=V)\\d+.\\d+")\n```\n\n### From Source ###\n\nBefore installation, make sure you have `conda` installed.\n\n```bash\ngit clone https://github.com/DeepGraphLearning/graphvite\ncd graphvite\nconda install -y --file conda/requirements.txt\nmkdir build\ncd build && cmake .. && make && cd -\ncd python && python setup.py install && cd -\n```\n\n### On Colab ###\n\n```bash\n!wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n!chmod +x Miniconda3-latest-Linux-x86_64.sh\n!./Miniconda3-latest-Linux-x86_64.sh -b -p /usr/local -f\n\n!conda install -y -c milagraph -c conda-forge graphvite \\\n    python=3.6 cudatoolkit=$(nvcc -V | grep -Po "(?<=V)\\d+\\.\\d+")\n!conda install -y wurlitzer ipykernel\n```\n\n```python\nimport site\nsite.addsitedir("/usr/local/lib/python3.6/site-packages")\n%reload_ext wurlitzer\n```\n\nQuick Start\n-----------\n\nHere is a quick-start example of the node embedding application.\n\n```bash\ngraphvite baseline quick start\n```\n\nTypically, the example takes no more than 1 minute. You will obtain some output like\n\n```\nBatch id: 6000\nloss = 0.371041\n\n------------- link prediction --------------\nAUC: 0.899933\n\n----------- node classification ------------\nmacro-F1@20%: 0.242114\nmicro-F1@20%: 0.391342\n```\n\nBaseline Benchmark\n------------------\n\nTo reproduce a baseline benchmark, you only need to specify the keywords of the\nexperiment. e.g. model and dataset.\n\n```bash\ngraphvite baseline [keyword ...] [--no-eval] [--gpu n] [--cpu m] [--epoch e]\n```\n\nYou may also set the number of GPUs and the number of CPUs per GPU.\n\nUse ``graphvite list`` to get a list of available baselines.\n\nCustom Experiment\n-----------------\n\nCreate a yaml configuration scaffold for graph, knowledge graph, visualization or\nword graph.\n\n```bash\ngraphvite new [application ...] [--file f]\n```\n\nFill some necessary entries in the configuration following the instructions. You\ncan run the configuration by\n\n```bash\ngraphvite run [config] [--no-eval] [--gpu n] [--cpu m] [--epoch e]\n```\n\nHigh-dimensional Data Visualization\n-----------------------------------\n\nYou can visualize your high-dimensional vectors with a simple command line in\nGraphVite.\n\n```bash\ngraphvite visualize [file] [--label label_file] [--save save_file] [--perplexity n] [--3d]\n```\n\nThe file can be either a numpy dump `*.npy` or a text matrix `*.txt`. For the save\nfile, we recommend to use `png` format, while `pdf` is also supported.\n\nContributing\n------------\n\nWe welcome all contributions from bug fixs to new features. Please let us know if you\nhave any suggestion to our library.\n\nDevelopment Team\n----------------\n\nGraphVite is developed by [MilaGraph], led by Prof. [Jian Tang].\n\nAuthors of this project are [Zhaocheng Zhu], [Shizhen Xu], [Meng Qu] and [Jian Tang].\nContributors include [Kunpeng Wang] and [Zhijian Duan].\n\n[MilaGraph]: https://github.com/DeepGraphLearning\n[Zhaocheng Zhu]: https://kiddozhu.github.io\n[Shizhen Xu]: https://github.com/xsz\n[Meng Qu]: https://mnqu.github.io\n[Jian Tang]: https://jian-tang.com\n[Kunpeng Wang]: https://github.com/Kwinpeng\n[Zhijian Duan]: https://github.com/zjduan\n\nCitation\n--------\n\nIf you find GraphVite useful for your research or development, please cite the\nfollowing [paper].\n\n[paper]: https://arxiv.org/pdf/1903.00757.pdf\n\n```\n@inproceedings{zhu2019graphvite,\n    title={GraphVite: A High-Performance CPU-GPU Hybrid System for Node Embedding},\n     author={Zhu, Zhaocheng and Xu, Shizhen and Qu, Meng and Tang, Jian},\n     booktitle={The World Wide Web Conference},\n     pages={2494--2504},\n     year={2019},\n     organization={ACM}\n }\n```\n\nAcknowledgements\n----------------\n\nWe would like to thank Compute Canada for supporting GPU servers. We specially thank\nWenbin Hou for useful discussions on C++ and GPU programming techniques.'