b'.. image:: https://img.shields.io/pypi/v/kmodes.svg\n    :target: https://pypi.python.org/pypi/kmodes/\n    :alt: Version\n.. image:: https://travis-ci.org/nicodv/kmodes.svg?branch=master\n    :target: https://travis-ci.org/nicodv/kmodes\n    :alt: Test Status\n.. image:: https://coveralls.io/repos/nicodv/kmodes/badge.svg\n    :target: https://coveralls.io/r/nicodv/kmodes\n    :alt: Test Coverage\n.. image:: https://api.codacy.com/project/badge/Grade/cb19f1f1093a44fa845ebfdaf76975f6\n   :alt: Codacy Badge\n   :target: https://app.codacy.com/app/nicodv/kmodes?utm_source=github.com&utm_medium=referral&utm_content=nicodv/kmodes&utm_campaign=Badge_Grade_Dashboard\n.. image:: https://requires.io/github/nicodv/kmodes/requirements.svg\n     :target: https://requires.io/github/nicodv/kmodes/requirements/\n     :alt: Requirements Status\n.. image:: https://img.shields.io/pypi/pyversions/kmodes.svg\n    :target: https://pypi.python.org/pypi/kmodes/\n    :alt: Supported Python versions\n.. image:: https://img.shields.io/github/stars/nicodv/kmodes.svg\n    :target: https://github.com/nicodv/kmodes/\n    :alt: Github stars\n.. image:: https://img.shields.io/pypi/l/kmodes.svg\n    :target: https://github.com/nicodv/kmodes/blob/master/LICENSE\n    :alt: License\n\nkmodes\n======\n\nDescription\n-----------\n\nPython implementations of the k-modes and k-prototypes clustering\nalgorithms. Relies on numpy for a lot of the heavy lifting.\n\nk-modes is used for clustering categorical variables. It defines clusters\nbased on the number of matching categories between data points. (This is\nin contrast to the more well-known k-means algorithm, which clusters\nnumerical data based on Euclidean distance.) The k-prototypes algorithm\ncombines k-modes and k-means and is able to cluster mixed numerical /\ncategorical data.\n\nImplemented are:\n\n- k-modes [HUANG97]_ [HUANG98]_\n- k-modes with initialization based on density [CAO09]_\n- k-prototypes [HUANG97]_\n\nThe code is modeled after the clustering algorithms in :code:`scikit-learn`\nand has the same familiar interface.\n\nI would love to have more people play around with this and give me\nfeedback on my implementation. If you come across any issues in running or\ninstalling kmodes,\n`please submit a bug report <https://github.com/nicodv/kmodes/issues>`_.\n\nEnjoy!\n\nInstallation\n------------\n\nkmodes can be installed using pip:\n\n.. code:: bash\n\n    pip install kmodes\n\nTo upgrade to the latest version (recommended), run it like this:\n\n.. code:: bash\n\n    pip install --upgrade kmodes\n\nAlternatively, you can build the latest development version from source:\n\n.. code:: bash\n\n    git clone https://github.com/nicodv/kmodes.git\n    cd kmodes\n    python setup.py install\n\nUsage\n-----\n.. code:: python\n\n    import numpy as np\n    from kmodes.kmodes import KModes\n\n    # random categorical data\n    data = np.random.choice(20, (100, 10))\n\n    km = KModes(n_clusters=4, init=\'Huang\', n_init=5, verbose=1)\n\n    clusters = km.fit_predict(data)\n\n    # Print the cluster centroids\n    print(km.cluster_centroids_)\n\nThe examples directory showcases simple use cases of both k-modes\n(\'soybean.py\') and k-prototypes (\'stocks.py\').\n\nMissing / unseen data\n_____________________\n\nThe k-modes algorithm accepts :code:`np.NaN` values as missing values in\nthe :code:`X` matrix. However, users are strongly suggested to consider\nfilling in the missing data themselves in a way that makes sense for\nthe problem at hand. This is especially important in case of many missing\nvalues.\n\nThe k-modes algorithm currently handles missing data as follows. When\nfitting the model, :code:`np.NaN` values are encoded into their own\ncategory (let\'s call it "unknown values"). When predicting, the model\ntreats any values in :code:`X` that (1) it has not seen before during\ntraining, or (2) are missing, as being a member of the "unknown values"\ncategory. Simply put, the algorithm treats any missing / unseen data as\nmatching with each other but mismatching with non-missing / seen data\nwhen determining similarity between points.\n\nThe k-prototypes also accepts :code:`np.NaN` values as missing values for\nthe categorical variables, but does *not* accept missing values for the\nnumerical values. It is up to the user to come up with a way of\nhandling these missing data that is appropriate for the problem at hand.\n\nParallel execution\n------------------\n\nThe k-modes and k-prototypes implementations both offer support for\nmultiprocessing via the \n`joblib library <https://pythonhosted.org/joblib/generated/joblib.Parallel.html>`_,\nsimilar to e.g.\xc2\xa0scikit-learn\'s implementation of k-means, using the\n:code:`n_jobs` parameter. It generally does not make sense to set more jobs\nthan there are processor cores available on your system.\n\nThis potentially speeds up any execution with more than one initialization try,\n:code:`n_init > 1`, which may be helpful to reduce the execution time for\nlarger problems. Note that it depends on your problem whether multiprocessing\nactually helps, so be sure to try that out first. You can check out the\nexamples for some benchmarks.\n\nFAQ\n---\n\nQ: I\'m seeing errors such as :code:`TypeError: \'<\' not supported between instances of \'str\' and \'float\'`\nwhen using the :code:`kprototypes` algorithm.\n\nA: One or more of your numerical feature columns have string values in them. Make sure that all \ncolumns have consistent data types.\n\nReferences\n----------\n\n.. [HUANG97] Huang, Z.: Clustering large data sets with mixed numeric and\n   categorical values, Proceedings of the First Pacific Asia Knowledge\n   Discovery and Data Mining Conference, Singapore, pp. 21-34, 1997.\n\n.. [HUANG98] Huang, Z.: Extensions to the k-modes algorithm for clustering\n   large data sets with categorical values, Data Mining and Knowledge\n   Discovery 2(3), pp. 283-304, 1998.\n\n.. [CAO09] Cao, F., Liang, J, Bai, L.: A new initialization method for\n   categorical data clustering, Expert Systems with Applications 36(7),\n   pp. 10223-10228., 2009.\n'