b'# sklearn-evaluation\n\n[![Build Status](https://travis-ci.org/edublancas/sklearn-evaluation.svg)](https://travis-ci.org/edublancas/sklearn-evaluation) [![PyPI version](https://badge.fury.io/py/sklearn-evaluation.svg)](https://badge.fury.io/py/sklearn-evaluation) [![Coverage Status](https://coveralls.io/repos/github/edublancas/sklearn-evaluation/badge.svg)](https://coveralls.io/github/edublancas/sklearn-evaluation) [![CircleCI](https://circleci.com/gh/edublancas/sklearn-evaluation.svg?style=shield)](https://circleci.com/gh/edublancas/sklearn-evaluation)\n\n\n\nscikit-learn model evaluation made easy: plots, tables and markdown reports.\n\nSupport for Python 3 only.\n\n[Documentation here.](http://edublancas.github.io/sklearn-evaluation)\n\n# Install  \n\n```bash\npip install sklearn-evaluation\n```\n\n# Usage\n\n## `plot` module\n\nGenerate evaluation plots with a single function call.\n```python\nfrom sklearn_evaluation import plot\n\n# code for data loading and model training\n\nplot.confusion_matrix(y_true, y_pred, target_names=target_names)\n```\n\n![confusion matrix](examples/cm.png)\n\n## `table` module\n\nGenerate good looking tables from your model results.\n\n```python\nfrom sklearn_evaluation import table\n\n# code for data loading and training\n\ntable.feature_importances(model)\n```\n\n```\n+-----------+--------------+-----------+\n| name      |   importance |       std |\n+===========+==============+===========+\n| Feature 0 |    0.250398  | 0.0530907 |\n+-----------+--------------+-----------+\n| Feature 1 |    0.232397  | 0.0523836 |\n+-----------+--------------+-----------+\n| Feature 2 |    0.148898  | 0.0331814 |\n+-----------+--------------+-----------+\n| Feature 3 |    0.0553634 | 0.0128296 |\n+-----------+--------------+-----------+\n| Feature 8 |    0.05401   | 0.0122248 |\n+-----------+--------------+-----------+\n| Feature 5 |    0.053878  | 0.01289   |\n+-----------+--------------+-----------+\n| Feature 6 |    0.0525828 | 0.0130225 |\n+-----------+--------------+-----------+\n| Feature 9 |    0.0510197 | 0.0129436 |\n+-----------+--------------+-----------+\n| Feature 7 |    0.0509633 | 0.0117197 |\n+-----------+--------------+-----------+\n| Feature 4 |    0.0504887 | 0.012844  |\n+-----------+--------------+-----------+\n```\n\nAlso, running this in Jupyter will generate a pandas-like output.\n\n## Using the OOP interface\n\nA simplified API is available by packing the results of your estimator in the `ClassifierEvaluator` class.\n\n```python\nfrom sklearn_evaluation import ClassifierEvaluator\n\n# code for data loading and model training\n\nce = ClassifierEvaluator(classifier, y_test, y_pred, y_score,\n                         feature_list, target_names)\n\n# this plots the confusion matrix\nce.confusion_matrix()\n```\n\n## Generating reports\n\nGenerate reports using Markdown templates.\n\n```python\nce.make_report()\n```\n\nThe code above will generate a report [like this one.](http://htmlpreview.github.com/?https://github.com/edublancas/sklearn-model-evaluation/blob/master/examples/report.html)\n\nReports are self-contained, all images are included in the html file using [base64](https://en.wikipedia.org/wiki/Base64).\n'