b'# Hydrosphere Serving\n\n[![Join the chat at https://gitter.im/Hydrospheredata/hydro-serving](https://badges.gitter.im/Hydrospheredata/hydro-serving.svg)](https://gitter.im/Hydrospheredata/hydro-serving?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![](https://img.shields.io/badge/documentation-latest-af1a97.svg)](https://hydrosphere.io/serving-docs/) \n\nHomepage: https://hydrosphere.io/serving  \nInstallation guide: https://hydrosphere.io/serving-docs/latest/install  \nGetting started: https://hydrosphere.io/serving-docs/latest/tutorials\n\n---\n\nHydrosphere.io is the first open source platform for Data Science Management automation. \nIt delivers reliability, scalability and observability for machine learning and AI applications in production.\nHydrosphere.io automates deployment and serving ML models, monitoring and profiling of production traffic, \nmonitoring of models performance, data subsampling and model retraining.\n\nThe platform makes more Data Science and less data plumbing and tinkering happen.\n\nHydrosphere Serving enables you to get your models up and running in an instant, \non just about any infrastructure and using any of the available machine learning toolkits. \nIt lets you monitor your models\xe2\x80\x99 performance, analyse their inputs \n(for example, determine whether there is recently an increased number of outliers or not),\nobserve models\xe2\x80\x99 inference on given data and so on.\n\nFeatures:\n* **Serverless** user experience in your data center or public cloud. \n* **Plumbing**. Automatic generation of Protobuf contracts for REST, gRPC and Streaming Kafka API from the model metadata\n* Safe experiments and models warm up on **shadowed or canary traffic**\n* Unified across ML frameworks\n* Automatic data profiling and statistical check of the model quality \n* Immutable model versioning\n* Agnostic to training pipeline and notebook environment \n* **Multi-framework Pipelines** (e.g. Scikit-learn -> Spark ML -> TensorFlow pipeline)\n* Out of the box tuned and optimized Serving Runtimes\n* Models optimization for Serving\n\n#### Check UI - explore, deploy and test models\n\n![Hydrosphere Serving Deploy Models](https://media.giphy.com/media/KyEVbxQEr4IGLuaQlR/giphy.gif)\n\n![Hydrosphere Serving Create an AI application](https://media.giphy.com/media/1dHWK2HJjdheyqB8lZ/giphy.gif)\n\n![Hydrosphere Serving Test ML Models](https://media.giphy.com/media/2A67Wd88zQTcZk4lEs/giphy.gif)\n\n## Related repositories\n * Runtimes:\n   * Tensorflow: https://github.com/Hydrospheredata/hydro-serving-tensorflow\n   * Python: https://github.com/Hydrospheredata/hydro-serving-python\n   * Spark: https://github.com/Hydrospheredata/hydro-serving-spark\n     * Spark local inference implementation: https://github.com/Hydrospheredata/spark-ml-serving\n * Protobuf messages: https://github.com/Hydrospheredata/hydro-serving-protos\n * Manager service: https://github.com/Hydrospheredata/hydro-serving-manager\n * Gateway service: https://github.com/Hydrospheredata/hydro-serving-gateway\n * Example models: https://github.com/Hydrospheredata/hydro-serving-example\n'