b'\n[![Build Status](https://travis-ci.org/vfdev-5/iterative-stratification.svg?branch=master)](https://travis-ci.org/vfdev-5/iterative-stratification)\n[![Coverage Status](https://coveralls.io/repos/github/vfdev-5/iterative-stratification/badge.svg?branch=master)](https://coveralls.io/github/vfdev-5/iterative-stratification?branch=master)\n\n# iterative-stratification\niterative-stratification is a project that provides [scikit-learn](http://scikit-learn.org/) compatible cross validators with stratification for multilabel data.\n\nPresently scikit-learn provides several cross validators with stratification. However, these cross validators do not offer the ability to stratify _multilabel_ data. This iterative-stratification project offers implementations of MultilabelStratifiedKFold, MultilabelRepeatedStratifiedKFold, and MultilabelStratifiedShuffleSplit with a base algorithm for stratifying multilabel data described in the following paper:\n\nSechidis K., Tsoumakas G., Vlahavas I. (2011) On the Stratification of Multi-Label Data. In: Gunopulos D., Hofmann T., Malerba D., Vazirgiannis M. (eds) Machine Learning and Knowledge Discovery in Databases. ECML PKDD 2011. Lecture Notes in Computer Science, vol 6913. Springer, Berlin, Heidelberg.\n\n## Requirements\niterative-stratification has been tested under Python 3.4 through 3.7 with the following dependencies:\n- scipy(>=0.13.3)\n- numpy(>=1.8.2)\n- scikit-learn(>=0.19.0)\n\n## Installation\niterative-stratification is currently available on the PyPi repository and can be installed via pip:\n```\npip install iterative-stratification\n```\n\\\nThe package is also installable from the Anaconda Cloud platform:\n```\nconda install -c trent-b iterative-stratification\n```\n\n## Toy Examples\nThe multilabel cross validators that this package provides may be used with the scikit-learn API in the same manner as any other cross validators. For example, these cross validators may be passed to [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) or [cross_val_predict](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html). Below are some toy examples of the direct use of the multilabel cross validators.\n\n### MultilabelStratifiedKFold\n```\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nimport numpy as np\n\nX = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\ny = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n\nmskf = MultilabelStratifiedKFold(n_splits=2, random_state=0)\n\nfor train_index, test_index in mskf.split(X, y):\n   print("TRAIN:", train_index, "TEST:", test_index)\n   X_train, X_test = X[train_index], X[test_index]\n   y_train, y_test = y[train_index], y[test_index]\n```\nOutput:\n```\nTRAIN: [0 3 4 6] TEST: [1 2 5 7]\nTRAIN: [1 2 5 7] TEST: [0 3 4 6]\n```\n### RepeatedMultilabelStratifiedKFold\n```\nfrom iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\nimport numpy as np\n\nX = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\ny = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n\nrmskf = RepeatedMultilabelStratifiedKFold(n_splits=2, n_repeats=2, random_state=0)\n\nfor train_index, test_index in rmskf.split(X, y):\n   print("TRAIN:", train_index, "TEST:", test_index)\n   X_train, X_test = X[train_index], X[test_index]\n   y_train, y_test = y[train_index], y[test_index]\n```\nOutput:\n```\nTRAIN: [0 3 4 6] TEST: [1 2 5 7]\nTRAIN: [1 2 5 7] TEST: [0 3 4 6]\nTRAIN: [0 1 4 5] TEST: [2 3 6 7]\nTRAIN: [2 3 6 7] TEST: [0 1 4 5]\n```\n### MultilabelStratifiedShuffleSplit\n```\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\nimport numpy as np\n\nX = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\ny = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n\nmsss = MultilabelStratifiedShuffleSplit(n_splits=3, test_size=0.5, random_state=0)\n\nfor train_index, test_index in msss.split(X, y):\n\tprint("TRAIN:", train_index, "TEST:", test_index)\n\tX_train, X_test = X[train_index], X[test_index]\n\ty_train, y_test = y[train_index], y[test_index]\n```\nOutput:\n```\nTRAIN: [1 2 5 7] TEST: [0 3 4 6]\nTRAIN: [2 3 6 7] TEST: [0 1 4 5]\nTRAIN: [1 2 5 6] TEST: [0 3 4 7]\n```\n'