b'# algorithms-primer\nA consolidated collection of resources for you to learn and understand algorithms and data structures easily. \n\n# Objectives\nIt is difficult to find consolidated resources on algorithms. \nThis repo hopes to gather resources to help one understand algorithms better to prepare \nfor technical tests or simply to strengthen your foundation of computer science to help you become a better coder.\n\n# Contributions\nContributions are more than welcome. I cant do everything myself, so I will need all the help I can get. To \n- add a new section or to \n- add on to existing sections, \n- or translate\nsimply submit a pull request. \n\nIf you are arent sure of how to create a pull request, view the [pull request documentation](https://help.github.com/articles/about-pull-requests/).\n\n# Algorithms Topics\nSummaries of the algorithms topics:\n- [P versus NP](#p-versus-np)\n- [Brute force method](#brute-force-method)\n- [Divide and conquer algorithm](#divide-and-conquer-algorithm)\n- [Dynamic Programming](#dynamic-programming)\n\t- [Memoization](#memoization)\n\t-\t[Greedy Algorithms](#greedy-algorithms)\n- [Knapsack problem](#knapsack-problem)\n- [Djikstra](#djikstra)\n- [Prim\'s Algorithm](#prim\'s-algorithm)\n- [Data Structure](#data-structure)\n\t- [Linked Lists](#linked-lists)\n\t- [Arrays vs linked lists](#arrays-vs-linked-lists)\n\t- [Single Linked List](#single-linked-list)\n\t- [Doubly Linked List](#doubly-linked-list)\n\t- [Circular Linked List](#circular-linked-list)\n\t- [Operations on a Linked List](#operations-on-a-linked-list)\n- [Queues](#queues)\n- [Stacks](#stacks)\n- [Asymptotic Notation](#asymptotic-notation)\n\t- [Big-O Notation](#big-o-notation)\n\t- [Big-\xce\xa9 (Big-Omega) notation](#big-\xce\xa9-(big-omega)-notation)\n\t- [Big-\xce\xb8 (Big-Theta) notation](#big-\xce\xb8-(big-theta)-notation)\n- [Search](#search)\n\t- [Linear Search](#linear-search)\n\t- [Binary Search](#linear-search)\n\t- [Red Black Trees](#red-black-trees)\n- [Sorting](#sorting)\n\t- [Bubble sort](#bubble-sort)\n\t- [Selection sort](#selection-sort)\n\t- [Insertion sort](#insertion-sort)\n\t- [Merge sort](#merge-sort)\n\n## P versus NP\n**What is P vs NP?**\n\nP vs NP is a notorious problem in algorithms and in Computer Science.\n\n**P** stands for **polynomial time** (Polynomial time means that the complexity of the algorithm is O(n^k), where n is the size of your data (e. g. number of elements in a list to be sorted), and k is a constant). \n\n**NP** stands for **non-deterministic polynomial time**.\n\n**NP-complete** is a family of NP problems for which you know that if one of them had a polynomial solution then everyone of them has.\n\nProblems can be divided into P problems, which are easily **solved** by computers, and NP problems are not easily solvable, but if you present a potential solution it\xe2\x80\x99s easy to **verify** whether it\xe2\x80\x99s correct or not.\n\n**Is P=NP and why do I need to care?**\n\nFor the longest of time, people have been trying to prove that P=NP or otherwise. It is important that we pay attention to it because many NP problems are problems we want to solve, e.g. in circuit design or in other industrial design applications.\n\nIf it were proven that P = NP and the proof provided a specific polynomial time algorithm for an NP-complete problem, then because of the existing reduction proofs, we could immediately produce polynomial time algorithms for all our other NP problems.\n\n**Read more here:**\n- [Regarding RSA cryptography](https://www.quora.com/What-is-an-intuitive-explanation-of-P-NP)\n- https://danielmiessler.com/study/pvsnp/#gs.null\n- http://news.mit.edu/2009/explainer-pnp\n\n## Brute force method\nBrute force method (Generate & Test) is simplest way to explore the space of solutions - it simply means to go through all solutions, however unlikely they may be, something which is not particularly elegant.\n\n## Divide and conquer algorithm\nDivide and Conquer means to break down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly.\n\nExamples:\n- [Quick sort](#quick-sort)\n- [Merge sort](#merge-sort)\n\n## Dynamic Programming\n**What is DP?**\n\nDP or dynamic programming basically means to take our problem and somehow break it down into a reasonable number of subproblems so that we can use optimal solutions to the smaller subproblems to give us optimal solutions to the larger ones.\n\n- Allows one to solve many different types of problems in time O(n)^2 or O(n)^3\n- Usually focused on Principle of Optimality, "An optimal solution to any instance of an optimization problem is composed of optimal solutions to its subinstances"\n\n**Read more:**\n- [Competitive Programming book by Steven and Felix Halim](http://www.comp.nus.edu.sg/~stevenha/myteaching/competitive_programming/cp1.pdf)\n- [Introduction to Dynamic Programming](http://www.techiedelight.com/introduction-dynamic-programming/)\n- [Dynamic Programming \xe2\x80\x93 From Novice to Advanced](https://www.topcoder.com/community/data-science/data-science-tutorials/dynamic-programming-from-novice-to-advanced/)\n- https://people.eecs.berkeley.edu/~vazirani/algorithms/chap6.pdf\n\n**Courses**\n- [MIT (Introduction to Algorithms (chapter 15))](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-15-dynamic-programming-longest-common-subsequence/)\n\n**Practice here:**\n- https://www.hackerrank.com/domains/algorithms/dynamic-programming\n\n**Common interview questions:**\n- 0/1 Knapsack Problem\n- Coin change - Given a set of coins and amount, Write an algo\xc2\xadrithm to find out how many ways we can make the change of the amount using the coins given.\n- Edit Distance - Given two strings and a set of operations Change (C), insert (I) and delete (D) , find minimum number of edits (operations) required to transform one string into another.\n- Longest Common Subsequence\n\n### Memoization\nMemoization is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again. \n\n**Read more here:**\n- http://www.geeksforgeeks.org/tabulation-vs-memoizatation/\n\n### Greedy Algorithms \nIn greedy algorithm approach, it builds up a solution piece by piece, where the next piece that offers the most obvious and immediate benefit is chosen.\n\nAlgorithms which use the greedy approach:\n- Travelling Salesman Problem\n- Prim\'s Minimal Spanning Tree Algorithm\n- Kruskal\'s Minimal Spanning Tree Algorithm\n- Dijkstra\'s Minimal Spanning Tree Alsgorithm\n- Graph - Map Coloring\n- Graph - Vertex Cover\n- Knapsack Problem\n- Job Scheduling Problem \n\n## Knapsack problem\nKnapsack problem or the rucksack problem is part of dynamic programming and it is where given a set of items, each with a weight and a value, determine the number of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible. \n\n**Read more here:**\n- [Introduction to Knapsack](https://www.youtube.com/watch?v=8LusJS5-AGo)\n- [0-1 Knapsack problem](http://cse.unl.edu/~goddard/Courses/CSCE310J/Lectures/Lecture8-DynamicProgramming.pdf)\n\n**Practice here:**\n- https://www.hackerrank.com/challenges/unbounded-knapsack\n- http://practice.geeksforgeeks.org/problems/0-1-knapsack-problem/0\n\n## Djikstra\nTODO\n\n## Prim\'s Algorithm\nTODO\n\n# Data Structure\n## Linked Lists\n\n[Introduction to linked lists/ Vectors vs. Linked List](https://www.youtube.com/watch?v=pBrz9HmjFOs) (13 minute video)\n\n- Link \xe2\x88\x92 Each link of a linked list can store a data called an element.\n\n- Next \xe2\x88\x92 Each link of a linked list contains a link to the next link called Next.\n\n- LinkedList \xe2\x88\x92 A Linked List contains the connection link to the first link called First.\n\n![alt text](./images/doubly_linked_list.jpg "Doubly linked list")\n\n- Linked List contains a link element called first.\n\n- Each link carries a data field(s) and a link field called next.\n\n- Each link is linked with its next link using its next link.\n\n- Last link carries a link as null to mark the end of the list.\n\n### Arrays vs linked lists\nThe linked lists have pointers to the next and the previous item unlike arrays.\n\n**Advs of Linked Lists**\n- Dynamic size\n- Less expensive to insert/delete\n\tIn arrays, you will have to shifts the items each time an items is inserted/deleted. For linked lists, you just have to change the links to point to the items.\n\n**Disadvs of Linked Lists** \n- We cannot perform a random access of items. We have to access elements sequentially starting from the first node (or at the last node if it is a doubly linked list). So we cannot do binary search with linked lists. In arrays, however, you can simply specify the index of the array to get to the item.\n- Extra memory space for a pointer is required with each element of the list.\n- Arrays have better cache locality that can make a pretty big difference in performance.\n\n### Single Linked List \nItem navigation is forward only\n\n### Doubly Linked List\nItems can be navigated forward and backward\n\n### Circular Linked List \nIn a circular singly linked list, the last node of the list is made to point to the first node.\n\n### Operations on a Linked List\n- Insertion \xe2\x88\x92 Add a new data item in the given collection of data items\n- Deletion \xe2\x88\x92 Delete an existing data item from the given collection of data items\n- Traversal \xe2\x88\x92 Access each data item exactly once so that it can be processed\n- Searching \xe2\x88\x92 Find out the location of the data item if it exists in the given collection of data items\n- Sorting \xe2\x88\x92 Arranging the data items in some order i.e. in ascending or descending order in case of numerical data and in dictionary order in case of alphanumeric data\n\n**Common interview questions**:\n\n- Reverse a Linked List (recursive)\n- Reverse a Linked List (iterative)\n- Detect Loop in a Linked List\n- Given pointers to two single-linked list, find out if they intersect and at which node they intersect\n- Merge two unsorted linked list in efficient way\n- Delete repeated elements from linked list\n\n**Practice here**: \n- https://www.hackerrank.com/domains/data-structures/linked-lists\n- http://www.geeksforgeeks.org/practice-questions-for-linked-list-and-recursion/\n\n## Queues\n![alt text](./images/queue.png "Implementation of a queue")\n\nsource: [Stoimen](http://www.stoimen.com/blog/2012/06/05/computer-algorithms-stack-and-queue-data-structure/).\n\nQueues is a data structure which follows a First-In-First-Out (FIFO) or Last-In-Last-Out (LILO) methodology. \nOne end is always used to insert data (enqueue) and the other is used to remove data (dequeue).\n\n### Applications of a queue\n- Pipes\n- File IO\n\n**Practice here**: \n\n- https://www.hackerrank.com/domains/data-structures/queues\n\n## Stacks\n![alt text](./images/stack.png "Implementation of a stack")\n\nsource: [Stoimen](http://www.stoimen.com/blog/2012/06/05/computer-algorithms-stack-and-queue-data-structure/).\n\nStacks is a data structure which follows a LIFO (last in, first out) methodology.\t\n\nTo insert an item, it is called \xe2\x80\x9cPush\xe2\x80\x9d, to remove an item off is called \xe2\x80\x9cPop\xe2\x80\x9d.\n\n### Applications of a stack\n- Infix to Postfix Conversion using Stack\n- Evaluation of Postfix Expression\n- Reverse a String using Stack\n- Implement two stacks in an array\n- Check for balanced parentheses in an expression\n\n**Practice here**: \n\n- https://www.hackerrank.com/domains/data-structures/stacks\n\n**Common interview questions for queues and stacks:**\n\n- Which Data Structure Should be used for implementiong LRU cache? (Ans: Queue which is implemented using a doubly linked list)\n- Queue Implemented with Two Stacks\n\n### Heaps\nTODO\n### Tree Traversal\nTODO\n### Deque\nTODO\n\n# Asymptotic Notation\n## Big-O Notation \nThe Big O notation describes the complexity of an algorithm. \nIt describes:\n- The worst-case scenario, \n- the execution time required/space used\n- the upper asymptotic bound\n\n**O(1)**\n\nSame time regardless of the size of the input data\n\nCoding examples:\n- Accessing Array Index (int a = array[0];)\n- print "hello";\n\n\n**O(N)**\n\nPerformance will grow linearly and in direct proportion to the size of the input data set.\n\nCoding examples: \n- Traversing an array\n- Traversing a linked list\n- Linear Search\n\n**O(N)^2**\n\nPerformance is directly proportional to the square of the size of the input data set.\nThis is common with nested iterations over the data set.\n\nThese ones are supposed to be the less efficient algorithms if their O(n log n) counterparts are present.\n\nCoding examples: \n- Bubble Sort\n- Insertion Sort\n-\tSelection Sort\n\n**O(2N)**\n\nPerformance doubles with each additon to the input data set. The growth curve of an O(2N) function is exponential.\n\nCoding examples: \n- Recursive calculation of Fibonacci numbers\n\n**O(log n)**\n\nO(log n) is slightly more difficult to explain. \nOne good example of a O(log n) problem is when searching up a phone book. Even if the phone book is thick, you would not need to search every name, but you just have to look for the name under the correct alphabet. \n\nReducing the problem size with every iteration\n\nCoding examples:\n- Binary search\n- Finding largest/smallest number in a binary search tree\n\n**O(n log n)**\n\nTo better understand it, think of it as O(N) and O(log n). An example of such a notation is the Quick sort when we divide the array into two parts and each time it takes O(N) time to find a pivot element. \n\nCoding examples:\n- Merge Sort\n- Heap Sort\n- Quick Sort\n\n## Big-\xce\xa9 (Big-Omega) notation\nIt describes:\n- The best-case scenario\n- the lower asymptotic bound\n\nAn example of Big O vs Big Omega of a problem:\nhttp://www.programmerinterview.com/index.php/data-structures/big-o-versus-big-omega-notations/\n\n\n## Big-\xce\xb8 (Big-Theta) notation\n- Both the lower and upper asymptotic bound (tight bound)\n\n**Common interview questions**\n\n- What are the expected runtimes of some common data structures? (e.g., Hash Table, Binary Search Tree, Array, etc)\n\n# Search\n## Linear Search/Sequential Search\n- Linear Search/Sequential Search is used when a list of integers is not in any order\n- Examines the first element in the list and then examines each "sequential" element in the list until a match is found\n- Worst-case performance\xe2\x80\x8e: \xe2\x80\x8eO(n)\n- Best-case performance\xe2\x80\x8e: \xe2\x80\x8eO(1)\n\n**Read more here**\n\n- https://www.tutorialspoint.com/data_structures_algorithms/linear_search_algorithm.htm\n\n## Binary Search\n- Used when in a sorted sequence\n- Worst-case performance\xe2\x80\x8e: \xe2\x80\x8eO(log n)\n- Best-case performance\xe2\x80\x8e: \xe2\x80\x8eO(1)\n\n**How does it work?**\n\nAssume we have an array of numbers which are arranged in sequence where we want to find out if the number, 17 is within the array. \n\n```\n[2, 3, 5, 7, 11, 13, 17, 19, 23]\n```\n\nBased on linear search, we have to start at index 0 and progressively go through each element in the array. That would take us 7 searches before we arrive at 17. \nHowever, based on binary search, \n\n1. **Set the minIndex and maxIndex** - In this case, let minIndex = 0 and maxIndex = 8.\n\n2. **Set the middle element as the first guess** - The first guess would be value 11, index 4 (since 8/4). Since the array is sorted, we know that if 17 exists, it would be on the right side of the array since 17>11. \n\n3. **Change the minIndex/maxIndex** - We shift the minIndex to be 5 and maxIndex stays the same at 8. \n\n4. **Make another guess based on the new minIndex/maxIndex** - Taking the average, our second guess would be at index (8+5)/2 = 6.5 ~ 6, with a value of 17. We have found our integer. \n\n**In conclusion:**\n\n| Search        |            \t|\n| ------------- |:-----------:|\n| Linear \t\t\t\t| 7 \t\t\t\t\t|\n| Binary \t\t\t\t| 2      \t\t\t|\n\n**Practice here:** \n- https://www.hackerrank.com/challenges/binary-search-tree-insertion\n\n**Read more here**\n- http://www.geeksforgeeks.org/binary-search/\n\n**Common interview questions:**\n- How to verify whether a binary tree is a binary search tree? ([Answer](http://www.ardendertat.com/2011/10/10/programming-interview-questions-7-binary-search-tree-check/))\n- Find Minimum Depth of a Binary Tree\n- Maximum Path Sum in a Binary Tree\n- Check if a given array can represent Preorder Traversal of Binary Search Tree\n\n## Red Black Trees\nA red-black tree is a binary search tree.\n\nIts properties: \n- Every node is either red or black\n- Every leaf (root of tree) (NULL) is black. \n- If a node is red, then both its children are black\n- Every simple path from a node to a descendant leaf contains the same number of black nodes\n\n**Courses**\n- http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-10-red-black-trees-rotations-insertions-deletions/\n\n## Na\xc3\xafve Divide and Conquer\nTODO\n## Breadth first search\nTODO\n\n# Sorting\n## Bubble sort\nThis sorting algorithm is where each item is compared to adjacent items and is exchanged with those that are out of order. Simply put, each item \xe2\x80\x9cbubbles\xe2\x80\x9d up to the location where it belongs\n\n- Best-case performance\xe2\x80\x8e: \xe2\x80\x8eO(N)^2\n- Worst-case performance\xe2\x80\x8e: \xe2\x80\x8eO(N)^2\n\nBubble sort in C : \n- https://www.tutorialspoint.com/data_structures_algorithms/bubble_sort_program_in_c.htm\n\n## Selection sort\nThis sorting algorithm is where a list of numbers is divided into two parts, the sorted part at the left end and the unsorted part at the right end. Initially, the list is unsorted. \n\n1. **Select and swap** - Select the smallest element from the unsorted part and swapped with the leftmost element\n2. **Continue the process** - This process continues until eventually the whole list becomes sorted\n\n- Best-case performance\xe2\x80\x8e: \xe2\x80\x8eO(N)^2\n- Worst-case performance\xe2\x80\x8e: \xe2\x80\x8eO(N)^2\n\n**Read more here:**\n\n- https://www.tutorialspoint.com/data_structures_algorithms/selection_sort_algorithm.htm\n\n\n## Quick sort\nA sorting algorithm which uses divide-and-conquer. \n\n**How it works?**\n\n1. **Pick a pivot** - Given an unsorted list of numbers, pick an element in the list as a pivot\n\n2. **Partitioning** - Rearrange the elements so that all other elements in the list that are less than or equal to the pivot are to its left and all elements in the list are to the pivot\'s right\n\n3. **Recursively sort** - Recursively sort the elements to the left of the pivot, which must be less than or equal to the pivot) and the elements to the right of the pivot, which must be greater than the pivot\n\n- Best-case performance\xe2\x80\x8e: \xe2\x80\x8eO(n log n)\n- Worst-case performance\xe2\x80\x8e: \xe2\x80\x8eO(n)^2\n\n**Read more here**\n- https://www.tutorialspoint.com/data_structures_algorithms/quick_sort_algorithm.htm\n\n**Practice here:** \n- https://www.hackerrank.com/challenges/quicksort1\n- https://www.hackerrank.com/challenges/quicksort2\n- https://www.hackerrank.com/challenges/quicksort3\n\n## Merge sort\n\n**How it works?**\n\n1. Continuously split the whole list into equal halves until atomic values are achieved and it can no longer be divided. If the list is empty or has one item, it is sorted by definition (the base case).\n\n2. Merge the smaller lists into a new list in sorted order\n\n![1](./images/unsorted_array.jpg)\n\n![1](./images/merge_sort_divide_1.jpg)\n\n![1](./images/merge_sort_divide_2.jpg)\n\n![1](./images/merge_sort_divide_3.jpg)\n\nSource: [Tutorialspoint](https://www.tutorialspoint.com/data_structures_algorithms/merge_sort_algorithm.htm)\n\n- Best-case performance\xe2\x80\x8e: \xe2\x80\x8eO(n log n)\n- Worst-case performance\xe2\x80\x8e: \xe2\x80\x8eO(n log n)\n\n**Practice here**\n- [Quiz for sorting](http://quiz.geeksforgeeks.org/quiz-quicksort/)\n\n# Recursion\nTODO\n# Graph Representation\nTODO\n# Travelling Salesman Problem\nTODO\n\n# Credits\nI myself have learnt a lot while compiling these resources. Thanks to:\n- [Hackerrank](https://www.hackerrank.com) \n- https://www.cs.cmu.edu/~avrim/451f09/lectures/lect1001.pdf\n- Introduction to the Design & Analysis of Algorithms\n- Quora\n- Wikipedia\n- http://algorithms.tutorialhorizon.com/dynamic-programming-coin-change-problem/\n- https://www.tutorialspoint.com\n- https://www.youtube.com/watch?v=pBrz9HmjFOs\n- http://www.geeksforgeeks.org/linked-list-vs-array/\n- https://rob-bell.net/2009/06/a-beginners-guide-to-big-o-notation/\n- https://danielmiessler.com\n- https://www.khanacademy.org\n- http://interactivepython.org/\n- https://math.stackexchange.com\n\nInspired by:\nhttps://github.com/donnemartin/system-design-primer#step-1-review-the-scalability-video-lecture\n\n# Contact\nI would really like to learn from you, so contact me for any issues or questions or ideas.\nMy github page is [here](https://github.com/stacygohyunsi) and my email is hello@imstacy.com\n\n# License\n```\nCreative Commons Attribution 4.0 International License (CC BY 4.0)\n\nhttp://creativecommons.org/licenses/by/4.0/\n```\n\n\n\n\n\n'