b'# InfluxDB [![CircleCI](https://circleci.com/gh/influxdata/influxdb.svg?style=svg)](https://circleci.com/gh/influxdata/influxdb)\n\nInfluxDB is an open source time series platform. This includes APIs for storing and querying data, processing it in the background for ETL or monitoring and alerting purposes, user dashboards, and visualizing and exploring the data and more. The master branch on this repo now represents InfluxDB 2.0, which includes functionality for Kapacitor (background processing) and Chronograf (the UI). If you are looking for the 1.x line of releases, there are branches for each of those. InfluxDB 1.8 will be the next (and likely last) release in the 1.x line and the [working branch is here](https://github.com/influxdata/influxdb/tree/1.8).\n\nIf you are looking for the [InfluxDB 1.x Go Client, we\'ve created a new repo](https://github.com/influxdata/influxdb1-client) for that. There will be a Go client for the 2.0 API coming very soon.\n\n## State of the Project\n\nThe latest InfluxDB 1.x is the stable release and recommended for production use. InfluxDB 2.0 (what\'s in the master branch) is currently in the alpha stage. This means that it is **not** recommended for production usage. There may be breaking API changes, breaking changes in the [Flux language](https://github.com/influxdata/flux), changes in the underlying storage format that will require you to delete all your data, and significant changes to the UI. The alpha is intended for feature exploration and gathering feedback on the available feature set. It **should not** be used for performance testing, benchmarks, or other stress tests.\n\nAdditional features will arrive during the weekly alpha updates. We will be cutting versioned releases every week starting in the first week of February. There will also be nightly builds.\n\nOnce we close on the final feature set of what will be in the first release of InfluxDB in the 2.x line, we will move into the beta phase. At that point, our intention is to avoid making breaking changes to the API or the Flux language. However, it still may be necessary to do so. We will do our best to keep this to an absolute minimum and clearly communicate ANY and ALL changes in this regard via the changelog.\n\nThe beta will still not be recommended for production usage. During the beta period we will focus on bug fixes, performance, and additive features (where time permits).\n\n### What you can expect Alpha and Beta Phases\n\n#### Alpha\n**Weekly alpha releases with incremental feature additions and changes to the user interface**\n\nPlanned additions include:\n- Initial alpha release only supports a single user through the UI and the permission assigned via the security token are "full access".  This restriction will be relaxed delivering the ability to define multiple users and change the access permissions provided via the token.\n- Compatibility layer with 1.x including: 1.x HTTP Write API  and HTTP Read API support for InfluxQL\n- Import Bulk Data from 1.x - convert TSM from 1.x to 2.x\n- Delete API w/ predicates for time (and other)\n\n#### Beta\n**Releases every 2 - 3 weeks or as needed**\n\nPlanned activities include:\n- Performance tuning, stability improvements, and fine tuning based on community feedback.\n- Finalization of supported client libraries starting with JavaScript and Go.\n\n### What is **NOT** planned?\n- Migration of users/security permissions from InfluxDB v1.x to 2.x.  ACTION REQUIRED: Re-establish users and permissions within the new unified security model which now spans the underlying database and user interface.\n- Migration of Continuous Queries.  ACTION REQUIRED: These will need to be re-implemented as Flux tasks.\n- Direct support by InfluxDB for CollectD, StatsD, Graphite, or UDP.  ACTION REQUIRED: Leverage Telegraf 1.9+ along with the InfluxDB v2.0 output plugin to translate these protocols/formats.\n\n## Installing from Source\n\nWe have nightly and weekly versioned Docker images, Debian packages, RPM packages, and tarballs of InfluxDB 2.0 available at the [InfluxData downloads page](https://portal.influxdata.com/downloads/).\n\n## Building From Source\n\nThis project requires Go 1.11 and Go module support.\n\nSet `GO111MODULE=on` or build the project outside of your `GOPATH` for it to succeed.\n\nIf you are getting an `error loading module requirements` error with `bzr executable file not found in $PATH\xe2\x80\x9d` on `make`, then you need to ensure you have `bazaar`, `protobuf`, and `yarn` installed.\n\n- OSX: `brew install bazaar yarn`\n- Linux (Arch): `pacman -S bzr protobuf yarn`\n- Linux (Ubuntu): `apt install bzr protobuf-compiler yarnpkg`\n\n**NB:** For RedHat, there are some extra steps:\n\n1. You must enable the [EPEL](https://fedoraproject.org/wiki/EPEL)\n2. You must add the `yarn` [repository](https://yarnpkg.com/lang/en/docs/install/#centos-stable)\n\nFor information about modules, please refer to the [wiki](https://github.com/golang/go/wiki/Modules).\n\nA successful `make` run results in two binaries, with platform-dependent paths:\n\n```\n$ make\n...\nenv GO111MODULE=on go build -tags \'assets \' -o bin/$(uname -s | tr \'[:upper:]\' \'[:lower:]\')/influx ./cmd/influx\nenv GO111MODULE=on go build -tags \'assets \' -o bin/$(uname -s | tr \'[:upper:]\' \'[:lower:]\')/influxd ./cmd/influxd\n```\n\n`influxd` is the InfluxDB service.\n`influx` is the CLI management tool.\n\nStart the service.\nLogs to stdout by default:\n\n```\n$ bin/$(uname -s | tr \'[:upper:]\' \'[:lower:]\')/influxd\n```\n\n## Getting Started\n\nTo write and query data or use the API in any way, you\'ll need to first create a user, credentials, organization and bucket.\nEverything in InfluxDB 2.0 is organized under a concept of an organization. The API is designed to be multi-tenant.\nBuckets represent where you store time series data.\nThey\'re synonymous with what was previously in InfluxDB 1.x a database and retention policy.\n\nThe simplest way to get set up is to point your browser to [http://localhost:9999](http://localhost:9999) and go through the prompts.\n\n**Note**: Port 9999 will be used during the alpha and beta phases of development of InfluxDB v2.0.\nThis should allow a v2.0-alpha instance to be run alongside a v1.x instance without interfering on port 8086.\nInfluxDB v2.0 will thereafter continue to use 8086.\n\nYou can also get set up from the CLI using the subcommands `influx user`, `influx auth`, `influx org` and `influx bucket`,\nor do it all in one breath with `influx setup`:\n\n\n```\n$ bin/$(uname -s | tr \'[:upper:]\' \'[:lower:]\')/influx setup\nWelcome to InfluxDB 2.0!\nPlease type your primary username: user\n\nPlease type your password: hunter2\n\nPlease type your password again: hunter2\n\nPlease type your primary organization name.: my-org\n\nPlease type your primary bucket name.: my-bucket\n\nPlease type your retention period in hours.\nOr press ENTER for infinite.: 72\n\n\nYou have entered:\n  Username:          user\n  Organization:      my-org\n  Bucket:            my-bucket\n  Retention Period:  72 hrs\nConfirm? (y/n): y\n\nUserID                  Username        Organization    Bucket\n033a3f2c5ccaa000        user            my-org          my-bucket\nYour token has been stored in /Users/you/.influxdbv2/credentials\n```\n\nYou may get into a development loop where `influx setup` becomes tedious.\nSome added flags can help:\n```\n$ bin/$(uname -s | tr \'[:upper:]\' \'[:lower:]\')/influx setup --username user --password hunter2 --org my-org --bucket my-bucket --retention 168 --token my-token --force\n```\n\n`~/.influxdbv2/credentials` contains your auth token.\nMost `influx` commands read the token from this file path by default.\n\nYou may need the organization ID and bucket ID later:\n\n```\n$ influx org find\nID                      Name\n033a3f2c708aa000        my-org\n```\n\n```\n$ influx bucket find\nID                      Name            Retention       Organization    OrganizationID\n033a3f2c710aa000        my-bucket       72h0m0s         my-org          033a3f2c708aa000\n```\n\nWrite to measurement `m`, with tag `v=2`, in bucket `my-bucket`, which belongs to organization `my-org`:\n\n```\n$ bin/$(uname -s | tr \'[:upper:]\' \'[:lower:]\')/influx write --org my-org --bucket my-bucket --precision s "m v=2 $(date +%s)"\n```\n\nWrite the same point using `curl`:\n\n```\ncurl --header "Authorization: Token $(cat ~/.influxdbv2/credentials)" --data-raw "m v=2 $(date +%s)" "http://localhost:9999/api/v2/write?org=033a3f2c708aa000&bucket=033a3f2c710aa000&precision=s"\n```\n\nRead that back with a simple Flux query (currently, the `query` subcommand does not have a `--org` flag):\n\n```\n$ bin/$(uname -s | tr \'[:upper:]\' \'[:lower:]\')/influx query --org-id 033a3f2c708aa000 \'from(bucket:"my-bucket") |> range(start:-1h)\'\nResult: _result\nTable: keys: [_start, _stop, _field, _measurement]\n                   _start:time                      _stop:time           _field:string     _measurement:string                      _time:time                  _value:float\n------------------------------  ------------------------------  ----------------------  ----------------------  ------------------------------  ----------------------------\n2019-01-10T19:24:06.806244000Z  2019-01-10T20:24:06.806244000Z                       v                       m  2019-01-10T20:04:09.000000000Z                             2\n```\n\nUse the fancy REPL:\n\n```\n$ bin/$(uname -s | tr \'[:upper:]\' \'[:lower:]\')/influx repl --org my-org\n> from(bucket:"my-bucket") |> range(start:-1h)\nResult: _result\nTable: keys: [_start, _stop, _field, _measurement]\n                   _start:time                      _stop:time           _field:string     _measurement:string                      _time:time                  _value:float\n------------------------------  ------------------------------  ----------------------  ----------------------  ------------------------------  ----------------------------\n2019-01-10T19:36:23.361220000Z  2019-01-10T20:36:23.361220000Z                       v                       m  2019-01-10T20:04:09.000000000Z                             2\n>\n```\n\n## Introducing Flux\n\nWe recently announced Flux, the MIT-licensed data scripting language (previously named IFQL). The source for Flux is [available on GitHub](https://github.com/influxdata/flux). Learn more about Flux from [CTO Paul Dix\'s presentation](https://speakerdeck.com/pauldix/flux-number-fluxlang-a-new-time-series-data-scripting-language).\n\n## CI and Static Analysis\n\n### CI\n\nAll pull requests will run through CI, which is currently hosted by Circle.\nCommunity contributors should be able to see the outcome of this process by looking at the checks on their PR.\nPlease fix any issues to ensure a prompt review from members of the team.\n\nThe InfluxDB project is used internally in a number of proprietary InfluxData products, and as such, PRs and changes need to be tested internally.\nThis can take some time, and is not really visible to community contributors.\n\n### Static Analysis\n\nThis project uses the following static analysis tools.\nFailure during the running of any of these tools results in a failed build.\nGenerally, code must be adjusted to satisfy these tools, though there are exceptions.\n\n- [go vet](https://golang.org/cmd/vet/) checks for Go code that should be considered incorrect.\n- [go fmt](https://golang.org/cmd/gofmt/) checks that Go code is correctly formatted.\n- [go mod tidy](https://tip.golang.org/cmd/go/#hdr-Add_missing_and_remove_unused_modules) ensures that the source code and go.mod agree.\n- [staticcheck](http://next.staticcheck.io/docs/) checks for things like: unused code, code that can be simplified, code that is incorrect and code that will have performance issues.\n\n### staticcheck\n\nIf your PR fails `staticcheck` it is easy to dig into why it failed, and also to fix the problem.\nFirst, take a look at the error message in Circle under the `staticcheck` build section, e.g.,\n\n```\ntsdb/tsm1/encoding.gen.go:1445:24: func BooleanValues.assertOrdered is unused (U1000)\ntsdb/tsm1/encoding.go:172:7: receiver name should not be an underscore, omit the name if it is unused (ST1006)\n```\n\nNext, go and take a [look here](http://next.staticcheck.io/docs/checks) for some clarification on the error code that you have received, e.g., `U1000`.\nThe docs will tell you what\'s wrong, and often what you need to do to fix the issue.\n\n#### Generated Code\n\nSometimes generated code will contain unused code or occasionally that will fail a different check.\n`staticcheck` allows for [entire files](http://next.staticcheck.io/docs/#ignoring-problems) to be ignored, though it\'s not ideal.\nA linter directive, in the form of a comment, must be placed within the generated file.\nThis is problematic because it will be erased if the file is re-generated.\nUntil a better solution comes about, below is the list of generated files that need an ignores comment.\nIf you re-generate a file and find that `staticcheck` has failed, please see this list below for what you need to put back:\n\n|          File          |                             Comment                              |\n| :--------------------: | :--------------------------------------------------------------: |\n| query/promql/promql.go | //lint:file-ignore SA6001 Ignore all unused code, it\'s generated |\n\n#### End-to-End Tests\n\nCI also runs end-to-end tests. These test the integration between the influx server the ui. You can run them locally in two steps:\n\n- Start the server in "testing mode" by running `make run-e2e`.\n- Run the tests with `make e2e`.\n'