b'# Overview\n\n[![Build Status](https://travis-ci.org/kubernetes/kube-state-metrics.svg?branch=master)](https://travis-ci.org/kubernetes/kube-state-metrics)  [![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/kube-state-metrics)](https://goreportcard.com/report/github.com/kubernetes/kube-state-metrics) [![GoDoc](https://godoc.org/github.com/kubernetes/kube-state-metrics?status.svg)](https://godoc.org/github.com/kubernetes/kube-state-metrics)\n\nkube-state-metrics is a simple service that listens to the Kubernetes API\nserver and generates metrics about the state of the objects. (See examples in\nthe Metrics section below.) It is not focused on the health of the individual\nKubernetes components, but rather on the health of the various objects inside,\nsuch as deployments, nodes and pods.\n\nkube-state-metrics is about generating metrics from Kubernetes API objects\nwithout modification. This ensures that features provided by kube-state-metrics\nhave the same grade of stability as the Kubernetes API objects themselves. In\nturn, this means that kube-state-metrics in certain situations may not show the\nexact same values as kubectl, as kubectl applies certain heuristics to display\ncomprehensible messages. kube-state-metrics exposes raw data unmodified from the\nKubernetes API, this way users have all the data they require and perform\nheuristics as they see fit.\n\nThe metrics are exported on the HTTP endpoint `/metrics` on the listening port\n(default 80). They are served as plaintext. They are designed to be consumed\neither by Prometheus itself or by a scraper that is compatible with scraping a\nPrometheus client endpoint. You can also open `/metrics` in a browser to see\nthe raw metrics.\n\n## Table of Contents\n\n- [Versioning](#versioning)\n  - [Kubernetes Version](#kubernetes-version)\n  - [Compatibility matrix](#compatibility-matrix)\n  - [Resource group version compatibility](#resource-group-version-compatibility)\n  - [Container Image](#container-image)\n- [Metrics Documentation](#metrics-documentation)\n- [Kube-state-metrics self metrics](#kube-state-metrics-self-metrics)\n- [Resource recommendation](#resource-recommendation)\n- [A note on costing](#a-note-on-costing)\n- [kube-state-metrics vs. metrics-server](#kube-state-metrics-vs-metrics-server)\n- [Scaling kube-state-metrics](#scaling-kube-state-metrics)\n  - [Resource recommendation](#resource-recommendation)\n  - [Horizontal scaling (sharding)](#horizontal-scaling-sharding)\n    - [Automated sharding](#automated-sharding)\n- [Setup](#setup)\n  - [Building the Docker container](#building-the-docker-container)\n- [Usage](#usage)\n  - [Kubernetes Deployment](#kubernetes-deployment)\n  - [Limited privileges environment](#limited-privileges-environment)\n  - [Development](#development)\n  - [Developer Contributions](#developer-contributions)\n\n### Versioning\n\n#### Kubernetes Version\n\nkube-state-metrics uses [`client-go`](https://github.com/kubernetes/client-go) to talk with\nKubernetes clusters. The supported Kubernetes cluster version is determined by `client-go`.\nThe compatibility matrix for client-go and Kubernetes cluster can be found\n[here](https://github.com/kubernetes/client-go#compatibility-matrix).\nAll additional compatibility is only best effort, or happens to still/already be supported.\n\n#### Compatibility matrix\nAt most, 5 kube-state-metrics and 5 [kubernetes releases](https://github.com/kubernetes/kubernetes/releases) will be recorded below.\n\n| kube-state-metrics | client-go  | **Kubernetes 1.11** | **Kubernetes 1.12** | **Kubernetes 1.13** | **Kubernetes 1.14** |  **Kubernetes 1.15** |\n|--------------------|------------|---------------------|---------------------|---------------------|---------------------|----------------------|\n| **v1.4.0**         |  v8.0.0    |         \xe2\x9c\x93           |         \xe2\x9c\x93           |         -           |         -           |          -           |\n| **v1.5.0**         |  v8.0.0    |         \xe2\x9c\x93           |         \xe2\x9c\x93           |         -           |         -           |          -           |\n| **v1.6.0**         |  v11.0.0   |         \xe2\x9c\x93           |         \xe2\x9c\x93           |         \xe2\x9c\x93           |         \xe2\x9c\x93           |          -           |\n| **v1.7.2**         |  v12.0.0   |         \xe2\x9c\x93           |         \xe2\x9c\x93           |         \xe2\x9c\x93           |         \xe2\x9c\x93           |          \xe2\x9c\x93           |\n| **v1.8.0**         |  v12.0.0   |         \xe2\x9c\x93           |         \xe2\x9c\x93           |         \xe2\x9c\x93           |         \xe2\x9c\x93           |          \xe2\x9c\x93           |\n| **master**         |  v12.0.0   |         \xe2\x9c\x93           |         \xe2\x9c\x93           |         \xe2\x9c\x93           |         \xe2\x9c\x93           |          \xe2\x9c\x93           |\n- `\xe2\x9c\x93` Fully supported version range.\n- `-` The Kubernetes cluster has features the client-go library can\'t use (additional API objects, etc).\n\n#### Resource group version compatibility\nResources in Kubernetes can evolve, i.e., the group version for a resource may change from alpha to beta and finally GA\nin different Kubernetes versions. For now, kube-state-metrics will only use the oldest API available in the latest\nrelease.\n\n#### Container Image\n\nThe latest container image can be found at:\n* `quay.io/coreos/kube-state-metrics:v1.8.0`\n* `k8s.gcr.io/kube-state-metrics:v1.8.0`\n\n**Note**:\nThe recommended docker registry for kube-state-metrics is `quay.io`. kube-state-metrics on\n`gcr.io` is only maintained on best effort as it requires external help from Google employees.\n\n### Metrics Documentation\n\nThere are many more metrics we could report, but this first pass is focused on\nthose that could be used for actionable alerts. Please contribute PR\'s for\nadditional metrics!\n\n> WARNING: THESE METRIC/TAG NAMES ARE UNSTABLE AND MAY CHANGE IN A FUTURE RELEASE.\n> For now, the following metrics and collectors\n>\n> **metrics**\n>\t* `kube_pod_container_resource_requests_nvidia_gpu_devices`\n>\t* `kube_pod_container_resource_limits_nvidia_gpu_devices`\n>\t* `kube_node_status_capacity_nvidia_gpu_cards`\n>\t* `kube_node_status_allocatable_nvidia_gpu_cards`\n>\n>\tare removed in kube-state-metrics v1.4.0.\n>\n> Any collectors and metrics based on alpha Kubernetes APIs are excluded from any stability guarantee,\n> which may be changed at any given release.\n\nSee the [`docs`](docs) directory for more information on the exposed metrics.\n\n### Kube-state-metrics self metrics\n\nkube-state-metrics exposes its own general process metrics under `--telemetry-host` and `--telemetry-port` (default 81).\n\nkube-state-metrics also exposes list and watch success and error metrics. These can be used to calculate the error rate of list or watch resources.\nIf you encounter those errors in the metrics, it is most likely a configuration or permission issue, and the next thing to investigate would be looking\nat the logs of kube-state-metrics.\n\nExample of the above mentioned metrics:\n```\nkube_state_metrics_list_total{resource="*v1.Node",result="success"} 1\nkube_state_metrics_list_total{resource="*v1.Node",result="error"} 52\nkube_state_metrics_watch_total{resource="*v1beta1.Ingress",result="success"} 1\n```\n\n### Scaling kube-state-metrics\n\n#### Resource recommendation\n\n> Note: These recommendations are based on scalability tests done over a year ago. They may differ significantly today.\n\nResource usage for kube-state-metrics changes with the Kubernetes objects (Pods/Nodes/Deployments/Secrets etc.) size of the cluster.\nTo some extent, the Kubernetes objects in a cluster are in direct proportion to the node number of the cluster.\n\nAs a general rule, you should allocate\n\n* 200MiB memory\n* 0.1 cores\n\nFor clusters of more than 100 nodes, allocate at least\n\n* 2MiB memory per node\n* 0.001 cores per node\n\nThese numbers are based on [scalability tests](https://github.com/kubernetes/kube-state-metrics/issues/124#issuecomment-318394185) at 30 pods per node.\n\nNote that if CPU limits are set too low, kube-state-metrics\' internal queues will not be able to be worked off quickly enough, resulting in increased memory consumption as the queue length grows. If you experience problems resulting from high memory allocation, try increasing the CPU limits.\n\n### A note on costing\n\nBy default, kube-state-metrics exposes several metrics for events across your cluster. If you have a large number of frequently-updating resources on your cluster, you may find that a lot of data is ingested into these metrics. This can incur high costs on some cloud providers. Please take a moment to [configure what metrics you\'d like to expose](docs/cli-arguments.md), as well as consult the documentation for your Kubernetes environment in order to avoid unexpectedly high costs.\n\n### kube-state-metrics vs. metrics-server\n\nThe [metrics-server](https://github.com/kubernetes-incubator/metrics-server)\nis a project that has been inspired by\n[Heapster](https://github.com/kubernetes-retired/heapster) and is implemented\nto serve the goals of core metrics pipelines in [Kubernetes monitoring\narchitecture](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/monitoring_architecture.md).\nIt is a cluster level component which periodically scrapes metrics from all\nKubernetes nodes served by Kubelet through Summary API. The metrics are\naggregated, stored in memory and served in [Metrics API\nformat](https://git.k8s.io/metrics/pkg/apis/metrics/v1alpha1/types.go). The\nmetric-server stores the latest values only and is not responsible for\nforwarding metrics to third-party destinations.\n\nkube-state-metrics is focused on generating completely new metrics from\nKubernetes\' object state (e.g. metrics based on deployments, replica sets,\netc.). It holds an entire snapshot of Kubernetes state in memory and\ncontinuously generates new metrics based off of it. And just like the\nmetric-server it too is not responsibile for exporting its metrics anywhere.\n\nHaving kube-state-metrics as a separate project also enables access to these\nmetrics from monitoring systems such as Prometheus.\n\n#### Horizontal scaling (sharding)\n\nIn order to scale kube-state-metrics horizontally, some automated sharding capabilities have been implemented. It is configured with the following flags:\n\n* `--shard` (zero indexed)\n* `--total-shards`\n\nSharding is done by taking an md5 sum of the Kubernetes Object\'s UID and performing a modulo operation on it, with the total number of shards. The configured shard decides whether the object is handled by the respective instance of kube-state-metrics or not. Note that this means all instances of kube-state-metrics even if sharded will have the network traffic and the resource consumption for unmarshaling objects for all objects, not just the ones it is responsible for. To optimize this further, the Kubernetes API would need to support sharded list/watch capabilities. Overall memory consumption should be 1/n th of each shard compared to an unsharded setup. Typically, kube-state-metrics needs to be memory and latency optimized in order for it to return its metrics rather quickly to Prometheus.\n\nSharding should be used carefully, and additional monitoring should be set up in order to ensure that sharding is set up and functioning as expected (eg. instances for each shard out of the total shards are configured).\n\n##### Automated sharding\n\nThere is also an experimental feature, that allows kube-state-metrics to auto discover its nominal position if it is deployed in a StatefulSet, in order to automatically configure sharding. This is an experimental feature and may be broken or removed without notice.\n\nTo enable automated sharding kube-state-metrics must be run by a `StatefulSet` and the pod names and namespace must be handed to the kube-state-metrics process via the `--pod` and `--pod-namespace` flags.\n\nThere are example manifests demonstrating the autosharding functionality in [`/examples/autosharding`](./examples/autosharding).\n\n### Setup\n\nInstall this project to your `$GOPATH` using `go get`:\n\n```\ngo get k8s.io/kube-state-metrics\n```\n\n#### Building the Docker container\n\nSimply run the following command in this root folder, which will create a\nself-contained, statically-linked binary and build a Docker image:\n```\nmake container\n```\n\n### Usage\n\nSimply build and run kube-state-metrics inside a Kubernetes pod which has a\nservice account token that has read-only access to the Kubernetes cluster.\n\n#### Kubernetes Deployment\n\nTo deploy this project, you can simply run `kubectl apply -f examples/standard` and a\nKubernetes service and deployment will be created. (Note: Adjust the apiVersion of some resource if your kubernetes cluster\'s version is not 1.8+, check the yaml file for more information).\n\nTo have Prometheus discover kube-state-metrics instances it is advised to create a specific Prometheus scrape config for kube-state-metrics that picks up both metrics endpoints. Annotation based discovery is discouraged as only one of the endpoints would be able to be selected, plus kube-state-metrics in most cases has special authentication and authorization requirements as it essentially grants read access through the metrics endpoint to most information available to it.\n\n**Note:** Google Kubernetes Engine (GKE) Users - GKE has strict role permissions that will prevent the kube-state-metrics roles and role bindings from being created. To work around this, you can give your GCP identity the cluster-admin role by running the following one-liner:\n\n```\nkubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=$(gcloud info --format=\'value(config.account)\')\n```\n\nNote that your GCP identity is case sensitive but `gcloud info` as of Google Cloud SDK 221.0.0 is not. This means that if your IAM member contains capital letters, the above one-liner may not work for you. If you have 403 forbidden responses after running the above command and `kubectl apply -f examples/standard`, check the IAM member associated with your account at https://console.cloud.google.com/iam-admin/iam?project=PROJECT_ID. If it contains capital letters, you may need to set the --user flag in the command above to the case-sensitive role listed at https://console.cloud.google.com/iam-admin/iam?project=PROJECT_ID.\n\nAfter running the above, if you see `Clusterrolebinding "cluster-admin-binding" created`, then you are able to continue with the setup of this service.\n\n#### Limited privileges environment\n\nIf you want to run kube-state-metrics in an environment where you don\'t have cluster-reader role, you can:\n\n- create a serviceaccount\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: kube-state-metrics\n  namespace: your-namespace-where-kube-state-metrics-will-deployed\n```\n\n- give it `view` privileges on specific namespaces (using roleBinding) (*note: you can add this roleBinding to all the NS you want your serviceaccount to access*)\n```yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: kube-state-metrics\n  namespace: project1\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: view\nsubjects:\n  - kind: ServiceAccount\n    name: kube-state-metrics\n    namespace: your-namespace-where-kube-state-metrics-will-deployed\n```\n\n- then specify a set of namespaces (using the `--namespace` option) and a set of kubernetes objects (using the `--collectors`) that your serviceaccount has access to in the `kube-state-metrics` deployment configuration\n\n```yaml\nspec:\n  template:\n    spec:\n      containers:\n      - name: kube-state-metrics\n        args:\n          - \'--collectors=pods\'\n          - \'--namespace=project1\'\n```\n\nFor the full list of arguments available, see the documentation in [docs/cli-arguments.md](./docs/cli-arguments.md)\n\n#### Development\n\nWhen developing, test a metric dump against your local Kubernetes cluster by\nrunning:\n\n> Users can override the apiserver address in KUBE-CONFIG file with `--apiserver` command line.\n\n\tgo install\n\tkube-state-metrics --port=8080 --telemetry-port=8081 --kubeconfig=<KUBE-CONFIG> --apiserver=<APISERVER>\n\nThen curl the metrics endpoint\n\n\tcurl localhost:8080/metrics\n\nTo run the e2e tests locally see the documentation in [tests/README.md](./tests/README.md).\n\n#### Developer Contributions\n\nWhen developing, there are certain code patterns to follow to better your contributing experience and likelihood of e2e and other ci tests to pass. To learn more about them, see the documentation in [docs/developer/guide.md](./docs/developer/guide.md).\n'