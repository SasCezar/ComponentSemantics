b'## DeepDetect : Open Source Deep Learning Server & API\n\n[![Join the chat at https://gitter.im/beniz/deepdetect](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/beniz/deepdetect?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) [![Build Status](https://travis-ci.org/beniz/deepdetect.png)](https://travis-ci.org/jolibrain/deepdetect)\n\nDeepDetect (http://www.deepdetect.com/) is a machine learning API and server written in C++11. It makes state of the art machine learning easy to work with and integrate into existing applications.\n\nDeepDetect relies on external machine learning libraries through a very generic and flexible API. At the moment it has support for:\n\n- the deep learning libraries [Caffe](https://github.com/BVLC/caffe), [Tensorflow](https://tensorflow.org), [Caffe2](https://caffe2.ai/) and [Dlib](http://dlib.net/ml.html)\n- distributed gradient boosting library [XGBoost](https://github.com/dmlc/xgboost)\n- clustering with [T-SNE](https://github.com/DmitryUlyanov/Multicore-TSNE)\n- similarity search with [Annoy](https://github.com/spotify/annoy/)\n\n#### Machine Learning functionalities per library (current):\n\n|            | Training | Prediction | Classification | Object Detection | Segmentation | Regression | Autoencoder | OCR / Seq2Seq |\n|------------|----------|------------|----------------|-----------|-----------|------------|-------------|-------------|\n| Caffe      | Y        | Y          | Y              | Y         |   Y       |   Y        | Y           | Y           |\n| Caffe2     | Y        | Y          | Y              | Y         |   N       |   N        | N           | N           |\n| XGBoost    | Y        | Y          | Y              | N         |   N       |   Y        | N/A         | N           |\n| Tensorflow | N        | Y          | Y              | N         |   N       |   N        | N           | N           |\n| T-SNE      | Y        | N/A        | N/A            | N/A       |   N/A     |   N/A      | N/A         | N           |\n| Dlib       | N        | Y          | Y              | Y         |   N       |   N        | N           | N           |\n| TensorRT   | N        | Y          | Y              | Y         |   N       |   N        | N           | N           |\n| Libtorch   | N        | Y          | Y              | N         |   N       |   N        | N           | N           |\n\n\n#### GPU support per library\n\n|            | Training | Prediction |\n|------------|----------|------------|\n| Caffe      | Y        | Y          |\n| Caffe2     | Y        | Y          |\n| XGBoost    | Y        | Y          |\n| Tensorflow | N        | Y          |\n| T-SNE      | Y        | N          |\n| Dlib       | N        | Y          |\n| TensorRT   | N        | Y          |\n| Libtorch   | N        | Y          |\n\n#### Input data support per library (current):\n\n|            | CSV | SVM | Text words | Text characters | Images |\n|------------|-----|-----|------------|-----------------|--------|\n| Caffe      | Y   | Y   | Y          | Y               | Y      |\n| Caffe2     | N   | N   | N          | N               | Y      |\n| XGBoost    | Y   | Y   | Y          | N               | N      |\n| Tensorflow | N   | N   | N          | N               | Y      |\n| T-SNE      | Y   | N   | N          | N               | Y      | (*)\n| Dlib       | N   | N   | N          | N               | Y      |\n| TensorRT   | N   | N   | N          | N               | Y      |\n| Libtorch   | N   | N   | N          | N               | Y      |\n(*) more input support for T-SNE is pending\n\n#### Main functionalities\n\nDeepDetect implements support for supervised and unsupervised deep learning of images, text and other data, with focus on simplicity and ease of use, test and connection into existing applications. It supports classification, object detection, segmentation, regression, autoencoders, ...\n\n#### Support\n\nPlease join either the community on [Gitter](https://gitter.im/beniz/deepdetect) or on IRC Freenode #deepdetect, where we help users get through with installation, API, neural nets and connection to external applications.\n\n#### Supported Platforms\n\nThe reference platforms with support are **Ubuntu 14.04 LTS** and **Ubuntu 16.04 LTS**.\n\nSupported images that come with pre-trained image classification deep (residual) neural nets:\n\n- **docker images** for CPU and GPU machines are available at https://hub.docker.com/r/jolibrain/deepdetect_cpu/ and https://hub.docker.com/r/jolibrain/deepdetect_gpu/ respectively. See https://github.com/jolibrain/deepdetect/tree/master/docker/README.md for details on how to use them.\n\n- For **Amazon AMI** see official builds documentation at https://deepdetect.com/products/ami/, and direct links to [GPU AMI](https://aws.amazon.com/marketplace/pp/B01N4D483M) and [CPU AMI](https://aws.amazon.com/marketplace/pp/B01N1RGWQZ).\n\n#### Performances\n\nSee https://github.com/jolibrain/dd_performances for a report on performances on NVidia Desktop and embedded GPUs, along with Raspberry Pi 3.\n\n#### Quickstart\nSetup an image classifier API service in a few minutes:\nhttp://www.deepdetect.com/tutorials/imagenet-classifier/\n\n#### Tutorials\nList of tutorials, training from text, data and images, setup of prediction services, and export to external software (e.g. ElasticSearch): http://www.deepdetect.com/tutorials/tutorials/\n\n#### Features and Documentation\nCurrent features include:\n\n- high-level API for machine learning and deep learning\n- support for Caffe, Tensorflow, XGBoost and T-SNE\n- classification, regression, autoencoders, object detection, segmentation\n- JSON communication format\n- remote Python client library\n- dedicated server with support for asynchronous training calls\n- high performances, benefit from multicore CPU and GPU\n- built-in similarity search via neural embeddings\n- connector to handle large collections of images with on-the-fly data augmentation (e.g. rotations, mirroring)\n- connector to handle CSV files with preprocessing capabilities\n- connector to handle text files, sentences, and character-based models\n- connector to handle SVM file format for sparse data\n- range of built-in model assessment measures (e.g. F1, multiclass log loss, ...)\n- no database dependency and sync, all information and model parameters organized and available from the filesystem\n- flexible template output format to simplify connection to external applications\n- templates for the most useful neural architectures (e.g. Googlenet, Alexnet, ResNet, convnet, character-based convnet, mlp, logistic regression)\n- support for sparse features and computations on both GPU and CPU\n- built-in similarity indexing and search of predicted features and probability distributions\n\n##### Documentation\n\n- Full documentation is available from http://www.deepdetect.com/overview/introduction/\n- API documentation is available from http://www.deepdetect.com/api/\n- FAQ is available from http://www.deepdetect.com/overview/faq/\n\n##### Clients\n\n- Python client:\n  - REST client: https://github.com/jolibrain/deepdetect/tree/master/clients/python\n  - \'a la scikit\' bindings: https://github.com/ArdalanM/pyDD\n- Javacript client: https://github.com/jolibrain/deepdetect-js\n- Java client: https://github.com/kfadhel/deepdetect-api-java\n- Early C# client: https://github.com/jolibrain/deepdetect/pull/98\n\n##### Tools\n\n- Log DeepDetect training metrics via Tensorboard with [dd_board](https://github.com/jolibrain/dd_board)\n\n##### Dependencies\n\n- C++, gcc >= 4.8 or clang with support for C++11 (there are issues with Clang + Boost)\n- [eigen](http://eigen.tuxfamily.org/index.php?title=Main_Page) for all matrix operations;\n- [glog](https://code.google.com/p/google-glog/) for logging events and debug;\n- [gflags](https://code.google.com/p/gflags/) for command line parsing;\n- OpenCV >= 2.4\n- [cppnetlib](http://cpp-netlib.org/)\n- Boost\n- [curl](http://curl.haxx.se/)\n- [curlpp](http://www.curlpp.org/)\n- [utfcpp](http://utfcpp.sourceforge.net/)\n- [gtest](https://code.google.com/p/googletest/) for unit testing (optional);\n\n##### Caffe Dependencies\n\n- CUDA 9 or 8 is recommended for GPU mode.\n- BLAS via ATLAS, MKL, or OpenBLAS.\n- [protobuf](https://github.com/google/protobuf)\n- IO libraries hdf5, leveldb, snappy, lmdb\n\n##### XGBoost Dependencies\n\nNone outside of C++ compiler and make\n- CUDA 8 is recommended for GPU mode.\n\n#### Tensorflow Dependencies\n\n- Cmake > 3\n- [Bazel 0.8.x](https://www.bazel.io/versions/master/docs/install.html#install-on-ubuntu)\n\n#### Dlib Dependencies\n\n- CUDA 9 or 8 and cuDNN 7 for GPU mode. CUDA 10 for Ubuntu 18.04\n\n**Note:** The version of OpenBLAS (v0.2.20) shipped with Ubuntu 18.04 is not up to date and includes a bug. You must install a later version of OpenBLAS >= v0.3.0 to use Dlib on Ubuntu 18.04.\n\nThe easiest way currently is to manually install the Ubuntu 19.10 `libopenblas-base` and `libopenblas-dev` packages. You may download them here:\n\nhttp://launchpadlibrarian.net/410583809/libopenblas-base_0.3.5+ds-2_amd64.deb\n\nhttp://launchpadlibrarian.net/410583808/libopenblas-dev_0.3.5+ds-2_amd64.deb\n\nand install them with `sudo apt-get install ./package-name.deb` to automatically handle dependencies.\n\n##### Caffe version\n\nBy default DeepDetect automatically relies on a modified version of Caffe, https://github.com/jolibrain/caffe/tree/master\nThis version includes many improvements over the original Caffe, such as sparse input data support, exception handling, class weights, object detection, segmentation, and various additional losses and layers.\n\n##### Implementation\n\nThe code makes use of C++ policy design for modularity, performance and putting the maximum burden on the checks at compile time. The implementation uses many features from C++11.\n\n##### Demo\n\n- Image classification Web interface:\nHTML and javascript classification image demo in [demo/imgdetect](https://github.com/jolibrain/deepdetect/tree/master/demo/imgdetect)\n\n- Image similarity search:\nPython script for indexing and searching images is in [demo/imgsearch](https://github.com/jolibrain/deepdetect/tree/master/demo/imgsearch)\n\n- Image object detection:\nPython script for object detection within images is in [demo/objdetect](https://github.com/jolibrain/deepdetect/tree/master/demo/objdetect)\n\n- Image segmentation:\nPython script for image segmentation is in [demo/segmentation](https://github.com/jolibrain/deepdetect/tree/master/demo/segmentation)\n\n##### Examples\n\n- List of examples, from MLP for data, text, multi-target regression to CNN and GoogleNet, finetuning, etc...:\nhttp://www.deepdetect.com/overview/examples/\n\n##### Models\n\n|                          | Caffe | Tensorflow | Source        | Top-1 Accuracy (ImageNet) |\n|--------------------------|-------|------------|---------------|---------------------------|\n| AlexNet                  | Y     | N          | BVLC          |          57.1%                 |\n| SqueezeNet               | [Y](https://deepdetect.com/models/squeezenet/squeezenet_v1.1.caffemodel)     | N          | DeepScale              |       59.5%                    | \n| Inception v1 / GoogleNet | [Y](https://deepdetect.com/models/ggnet/bvlc_googlenet.caffemodel)     | [Y](https://deepdetect.com/models/tf/inception_v1.pb)          | BVLC / Google |             67.9%              |\n| Inception v2             | N     | [Y](https://deepdetect.com/models/tf/inception_v2.pb)          | Google        |     72.2%                      |\n| Inception v3             | N     | [Y](https://deepdetect.com/models/tf/inception_v3.pb)          | Google        |         76.9%                  |\n| Inception v4             | N     | [Y](https://deepdetect.com/models/tf/inception_v4.pb)          | Google        |         80.2%                  |\n| ResNet 50                | [Y](https://deepdetect.com/models/resnet/ResNet-50-model.caffemodel)     | [Y](https://deepdetect.com/models/tf/resnet_v1_50/resnet_v1_50.pb)          | MSR           |      75.3%                     |\n| ResNet 101               | [Y](https://deepdetect.com/models/resnet/ResNet-101-model.caffemodel)     | [Y](https://deepdetect.com/models/tf/resnet_v1_101/resnet_v1_101.pb)          | MSR           |        76.4%                   |\n| ResNet 152               | [Y](https://deepdetect.com/models/resnet/ResNet-152-model.caffemodel)     | [Y](https://deepdetect.com/models/tf/resnet_v1_152/resnet_v1_152.pb)         | MSR           |               77%            |\n| Inception-ResNet-v2      | N     | [Y](https://deepdetect.com/models/tf/inception_resnet_v2.pb)          | Google        |       79.79%                    |\n| VGG-16                   | [Y](https://deepdetect.com/models/vgg_16/VGG_ILSVRC_16_layers.caffemodel)     | [Y](https://deepdetect.com/models/tf/vgg_16/vgg_16.pb)          | Oxford        |               70.5%            |\n| VGG-19                   | [Y](https://deepdetect.com/models/vgg_19/VGG_ILSVRC_19_layers.caffemodel)     | [Y](https://deepdetect.com/models/tf/vgg_19/vgg_19.pb)          | Oxford        |               71.3%            |\n| ResNext 50                | [Y](https://deepdetect.com/models/resnext/resnext_50)     | N          | https://github.com/terrychenism/ResNeXt           |      76.9%                     |\n| ResNext 101                | [Y](https://deepdetect.com/models/resnext/resnext_101)     | N          | https://github.com/terrychenism/ResNeXt           |      77.9%                     |\n| ResNext 152               | [Y](https://deepdetect.com/models/resnext/resnext_152)     | N          | https://github.com/terrychenism/ResNeXt           |      78.7%                     |\n| DenseNet-121                   | [Y](https://deepdetect.com/models/densenet/densenet_121_32/)     | N          | https://github.com/shicai/DenseNet-Caffe        |               74.9%            |\n| DenseNet-161                   | [Y](https://deepdetect.com/models/densenet/densenet_161_48/)     | N          | https://github.com/shicai/DenseNet-Caffe        |               77.6%            |\n| DenseNet-169                   | [Y](https://deepdetect.com/models/densenet/densenet_169_32/)     | N          | https://github.com/shicai/DenseNet-Caffe        |               76.1%            |\n| DenseNet-201                   | [Y](https://deepdetect.com/models/densenet/densenet_201_32/)     | N          | https://github.com/shicai/DenseNet-Caffe        |               77.3%            |\n| SE-BN-Inception                   | [Y](https://deepdetect.com/models/senets/se_bn_inception/)     | N          | https://github.com/hujie-frank/SENet        |               76.38%            |\n| SE-ResNet-50                   | [Y](https://deepdetect.com/models/senets/se_resnet_50/)     | N          | https://github.com/hujie-frank/SENet        |               77.63%            |\n| SE-ResNet-101                   | [Y](https://deepdetect.com/models/senets/se_resnet_101/)     | N          | https://github.com/hujie-frank/SENet        |               78.25%            |\n| SE-ResNet-152                   | [Y](https://deepdetect.com/models/senets/se_resnet_152/)     | N          | https://github.com/hujie-frank/SENet        |               78.66%            |\n| SE-ResNext-50                   | [Y](https://deepdetect.com/models/senets/se_resnext_50/)     | N          | https://github.com/hujie-frank/SENet        |               79.03%            |\n| SE-ResNext-101                   | [Y](https://deepdetect.com/models/senets/se_resnext_101/)     | N          | https://github.com/hujie-frank/SENet        |               80.19%            |\n| SENet                   | [Y](https://deepdetect.com/models/senets/se_net/)     | N          | https://github.com/hujie-frank/SENet        |               81.32%            |\n| VOC0712 (object detection) | [Y](https://deepdetect.com/models/voc0712_dd.tar.gz) | N | https://github.com/weiliu89/caffe/tree/ssd | 71.2 mAP |\n| InceptionBN-21k | [Y](https://deepdetect.com/models/inception/inception_bn_21k) | N | https://github.com/pertusa/InceptionBN-21K-for-Caffe | 41.9% |\n| Inception v3 5K | N | [Y](https://deepdetect.com/models/tf/openimages_inception_v3) | https://github.com/openimages/dataset |  |\n| [5-point Face Landmarking Model (face detection)](http://dlib.net/files/mmod_human_face_detector.dat.bz2) | N | N | http://blog.dlib.net/2017/09/fast-multiclass-object-detection-in.html |  |\n| [Front/Rear vehicle detection (object detection)](http://dlib.net/files/mmod_front_and_rear_end_vehicle_detector.dat.bz2) | N | N | http://blog.dlib.net/2017/09/fast-multiclass-object-detection-in.html |  |\n\nMore models:\n\n- List of free, even for commercial use, deep neural nets for image classification, and character-based convolutional nets for text classification: http://www.deepdetect.com/applications/list_models/\n\n#### Templates\n\nDeepDetect comes with a built-in system of neural network templates (Caffe backend only at the moment). This allows the creation of custom networks based on recognized architectures, for images, text and data, and with much simplicity.\n\nUsage:\n- specify `template` to use, from `mlp`, `convnet` and `resnet`\n- specify the architecture with the `layers` parameter:\n  - for `mlp`, e.g. `[300,100,10]`\n  - for `convnet`, e.g. `["1CR64","1CR128","2CR256","1024","512"], where the main pattern is `xCRy` where `y` is the number of outputs (feature maps), `CR` stands for Convolution + Activation (with `relu` as default), and `x` specifies the number of chained `CR` blocks without pooling. Pooling is applied between all `xCRy`\n- for `resnets`:\n   - with images, e.g. `["Res50"]` where the main pattern is `ResX` with X the depth of the Resnet\n   - with character-based models (text), use the `xCRy` pattern of convnets instead, with the main difference that `x` now specifies the number of chained `CR` blocks within a resnet block\n   - for Resnets applied to CSV or SVM (sparse data), use the `mlp` pattern. In this latter case, at the moment, the `resnet` is built with blocks made of two layers for each specified layer after the first one. Here is an example: `[300,100,10]` means that a first hidden layer of size `300` is applied followed by a `resnet` block made of two `100` fully connected layer, and another block of two `10` fully connected layers. This is subjected to future changes and more control.\n\n### Authors\nDeepDetect is designed, implemented and supported by [Jolibrain](http://jolibrain.com/) with the help of other contributors.\n\n### Build\n\nBelow are instructions for Ubuntu 14.04 LTS and 16.04 LTS. For other Linux and Unix systems, steps may differ, CUDA, Caffe and other libraries may prove difficult to setup. If you are building on 16.04 LTS, look at https://github.com/jolibrain/deepdetect/issues/126 that tells you how to proceed.\n\nBeware of dependencies, typically on Debian/Ubuntu Linux, do:\n```\nsudo apt-get install build-essential libgoogle-glog-dev libgflags-dev libeigen3-dev libopencv-dev libcppnetlib-dev libboost-dev libboost-iostreams-dev libcurlpp-dev libcurl4-openssl-dev protobuf-compiler libopenblas-dev libhdf5-dev libprotobuf-dev libleveldb-dev libsnappy-dev liblmdb-dev libutfcpp-dev cmake libgoogle-perftools-dev unzip python-setuptools python-dev libspdlog-dev python-six python-enum34 libarchive-dev\n```\n\n#### Choosing interfaces : \n\nDeepDetect can be used:\n- directly from command line for caffe models. To build the executable use:\n```\ncmake .. -DUSE_COMMAND_LINE=ON\n```\n- from command line using the JSON API. To build the executable use:\n```\ncmake .. -DUSE_COMMAND_LINE=ON -DUSE_JSON_API=ON\n```\n- as a REST server (using JSON API). To build the server executable use (`USE_JSON_API` is auto-selected): \n```\ncmake .. -DUSE_HTTP_SERVER=ON\n```\n- linked into another executable. To build only the library (and use a `dd::DeepDetect<dd::JSonAPI>` object in your own code) use:\n```\ncmake .. -DUSE_JSON_API=ON -DUSE_HTTP_SERVER=OFF -DUSE_COMMAND_LINE=OFF\n\n```\n\n#### Default build with Caffe\nFor compiling along with Caffe:\n```\nmkdir build\ncd build\ncmake ..\nmake\n```\n\nIf you are building for one or more GPUs, you may need to add CUDA to your ld path:\n```\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64\n```\n\nIf you would like to build with cuDNN, your `cmake` line should be:\n```\ncmake .. -DUSE_CUDNN=ON\n```\n\nTo target the build of underlying Caffe to a specific CUDA architecture (e.g. Pascal), you can use:\n```\ncmake .. -DCUDA_ARCH="-gencode arch=compute_61,code=sm_61"\n```\n\nIf you would like to build on NVidia Jetson TX1:\n```\ncmake .. -DCUDA_ARCH="-gencode arch=compute_53,code=sm_53" -DUSE_CUDNN=ON -DJETSON=ON -DCUDA_USE_STATIC_CUDA_RUNTIME=OFF\n```\nOn Jetson TX2, use `-DCUDA_ARCH="-gencode arch=compute_62,code=sm_62"`\n\nIf you would like a CPU only build, use:\n```\ncmake .. -DUSE_CPU_ONLY=ON\n```\n\nIf you would like to constrain Caffe to CPU only, use:\n```\ncmake .. -DUSE_CAFFE_CPU_ONLY=ON\n```\n\n#### Build with XGBoost support\n\nIf you would like to build with XGBoost, include the `-DUSE_XGBOOST=ON` parameter to `cmake`:\n```\ncmake .. -DUSE_XGBOOST=ON\n```\n\nIf you would like to build the GPU support for XGBoost (experimental from DMLC), use the `-DUSE_XGBOOST_GPU=ON` parameter to `cmake`:\n```\ncmake .. -DUSE_XGBOOST=ON -DUSE_XGBOOST_GPU=ON\n```\n\n#### Build with Tensorflow support\nFirst you must install [Bazel](https://www.bazel.io/versions/master/docs/install.html#install-on-ubuntu) and Cmake with version > 3.\n\nAnd other dependencies:\n```\nsudo apt-get install python-numpy swig python-dev python-wheel unzip\n```\n\nIf you would like to build with Tensorflow, include the `-DUSE_TF=ON` paramter to `cmake`:\n```\ncmake .. -DUSE_TF=ON -DCUDA_USE_STATIC_CUDA_RUNTIME=OFF\n```\n\nIf you would like to constrain Tensorflow to CPU, use:\n```\ncmake .. -DUSE_TF=ON -DUSE_TF_CPU_ONLY=ON\n```\n\nYou can combine with XGBoost support with:\n```\ncmake .. -DUSE_TF=ON -DUSE_XGBOOST=ON\n```\n\n#### Build with T-SNE support\n\nSimply specify the option via cmake command line:\n```\ncmake .. -DUSE_TSNE=ON\n```\n\n#### Build with Dlib support\nSpecify the following option via cmake:\n```$xslt\ncmake .. -DUSE_DLIB=ON\n```\nThis will automatically build with GPU support if possible. Note: this will also enable cuDNN if available by default.\n\nIf you would like to constrain Dlib to CPU, use:\n```\ncmake .. -DUSE_DLIB=ON -DUSE_DLIB_CPU_ONLY=ON\n```\n\n#### Build with TensorRT support\nSpecify the following option via cmake:\n```$xslt\ncmake .. -DUSE_TENSORRT=ON\n```\nTensorRT requires GPU and CUDNN, they are automatically switched on. \n\n#### Build with Libtorch support\n\nSpecify the following option via cmake:\n```\ncmake .. -DUSE_TORCH=ON\n```\nIf you call cmake with the `-DUSE_CPU_ONLY` option, a cpu-only version of libtorch will be used.\n\n#### Build with Caffe2 support\n\nSpecify the option via cmake:\n```\ncmake .. -DUSE_CAFFE2=ON\n```\n\n#### Build without Caffe\n\nCaffe remains the default backend for DeepDetect though it can be deactivated with cmake. However, at least one library needs to be specified:\n```\ncmake .. -DUSE_CAFFE=OFF -DUSE_XGBOOST=ON\n```\n\n#### Build with similarity search support\n\nSpecify the following option via cmake:\n```\ncmake .. -DUSE_SIMSEARCH=ON\n```\n\n#### Build with logs output into syslog\n\nSpecify the following option via cmake:\n```\ncmake .. -DUSE_DD_SYSLOG=ON\n```\n\n### Run tests\n\nNote: running tests requires the automated download of ~75Mb of datasets, and computations may take around thirty minutes on a CPU-only machines.\n\nTo prepare for tests, compile with:\n```\ncmake -DBUILD_TESTS=ON ..\nmake\n```\nRun tests with:\n```\nctest\n```\n\n### Start the server\n\n```\ncd build/main\n./dede\n\nDeepDetect [ commit 73d4e638498d51254862572fe577a21ab8de2ef1 ]\nRunning DeepDetect HTTP server on localhost:8080\n```\n\nMain options are:\n- `-host` to select which host to run on, default is `localhost`, use `0.0.0.0` to listen on all interfaces\n- `-port` to select which port to listen to, default is `8080`\n- `-nthreads` to select the number of HTTP threads, default is `10`\n\nTo see all options, do:\n```\n./dede --help\n```\n\n### Services auto-start\n\nA list of services can be stored into a file and passed to the `dede` server so that they are all created upon server start. A list fo predictions can also be run automatically upon server start. The file is passed with:\n\n```\n./dede -service_start_list <yourfile>\n```\n\nFile format is as follows:\n\n- service creation:\n```\nservice_create;sname;JSON string\n```\nwhere `sname` is the service name and the JSON is a string without external quotes\n\n- service prediction\n```\nservice_predict;JSON string\n``` \n\n### Pure command line JSON API\n\nTo use deepdetect without the client/server architecture while passing the exact same JSON messages from the API:\n\n```\n./dede --jsonapi 1 <other options>\n```\n\nwhere `<other options>` stands for the command line parameters from the command line JSON API:\n\n```\n-info (/info JSON call) type: bool default: false\n-service_create (/service/service_name call JSON string) type: string default: ""\n-service_delete (/service/service_name DELETE call JSON string) type: string default: ""\n-service_name (service name string for JSON call /service/service_name) type: string default: ""\n-service_predict (/predict POST call JSON string) type: string default: ""\n-service_train (/train POST call JSON string) type: string default: ""\n-service_train_delete (/train DELETE call JSON string) type: string default: ""\n-service_train_status (/train GET call JSON string) type: string default: ""\n\t\t\t\t\t\t\t  \n```\n\nThe options above can be obtained from running\n\n```\n./dede --help\n```\n\nExample of creating a service then listing it:\n\n```\n./dede --jsonapi 1 --service_name test --service_create \'{"mllib":"caffe","description":"classification service","type":"supervised","parameters":{"input":{"connector":"image"},"mllib":{"template":"googlenet","nclasses":10}},"model":{"templates":"/path/to/deepdetect/templates/caffe/","repository":"/path/to/model/"}}\'\n```\n\nNote that in command line mode the `--service_xxx` calls are executed sequentially, and synchronously. Also note the logs are those from the server, the JSON API response is not available in pure command line mode.\n\n### Run examples\n\nSee tutorials from http://www.deepdetect.com/tutorials/tutorials/\n\n### References\n\n- DeepDetect (http://www.deepdetect.com/)\n- Caffe (https://github.com/BVLC/caffe)\n- XGBoost (https://github.com/dmlc/xgboost)\n- T-SNE (https://github.com/DmitryUlyanov/Multicore-TSNE)\n'