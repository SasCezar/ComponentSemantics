b'**Miller is like awk, sed, cut, join, and sort for name-indexed data such as CSV, TSV, and tabular JSON.**\n\n[![Linux build status](https://travis-ci.org/johnkerl/miller.svg?branch=master)](https://travis-ci.org/johnkerl/miller)\n[![Windows build status](https://ci.appveyor.com/api/projects/status/github/johnkerl/miller?branch=master&svg=true)](https://ci.appveyor.com/project/johnkerl/miller)\n[![License](http://img.shields.io/badge/license-BSD2-blue.svg)](https://github.com/johnkerl/miller/blob/master/LICENSE.txt)\n[![Docs](https://img.shields.io/badge/docs-here-yellow.svg)](http://johnkerl.org/miller/doc)\n\n[![Ubuntu](https://img.shields.io/badge/distros-ubuntu-db4923.svg)](https://launchpad.net/ubuntu/+source/miller)\n[![Ubuntu 16.04 LTS](https://img.shields.io/badge/distros-ubuntu1604lts-db4923.svg)](https://launchpad.net/ubuntu/xenial/+package/miller)\n[![Fedora](https://img.shields.io/badge/distros-fedora-173b70.svg)](https://apps.fedoraproject.org/packages/miller)\n[![Debian](https://img.shields.io/badge/distros-debian-c70036.svg)](https://packages.debian.org/stable/miller)\n[![Gentoo](https://img.shields.io/badge/distros-gentoo-4e4371.svg)](https://packages.gentoo.org/packages/sys-apps/miller)\n\n[![NetBSD](https://img.shields.io/badge/distros-netbsd-f26711.svg)](http://pkgsrc.se/textproc/miller)\n[![FreeBSD](https://img.shields.io/badge/distros-freebsd-8c0707.svg)](https://www.freshports.org/textproc/miller/)\n[![Pro-Linux](https://img.shields.io/badge/distros-prolinux-3a679d.svg)](http://www.pro-linux.de/cgi-bin/DBApp/check.cgi?ShowApp..20427.100)\n[![Arch Linux](https://img.shields.io/badge/distros-archlinux-1792d0.svg)](https://aur.archlinux.org/packages/miller-git)\n[![Homebrew/MacOSX](https://img.shields.io/badge/distros-macosxbrew-ba832b.svg)](https://github.com/Homebrew/homebrew-core/search?utf8=%E2%9C%93&q=miller)\n[![MacPorts/MacOSX](https://img.shields.io/badge/distros-macports-1376ec.svg)](https://www.macports.org/ports.php?by=name&substr=miller)\n\nWith Miller, you get to use named fields without needing to count positional\nindices, using familiar formats such as CSV, TSV, JSON, and positionally-indexed.\n\nFor example, suppose you have a CSV data file like this:\n\n```\ncounty,tiv_2011,tiv_2012,line,construction\nSEMINOLE,22890.55,20848.71,Residential,Wood\nMIAMI DADE,1158674.85,1076001.08,Residential,Masonry\nPALM BEACH,1174081.5,1856589.17,Residential,Masonry\nMIAMI DADE,2850980.31,2650932.72,Commercial,Reinforced Masonry\nHIGHLANDS,23006.41,19757.91,Residential,Wood\nHIGHLANDS,49155.16,47362.96,Residential,Wood\nDUVAL,1731888.18,2785551.63,Residential,Masonry\nST. JOHNS,29589.12,35207.53,Residential,Wood\n```\n\nThen, on the fly, you can add new fields which are functions of existing fields, drop fields, sort, aggregate statistically, pretty-print, and more:\n```\n$ mlr --icsv --opprint --barred \\\n  put \'$tiv_delta = $tiv_2012 - $tiv_2011; unset $tiv_2011, $tiv_2012\' \\\n  then sort -nr tiv_delta flins.csv \n+------------+-------------+----------------+\n| county     | line        | tiv_delta      |\n+------------+-------------+----------------+\n| Duval      | Residential | 1053663.450000 |\n| Palm Beach | Residential | 682507.670000  |\n| St. Johns  | Residential | 5618.410000    |\n| Highlands  | Residential | -1792.200000   |\n| Seminole   | Residential | -2041.840000   |\n| Highlands  | Residential | -3248.500000   |\n| Miami Dade | Residential | -82673.770000  |\n| Miami Dade | Commercial  | -200047.590000 |\n+------------+-------------+----------------+\n```\n\nThis is something the Unix toolkit always could have done, and arguably always\nshould have done.  It operates on **key-value-pair data** while the familiar\nUnix tools operate on integer-indexed fields: if the natural data structure for\nthe latter is the array, then Miller\'s natural data structure is the\ninsertion-ordered hash map.  This encompasses a **variety of data formats**,\nincluding but not limited to the familiar **CSV**, **TSV**, and **JSON**.\n(Miller can handle **positionally-indexed data** as a special case.)\n\nFor a few more examples please see [Miller in 10 minutes](http://johnkerl.org/miller/doc/10-min.html).\n\nFeatures:\n\n* Miller is **multi-purpose**: it\'s useful for **data cleaning**,\n**data reduction**, **statistical reporting**, **devops**, **system\nadministration**, **log-file processing**, **format conversion**, and\n**database-query post-processing**.\n\n* You can use Miller to snarf and munge **log-file data**, including selecting\nout relevant substreams, then produce CSV format and load that into\nall-in-memory/data-frame utilities for further statistical and/or graphical\nprocessing.\n\n* Miller complements **data-analysis tools** such as **R**, **pandas**, etc.:\nyou can use Miller to **clean** and **prepare** your data. While you can do\n**basic statistics** entirely in Miller, its streaming-data feature and\nsingle-pass algorithms enable you to **reduce very large data sets**.\n\n* Miller complements SQL **databases**: you can slice, dice, and reformat data\non the client side on its way into or out of a database. You can also reap some\nof the benefits of databases for quick, setup-free one-off tasks when you just\nneed to query some data in disk files in a hurry.\n\n* Miller also goes beyond the classic Unix tools by stepping fully into our\nmodern, **no-SQL** world: its essential record-heterogeneity property allows\nMiller to operate on data where records with different schema (field names) are\ninterleaved.\n\n* Miller is **streaming**: most operations need only a single record in\nmemory at a time, rather than ingesting all input before producing any output.\nFor those operations which require deeper retention (`sort`, `tac`, `stats1`),\nMiller retains only as much data as needed. This means that whenever\nfunctionally possible, you can operate on files which are larger than your\nsystem&rsquo;s available RAM, and you can use Miller in **tail -f** contexts.\n\n* Miller is **pipe-friendly** and interoperates with the Unix toolkit\n\n* Miller\'s I/O formats include **tabular pretty-printing**, **positionally\n  indexed** (Unix-toolkit style), CSV, JSON, and others\n\n* Miller does **conversion** between formats\n\n* Miller\'s **processing is format-aware**: e.g. CSV `sort` and `tac` keep header\nlines first\n\n* Miller has high-throughput **performance** on par with the Unix toolkit\n\n* Not unlike `jq` (http://stedolan.github.io/jq/) for JSON, Miller is written\nin portable, modern C, with **zero runtime dependencies**. You can download or\ncompile a single binary, `scp` it to a faraway machine, and expect it to work.\n\nDocumentation links:\n\n* [**Full documentation for latest release**](http://johnkerl.org/miller/doc)\n* [Head docs](http://johnkerl.org/miller-releases/miller-head/doc/index.html) match\n[head code](https://github.com/johnkerl/miller); [release-specific docs](http://johnkerl.org/miller/doc/release-docs.html)\nmatch [release-specific code](https://github.com/johnkerl/miller/tags).\n* [Miller\'s license is two-clause BSD](https://github.com/johnkerl/miller/blob/master/LICENSE.txt).\n* [Build information including dependencies](http://johnkerl.org/miller/doc/build.html)\n* [Notes about issue-labeling in the Github repo](https://github.com/johnkerl/miller/wiki/Issue-labeling)\n* [Active issues](https://github.com/johnkerl/miller/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc)\n\nMore examples:\n\n```\n% mlr --csv cut -f hostname,uptime mydata.csv\n% mlr --tsv --rs lf filter \'$status != "down" && $upsec >= 10000\' *.tsv\n% mlr --nidx put \'$sum = $7 < 0.0 ? 3.5 : $7 + 2.1*$8\' *.dat\n% grep -v \'^#\' /etc/group | mlr --ifs : --nidx --opprint label group,pass,gid,member then sort -f group\n% mlr join -j account_id -f accounts.dat then group-by account_name balances.dat\n% mlr --json put \'$attr = sub($attr, "([0-9]+)_([0-9]+)_.*", "\\1:\\2")\' data/*.json\n% mlr stats1 -a min,mean,max,p10,p50,p90 -f flag,u,v data/*\n% mlr stats2 -a linreg-pca -f u,v -g shape data/*\n% mlr put -q \'@sum[$a][$b] += $x; end {emit @sum, "a", "b"}\' data/*\n% mlr --from estimates.tbl put \'\n  for (k,v in $*) {\n    if (isnumeric(v) && k =~ "^[t-z].*$") {\n      $sum += v; $count += 1\n    }\n  }\n  $mean = $sum / $count # no assignment if count unset\n\'\n% mlr --from infile.dat put -f analyze.mlr\n% mlr --from infile.dat put \'tee > "./taps/data-".$a."-".$b, $*\'\n% mlr --from infile.dat put \'tee | "gzip > ./taps/data-".$a."-".$b.".gz", $*\'\n% mlr --from infile.dat put -q \'@v=$*; dump | "jq .[]"\'\n% mlr --from infile.dat put  \'(NR % 1000 == 0) { print > stderr, "Checkpoint ".NR}\'\n```\n\n<!-- In case freshports becomes stale: https://svnweb.freebsd.org/ports/head/textproc/miller/ -->\n'