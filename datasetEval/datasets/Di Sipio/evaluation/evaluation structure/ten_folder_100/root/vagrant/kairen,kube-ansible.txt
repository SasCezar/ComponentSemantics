b'[![Build Status](https://travis-ci.org/kairen/kube-ansible.svg?branch=master)](https://travis-ci.org/kairen/kube-ansible)\n# Kubernetes Ansible\nA collection of playbooks for deploying/managing/upgrading a Kubernetes cluster onto machines, they are fully automated command to bring up a Kubernetes cluster on bare-metal or VMs.\n\n[![asciicast](https://asciinema.org/a/fDjMx3fTZX9SZktqEdTtWwZwi.png)](https://asciinema.org/a/fDjMx3fTZX9SZktqEdTtWwZwi?speed=2)\n\nFeature list:\n- [x] Support Kubernetes v1.10.0+.\n- [x] Highly available Kubernetes cluster.\n- [x] Full of the binaries installation.\n- [x] Kubernetes addons:\n  - [x] Promethues Monitoring.\n  - [x] EFK Logging.\n  - [x] Metrics Server.\n  - [x] NGINX Ingress Controller.\n  - [x] Kubernetes Dashboard.\n- [x] Support container network:\n  - [x] Calico.\n  - [x] Flannel.\n- [x] Support container runtime:\n  - [x] Docker.\n  - [x] NVIDIA-Docker.(Require NVIDIA driver and CUDA 9.0+)\n  - [x] Containerd.\n  - [ ] CRI-O.\n\n## Quick Start\nIn this section you will deploy a cluster via vagrant.\n\nPrerequisites:\n* Ansible version: *v2.5 (or newer)*.\n* [Vagrant](https://www.vagrantup.com/downloads.html): >= 2.0.0.\n* [VirtualBox](https://www.virtualbox.org/wiki/Downloads): >= 5.0.0.\n* Mac OS X need to install `sshpass` tool.\n\n```sh\n$ brew install http://git.io/sshpass.rb\n```\n\nThe getting started guide will use Vagrant with VirtualBox to deploy a Kubernetes cluster onto virtual machines. You can deploy the cluster with a single command:\n```sh\n$ ./hack/setup-vms\nCluster Size: 1 master, 2 worker.\n  VM Size: 1 vCPU, 2048 MB\n  VM Info: ubuntu16, virtualbox\n  CNI binding iface: eth1\nStart to deploy?(y):\n```\n> * You also can use `sudo ./hack/setup-vms -p libvirt -i eth1` command to deploy the cluster onto KVM.\n\nIf you want to access API you need to create RBAC object define the permission of role. For example using `cluster-admin` role:\n```sh\n$ kubectl create clusterrolebinding open-api --clusterrole=cluster-admin --user=system:anonymous\n```\n\nLogin the addon\'s dashboard:\n- Dashboard: [https://API_SERVER:8443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/](https://API_SERVER:8443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/)\n- Logging: [https://API_SERVER:8443/api/v1/namespaces/kube-system/services/kibana-logging/proxy/](https://API_SERVER:8443/api/v1/namespaces/kube-system/services/kibana-logging/proxy/)\n\nAs of release 1.7 Dashboard no longer has full admin privileges granted by default, so you need to create a token to access the resources:\n```sh\n$ kubectl -n kube-system create sa dashboard\n$ kubectl create clusterrolebinding dashboard --clusterrole cluster-admin --serviceaccount=kube-system:dashboard\n$ kubectl -n kube-system get sa dashboard -o yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  creationTimestamp: 2017-11-27T17:06:41Z\n  name: dashboard\n  namespace: kube-system\n  resourceVersion: "69076"\n  selfLink: /api/v1/namespaces/kube-system/serviceaccounts/dashboard\n  uid: 56b880bf-d395-11e7-9528-448a5ba4bd34\nsecrets:\n- name: dashboard-token-vg52j\n\n$ kubectl -n kube-system describe secrets dashboard-token-vg52j\n...\ntoken:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtdG9rZW4tdmc1MmoiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNTZiODgwYmYtZDM5NS0xMWU3LTk1MjgtNDQ4YTViYTRiZDM0Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZCJ9.bVRECfNS4NDmWAFWxGbAi1n9SfQ-TMNafPtF70pbp9Kun9RbC3BNR5NjTEuKjwt8nqZ6k3r09UKJ4dpo2lHtr2RTNAfEsoEGtoMlW8X9lg70ccPB0M1KJiz3c7-gpDUaQRIMNwz42db7Q1dN7HLieD6I4lFsHgk9NPUIVKqJ0p6PNTp99pBwvpvnKX72NIiIvgRwC2cnFr3R6WdUEsuVfuWGdF-jXyc6lS7_kOiXp2yh6Ym_YYIr3SsjYK7XUIPHrBqWjF-KXO_AL3J8J_UebtWSGomYvuXXbbAUefbOK4qopqQ6FzRXQs00KrKa8sfqrKMm_x71Kyqq6RbFECsHPA\n```\n> Copy and paste the `token` to dashboard.\n\n## Manual deployment\nIn this section you will manually deploy a cluster on your machines.\n\nPrerequisites:\n* Ansible version: *v2.5 (or newer)*.\n* *Linux distributions*: Ubuntu 16+/Debian/CentOS 7.x.\n* All Master/Node should have password-less access from `deploy` node.\n\nFor machine example:\n\n| IP Address      |   Role           |   CPU    |   Memory   |\n|-----------------|------------------|----------|------------|\n| 172.16.35.9     | vip              |    -     |     -      |\n| 172.16.35.10    | k8s-m1           |    4     |     8G     |\n| 172.16.35.11    | k8s-n1           |    4     |     8G     |\n| 172.16.35.12    | k8s-n2           |    4     |     8G     |\n| 172.16.35.13    | k8s-n3           |    4     |     8G     |\n\nAdd the machine info gathered above into a file called `inventory/hosts.ini`. For inventory example:\n```\n[etcds]\nk8s-m1\nk8s-n[1:2]\n\n[masters]\nk8s-m1\nk8s-n1\n\n[nodes]\nk8s-n[1:3]\n\n[kube-cluster:children]\nmasters\nnodes\n```\n\nSet the variables in `group_vars/all.yml` to reflect you need options. For example:\n```yml\n# overide kubernetes version(default: 1.10.6)\nkube_version: 1.11.2\n\n# container runtime, supported: docker, nvidia-docker, containerd.\ncontainer_runtime: docker\n\n# container network, supported: calico, flannel.\ncni_enable: true\ncontainer_network: calico\ncni_iface: \'\'\n\n# highly available variables\nvip_interface: \'\'\nvip_address: 172.16.35.9\n\n# etcd variables\netcd_iface: \'\'\n\n# kubernetes extra addons variables\nenable_dashboard: true\nenable_logging: false\nenable_monitoring: false\nenable_ingress: false\nenable_metric_server: true\n\n# monitoring grafana user/password\nmonitoring_grafana_user: "admin"\nmonitoring_grafana_password: "p@ssw0rd"\n```\n\n### Deploy a Kubernetes cluster\nIf everything is ready, just run `cluster.yml` playbook to deploy the cluster:\n```sh\n$ ansible-playbook -i inventory/hosts.ini cluster.yml\n```\n\nAnd then run `addons.yml` to create addons:\n```sh\n$ ansible-playbook -i inventory/hosts.ini addons.yml\n```\n\n## Verify cluster\nVerify that you have deployed the cluster, check the cluster as following commands:\n```sh\n$ kubectl -n kube-system get po,svc\n\nNAME                                 READY     STATUS    RESTARTS   AGE       IP             NODE\npo/haproxy-master1                   1/1       Running   0          2h        172.16.35.10   k8s-m1\n...\n```\n\n### Reset cluster\nFinally, if you want to clean the cluster and redeploy, you can reset the cluster by `reset-cluster.yml` playbook.:\n```sh\n$ ansible-playbook -i inventory/hosts.ini reset-cluster.yml\n```\n\n## Contributing\nPull requests are always welcome!!! I am always thrilled to receive pull requests.\n'