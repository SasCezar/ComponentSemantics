b'# ops_contrib\n\nThis repo contains scripts to install & operate [VersionEye](https://www.versioneye.com) as on prem. installation. Everybody can contribute!\n\nThe software for [VersionEye](https://www.versioneye.com) is shipped in multiple [Docker](https://www.docker.com/) images. VersionEye is a distributed system which is a composition of at least 8 Docker images. The Docker images and their relations to each other are described in docker compose files.\nThis repository describes how to fetch, start, stop and monitor the VersionEye Docker images.\n\n## Table of Contents\n\n- [Starting Point](#starting-point)\n- [Vagrant](#vagrant)\n- [System requirements](#system-requirements)\n- [Network configuration](#network-configuration)\n- [Environment dependencies](#environment-dependencies)\n- [Start backend services for VersionEye](#start-backend-services-for-VersionEye)\n- [Start the VersionEye containers](#start-the-versioneye-containers)\n- [Stop the VersionEye containers](#stop-the-versioneye-containers)\n- [Clean up unused Docker images](#clean-up-unused-docker-images)\n- [Automated updates](automated-updates)\n- [Use Nginx as proxy](#use-nginx-as-proxy)\n- [SSL](#ssl)\n- [Configure cron jobs for crawling](#configure-cron-jobs-for-crawling)\n- [Importing site certificate into Java Runtime](#importing-site-certificate-into-java-runtime)\n- [Importing site certificate into Ruby Runtime](#importing-site-certificate-into-ruby-runtime)\n- [Timezone](#timezone)\n- [Logging](#logging)\n- [Monitoring](#monitoring)\n- [RabbitMQ Management Plugin](#rabbitmq-management-plugin)\n- [Backup your data](#backup-your-data)\n- [Restore your data](#restore-your-data)\n- [Support](#support)\n- [License](#license)\n\n## Starting point\n\nClone this repository and `cd` into it:\n\n`git clone https://github.com/versioneye/ops_contrib.git && cd ops_contrib`\n\nSome of the commands and files below are found on the root of this repository, thus cloning the repository is the easier way to get access to them. Alternatively you can download the files or use the [repository archive](https://github.com/versioneye/ops_contrib/archive/master.zip).\n\nThere are 2 ways of running the VersionEye software.\nThe simplest is to run the Vagrant box in the next section.\nThat is perfect for a quick start to try out the software.\nFor production environments we recommend to setup the Docker containers natively.\nIn that case you can skip the Vagrant section.\n\n## Vagrant\n\nThere is a Vagrantfile in this directory which describes a Vagrant box for VersionEye.\n[Vagrant](https://www.vagrantup.com) is a cool technology to describe and manage VMs.\nIf you don\'t have it yet, please download it from [here](https://www.vagrantup.com/downloads.html).\nBy default Vagrant is using VirtualBox as VM provider. You can download VirtualBox from [here](https://www.virtualbox.org/wiki/Downloads). This setup is tested with Vagrant version\n 1.8.5 and VirtualBox version 5.0.16 r105871.\n\nOpen a console and navigate to the root of this git repository and run simply this command:\n\n```\nvagrant up\n```\n\nThat will create a new virtual machine image in VirtualBox and install the VersionEye Docker images\non it. Dependening on your internet connection it can take a couple minutes. If everything is done\nyou can reach the VersionEye application under `http://127.0.0.1:7070`.\n\n**But keep it mind that this Vagrant setup is just for development and testing. It\'s not a production setup! If you shut down the Vagrant box, you might lose data!**\n\nIf you don\'t\nwant to use Vagrant and you are interested in running the Docker containers natively\non your machine then keep reading. The following sections describe how to start, stop\nand monitor the VersionEye Docker images natively.\n\n## System requirements\n\nWe recommend a minimum resource configuration of:\n\n - 2 vCPUS\n - 8GB of RAM\n - 25GB of storage\n\nThis setup will allow you to get VersionEye of the ground successfully. It\'s the equivalent to an [AWS `t2-large`](https://aws.amazon.com/ec2/instance-types/). Some customers are using VersionEye to monitor 1500 internal software projects. They are running the software with this hardware setup: \n\n - 4 vCPUS\n - 16 GB of RAM\n - 100 GB of storage\n\nFor more detailed requirements analysis please contact the VersionEye team at `support@versioneye.com`\n\n## Network configuration\n\nThe VersionEye host will need the following ports open:\n\n| Port  | Protocol  | Description  |\n|---|---|---|\n| 8080  | HTTP | Web application  |\n| 9090  | HTTP | API endpoint     |\n| 22  | SSH | Host management     |\n\nIf you [configure Nginx](#use-nginx-as-proxy) in front of the Web Application and API you can configure the following ports instead:\n\n| Port  | Protocol  | Description  |\n|---|---|---|\n| 80   | HTTP  | Web application & API Endpoint |\n| 433  | HTTPS | Web application & API Endpoint over SSL |\n| 22   | SSH   | Host management |\n\nYou might still want to leave `8080` and `9090` open if you still want direct access to the those services.\n\n## Environment dependencies\n\nThe scripts in this repository are all tested with Docker for Linux on Ubuntu 14.04. This installation guide requires that you have the following libraries installed:\n - jq\n - docker\n - docker-compose\n\n### Installing jq\n\nOn Ubuntu you can install it by running the following command on the terminal:\n```\napt-get install jq\n```\n\nAlternatively you can also check the official [jq docs](https://stedolan.github.io/jq/)\n\n### Installing docker and docker-compose\n\nFollow these guides to install docker and docker-compose:\n - [Installing docker engine in Ubuntu](https://docs.docker.com/engine/installation/linux/ubuntulinux/) ([or other distributions](https://docs.docker.com/engine/installation/))\n - [Installing docker-compose](https://docs.docker.com/compose/install/)\n\nMake sure you\'ve tested the docker dependencies before moving to the net next. On Ubuntu you can test them by running:\n\n```\nsudo docker run hello-world\n```\n\nand:\n\n```\ndocker-compose --version\n```\n\n## Start backend services for VersionEye\n\nVersionEye is currently using this backend systems:\n\n  - MongoDB\n  - RabbitMQ\n  - ElasticSearch\n  - Memcached\n\n\nThese are all available as Docker images from Docker Hub. This repository contains a file `versioneye-base.yml` for Docker Compose. You can start all backend systems like this:\n\nStart the docker containers:\n\n```\nsudo docker-compose -f versioneye-base.yml up -d\n```\n\nThat will start all 4 Docker containers in deamon mode. To stop backend services you can run:\n\n```sh\ndocker-compose -f versioneye-base.yml stop\n```\n\n**The MongoDB & ElasticSearch containers are not persistent by default!** If the Docker containers are\ngetting stopped/killed the data is lost. For persistence you need to comment in the\nmount volumes in the `versioneye-base.yml` file and adjust the paths to a directory on the host system.\nEspecially the MongoDB container should be adjusted to be persistent:\n\n```\nmongodb:\n  image: versioneye/mongodb:3.4\n  container_name: mongodb\n  restart: always\n  volumes:\n   - <PERSISTENT_PATH_ON_HOST_SYSTEM>:/data\n```\n\nFor example:\n\n```\nmongodb:\n  image: versioneye/mongodb:3.4\n  container_name: mongodb\n  restart: always\n  volumes:\n   - /mnt/mongodb:/data\n```\n\nThe ElasticSearch container should be adjusted in the same fashion. The other containers in `versioneye-base.yml` can be adjusted the same way, but are not critical.\n\n## Start the VersionEye containers\n\nThe next command will start the VersionEye containers. That includes the web application, the API and some background services:\n\n```\n./versioneye-update\n```\n\nThis script will:\n\n - Fetch the newest versions for the Docker images from the VersionEye API\n - Set some environment variables\n - Pull down the Docker images from Docher Hub\n - Start the Docker containers with docker-compose\n\nIf everything goes well you can access the VersionEye web application on `http://localhost:8080` and should see something like this: \n\n![VersionEye Enterprise Landing Page](images/VersionEye-Landing.png)\n\n## Stop the VersionEye containers\n\nWith this command the VersionEye containers can be stopped:\n\n```\n./versioneye-stop\n```\n\nThat will stop the VersionEye containers, but not the backend services.\n\n## Clean up unused Docker images\n\nThe script `./versioneye-update` will always download the newest Docker images from VersionEye. \nBut it doesn\'t remove old Docker images. This command is removing ALL Docker images which are currently not active running: \n\n```\ndocker rmi `docker images -aq`\n```\n\nIf VersionEye is the only application running on the Host, then this command can be added \nto the last line of the `./versioneye-update` script. \n\n## Automated updates\n\nWe are publishing new Docker images almost every day! \nIf you want to keep your instance always up-to-date then it\'s \nrecommended to run the `./versioneye-update` script once a day via a cron job. \nIf you are logged in as admin to the VersionEye server, run this coammand: \n\n```\ncrontab -e\n```\n\nThat will open the crontab file for root with the default editor. Then add this line \nto the end of the file and save the file: \n\n```\n1 0 * * * cd /opt/ops_contrib/ && ./versioneye-update >/dev/null 2>&1\n```\n\nThat will run the `./versioneye-update` script every day 1 minute after midnight. \nIf the absolute path to the `./versionye-update` script is not correct then you need to adjust it! \n\n## Use Nginx as proxy\n\nBy default the VersionEye Web App is running on port 8080 and the API on port 9090.\nIt makes sense to use a webserver in front of it on port 80, which does forward the\nrequests to port 8080 and 9090. Beside that the webserver can be used for SSL\ntermination. On Ubuntu the Nginx webserver can be installed like this:\n\n```\napt-get install nginx\n```\n\nAssuming this repository is checked out into `/opt/ops_contrib`,\nthe Nginx can be re configured as proxy for VersionEye by copying this 2 files to the right location:\n\n```\nsudo cp /opt/ops_contrib/nginx/ansible/roles/nginx/files/nginx.conf /etc/nginx/nginx.conf\nsudo cp /opt/ops_contrib/nginx/ansible/roles/nginx/files/default.conf /etc/nginx/conf.d/default.conf\n```\n\nAfter that the Nginx needs to be restarted:\n\n```\nsudo service nginx restart\n```\n\nNow the VersionEye web app should be available on port 80.\n\n## SSL \n\nBy default the web application is running on port 8080 and the API on port 9090. \nAny webserver can be used as proxy for those ports and any webserver in front of it can be used for SSL termination. \nBy default we are using Nginx for this job. \nHere is described how to setup [Nginx with SSL certificates from letsencrypt](letsencrypt.md). \n\nHere are some [Ansible playbooks](nginx/ansible)\nwhich is automate this steps and contain a role for setting up Nginx with an SSL certificate.\n\n## Configure cron jobs for crawling\n\nThe Docker image `versioneye/crawlj` contains the crawlers which enable you to crawl internal Maven repositories such as Sonatype Nexus, JFrog Artifactory or Apache Archiva. Inside of the Docker container the crawlers are triggered by a cron job. The crontab for that can be found [here](https://github.com/versioneye/crawl_j/blob/master/crontab_enterprise). If you want to trigger the crawlers on a different schedule you have to mount another crontab file into the Docker container to `/mnt/crawl_j/crontab_enterprise`.\n\n## Importing site certificate into Java Runtime\n\nThe crawlj container(s) are running on Java. When the Java process attempts to connect to a server that has an invalid or self signed certificate, such as an Maven repository server (Artifactory or Sonatype) in a development environment, there might be the following exception:\n\n```\njavax.net.ssl.SSLHandshakeException: \nsun.security.validator.ValidatorException: PKIX path building failed:\nsun.security.provider.certpath.SunCertPathBuilderException: \nunable to find valid certification path to requested target\n```\n\nTo make the Java runtime trust the certificate, it needs to be imported into the JRE certificate store. Here is a detailed tutorial for importing the site certificate into the crawlj container: [Import site certs](import_site_cert.md)\n\n## Importing site certificate into Ruby Runtime\n\nThe VersionEye Web App, API and background tasks are running on a Ruby runtime. If the Web App should access an LDAP server with a self signed certificate then that certificate has to be made available for the Ruby runtime. Ruby is using the native openssl C library for SSL connections. If a self signed certificate should be made available for the Ruby runtime then the certificate has to be placed as `*.crt` file in the `/usr/local/share/ca-certificates` directory inside of the Docker container.\n\nIt is recommended to hold the certificates in a directory on the Host system. For example in `/certs`. That directory can be mounted into the Docker container. Here is example for the `versioneye/rails_app` Docker container: \n\n```\nrails_app:\n  image: versioneye/rails_app:${VERSION_RAILS_APP}\n  container_name: rails_app\n  restart: always\n  environment:\n    TZ: Europe/London\n  ports:\n   - "8080:8080"\n  volumes:\n   - /certs:/usr/local/share/ca-certificates\n  external_links:\n   - rabbitmq:rm\n   - memcached:mc\n   - elasticsearch:es\n   - mongodb:db\n```\n\nIn the volumes seciton above the directory `/certs` is mounted to `/usr/local/share/ca-certificates` inside of the Docker container. This configuration can be applied to this Docker containers: \n\n - versioneye/rails_app\n - versioneye/rails_api\n - versioneye/tasks\n \nThis change in the configuration requires a restart of the Docker containers. \n\n## Timezone\n\nEach Docker container has his own time zone settings. By default Ubuntu machines are running with UTC time zone. In the docker-compose files we set the time zone explicitly to London timezone. That\'s this part: \n\n```\n  environment:\n    TZ: Europe/London\n```\n\nIf you want to use a different time zone you need to adjust the `TZ` variable for all Docker containers. \nAssuming you want to run the MongoDB container in Berlin time zone, then the configuration for that \ncontainer in the `versioneye-base.yml` would look like this: \n\n```\nmongodb:\n  image: versioneye/mongodb:3.4\n  container_name: mongodb\n  restart: always\n  environment:\n    TZ: Europe/Berlin\n```\n\nThe last 2 lines in the code example above set the time zone. After each change in `versioneye-base.yml` and `docker-compose.yml` the Docker containers need to be re started.\n\n**The changes above let the whole application run in a certain time zone. \nHowever, MongoDB is storing Dates always in UTC. Log in to VersionEye as admin and pick \nthe same time zone in the `Global Settings` as set in the docker compose files. With that\ntha application will convert UTC date/times from MongoDB to the selected target time zone.**\n\n## Logging\n\nThe VersionEye Docker containers are using rotating log files with 10 MB per file and max 10 files. \nThat way the hard disk will not run full with log files.\n**By default the log files are not persistent**.\nIf you want to have the log files persistent on the Host system you have to adjust the \nvolumes in the `docker-compose.yml` file. To make the logs from the web application persistent\nthe volumes section could be adjusted like this: \n\n```\nrails_app:\n  image: versioneye/rails_app:${VERSION_RAILS_APP}\n  container_name: rails_app\n  restart: always\n  ports:\n   - "8080:8080"\n  volumes:\n   - /mnt/logs:/app/log\n  external_links:\n   - rabbitmq:rm\n   - memcached:mc\n   - elasticsearch:es\n   - mongodb:db\n```\n\nMake sure that `/mnt/logs` is an existing directoroy on the Host system or adjust the path to \nan existing directory.\n\n**If you make this changes to the `docker-compose.yml` file you have to restart the Docker containers.**\n\n## Monitoring\n\nWith this command the running containers can be monitored.\n\n```\n./docker-mon\n```\n\nThat will display in real time how much CPU, RAM and IO each containers is using.\n\n## RabbitMQ Management Plugin\n\nBy default the RabbitMQ container is running without a UI. But if the management plugin\nis enabled a Web UI can be used to watch and control the queues. To do that you need\nto get a shell on the running rabbitmq container:\n\n```\ndocker exec -it rabbitmq bash\n```\n\nThen run this command to enable the management plugin:\n\n```\nrabbitmq-plugins enable rabbitmq_management\n```\n\nand leave the container with `exit`. Now leave the Host server and build up an SSH tunnel\nfrom your local machine to the Host and the running container:\n\n```\nssh -f <USER>@<HOST_IP> -L 15672:<IP_OF_DOCKER_CONTAINER>:15672 -N\n```\n\nFor example:\n\n```\nssh -f ubuntu@192.168.0.33 -L 15672:172.17.0.4:15672 -N\n```\n\nNow open a browser on your machine and navigate to `http://localhost:15672/`. Now you should be able to see the RabbitMQ UI.\n\n## Backup your data\n\nThe primary database for this application is MongoDB. If you run the MongoDB container\nwith a persistent volume your MongoDB config in the `versioneye-base` might look like this:\n\n```\nmongodb:\n  image: versioneye/mongodb:3.2.8\n  container_name: mongodb\n  restart: always\n  volumes:\n   - /mnt/mongodb:/data\n```\n\nIn the above configuration we use `/mnt/mongodb` on the host system to persist the data\nfor MongoDB. To create a dump get a shell on the running MongoDB container like this:\n\n```\ndocker exec -it mongodb bash\n```\n\nThen navigate to the `/data` directory and create a dump with this command:\n\n```\nmongodump --db veye_enterprise\n```\n\nThat will create a complete database dump which will be persisted in `/mnt/mongodb/dump` on the host.\nFrom there you can zip it and copy it to somewhere else.\n\n## Restore your data\n\nAssume you created a dump of one of your VersionEye instances and now you would like to restore the data\non another VersionEye instance. If your Docker container is persisting the data under `/mnt/mongodb` on the host\nthan simply compy your dump into that directory. Get a shell on the running MongoDB container:\n\n```\ndocker exec -it mongodb bash\n```\n\nNavigate to `/data` and run the restore process:\n\n```\nmongorestore --db veye_enterprise dump/veye_enterprise/\n```\n\nAssuming that your MongoDB is empty, this will restore all the data from the previous backup.\n\n## Support\n\nFor commercial support send a message to `support@versioneye.com`.\n\n## License\n\nops_contrib is licensed under the MIT license!\n\nCopyright (c) 2016 VersionEye GmbH\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the "Software"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n'