b'# Kubeadm Ansible Playbook\n\nBuild a Kubernetes cluster using Ansible with kubeadm. The goal is easily install a Kubernetes cluster on machines running:\n\n  - Ubuntu 16.04\n  - CentOS 7\n  - Debian 9\n\nSystem requirements:\n\n  - Deployment environment must have Ansible `2.4.0+`\n  - Master and nodes must have passwordless SSH access\n\n# Usage\n\nAdd the system information gathered above into a file called `hosts.ini`. For example:\n```\n[master]\n192.16.35.12\n\n[node]\n192.16.35.[10:11]\n\n[kube-cluster:children]\nmaster\nnode\n```\n\nIf you\'re working with ubuntu, add the following properties to each host `ansible_python_interpreter=\'python3\'`:\n```\n[master]\n192.16.35.12 ansible_python_interpreter=\'python3\'\n\n[node]\n192.16.35.[10:11] ansible_python_interpreter=\'python3\'\n\n[kube-cluster:children]\nmaster\nnode\n\n```\n\nBefore continuing, edit `group_vars/all.yml` to your specified configuration.\n\nFor example, I choose to run `flannel` instead of calico, and thus:\n\n```yaml\n# Network implementation(\'flannel\', \'calico\')\nnetwork: flannel\n```\n\n**Note:** Depending on your setup, you may need to modify `cni_opts` to an available network interface. By default, `kubeadm-ansible` uses `eth1`. Your default interface may be `eth0`.\n\nAfter going through the setup, run the `site.yaml` playbook:\n\n```sh\n$ ansible-playbook site.yaml\n...\n==> master1: TASK [addon : Create Kubernetes dashboard deployment] **************************\n==> master1: changed: [192.16.35.12 -> 192.16.35.12]\n==> master1:\n==> master1: PLAY RECAP *********************************************************************\n==> master1: 192.16.35.10               : ok=18   changed=14   unreachable=0    failed=0\n==> master1: 192.16.35.11               : ok=18   changed=14   unreachable=0    failed=0\n==> master1: 192.16.35.12               : ok=34   changed=29   unreachable=0    failed=0\n```\n\nThe playbook will download `/etc/kubernetes/admin.conf` file to `$HOME/admin.conf`.\n\nIf it doesn\'t work download the `admin.conf` from the master node:\n\n```sh\n$ scp k8s@k8s-master:/etc/kubernetes/admin.conf .\n```\n\nVerify cluster is fully running using kubectl:\n\n```sh\n\n$ export KUBECONFIG=~/admin.conf\n$ kubectl get node\nNAME      STATUS    AGE       VERSION\nmaster1   Ready     22m       v1.6.3\nnode1     Ready     20m       v1.6.3\nnode2     Ready     20m       v1.6.3\n\n$ kubectl get po -n kube-system\nNAME                                    READY     STATUS    RESTARTS   AGE\netcd-master1                            1/1       Running   0          23m\n...\n```\n\n# Resetting the environment\n\nFinally, reset all kubeadm installed state using `reset-site.yaml` playbook:\n\n```sh\n$ ansible-playbook reset-site.yaml\n```\n\n# Additional features\nThese are features that you could want to install to make your life easier.\n\nEnable/disable these features in `group_vars/all.yml` (all disabled by default):\n```\n# Additional feature to install\nadditional_features:\n  helm: false\n  metallb: false\n  healthcheck: false\n```\n\n## Helm\nThis will install helm in your cluster (https://helm.sh/) so you can deploy charts.\n\n## MetalLB\nThis will install MetalLB (https://metallb.universe.tf/), very useful if you deploy the cluster locally and you need a load balancer to access the services.\n\n## Healthcheck\nThis will install k8s-healthcheck (https://github.com/emrekenci/k8s-healthcheck), a small application to report cluster status.\n\n# Utils\nCollection of scripts/utilities\n\n## Vagrantfile\nThis Vagrantfile is taken from https://github.com/ecomm-integration-ballerina/kubernetes-cluster and slightly modified to copy ssh keys inside the cluster (install https://github.com/dotless-de/vagrant-vbguest is highly recommended)\n\n# Tips & Tricks\n## Specify user for Ansible\nIf you use vagrant or your remote user is root, add this to `hosts.ini`\n```\n[master]\n192.16.35.12 ansible_user=\'root\'\n\n[node]\n192.16.35.[10:11] ansible_user=\'root\'\n```\n\n## Access Kubernetes Dashboard\nAs of release 1.7 Dashboard no longer has full admin privileges granted by default, so you need to create a token to access the resources:\n```sh\n$ kubectl -n kube-system create sa dashboard\n$ kubectl create clusterrolebinding dashboard --clusterrole cluster-admin --serviceaccount=kube-system:dashboard\n$ kubectl -n kube-system get sa dashboard -o yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  creationTimestamp: 2017-11-27T17:06:41Z\n  name: dashboard\n  namespace: kube-system\n  resourceVersion: "69076"\n  selfLink: /api/v1/namespaces/kube-system/serviceaccounts/dashboard\n  uid: 56b880bf-d395-11e7-9528-448a5ba4bd34\nsecrets:\n- name: dashboard-token-vg52j\n\n$ kubectl -n kube-system describe secrets dashboard-token-vg52j\n...\ntoken:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtdG9rZW4tdmc1MmoiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNTZiODgwYmYtZDM5NS0xMWU3LTk1MjgtNDQ4YTViYTRiZDM0Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZCJ9.bVRECfNS4NDmWAFWxGbAi1n9SfQ-TMNafPtF70pbp9Kun9RbC3BNR5NjTEuKjwt8nqZ6k3r09UKJ4dpo2lHtr2RTNAfEsoEGtoMlW8X9lg70ccPB0M1KJiz3c7-gpDUaQRIMNwz42db7Q1dN7HLieD6I4lFsHgk9NPUIVKqJ0p6PNTp99pBwvpvnKX72NIiIvgRwC2cnFr3R6WdUEsuVfuWGdF-jXyc6lS7_kOiXp2yh6Ym_YYIr3SsjYK7XUIPHrBqWjF-KXO_AL3J8J_UebtWSGomYvuXXbbAUefbOK4qopqQ6FzRXQs00KrKa8sfqrKMm_x71Kyqq6RbFECsHPA\n\n$ kubectl proxy\n```\n> Copy and paste the `token` from above to dashboard.\n\nLogin the dashboard:\n- Dashboard: [https://API_SERVER:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/](https://API_SERVER:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/)\n- Logging: [https://API_SERVER:8001/api/v1/namespaces/kube-system/services/kibana-logging/proxy/](https://API_SERVER:8001/api/v1/namespaces/kube-system/services/kibana-logging/proxy/)\n\n'