b'<img src="https://storage.googleapis.com/lucid-static/common/stickers/channels-visualizations.jpg" width="782"></img>\n\n# Lucid\n\n<!--*DeepDream, but sane. Home of cats, dreams, and interpretable neural networks.*-->\n\n[![PyPI project status](https://img.shields.io/pypi/status/Lucid.svg)]()\n[![Travis build status](https://img.shields.io/travis/tensorflow/lucid.svg)](https://travis-ci.org/tensorflow/lucid)\n[![Code coverage](https://img.shields.io/coveralls/github/tensorflow/lucid.svg)](https://coveralls.io/github/tensorflow/lucid)\n[![Supported Python version](https://img.shields.io/pypi/pyversions/Lucid.svg)]()\n[![PyPI release version](https://img.shields.io/pypi/v/Lucid.svg)](https://pypi.org/project/Lucid/)\n\n\nLucid is a collection of infrastructure and tools for research in neural\nnetwork interpretability. **We\'re not currently supporting tensorflow 2!**\n\n* [\xf0\x9f\x93\x93\xe2\x80\x82**Notebooks**](#notebooks) -- Get started without any setup!\n* [\xf0\x9f\x93\x9a\xe2\x80\x82**Reading**](#recomended-reading) -- Learn more about visualizing neural nets.\n* [\xf0\x9f\x92\xac\xe2\x80\x82**Community**](#community) -- Want to get involved? Please reach out!\n* [\xf0\x9f\x94\xa7\xe2\x80\x82**Additional Information**](#additional-information) -- Licensing, code style, etc.\n* [\xf0\x9f\x94\xac\xe2\x80\x82**Start Doing Research!**](https://github.com/tensorflow/lucid/issues?utf8=%E2%9C%93&q=is%3Aissue+label%3Aresearch) -- Want to get involved? We\'re trying to research openly!\n* [\xf0\x9f\x93\xa6 **Visualize your own model**](https://github.com/tensorflow/lucid/wiki/Importing-Models-into-Lucid) -- How to import your own model for visualization\n\n<br>\n\n# Notebooks\n\nStart visualizing neural networks ***with no setup***. The following notebooks\nrun right from your browser, thanks to [Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb). It\'s a Jupyter notebook environment that requires no setup to use and runs entirely in the cloud.\n\nYou can run the notebooks on your local machine, too. Clone the repository and find them in the `notebooks` subfolder. You will need to run a local instance of the [Jupyter notebook environment](http://jupyter.org/install.html) to execute them.\n\n## Tutorial Notebooks\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/tutorial.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/common/stickers/colab-tutorial.png" width="500" alt=""></img>\n</a>\n\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/modelzoo.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/common/stickers/colab-modelzoo.png" width="500" alt=""></img>\n</a>\n\n<!--If you want to study techniques for visualizing and understanding neural networks, it\'s important to be able to try your experiments on multiple models. As of lucid v0.3, we provide a consistent API for interacting with 27 different vision models.-->\n\n## Feature Visualization Notebooks\n*Notebooks corresponding to the [Feature Visualization](https://distill.pub/2017/feature-visualization/) article*\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/feature-visualization/negative_neurons.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/feature-visualization/stickers/colab-neuron-negative.png" width="500" alt=""></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/feature-visualization/neuron_diversity.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/feature-visualization/stickers/colab-neuron-diversity.png" width="500" alt=""></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/feature-visualization/neuron_interaction.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/feature-visualization/stickers/colab-neuron-interaction.png" width="500" alt=""></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/feature-visualization/regularization.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/feature-visualization/stickers/colab-regularization.png" width="500" alt=""></img>\n</a>\n\n## Building Blocks Notebooks\n*Notebooks corresponding to the [Building Blocks of Interpretability](https://distill.pub/2018/building-blocks/) article*\n\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/building-blocks/SemanticDictionary.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/building-blocks/stickers/colab-semantic-dict.png" width="500" alt=""></img>\n</a>\n<br>\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/building-blocks/ActivationGrid.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/building-blocks/stickers/colab-grid.png" width="500" alt=""></img>\n</a>\n<br>\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/building-blocks/AttrSpatial.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/building-blocks/stickers/colab-spatial-attr.png" width="500" alt=""></img>\n</a>\n<br>\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/building-blocks/AttrChannel.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/building-blocks/stickers/colab-channel-attr.png" width="500" alt=""></img>\n</a>\n<br>\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/building-blocks/NeuronGroups.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/building-blocks/stickers/colab-neuron-groups.png" width="500" alt=""></img>\n</a>\n\n\n## Differentiable Image Parameterizations Notebooks\n*Notebooks corresponding to the [Differentiable Image Parameterizations](https://distill.pub/2018/differentiable-parameterizations/) article*\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/differentiable-parameterizations/aligned_interpolation.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/differentiable-parameterizations/stickers/colab-interpolate.png" width="500" alt=""></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/differentiable-parameterizations/style_transfer_2d.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/differentiable-parameterizations/stickers/colab-style-beyond-vgg.png" width="500" alt=""></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/differentiable-parameterizations/xy2rgb.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/differentiable-parameterizations/stickers/colab-xy2rgb.png" width="500" alt=""></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/differentiable-parameterizations/transparency.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/differentiable-parameterizations/stickers/colab-transparent.png" width="500" alt=""></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/differentiable-parameterizations/texture_synth_3d.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/differentiable-parameterizations/stickers/colab-3d-texture.png" width="500" alt=""></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/differentiable-parameterizations/style_transfer_3d.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/differentiable-parameterizations/stickers/colab-3d-style.png" width="500" alt=""></img>\n</a>\n\n<br>\n\n## Activation Atlas Notebooks\n*Notebooks corresponding to the [Activation Atlas](https://distill.pub/2019/activation-atlas/) article*\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/activation-atlas/activation-atlas-collect.ipynb">\n<img src="https://storage.googleapis.com/modelzoo/tmp/activation-atlas/stickers/lucid-notebook-1-collect.png" width="500" alt="Collecting activations"></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/activation-atlas/activation-atlas-simple.ipynb">\n<img src="https://storage.googleapis.com/modelzoo/tmp/activation-atlas/stickers/lucid-notebook-2-atlas.png" width="500" alt="Simple activation atlas"></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/activation-atlas/class-activation-atlas.ipynb">\n<img src="https://storage.googleapis.com/modelzoo/tmp/activation-atlas/stickers/lucid-notebook-3-class-atlas.png" width="500" alt="Class activation atlas"></img>\n</a>\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/activation-atlas/activation-atlas-adversarial.ipynb">\n<img src="https://storage.googleapis.com/modelzoo/tmp/activation-atlas/stickers/lucid-notebook-4-patches.png" width="500" alt="Activation atlas patches"></img>\n</a>\n\n## Miscellaneous Notebooks\n\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/misc/feature_inversion_caricatures.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/misc/stickers/colab-feature-inversion.ipynb.png" width="500" alt=""></img>\n</a>\n<br>\n<a href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/misc/neuron_interaction_grids.ipynb">\n<img src="https://storage.googleapis.com/lucid-static/misc/stickers/colab-interaction-grid.png" width="500" alt=""></img>\n</a>\n\n<br> \n\n# Recomended Reading\n\n* [Feature Visualization](https://distill.pub/2017/feature-visualization/)\n* [The Building Blocks of Interpretability](https://distill.pub/2018/building-blocks/)\n* [Using Arti\xef\xac\x81cial Intelligence to Augment Human Intelligence](https://distill.pub/2017/aia/)\n* [Visualizing Representations: Deep Learning and Human Beings](http://colah.github.io/posts/2015-01-Visualizing-Representations/)\n* [Differentiable Image Parameterizations](https://distill.pub/2018/differentiable-parameterizations/)\n* [Activation Atlas](https://distill.pub/2019/activation-atlas/)\n\n## Related Talks\n* [Lessons from a year of Distill ML Research](https://www.youtube.com/watch?v=jlZsgUZaIyY) (Shan Carter, OpenVisConf)\n* [Machine Learning for Visualization](https://www.youtube.com/watch?v=6n-kCYn0zxU) (Ian Johnson, OpenVisConf)\n\n# Community\n\nWe\'re in `#proj-lucid` on the Distill slack ([join link](http://slack.distill.pub)).\n\nWe\'d love to see more people doing research in this space!\n\n<br>\n\n# Additional Information\n\n## License and Disclaimer\n\nYou may use this software under the Apache 2.0 License. See [LICENSE](LICENSE).\n\nThis project is research code. It is not an official Google product.\n\n## Special consideration for TensorFlow dependency\n\nLucid requires `tensorflow`, but does not explicitly depend on it in `setup.py`. Due to the way [tensorflow is packaged](https://github.com/tensorflow/tensorflow/issues/7166) and some deficiencies in how pip handles dependencies, specifying either the GPU or the non-GPU version of tensorflow will conflict with the version of tensorflow your already may have installed.\n\nIf you don\'t want to add your own dependency on tensorflow, you can specify which tensorflow version you want lucid to install by selecting from `extras_require` like so: `lucid[tf]` or `lucid[tf_gpu]`.\n\n**In actual practice, we recommend you use your already installed version of tensorflow.**\n'