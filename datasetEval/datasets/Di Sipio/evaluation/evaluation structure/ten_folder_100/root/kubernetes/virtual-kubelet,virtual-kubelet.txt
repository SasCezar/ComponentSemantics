b'# Virtual Kubelet\n\nVirtual Kubelet is an open source [Kubernetes kubelet](https://kubernetes.io/docs/reference/generated/kubelet/)\nimplementation that masquerades as a kubelet for the purposes of connecting Kubernetes to other APIs.\nThis allows the nodes to be backed by other services like ACI, AWS Fargate, [IoT Edge](https://github.com/Azure/iot-edge-virtual-kubelet-provider) etc. The primary scenario for VK is enabling the extension of the Kubernetes API into serverless container platforms like ACI and Fargate, though we are open to others. However, it should be noted that VK is explicitly not intended to be an alternative to Kubernetes federation.\n\nVirtual Kubelet features a pluggable architecture and direct use of Kubernetes primitives, making it much easier to build on.\n\nWe invite the Kubernetes ecosystem to join us in empowering developers to build\nupon our base. Join our slack channel named, virtual-kubelet, within the [Kubernetes slack group](https://kubernetes.slack.com/).\n\nThe best description is "Kubernetes API on top, programmable back."\n\n#### Table of Contents\n\n* [How It Works](#how-it-works)\n* [Usage](#usage)\n* [Providers](#providers)\n    + [Alibaba Cloud ECI Provider](#alibaba-cloud-eci-provider)\n    + [Azure Container Instances Provider](#azure-container-instances-provider)\n\t+ [Azure Batch GPU Provider](https://github.com/virtual-kubelet/azure-batch/blob/master/README.md)\n    + [AWS Fargate Provider](#aws-fargate-provider)\n\t+ [HashiCorp Nomad](#hashicorp-nomad-provider)\n    + [OpenStack Zun](#openstack-zun-provider)\n    + [Adding a New Provider via the Provider Interface](#adding-a-new-provider-via-the-provider-interface)\n* [Testing](#testing)\n    + [Unit tests](#unit-tests)\n    + [End-to-end tests](#end-to-end-tests)\n* [Known quirks and workarounds](#known-quirks-and-workarounds)\n* [Contributing](#contributing)\n\n## How It Works\n\nThe diagram below illustrates how Virtual-Kubelet works.\n\n![diagram](website/static/img/diagram.svg)\n\n## Usage\n\nVirtual Kubelet is focused on providing a library that you can consume in your\nproject to build a custom Kubernetes node agent.\n\nSee godoc for up to date instructions on consuming this project:\nhttps://godoc.org/github.com/virtual-kubelet/virtual-kubelet\n\nThere are implementations available for several provides (listed above), see\nthose repos for details on how to deploy.\n\n## Current Features\n\n- create, delete and update pods\n- container logs, exec, and metrics\n- get pod, pods and pod status\n- capacity\n- node addresses, node capacity, node daemon endpoints\n- operating system\n- bring your own virtual network\n\n\n## Providers\n\nThis project features a pluggable provider interface developers can implement\nthat defines the actions of a typical kubelet.\n\nThis enables on-demand and nearly instantaneous container compute, orchestrated\nby Kubernetes, without having VM infrastructure to manage and while still\nleveraging the portable Kubernetes API.\n\nEach provider may have its own configuration file, and required environmental variables.\n\nProviders must provide the following functionality to be considered a supported integration with Virtual Kubelet.\n1. Provides the back-end plumbing necessary to support the lifecycle management of pods, containers and supporting resources in the context of Kubernetes.\n2. Conforms to the current API provided by Virtual Kubelet.\n3. Does not have access to the Kubernetes API Server and has a well-defined callback mechanism for getting data like secrets or configmaps.\n\n\n### Alibaba Cloud ECI Provider\n\nAlibaba Cloud ECI(Elastic Container Instance) is a service that allow you run containers without having to manage servers or clusters.\n\nYou can find more details in the [Alibaba Cloud ECI provider documentation](https://github.com/virtual-kubelet/alibabacloud-eci/blob/master/README.md).\n\n#### Configuration File\n\nThe alibaba ECI provider will read configuration file specified by the `--provider-config` flag.\n\nThe example configure file is in the [ECI provider repository](https://github.com/virtual-kubelet/alibabacloud-eci/blob/master/eci.toml).\n\n### Azure Container Instances Provider\n\nThe Azure Container Instances Provider allows you to utilize both\ntypical pods on VMs and Azure Container instances simultaneously in the\nsame Kubernetes cluster.\n\nYou can find detailed instructions on how to set it up and how to test it in the [Azure Container Instances Provider documentation](https://github.com/virtual-kubelet/azure-aci/blob/master/README.md).\n\n#### Configuration File\n\nThe Azure connector can use a configuration file specified by the `--provider-config` flag.\nThe config file is in TOML format, and an example lives in `providers/azure/example.toml`.\n\n### AWS Fargate Provider\n\n[AWS Fargate](https://aws.amazon.com/fargate/) is a technology that allows you to run containers\nwithout having to manage servers or clusters.\n\nThe AWS Fargate provider allows you to deploy pods to [AWS Fargate](https://aws.amazon.com/fargate/).\nYour pods on AWS Fargate have access to VPC networking with dedicated ENIs in your subnets, public\nIP addresses to connect to the internet, private IP addresses to connect to your Kubernetes cluster,\nsecurity groups, IAM roles, CloudWatch Logs and many other AWS services. Pods on Fargate can\nco-exist with pods on regular worker nodes in the same Kubernetes cluster.\n\nEasy instructions and a sample configuration file is available in the [AWS Fargate provider documentation](https://github.com/virtual-kubelet/aws-fargate). Please note that this provider is not currently supported. \n\n### HashiCorp Nomad Provider\n\nHashiCorp [Nomad](https://nomadproject.io) provider for Virtual Kubelet connects your Kubernetes cluster\nwith Nomad cluster by exposing the Nomad cluster as a node in Kubernetes. By\nusing the provider, pods that are scheduled on the virtual Nomad node\nregistered on Kubernetes will run as jobs on Nomad clients as they\nwould on a Kubernetes node.\n\nFor detailed instructions, follow the guide [here](https://github.com/virtual-kubelet/nomad/blob/master/README.md).\n\n### OpenStack Zun Provider\n\nOpenStack [Zun](https://docs.openstack.org/zun/latest/) provider for Virtual Kubelet connects\nyour Kubernetes cluster with OpenStack in order to run Kubernetes pods on OpenStack Cloud.\nYour pods on OpenStack have access to OpenStack tenant networks because they have Neutron ports\nin your subnets. Each pod will have private IP addresses to connect to other OpenStack resources\n(i.e. VMs) within your tenant, optionally have floating IP addresses to connect to the internet,\nand bind-mount Cinder volumes into a path inside a pod\'s container.\n\n```bash\n./bin/virtual-kubelet --provider="openstack"\n```\n\nFor detailed instructions, follow the guide [here](https://github.com/virtual-kubelet/openstack-zun/blob/master/README.md).\n\n### Adding a New Provider via the Provider Interface\n\nProviders consume this project as a library which implements the core logic of\na Kubernetes node agent (Kubelet), and wire up their implementation for\nperforming the neccessary actions.\n\nThere are 3 main interfaces:\n\n#### PodLifecylceHandler\n\nWhen pods are created, updated, or deleted from Kubernetes, these methods are\ncalled to handle those actions.\n\n[godoc#PodLifecylceHandler](https://godoc.org/github.com/virtual-kubelet/virtual-kubelet/node#PodLifecycleHandler)\n\n```go\ntype PodLifecycleHandler interface {\n    // CreatePod takes a Kubernetes Pod and deploys it within the provider.\n    CreatePod(ctx context.Context, pod *corev1.Pod) error\n\n    // UpdatePod takes a Kubernetes Pod and updates it within the provider.\n    UpdatePod(ctx context.Context, pod *corev1.Pod) error\n\n    // DeletePod takes a Kubernetes Pod and deletes it from the provider.\n    DeletePod(ctx context.Context, pod *corev1.Pod) error\n\n    // GetPod retrieves a pod by name from the provider (can be cached).\n    GetPod(ctx context.Context, namespace, name string) (*corev1.Pod, error)\n\n    // GetPodStatus retrieves the status of a pod by name from the provider.\n    GetPodStatus(ctx context.Context, namespace, name string) (*corev1.PodStatus, error)\n\n    // GetPods retrieves a list of all pods running on the provider (can be cached).\n    GetPods(context.Context) ([]*corev1.Pod, error)\n}\n```\n\nThere is also an optional interface `PodNotifier` which enables the provider to\nasynchronously notify the virtual-kubelet about pod status changes. If this\ninterface is not implemented, virtual-kubelet will periodically check the status\nof all pods.\n\nIt is highly recommended to implement `PodNotifier`, especially if you plan\nto run a large number of pods.\n\n[godoc#PodNotifier](https://godoc.org/github.com/virtual-kubelet/virtual-kubelet/node#PodNotifier)\n\n```go\ntype PodNotifier interface {\n    // NotifyPods instructs the notifier to call the passed in function when\n    // the pod status changes.\n    //\n    // NotifyPods should not block callers.\n    NotifyPods(context.Context, func(*corev1.Pod))\n}\n```\n\n`PodLifecycleHandler` is consumed by the `PodController` which is the core\nlogic for managing pods assigned to the node.\n\n```go\n\tpc, _ := node.NewPodController(podControllerConfig) // <-- instatiates the pod controller\n\tpc.Run(ctx) // <-- starts watching for pods to be scheduled on the node\n```\n\n#### NodeProvider\n\nNodeProvider is responsible for notifying the virtual-kubelet about node status\nupdates. Virtual-Kubelet will periodically check the status of the node and\nupdate Kubernetes accordingly.\n\n[godoc#NodeProvider](https://godoc.org/github.com/virtual-kubelet/virtual-kubelet/node#NodeProvider)\n\n```go\ntype NodeProvider interface {\n    // Ping checks if the node is still active.\n    // This is intended to be lightweight as it will be called periodically as a\n    // heartbeat to keep the node marked as ready in Kubernetes.\n    Ping(context.Context) error\n\n    // NotifyNodeStatus is used to asynchronously monitor the node.\n    // The passed in callback should be called any time there is a change to the\n    // node\'s status.\n    // This will generally trigger a call to the Kubernetes API server to update\n    // the status.\n    //\n    // NotifyNodeStatus should not block callers.\n    NotifyNodeStatus(ctx context.Context, cb func(*corev1.Node))\n}\n```\n\nVirtual Kubelet provides a `NaiveNodeProvider` that you can use if you do not\nplan to have custom node behavior.\n\n[godoc#NaiveNodeProvider](https://godoc.org/github.com/virtual-kubelet/virtual-kubelet/node#NaiveNodeProvider)\n\n`NodeProvider` gets consumed by the `NodeController`, which is core logic for\nmanaging the node object in Kubernetes.\n\n```go\n\tnc, _ := node.NewNodeController(nodeProvider, nodeSpec) // <-- instantiate a node controller from a node provider and a kubernetes node spec\n\tnc.Run(ctx) // <-- creates the node in kubernetes and starts up he controller\n```\n\n#### API endpoints\n\nOne of the roles of a Kubelet is to accept requests from the API server for\nthings like `kubectl logs` and  `kubectl exec`. Helpers for setting this up are\nprovided [here](https://godoc.org/github.com/virtual-kubelet/virtual-kubelet/node/api)\n\n## Testing\n\n### Unit tests\n\nRunning the unit tests locally is as simple as `make test`.\n\n### End-to-end tests\n\nCheck out [`test/e2e`](./test/e2e) for more details.\n\n## Known quirks and workarounds\n\n### Missing Load Balancer IP addresses for services\n\n#### Providers that do not support service discovery\n\nKubernetes 1.9 introduces a new flag, `ServiceNodeExclusion`, for the control plane\'s Controller Manager. Enabling this flag in the Controller Manager\'s manifest allows Kubernetes to exclude Virtual Kubelet nodes from being added to Load Balancer pools, allowing you to create public facing services with external IPs without issue.\n\n#### Workaround\n\nCluster requirements: Kubernetes 1.9 or above\n\nEnable the ServiceNodeExclusion flag, by modifying the Controller Manager manifest and adding `--feature-gates=ServiceNodeExclusion=true` to the command line arguments.\n\n## Contributing\n\nVirtual Kubelet follows the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md).\nSign the [CNCF CLA](https://github.com/kubernetes/community/blob/master/CLA.md) to be able to make Pull Requests to this repo.\n\nBi-weekly Virtual Kubelet Architecture meetings are held at 11am PST every other Wednesday in this [zoom meeting room](https://zoom.us/j/245165908).  Check out the calendar [here](https://calendar.google.com/calendar?cid=bjRtbGMxYWNtNXR0NXQ1a2hqZmRkNTRncGNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ).\n\nOur google drive with design specifications and meeting notes are [here](https://drive.google.com/drive/folders/19Ndu11WBCCBDowo9CrrGUHoIfd2L8Ueg?usp=sharing).\n\nWe also have a community slack channel named virtual-kubelet in the Kubernetes slack. \n\n\n'