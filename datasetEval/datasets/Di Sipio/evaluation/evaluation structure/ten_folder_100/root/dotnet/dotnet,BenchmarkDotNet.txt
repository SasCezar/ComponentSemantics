b'<h3 align="center">\n\n  ![](docs/logo/logo-wide.png)\n\n</h3>\n\n<h3 align="center">\n\n  [![NuGet](https://img.shields.io/nuget/v/BenchmarkDotNet.svg)](https://www.nuget.org/packages/BenchmarkDotNet/)\n  [![Downloads](https://img.shields.io/nuget/dt/benchmarkdotnet.svg)](https://www.nuget.org/packages/BenchmarkDotNet/)\n  ![Stars](https://img.shields.io/github/stars/dotnet/BenchmarkDotNet?color=brightgreen)\n  [![Gitter](https://img.shields.io/gitter/room/dotnet/BenchmarkDotNet?color=yellow)](https://gitter.im/dotnet/BenchmarkDotNet)\n  [![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE.md)\n\n</h3>\n\n<h3 align="center">\n  <a href="#Features">Features</a>\n  <span> \xc2\xb7 </span>\n  <a href="https://benchmarkdotnet.org/articles/guides/getting-started.html">Getting started</a>\n  <span> \xc2\xb7 </span>\n  <a href="https://benchmarkdotnet.org/articles/overview.html">Documentation</a>\n  <span> \xc2\xb7 </span>\n  <a href="#learn-more-about-benchmarking">Learn more about benchmarking</a>\n</h3>\n\n**BenchmarkDotNet** helps you to transform methods into benchmarks, track their performance, and share reproducible measurement experiments.\nIt\'s no harder than writing unit tests!\nUnder the hood, it performs a lot of [magic](#Automation) that guarantees [reliable and precise](#Reliability) results.\nBenchmarkDotNet protects you from popular benchmarking mistakes and warns you if something is wrong with your benchmark design or obtained measurements.\nThe results are presented in a [user-friendly](#Friendliness) form that highlights all the important facts about your experiment.\nThe library is adopted by [3000+ projects](#who-use-benchmarkdotnet) including .NET Core and supported by the [.NET Foundation](https://dotnetfoundation.org).\n\nIt\'s [easy](#Simplicity) to start writing benchmarks, check out an example\n  (copy-pastable version is [here](https://benchmarkdotnet.org/articles/guides/getting-started.html)):\n\n```cs\n[SimpleJob(RuntimeMoniker.Net472, baseline: true)]\n[SimpleJob(RuntimeMoniker.NetCoreApp30)]\n[SimpleJob(RuntimeMoniker.CoreRt30)]\n[SimpleJob(RuntimeMoniker.Mono)]\n[RPlotExporter]\npublic class Md5VsSha256\n{\n    private SHA256 sha256 = SHA256.Create();\n    private MD5 md5 = MD5.Create();\n    private byte[] data;\n\n    [Params(1000, 10000)]\n    public int N;\n\n    [GlobalSetup]\n    public void Setup()\n    {\n        data = new byte[N];\n        new Random(42).NextBytes(data);\n    }\n\n    [Benchmark]\n    public byte[] Sha256() => sha256.ComputeHash(data);\n\n    [Benchmark]\n    public byte[] Md5() => md5.ComputeHash(data);\n}\n```\n\nBenchmarkDotNet automatically\n  runs the benchmarks on all the runtimes,\n  aggregates the measurements,\n  and prints a summary table with the most important information:\n\n```md\nBenchmarkDotNet=v0.12.0, OS=Windows 10.0.17763.805 (1809/October2018Update/Redstone5)\nIntel Core i7-7700K CPU 4.20GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\n  [Host]       : .NET Framework 4.7.2 (4.7.3468.0), X64 RyuJIT\n  Net472       : .NET Framework 4.7.2 (4.7.3468.0), X64 RyuJIT\n  NetCoreApp30 : .NET Core 3.0.0 (CoreCLR 4.700.19.46205, CoreFX 4.700.19.46214), X64 RyuJIT\n  CoreRt30     : .NET CoreRT 1.0.28231.02 @Commit: 741d61493c560ba96e8151f9e56876d4d3828489, X64 AOT\n  Mono         : Mono 6.4.0 (Visual Studio), X64\n\n\n| Method |       Runtime |     N |       Mean |     Error |    StdDev | Ratio |\n|------- |-------------- |------ |-----------:|----------:|----------:|------:|\n| Sha256 |    .NET 4.7.2 |  1000 |   7.735 us | 0.1913 us | 0.4034 us |  1.00 |\n| Sha256 | .NET Core 3.0 |  1000 |   3.989 us | 0.0796 us | 0.0745 us |  0.50 |\n| Sha256 |    CoreRt 3.0 |  1000 |   4.091 us | 0.0811 us | 0.1562 us |  0.53 |\n| Sha256 |          Mono |  1000 |  13.117 us | 0.2485 us | 0.5019 us |  1.70 |\n|        |               |       |            |           |           |       |\n|    Md5 |    .NET 4.7.2 |  1000 |   2.872 us | 0.0552 us | 0.0737 us |  1.00 |\n|    Md5 | .NET Core 3.0 |  1000 |   1.848 us | 0.0348 us | 0.0326 us |  0.64 |\n|    Md5 |    CoreRt 3.0 |  1000 |   1.817 us | 0.0359 us | 0.0427 us |  0.63 |\n|    Md5 |          Mono |  1000 |   3.574 us | 0.0678 us | 0.0753 us |  1.24 |\n|        |               |       |            |           |           |       |\n| Sha256 |    .NET 4.7.2 | 10000 |  74.509 us | 1.5787 us | 4.6052 us |  1.00 |\n| Sha256 | .NET Core 3.0 | 10000 |  36.049 us | 0.7151 us | 1.0025 us |  0.49 |\n| Sha256 |    CoreRt 3.0 | 10000 |  36.253 us | 0.7076 us | 0.7571 us |  0.49 |\n| Sha256 |          Mono | 10000 | 116.350 us | 2.2555 us | 3.0110 us |  1.58 |\n|        |               |       |            |           |           |       |\n|    Md5 |    .NET 4.7.2 | 10000 |  17.308 us | 0.3361 us | 0.4250 us |  1.00 |\n|    Md5 | .NET Core 3.0 | 10000 |  15.726 us | 0.2064 us | 0.1930 us |  0.90 |\n|    Md5 |    CoreRt 3.0 | 10000 |  15.627 us | 0.2631 us | 0.2461 us |  0.89 |\n|    Md5 |          Mono | 10000 |  30.205 us | 0.5868 us | 0.6522 us |  1.74 |\n\n```\n\nThe measured data can be exported to different formats (md, html, csv, xml, json, etc.) including plots:\n\n![](https://i.imgur.com/qAHMQ30.png)\n\n*Supported runtimes:* .NET Framework 4.6.1+, .NET Core 2.0+, Mono, CoreRT  \n*Supported languages:* C#, F#, Visual Basic  \n*Supported OS:* Windows, Linux, macOS\n\n## Features\n\nBenchmarkDotNet has tons of features that are essential in comprehensive performance investigations.\nFour aspects define the design of these features:\n  *simplicity*, *automation*, *reliability*, and *friendliness*.\n\n### Simplicity\n\nYou shouldn\'t be an experience performance engineer if you want to write benchmarks.\nYou can design very complicated performance experiments in the declarative style using simple APIs.\n\nFor example, if you want to [parameterize](https://benchmarkdotnet.org/articles/features/parameterization.html) your benchmark,\n  mark a field or a property with `[Params(1, 2, 3)]`: BenchmarkDotNet will enumerate all of the specified values\n  and run benchmarks for each case.\nIf you want to compare benchmarks with each other,\n  mark one of the benchmark as the [baseline](https://benchmarkdotnet.org/articles/features/baselines.html)\n  via `[Benchmark(baseline: true)]`: BenchmarkDotNet will compare it with all of the other benchmarks.\nIf you want to compare performance in different environments, use [jobs](https://benchmarkdotnet.org/articles/configs/jobs.html).\nFor example, you can run all the benchmarks on .NET Core 3.0 and Mono via\n  `[SimpleJob(RuntimeMoniker.NetCoreApp30)]` and `[SimpleJob(RuntimeMoniker.Mono)]`.\n\nIf you don\'t like attributes, you can call most of the APIs via the fluent style and write code like this:\n\n```cs\nManualConfig.CreateEmpty() // A configuration for our benchmarks\n    .With(Job.Default // Adding first job\n            .With(ClrRuntime.Net472) // .NET Framework 4.7.2\n            .With(Platform.X64) // Run as x64 application\n            .With(Jit.LegacyJit) // Use LegacyJIT instead of the default RyuJIT\n            .WithGcServer(true) // Use Server GC\n    ).With(Job.Default // Adding second job\n            .AsBaseline() // It will be marked as baseline\n            .WithEnvironmentVariable("Key", "Value") // Setting an environment variable\n            .WithWarmupCount(0) // Disable warm-up stage\n    );\n```\n\nIf you prefer command-line experience, you can configure your benchmarks via\n  the [console arguments](https://benchmarkdotnet.org/articles/guides/console-args.html)\n  in any console application or use\n  [.NET Core command-line tool](https://benchmarkdotnet.org/articles/guides/global-dotnet-tool.html)\n  to run benchmarks from any dll:\n\n```sh\ndotnet benchmark MyAssembly.dll --runtimes net472 netcoreapp2.1 Mono\n```\n\n### Automation\n\nReliable benchmarks always include a lot of boilerplate code.\n\nLet\'s think about what should you do in a typical case.\nFirst, you should perform a pilot experiment and determine the best number of method invocations.\nNext, you should execute several warm-up iterations and ensure that your benchmark achieved a steady state.\nAfter that, you should execute the main iterations and calculate some basic statistics.\nIf you calculate some values in your benchmark, you should use it somehow to prevent the dead code elimination.\nIf you use loops, you should care about an effect of the loop unrolling on your results\n  (which may depend on the processor architecture).\nOnce you get results, you should check for some special properties of the obtained performance distribution\n  like multimodality or extremely high outliers.\nYou should also evaluate the overhead of your infrastructure and deduct it from your results.\nIf you want to test several environments, you should perform the measurements in each of them and manually aggregate the results.\n\nIf you write this code from scratch, it\'s easy to make a mistake and spoil your measurements.\nNote that it\'s a shortened version of the full checklist that you should follow during benchmarking:\n  there are a lot of additional hidden pitfalls that should be handled appropriately.\nFortunately, you shouldn\'t worry about it because\n  BenchmarkDotNet [will do](https://benchmarkdotnet.org/articles/guides/how-it-works.html) this boring and time-consuming stuff for you.\n\nMoreover, the library can help you with some advanced tasks that you may want to perform during the investigation.\nFor example,\n  BenchmarkDotNet can measure the [managed](https://benchmarkdotnet.org/articles/configs/diagnosers.html#usage) and\n  [native](https://benchmarkdotnet.org/articles/samples/IntroNativeMemory.html) memory traffic\n  and print [disassembly listings](https://benchmarkdotnet.org/articles/configs/diagnosers.html#sample-introdisassembly) for your benchmarks.\n\n### Reliability\n\nA lot of hand-written benchmarks produce wrong numbers that lead to incorrect business decisions.\nBenchmarkDotNet protects you from most of the benchmarking pitfalls and allows achieving high measurement precision.\n\nYou shouldn\'t worry about the perfect number of method invocation, the number of warm-up and actual iterations:\n  BenchmarkDotNet tries to choose the best benchmarking parameters and\n  achieve a good trade-off between the measurement prevision and the total duration of all benchmark runs.\nSo, you shouldn\'t use any magic numbers (like "We should perform 100 iterations here"),\n  the library will do it for you based on the values of statistical metrics.\n\nBenchmarkDotNet also prevents benchmarking of non-optimized assemblies that was built using DEBUG mode because\n  the corresponding results will be unreliable.\nIt will print a warning you if you have an attached debugger,\n  if you use hypervisor (HyperV, VMware, VirtualBox),\n  or if you have any other problems with the current environment.\n\nDuring 6+ years of development, we faced dozens of different problems that may spoil your measurements.\nInside BenchmarkDotNet, there are a lot of heuristics, checks, hacks, and tricks that help you to\n  increase the reliability of the results.\n\n### Friendliness\n\nAnalysis of performance data is a time-consuming activity that requires attentiveness, knowledge, and experience.\nBenchmarkDotNet performs the main part of this analysis for you and presents results in a user-friendly form.\n\nAfter the experiments, you get a summary table that contains a lot of useful data about the executed benchmarks.\nBy default, it includes only the most important columns,\n  but they can be [easily customized](https://benchmarkdotnet.org/articles/configs/columns.html).\nThe column set is adaptive and depends on the benchmark definition and measured values.\nFor example, if you mark one of the benchmarks as a [baseline](https://benchmarkdotnet.org/articles/features/baselines.html),\n  you will get additional columns that will help you to compare all the benchmarks with the baseline.\nBy default, it always shows the Mean column,\n  but if we detected a vast difference between the Mean and the Median values,\n  both columns will be presented.\n\nBenchmarkDotNet tries to find some unusual properties of your performance distributions and prints nice messages about it.\nFor example, it will warn you in case of multimodal distribution or high outliers.\nIn this case, you can scroll the results up and check out ASCII-style histograms for each distribution\n  or generate beautiful png plots using `[RPlotExporter]`.\n\nBenchmarkDotNet doesn\'t overload you with data; it shows only the essential information depending on your results:\n  it allows you to keep summary small for primitive cases and extend it only for the complicated cases.\nOf course, you can request any additional statistics and visualizations manually.\nIf you don\'t customize the summary view,\n  the default presentation will be as much user-friendly as possible. :)\n\n## Who use BenchmarkDotNet?\n\nEveryone!\nBenchmarkDotNet is already adopted by more than [3000+](https://github.com/dotnet/BenchmarkDotNet/network/dependents?package_id=UGFja2FnZS0xNTY3MzExMzE%3D) projects including\n  [dotnet/performance](https://github.com/dotnet/performance) (reference benchmarks for all .NET Runtimes),\n  [CoreCLR](https://github.com/dotnet/coreclr/issues?utf8=\xe2\x9c\x93&q=BenchmarkDotNet) (.NET Core Runtime),\n  [CoreFX](https://github.com/dotnet/corefx/issues?utf8=\xe2\x9c\x93&q=BenchmarkDotNet) (.NET Core Base Class Libraries),\n  [Roslyn](https://github.com/dotnet/roslyn/search?q=BenchmarkDotNet&type=Issues&utf8=\xe2\x9c\x93) (C# and Visual Basic compiler),\n  [ASP.NET Core](https://github.com/aspnet/AspNetCore/tree/master/src/Servers/IIS/IIS/benchmarks),\n  [ML.NET](https://github.com/dotnet/machinelearning/tree/master/test/Microsoft.ML.Benchmarks),\n  [EntityFrameworkCore](https://github.com/aspnet/EntityFrameworkCore/tree/master/benchmark),\n  [SignalR](https://github.com/aspnet/SignalR/tree/master/benchmarks/Microsoft.AspNetCore.SignalR.Microbenchmarks),\n  [F#](https://github.com/fsharp/fsharp/blob/master/tests/scripts/array-perf/array-perf.fs),\n  [Orleans](https://github.com/dotnet/orleans/tree/master/test/Benchmarks),\n  [Newtonsoft.Json](https://github.com/JamesNK/Newtonsoft.Json/tree/master/Src/Newtonsoft.Json.Tests/Benchmarks),\n  [Elasticsearch.Net](https://www.elastic.co/guide/en/elasticsearch/client/net-api/current/bool-queries.html#_perfomance_considerations),\n  [Dapper](https://github.com/StackExchange/Dapper/tree/master/Dapper.Tests.Performance),\n  [Expecto](https://github.com/haf/expecto/tree/master/Expecto.BenchmarkDotNet),\n  [Accord.NET](https://github.com/accord-net/framework/tree/development/Tools/Performance),\n  [ImageSharp](https://github.com/SixLabors/ImageSharp/tree/master/tests/ImageSharp.Benchmarks),\n  [RavenDB](https://github.com/ravendb/ravendb/tree/v4.0/bench),\n  [NodaTime](https://github.com/nodatime/nodatime/tree/master/src/NodaTime.Benchmarks),\n  [Jint](https://github.com/sebastienros/jint/tree/dev/Jint.Benchmark),\n  [NServiceBus](https://github.com/Particular/NServiceBus/issues?utf8=\xe2\x9c\x93&q=+BenchmarkDotNet+),\n  [Serilog](https://github.com/serilog/serilog/tree/dev/test/Serilog.PerformanceTests),\n  [Autofac](https://github.com/autofac/Autofac/tree/develop/bench/Autofac.Benchmarks),\n  [Npgsql](https://github.com/npgsql/npgsql/tree/dev/test/Npgsql.Benchmarks),\n  [Avalonia](https://github.com/AvaloniaUI/Avalonia/tree/master/tests/Avalonia.Benchmarks),\n  [ReactiveUI](https://github.com/reactiveui/ReactiveUI/tree/master/src/Benchmarks).  \nOn GitHub, you can find\n  2000+ [issues](https://github.com/search?o=desc&q=BenchmarkDotNet+-repo:dotnet%2FBenchmarkDotNet&s=created&type=Issues&utf8=\xe2\x9c\x93),\n  1500+ [commits](https://github.com/search?o=desc&q=BenchmarkDotNet+-repo:dotnet%2FBenchmarkDotNet&s=committer-date&type=Commits&utf8=\xe2\x9c\x93), and\n  350000+ [files](https://github.com/search?o=desc&q=BenchmarkDotNet+-repo:dotnet%2FBenchmarkDotNet&s=indexed&type=Code&utf8=\xe2\x9c\x93)\n  that involve BenchmarkDotNet.\n\n## Learn more about benchmarking\n\nBenchmarkDotNet is not a silver bullet that magically makes all of your benchmarks correct and analyzes the measurements for you.\nEven if you use this library, you still should know how to design the benchmark experiments and how to make correct conclusions based on the raw data.\nIf you want to know more about benchmarking methodology and good practices,\n  it\'s recommended to read a book by Andrey Akinshin (the BenchmarkDotNet project lead): ["Pro .NET Benchmarking"](https://aakinshin.net/prodotnetbenchmarking/).\nUse this in-depth guide to correctly design benchmarks, measure key performance metrics of .NET applications, and analyze results.\nThis book presents dozens of case studies to help you understand complicated benchmarking topics.\nYou will avoid common pitfalls, control the accuracy of your measurements, and improve the performance of your software.\n\n<div align="center">\n  <a href="https://aakinshin.net/prodotnetbenchmarking/">\n    <img src="https://aakinshin.net/img/misc/prodotnetbenchmarking-cover.png" width="400" />\n  </a>\n</div>\n\n## Build status\n\n| Build server | Platform | Build status |\n|--------------|----------|--------------|\n| Azure Pipelines | Windows | [![Azure Pipelines Windows](https://dev.azure.com/dotnet/BenchmarkDotNet/_apis/build/status/BenchmarkDotNet%20-%20Windows)](https://dev.azure.com/dotnet/BenchmarkDotNet/_build/latest?definitionId=55) |\n| Azure Pipelines | Ubuntu  | [![Azure Pipelines Ubuntu](https://dev.azure.com/dotnet/BenchmarkDotNet/_apis/build/status/BenchmarkDotNet%20-%20Ubuntu)](https://dev.azure.com/dotnet/BenchmarkDotNet/_build/latest?definitionId=56) |\n| Azure Pipelines | macOS | [![Azure Pipelines macOS](https://dev.azure.com/dotnet/BenchmarkDotNet/_apis/build/status/BenchmarkDotNet%20-%20macOS)](https://dev.azure.com/dotnet/BenchmarkDotNet/_build/latest?definitionId=57) |\n| AppVeyor | Windows | [![AppVeyor/Windows](https://img.shields.io/appveyor/ci/dotnetfoundation/benchmarkdotnet/master.svg)](https://ci.appveyor.com/project/dotnetfoundation/benchmarkdotnet/branch/master) |\n| Travis | Linux | [![Travis/Linux](https://travis-matrix-badges.herokuapp.com/repos/dotnet/BenchmarkDotNet/branches/master/1)](https://travis-ci.org/dotnet/BenchmarkDotNet) |\n| Travis | macOS | [![Travis/macOS](https://travis-matrix-badges.herokuapp.com/repos/dotnet/BenchmarkDotNet/branches/master/2)](https://travis-ci.org/dotnet/BenchmarkDotNet) |\n\n## Contributions are welcome!\n\nBenchmarkDotNet is already a stable full-featured library that allows performing performance investigation on a professional level.\nAnd it continues to evolve!\nWe add new features all the time, but we have too many new cool ideas.\nAny help will be appreciated.\nYou can develop new features, fix bugs, improve the documentation, or do some other cool stuff.\n\nIf you want to contribute, check out the\n  [Contributing guide](https://benchmarkdotnet.org/articles/contributing/building.html) and\n  [up-for-grabs](https://github.com/dotnet/BenchmarkDotNet/issues?q=is:open+is:issue+label:up-for-grabs) issues.\nIf you have new ideas or want to complain about bugs, feel free to [create a new issue](https://github.com/dotnet/BenchmarkDotNet/issues/new).\nLet\'s build the best tool for benchmarking together!\n\n## Code of Conduct\n\nThis project has adopted the code of conduct defined by the [Contributor Covenant](http://contributor-covenant.org/)\nto clarify expected behavior in our community.\nFor more information, see the [.NET Foundation Code of Conduct](https://dotnetfoundation.org/code-of-conduct).\n'