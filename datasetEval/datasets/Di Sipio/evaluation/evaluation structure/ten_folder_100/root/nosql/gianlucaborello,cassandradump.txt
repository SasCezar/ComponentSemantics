b'cassandradump\n=============\n\n.. image:: https://travis-ci.org/gianlucaborello/cassandradump.svg?branch=master\n    :target: https://travis-ci.org/gianlucaborello/cassandradump\n\nDescription\n-----------\n\nA data exporting tool for Cassandra inspired from mysqldump, with some\nadditional slice and dice capabilities.\n\nDisclaimer: most of the times, you really shouldn\'t be using this. It\'s\nfragile, non-scalable, inefficient and verbose. Cassandra already offers\nexcellent exporting/importing tools:\n\n-  Snapshots\n-  CQL\'s COPY FROM/TO\n-  sstable2json\n\nHowever, especially during development, I frequently need to:\n\n-  Quickly take a snapshot of an entire keyspace, and import it just as\n   quickly without copying too many files around or losing too much time\n-  Ability to take a very small subset of a massive production database\n   (according to some CQL-like filtering) and import it quickly on my\n   development environment\n\nIf these use cases sound familiar, this tool might be useful for you.\n\nIt\'s still missing many major Cassandra features that I don\'t use daily,\nso feel free to open an issue pointing them out (or send a pull request)\nif you need something.\n\nUsage\n-----\n\nThe help should already contain some useful information:\n\n::\n\n    usage: cassandradump.py [-h] [--cf CF] [--export-file EXPORT_FILE]\n                            [--filter FILTER] [--host HOST] [--port PORT]\n                            [--import-file IMPORT_FILE] [--keyspace KEYSPACE]\n                            [--exclude-cf EXCLUDE_CF] [--no-create] [--no-insert]\n                            [--password PASSWORD]\n                            [--protocol-version PROTOCOL_VERSION] [--quiet]\n                            [--sync] [--username USERNAME] [--ssl]\n                            [--certfile CERTFILE]\n\n    A data exporting tool for Cassandra inspired from mysqldump, with some added\n    slice and dice capabilities.\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      --cf CF               export a column family. The name must include the\n                            keyspace, e.g. "system.schema_columns". Can be\n                            specified multiple times\n      --export-file EXPORT_FILE\n                            export data to the specified file\n      --filter FILTER       export a slice of a column family according to a CQL\n                            filter. This takes essentially a typical SELECT query\n                            stripped of the initial "SELECT ... FROM" part (e.g.\n                            "system.schema_columns where keyspace_name\n                            =\'OpsCenter\'", and exports only that data. Can be\n                            specified multiple times\n      --host HOST           the address of a Cassandra node in the cluster\n                            (localhost if omitted)\n      --port PORT           the port of a Cassandra node in the cluster\n                            (9042 if omitted)\n      --import-file IMPORT_FILE\n                            import data from the specified file\n      --keyspace KEYSPACE   export a keyspace along with all its column families.\n                            Can be specified multiple times\n      --exclude-cf EXCLUDE_CF\n                            when using --keyspace, specify column family to\n                            exclude. Can be specified multiple times\n      --no-create           don\'t generate create (and drop) statements\n      --no-insert           don\'t generate insert statements\n      --password PASSWORD   set password for authentication (only if\n                            protocol-version is set)\n      --protocol-version PROTOCOL_VERSION\n                            set auth_provider version (required for\n                            authentication)\n      --quiet               quiet progress logging\n      --sync                import data in synchronous mode (default asynchronous)\n      --username USERNAME   set username for auth (only if protocol-version is\n                            set)\n      --ssl                 enable ssl connection to Cassandra cluster.  Must also\n                            set --certfile.\n      --certfile CERTFILE   ca cert file for SSL.  Assumes --ssl.\n\nIn its simplest invocation, it exports data and schemas for all\nkeyspaces:\n\n::\n\n    $ python cassandradump.py --export-file dump.cql\n    Exporting all keyspaces\n    Exporting schema for keyspace OpsCenter\n    Exporting schema for column family OpsCenter.events_timeline\n    Exporting data for column family OpsCenter.events_timeline\n    Exporting schema for column family OpsCenter.settings\n    Exporting data for column family OpsCenter.settings\n    Exporting schema for column family OpsCenter.rollups60\n    Exporting data for column family OpsCenter.rollups60\n    ...\n\n::\n\n    $ cat dump.cql\n    DROP KEYSPACE IF EXISTS "OpsCenter";\n    CREATE KEYSPACE "OpsCenter" WITH replication = {\'class\': \'SimpleStrategy\', \'replication_factor\': \'1\'}  AND durable_writes = true;\n    DROP TABLE IF EXISTS "OpsCenter"."events_timeline";\n    CREATE TABLE "OpsCenter".events_timeline (key text, column1 bigint, value blob, PRIMARY KEY (key, column1)) WITH COMPACT STORAGE AND CLUSTERING ORDER BY (column1 ASC) AND caching = \'{"keys":"ALL", "rows_per_partition":"NONE"}\' AND comment = \'{"info": "OpsCenter management data.", "version": [5, 1, 0]}\' AND compaction = {\'min_threshold\': \'4\', \'class\': \'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy\', \'max_threshold\': \'8\'} AND compression = {\'sstable_compression\': \'org.apache.cassandra.io.compress.LZ4Compressor\'} AND dclocal_read_repair_chance = 0.0 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.25 AND speculative_retry = \'NONE\';\n    INSERT INTO "OpsCenter"."events_timeline" (key, column1, value) VALUES (\'201501\', 1419841027332869, 0x)\n    INSERT INTO "OpsCenter"."events_timeline" (key, column1, value) VALUES (\'201501\', 1419841027352525, 0x)\n    INSERT INTO "OpsCenter"."events_timeline" (key, column1, value) VALUES (\'201501\', 1419928979070954, 0x)\n    ...\n\nThe created dump file can be directly used with ``cqlsh -f``, or there\'s\nalso a ``--import-file`` that uses asynchronous import so it goes\ndefinitely fast.\n\nUsing ``--keyspace``, it\'s possible to filter for a specific set of\nkeyspaces\n\n::\n\n    $ python cassandradump.py --keyspace system --export-file dump.cql\n    Exporting schema for keyspace system\n    Exporting schema for column family system.peers\n    Exporting data for column family system.peers\n    Exporting schema for column family system.range_xfers\n    Exporting data for column family system.range_xfers\n    Exporting schema for column family system.schema_columns\n    Exporting data for column family system.schema_columns\n    ...\n\n::\n\n    $ cat dump.cql\n    DROP KEYSPACE IF EXISTS "system";\n    CREATE KEYSPACE system WITH replication = {\'class\': \'LocalStrategy\'}  AND durable_writes = true;\n    DROP TABLE IF EXISTS "system"."peers";\n    CREATE TABLE system.peers (peer inet PRIMARY KEY, data_center text, host_id uuid, preferred_ip inet, rack text, release_version text, rpc_address inet, schema_version uuid, tokens set<text>) WITH bloom_filter_fp_chance = 0.01 AND caching = \'{"keys":"ALL", "rows_per_partition":"NONE"}\' AND comment = \'known peers in the cluster\' AND compaction = {\'min_threshold\': \'4\', \'class\': \'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy\', \'max_threshold\': \'32\'} AND compression = {\'sstable_compression\': \'org.apache.cassandra.io.compress.LZ4Compressor\'} AND dclocal_read_repair_chance = 0.0 AND default_time_to_live = 0 AND gc_grace_seconds = 0 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 3600000 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = \'99.0PERCENTILE\';\n    ...\n\nUsing ``--cf``, it\'s possible to filter for a specific set of column\nfamilies:\n\n::\n\n    $ python cassandradump.py --cf OpsCenter.rollups7200 --no-create --export-file dump.cql\n    Exporting data for column family OpsCenter.rollups7200\n\n::\n\n    $ cat dump.cql\n    INSERT INTO "OpsCenter"."rollups7200" (key, column1, value) VALUES (\'127.0.0.1-foo\', 718946047, 0x000000000000000000000000)\n    INSERT INTO "OpsCenter"."rollups7200" (key, column1, value) VALUES (\'127.0.0.1-foo\', 718953247, 0x000000000000000000000000)\n    INSERT INTO "OpsCenter"."rollups7200" (key, column1, value) VALUES (\'127.0.0.1-foo\', 718960447, 0x000000000000000000000000)\n    INSERT INTO "OpsCenter"."rollups7200" (key, column1, value) VALUES (\'127.0.0.1-foo\', 718967647, 0x000000000000000000000000)\n    INSERT INTO "OpsCenter"."rollups7200" (key, column1, value) VALUES (\'127.0.0.1-foo\', 719032447, 0x40073fc200000000437bc000)\n    ...\n\nUsing ``--no-insert`` and ``--no-create`` it\'s possible to tweak what\nCQL statements are actually included in the dump.\n\nMost of the times, the column families in a production scenario are\nhuge, and you might just want a little slice of it. With ``--filter``,\nit\'s possible to specify a set of CQL filters, and just the data that\nsatisfies those filters will be included in the dump:\n\n::\n\n    $ python cassandradump.py --filter "system.schema_columns WHERE keyspace_name=\'OpsCenter\'" --export-file dump.cql\n    Exporting data for filter "system.schema_columns where keyspace_name =\'OpsCenter\'"\n\n::\n\n    $ cat dump.cql\n    INSERT INTO "system"."schema_columns" (keyspace_name, columnfamily_name, column_name, component_index, index_name, index_options, index_type, type, validator) VALUES (\'OpsCenter\', \'backup_reports\', \'backup_id\', 1, NULL, \'null\', NULL, \'clustering_key\', \'org.apache.cassandra.db.marshal.UTF8Type\')\n    INSERT INTO "system"."schema_columns" (keyspace_name, columnfamily_name, column_name, component_index, index_name, index_options, index_type, type, validator) VALUES (\'OpsCenter\', \'backup_reports\', \'deleted_at\', 4, NULL, \'null\', NULL, \'regular\', \'org.apache.cassandra.db.marshal.TimestampType\')\n'