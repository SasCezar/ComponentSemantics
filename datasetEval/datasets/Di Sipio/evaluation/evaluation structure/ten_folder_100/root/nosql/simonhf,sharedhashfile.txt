b'# SharedHashFile: Share Hash Tables With Stable Key Hints Stored In Memory Mapped Files Between Arbitrary Processes\n\nSharedHashFile is a lightweight, embeddable NoSQL key value store / hash table with stable key hints, a zero-copy IPC queue, & a multiplexed IPC logging library written in C for Linux.  Data accessed directly in shared memory; no sockets are used between SharedHashFile and the application program; no server process. APIs for C & C++.\n\n[![Build Status](https://travis-ci.org/simonhf/sharedhashfile.svg?branch=master)](https://travis-ci.org/simonhf/sharedhashfile)\n[![Coverage Status](https://coveralls.io/repos/github/simonhf/sharedhashfile/badge.svg?branch=master)](https://coveralls.io/github/simonhf/sharedhashfile?branch=master)\n[![Coverity Scan Build Status](https://img.shields.io/coverity/scan/17867.svg)](https://scan.coverity.com/projects/simonhf-sharedhashfile)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/5e9eac5334064beb84a841d4987ab548)](https://www.codacy.com/app/simonhf/sharedhashfile?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=simonhf/sharedhashfile&amp;utm_campaign=Badge_Grade)\n[![GNU Affero General Public License version 3](https://img.shields.io/badge/license-AGPL3-green.svg)](https://opensource.org/licenses/AGPL-3.0)\n[![Gitter](https://badges.gitter.im/sharedhashfile/community.svg)](https://gitter.im/sharedhashfile/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\n![Nailed It](http://simonhf.github.io/sharedhashfile/images/10m-tps-nailed-it.jpeg)\n\n## Project Goals\n\n* Faster speed.\n* Simpler & smaller footprint.\n* Lower memory usage.\n* Concurrent, in memory access.\n\n## Technology\n\n### Data Storage\n\nData is kept in shared memory by default, making all the data accessible to any processes. Up to 4 billion keys can be stored in a single SharedHashFile hash table which is limited in size only by available RAM.\n\nFor example, let\'s say you have a box with 128GB RAM of which 96GB is used by SharedHashFile hash tables. The box has 24 cores and there are 24 processes (e.g. nginx forked slave processes or whatever) concurrently accessing the 96GB of hash tables. Each process shares exactly the same 96GB of shared memory.\n\n### Direct Memory Access\n\nBecause a key,value pair is held in shared memory across n processes, that shared memory can change and/or move at any time. Therefore, getting a value always results in receiving a thread local copy of the value.\n\n### Data Encoding\n\nKeys and values are currently binary strings, with a combined maximum length of 2^32 bytes.\n\n### Allocation & Garbage Collection\n\nConventional malloc() does not function in shared memory, since we have to use offsets instead of conventional pointers. Hence SharedHashFile uses its own implementation of malloc() for shared memory.\n\nTo avoid memory holes then garbage collection happens from time to time upon key,value insertion. The number of key,value pairs effected during garbage collection is intentionally limited by the algorithm to a maximum of 8,192 pairs no matter how many keys have been inserted in the hash table. This means the hash table always feels very responsive.\n\n### Hash Table Expansion\n\nSharedHashFile is designed to expand gracefully as more key,value pairs are inserted. There are no sudden memory increases or memory doubling events. And there are no big pauses due to rehashing keys en masse.\n\n### Locking\n\nTo reduce contention there is no single global hash table lock by design. Instead keys are sharded across 256 locks to reduce lock contention.\n\n### Optional Fixed Length Keys and Values\n\nFor use cases with high levels of writing then performance can suffer due to too many system mmap() calls due to recycling / shrinking memory mapped areas when removing memory holes due to deleted keys.\n\nTo improve performance for write heavy use cases, keys and values can be fixed in size across the entire hash table, which means deleted keys can be easily re-used without creating memory holes, and no expensive system mmap() calls are necessary.\n\nUsing fixed length keys and values also reduces the amount of RAM used because the key and value sizes are no longer stored, e.g. 100 million keys and values would save 100 million * 8 bytes = 800 million bytes.\n\n### Persistent Storage\n\nHash tables are stored in memory mapped files in `/dev/shm` which means the data persists even when no processes are using hash tables. However, the hash tables will not survive rebooting.\n\n### Unique Identifers AKA Stable Key Hints\n\nUnlike other hash tables, every key stored in SharedHashFile gets assigned its own UID, e.g. ```shf_make_hash("key", 3); uint32_t uid =  shf_put_key_val(shf, "val", 3)```. To get the same key in the future, choose between accessing the key via its key, or via its UID, e.g. ```shf_make_hash("key", 3); shf_get_key_val_copy(shf)``` or ```shf_get_uid_val_copy(shf, uid)```.\n\nWhat are UIDs useful for? UIDs don\'t take up any extra resources and can be thought of as resource \'free\'. Accessing a key by its UID is faster than accessing the key via its key. Because a UID is only 32bits in size then it can be easily stored as a reference to a key in your program, or embedded in the values of of key,value pairs, or even embedded within other keys.\n\nExample usage: If uid1 points to key ```"user-id-<xyz>"```, and uid2 points to key ```"facebook.com"```, then another \'mash up\' key might be ```"<uid1><uid2>"```. Want to find out if ```"user-id-<xyz>"``` has ```"facebook.com"``` in their personal URL whitelist? Just see if key ```"<uid1><uid2>"``` exists.\n\nWhat does the \'stable\' in \'stable key hint\' mean? It means that the UID stays the same even if the key and/or value bytes move around in memory.\n\n### Zero-Copy IPC Queues\n\nHow does it work? Create X fixed-sized queue elements, and Y queues to push & pull those queue elements to/from.\n\nExample: Imagine two processes ```Process A``` & ```Process B```. ```Process A``` creates 100,000 queue elements and 3 queues; ```queue-free```, ```queue-a2b```, and ```queue-b2a```. Intitally, all queue elements are pushed onto ```queue-free```. ```Process A``` then spawns ```Process B``` which attaches to the SharedHashFile in order to pull from ```queue-a2b```. To perform zero-copy IPC then ```Process A``` can pull queue elements from ```queue-free```, manipulate the fixed size, shared memory queue elements, and push the queue elements into ```queue-a2b```. ```Process B``` does the opposite; pulls queue elements from ```queue-a2b```, manipulates the fixed size, shared memory queue queue elements, and pushes the queue elements into ```queue-b2a```. ```Process A``` can also pull queue items from ```queue-b2a``` in order to digest the results from ```Process B```.\n\nSo how many queue elements per second can be moved back and forth by ```Processes A``` & ```Process B```? On a Lenovo W530 laptop then about 90 million per second if both ```Process A``` & ```Process B``` are written in C.\n\nNote: When a queue element is moved from one queue to another then it is not copied, only a reference is updated.\n\n### Multiplexed IPC Logging\n\nHow does it work? ```Process A``` calls shf_log_thread_new() which creates a shared memory log buffer and a log output thread which periodically monitors for new log lines. ```Process B``` calls shf_log_attach_existing() to start logging to the same shared log. Log using C macros SHF_PLAIN() and SHF_DEBUG(). If shf_log_thread_new() has not been called then output goes automatically to stdout, else the logging is multiplexed by the log output thread.\n\nExample output:\n\n```\nsharedhashfile$ cat debug/test.q.shf.t.tout\n1..10\n=0.000000 23056 pid 23056 started; mode is \'c2c\'\n=0.000013 23056 - SHF_SNPRINTF() // \'test-23056-ipc-queue\'\nok 1 -    c2*: shf_attach()          works for non-existing file as expected\n=0.000002 23060 shf.monitor: monitoring pid 23056 to delete /dev/shm/test-23056-ipc-queue.shf\n1..7\n=0.000001 23064 pid 23064 started; mode is \'4c\'\n=0.000010 23064 - SHF_SNPRINTF() // \'test-23064-ipc-queue\'\nok 1 -     4c: shf_attach_existing() works for existing file as expected\n#0.003948 1 --> auto mapped to thread id 23061\n#0.003948 1 shf_log_thread(shf=?){}\nok 2 -    c2*: put lock in value as expected\nok 3 -    c2*: shf_q_new() returned as expected\nok 4 -    c2*: moved   expected number of new queue items // estimate 51,044,225 q items per second without contention\n#0.131327 2 --> auto mapped to thread id 23064\n#0.131327 2 \'4c\' mode; behaving as client\nok 2 -     4c: shf_q_get_name(\'qid-free\') returned qid as expected\nok 3 -     4c: shf_q_get_name(\'qid-a2b\' ) returned qid as expected\nok 4 -     4c: shf_q_get_name(\'qid-b2a\' ) returned qid as expected\n#0.158467 2 shf_race_start() // 2 horses started after 0.000001 seconds\n#0.158474 2 testing process b IPC queue a2b --> b2a speed\n#0.158467 3 --> auto mapped to thread id 23056\n#0.158467 3 shf_race_start() // 2 horses started after 0.027820 seconds\n#0.158484 3 testing process a IPC queue b2a --> a2b speed\nok 5 -     4c: moved   expected number of new queue items // estimate 53,106,512 q items per second with contention\n#0.179207 2 testing process b IPC lock speed\nok 6 -     4c: got lock value address as expected\nok 5 -    c2*: moved   expected number of new queue items // estimate 52,951,698 q items per second with contention\n#0.180467 3 testing process a IPC lock speed\nok 6 -    c2*: got lock value address as expected\n#0.180475 3 shf_race_start() // 2 horses started after 0.000000 seconds\n#0.180475 2 shf_race_start() // 2 horses started after 0.001165 seconds\nok 7 -    c2*: rw lock expected number of times           // estimate 4,422,109 locks per second; with contention\nok 7 -     4c: rw lock expected number of times           // estimate 4,411,319 locks per second; with contention\n#0.633875 2 ending child\nok 8 -    c2*: rw lock expected number of times           // estimate 51,144,435 locks per second; without contention\nok 9 -    c2*: rw lock expected number of times           // estimate 381,821,029 locks per second; without lock, just loop\nok 10 -    c2*: test still alive\n#0.677166 3 ending parent\n#0.677177 3 shf_del(shf=?)\n#0.677180 3 - SHF_SNPRINTF() // \'du -h -d 0 /dev/shm/test-23056-ipc-queue.shf ; rm -rf /dev/shm/test-23056-ipc-queue.shf/\'\n#0.677181 3 shf_detach(shf=?)\n#0.677183 3 shf_log_thread_del(shf=?) // waiting for log thread to end\n=0.686385 3 shf_backticks(\'du -h -d 0 /dev/shm/test-23056-ipc-queue.shf ; rm -rf /dev/shm/test-23056-ipc-queue.shf/\')\n=0.724220 3 - read 39 bytes from the pipe\ntest: shf size before deletion: 394M /dev/shm/test-23056-ipc-queue.shf\n```\n\nNotes:\n\n* The above example shows the output from 4 different thread ids:\n  * 29912 is the thread id of the test program main thread; aka \'3\'.\n  * 29916 is the thread id of the shf.monitor program main thread; never participates in multiplexed logging.\n  * 29917 is the thread id of the test program log output thread; aka \'1\'.\n  * 29920 is the thread id of the test program main thread; recursively spawned from 29912; aka \'2\'.\n* Lines beginning with \'=\':\n  * Were output to stdout; i.e. lines logged before or after the log output thread exists.\n  * Show the time stamp relative to the start of the process logging.\n  * Show the 5 digit thread id.\n* Lines beginning with \'#\':\n  * Were output to stdout using the log output thread.\n  * Show the time stamp relative to the start of the log output thread.\n  * Show the thread id mapped to a unique short integer; 1 usually means the log output thread itself.\n* Other lines -- e.g. test \'ok\' lines -- will automatically become multiplexed log lines if the log output thread exists.\n\n## Building\n\nBuild the release code using ```make```, and the debug code using ```make debug```. Tests are run automatically.\n\n```\nroot@16vcpu:/# make clean ; make\nrm -rf release debug\nmake: variable: PROD_SRCS=murmurhash3.c shf.c tap.c\nmake: variable: PROD_OBJS=release/murmurhash3.o release/shf.o release/tap.o\nmake: variable: TEST_SRCS=test.1.tap.c test.9.shf.c\nmake: variable: TEST_OBJS=release/test.1.tap.o release/test.9.shf.o\nmake: variable: TEST_EXES=release/test.1.tap.t release/test.9.shf.t\nmake: compling: release/test.1.tap.o\nmake: compling: release/murmurhash3.o\nmake: compling: release/shf.o\nmake: compling: release/tap.o\nmake: linking: release/test.1.tap.t\nmake: running: release/test.1.tap.t\n1..1\nok 1 - All passed\nmake: compling: release/test.9.shf.o\nmake: linking: release/test.9.shf.t\nmake: running: release/test.9.shf.t\n1..10\nok 1 - shf_attach_existing() fails for non-existing file as expected\nok 2 - shf_attach()          works for non-existing file as expected\nok 3 - shf_get_copy_via_key() could not find unput key as expected\nok 4 - shf_get_copy_via_key() could     find   put key as expected\nok 5 - put expected number of              keys // 2293581 keys per second\nok 6 - got expected number of non-existing keys // 3812667 keys per second\nok 7 - got expected number of     existing keys // 3021523 keys per second\nok 8 - graceful growth cleans up after itself as expected\nok 9 - del expected number of     existing keys // 3109056 keys per second\nok 10 - del does not   clean  up after itself as expected\nrunning tests on: via command: \'cat /proc/cpuinfo | egrep \'model name\' | head -n 1\'\nrunning tests on: `model name   : Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz`\n-OP MMAP REMAP SHRK PART TOTAL ------PERCENT OPERATIONS PER PROCESS PER SECOND -OPS\n--- -k/s --k/s --/s --/s M-OPS 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 -M/s\nPUT  3.4  16.9 1298  626   0.0 10 10  8  5  3  2  8  9  9  6  2  8  4  7  8  4  0.0\nPUT 51.4 363.7 1410 1200   5.4  7  6  7  6  7  5  6  7  6  6  6  7  7  6  5  6  5.4 -------\nPUT 65.2 336.9 2036 2036  10.1  7  5  7  6  7  6  7  7  6  6  6  7  7  6  5  6  4.6 ------\nPUT 56.8 331.7 1888 1888  14.9  6  5  6  7  6  7  7  7  6  6  6  7  7  6  5  6  4.9 ------\nPUT 73.8 286.8 2200 2200  18.8  7  5  5  7  7  7  7  7  6  7  6  6  6  5  5  7  3.9 -----\nPUT 21.2 412.9  726  726  25.1  6  5  5  7  7  8  7  7  6  6  6  6  6  5  5  7  6.3 --------\nPUT 77.9 312.0 2554 2557  29.3  6  6  6  6  6  7  6  6  6  6  6  7  6  6  6  7  4.2 -----\nPUT 96.7 272.2 3044 3041  32.5  7  6  6  6  6  7  6  6  6  7  6  7  6  6  6  7  3.1 ----\nPUT 63.3 303.3 1804 1804  36.6  7  6  6  5  5  7  6  7  5  6  5  7  7  6  6  7  4.2 -----\nPUT 11.5 380.9  349  349  43.2  7  6  6  5  5  7  6  6  6  5  6  7  7  6  6  6  6.6 --------\nPUT 26.3 444.5  895  898  49.1  7  6  6  5  5  7  6  7  6  6  6  7  7  6  6  7  5.9 -------\nPUT 55.0 283.9 1862 1860  53.8  5  6  6  6  6  6  5  7  6  6  7  7  7  6  6  7  4.7 ------\nPUT 75.0 312.1 2480 2480  57.4  7  7  6  5  6  5  7  7  6  6  7  7  6  7  5  6  3.6 ----\nPUT 88.5 191.2 2859 2858  60.6  7  7  6  6  7  6  7  5  7  5  7  7  6  7  6  5  3.2 ----\nPUT 90.6 244.9 2853 2854  63.5  7  7  5  7  7  5  7  5  7  5  7  7  6  7  7  5  2.9 ---\nPUT 82.6 258.8 2455 2455  66.4  7  7  5  7  7  6  7  5  6  5  7  7  5  7  6  5  3.0 ---\nPUT 69.7 185.9 1970 1970  70.3  7  7  6  5  7  6  7  6  5  5  7  7  6  7  7  5  3.9 -----\nPUT 28.8 409.6  761  760  75.6  6  7  6  6  6  5  6  6  7  5  7  7  5  7  7  6  5.2 ------\nPUT  7.2 490.9  230  230  82.0  6  8  5  6  6  5  5  6  5  5  7  8  6  8  7  6  6.4 --------\nPUT 11.1 414.9  391  391  88.4  6  7  7  6  6  5  5  6  6  5  6  7  5  7  7  6  6.4 --------\nPUT 22.3 323.4  810  810  94.5  7  8  8  7  6  6  5  7  6  5  7  2  6  8  7  7  6.1 --------\nPUT 26.1 302.4 1124 1124  99.3  2  5  8  9  7  8 10  1  9  9  6  0  8  4  9  6  4.8 ------\nPUT  1.6   6.8  239  239 100.0  0  0  0  0  0  0  0  0 14 58  0  0  5  0 23  0  0.7\nMIX  0.0   0.0    0    0 100.0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.0\nMIX 21.8 103.9    0    0 105.3  5  6  6  7  7  7  7  5  8  6  6  3  7  6  7  7  5.3 -------\nMIX  0.5   8.2    0    0 114.0  6  6  5  6  7  5  6  7  7  6  7  6  7  7  6  6  8.7 -----------\nMIX  0.0   8.5    0    0 122.8  6  6  5  6  7  5  6  7  7  6  7  6  7  7  6  6  8.7 -----------\nMIX  0.0   9.6    0    0 131.7  6  6  6  6  7  6  6  7  6  6  7  6  7  7  6  6  8.9 -----------\nMIX  0.0  11.1    0    0 140.8  6  6  7  6  7  6  5  7  6  6  7  5  7  7  5  6  9.1 ------------\nMIX  0.0  12.0    0    0 149.6  6  6  7  7  6  6  6  6  7  6  6  6  6  6  6  7  8.8 -----------\nMIX  0.0  12.7    0    0 158.3  7  6  6  7  6  6  7  6  7  6  6  6  6  6  7  7  8.7 -----------\nMIX  0.0  14.0    0    0 167.1  7  6  6  7  6  6  7  6  7  6  6  6  6  6  7  7  8.8 -----------\nMIX  0.0  14.7    0    0 176.2  7  6  6  5  6  6  7  6  7  6  6  5  6  6  7  7  9.1 ------------\nMIX  0.0  16.3    0    0 185.1  6  7  7  7  7  7  6  6  6  5  6  7  6  5  6  6  8.9 -----------\nMIX  0.0  17.0    0    0 194.3  6  7  7  7  7  6  6  6  6  5  6  7  6  5  6  6  9.2 ------------\nMIX  0.0   7.1    0    0 200.0  9  9  7  2  3 10  9  5  0 11  4 14  3  7  6  1  5.7 -------\nGET  0.0   0.0    0    0 200.0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.0\nGET  0.0   2.1    0    0 200.3  3  6  7  6  7  6  6  6  7  7  7  3  7  7  7  7  0.3\nGET  0.0   2.4    0    0 208.5  6  6  6  6  7  6  6  6  7  6  7  6  6  7  6  7  8.2 ----------\nGET  0.0   0.0    0    0 217.4  6  7  7  6  7  5  6  6  7  6  7  6  6  7  6  6  8.9 -----------\nGET  0.0   0.0    0    0 226.3  6  7  8  6  7  5  6  6  7  5  7  5  6  7  6  5  9.0 -----------\nGET  0.0   0.0    0    0 235.3  6  7  7  6  8  5  6  6  8  5  7  5  5  7  6  6  9.0 -----------\nGET  0.0   0.0    0    0 244.2  6  7  6  8  7  5  6  6  7  6  7  6  6  5  6  6  8.9 -----------\nGET  0.0   0.0    0    0 253.5  5  8  5  8  6  6  7  8  7  5  8  5  5  5  7  5  9.3 ------------\nGET  0.0   0.0    0    0 263.1  4  8  5  9  5  5  8  9  5  5  8  5  5  5  8  5  9.6 ------------\nGET  0.0   0.0    0    0 272.9  4  8  5  7  5  7  8  9  5  5  8  5  5  5  8  5  9.8 -------------\nGET  0.0   0.0    0    0 282.3  5  7  5  6  8  7  7  8  5  5  7  5  5  6  7  5  9.4 ------------\nGET  0.0   0.0    0    0 291.0  6  2  6  6  9 10  8  4  6  6  2  6  6  6  8  6  8.7 -----------\nGET  0.0   0.0    0    0 298.7 12  0 10  3  0  9  0  0  4 12  0 12 13  9  0 15  7.7 ----------\nGET  0.0   0.0    0    0 300.0 32  0  0  0  0  0  0  0  0 23  0 27 18  0  0  0  1.3 -\n* MIX is 2% (2000000) del/put, 98% (12100654) get\nmake: built and tested release version\n```\n\nNotes:\n\n* The above figures were generated on a Rackspace cloud server with 16 vCPUs & 60GB RAM.\n* A line of stats is output every second during the test.\n* During the \'PUT\' phase, 16 concurrent processes put 100 million unique keys into the hash table.\n* Then during the \'MIX\' phase, 16 concurrent processes get 98% of 100 million unique keys while updating (del/put) the other 2%.\n* Then during the \'GET\' phase, 16 concurrent processes get 100 million unique keys from the hash table; in this case up to 9.8 million get operations per second across the 16 concurrent processes.\n* In total 300 million hash table operations are performed.\n* Why does put performance vary so much? This is due to kernel memory mapping overhead; \'top\' shows bigger system CPU usage.\n\n## Performance\n\nHere\'s an example on an 8 core Lenovo W530 laptop showing a hash table with 100 million keys, and then doing 2% delete/insert and 98% read at a rate of over 10 million operations per second:\n\n```\n$ make clean ; make release\n$ PATH=release:$PATH SHF_PERFORMANCE_TEST_ENABLE=1 test.f.shf.t\n...\nperf testing: SharedHashFile\nrunning tests on: via command: \'cat /proc/cpuinfo | egrep \'model name\' | head -n 1\'\nrunning tests on: `model name   : Intel(R) Core(TM) i7-3720QM CPU @ 2.60GHz`\n-OP MMAP REMAP SHRK PART TOTAL ------PERCENT OPERATIONS PER PROCESS PER SECOND -OPS\n--- -k/s --k/s --/s --/s M-OPS 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 -M/s\nPUT  0.2   0.0    0    0   0.0 32 30  0  0  0  0  0 38  0  0  0  0  0  0  0  0  0.0\nPUT 30.0  89.4 1767 1767   4.5 13 13 13 12 13 12 12 13  0  0  0  0  0  0  0  0  4.5 -----\nPUT 30.6  70.8 1925 1925   8.6 13 12 13 13 13 12 13 12  0  0  0  0  0  0  0  0  4.1 -----\nPUT 17.1 103.3 1090 1090  13.7 12 12 13 13 13 12 13 13  0  0  0  0  0  0  0  0  5.1 ------\nPUT 37.2  47.6 2334 2334  16.4 13 12 13 13 13 12 12 13  0  0  0  0  0  0  0  0  2.6 ---\nPUT 15.7  88.1  944  944  21.4 13 12 13 12 12 12 13 12  0  0  0  0  0  0  0  0  5.0 ------\nPUT 15.6 105.9 1035 1035  26.1 13 12 13 12 13 12 13 13  0  0  0  0  0  0  0  0  4.7 ------\nPUT 34.3  63.6 2180 2181  29.3 13 12 13 12 12 13 12 13  0  0  0  0  0  0  0  0  3.1 ----\nPUT 39.7  48.8 2478 2478  31.9 13 12 13 12 13 13 13 12  0  0  0  0  0  0  0  0  2.7 ---\nPUT 32.1  47.3 1950 1949  35.0 12 12 12 12 13 13 12 12  0  0  0  0  0  0  0  0  3.0 ----\nPUT  9.2 108.6  542  542  40.6 13 13 13 12 13 12 13 13  0  0  0  0  0  0  0  0  5.7 -------\nPUT  8.4 132.2  552  552  46.4 13 12 13 12 12 12 13 12  0  0  0  0  0  0  0  0  5.8 -------\nPUT 18.1  44.8 1184 1184  51.0 12 12 13 12 12 13 12 13  0  0  0  0  0  0  0  0  4.6 ------\nPUT 25.3  98.8 1622 1622  54.4 13 12 13 12 13 12 13 13  0  0  0  0  0  0  0  0  3.4 ----\nPUT 27.0  52.5 1730 1730  56.9 12 13 12 13 13 12 12 13  0  0  0  0  0  0  0  0  2.5 ---\nPUT 35.4  67.9 2260 2260  59.4 13 13 13 13 13 13 12 12  0  0  0  0  0  0  0  0  2.5 ---\nPUT 38.1  52.3 2382 2383  61.9 13 12 12 13 13 13 13 12  0  0  0  0  0  0  0  0  2.5 ---\nPUT 37.2  18.8 2306 2306  64.4 13 13 12 13 13 13 12 12  0  0  0  0  0  0  0  0  2.5 ---\nPUT 33.7  25.1 2059 2059  67.1 13 12 12 13 12 13 13 12  0  0  0  0  0  0  0  0  2.8 ---\nPUT 23.8  75.4 1427 1426  70.1 13 12 12 13 13 13 13 12  0  0  0  0  0  0  0  0  3.0 ---\nPUT 12.2 191.3  705  706  73.9 12 13 13 13 13 13 12 12  0  0  0  0  0  0  0  0  3.8 -----\nPUT  4.5  15.7  270  269  80.8 12 12 13 13 13 13 12 12  0  0  0  0  0  0  0  0  6.9 ---------\nPUT  5.2 129.8  347  347  87.0 13 12 13 12 13 13 12 12  0  0  0  0  0  0  0  0  6.2 --------\nPUT  8.4 133.8  557  557  92.4 13 13 12 13 12 13 12 13  0  0  0  0  0  0  0  0  5.4 -------\nPUT 14.3   6.2  933  933  97.3 13 12 12 13 12 13 13 12  0  0  0  0  0  0  0  0  4.9 ------\nPUT 11.5  16.5  777  777 100.0 11 15 10 13 11 12 13 15  0  0  0  0  0  0  0  0  2.7 ---\nMIX  0.0   0.0    0    0 100.0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.0\nMIX  2.3   5.6    0    0 101.2 12 14 11 12 12 12 13 13  0  0  0  0  0  0  0  0  1.2 -\nMIX  0.3   3.9    0    0 110.4 12 13 13 13 12 13 12 13  0  0  0  0  0  0  0  0  9.2 ------------\nMIX  0.0   4.1    0    0 119.7 13 13 13 12 12 13 13 13  0  0  0  0  0  0  0  0  9.3 ------------\nMIX  0.0   5.3    0    0 129.4 13 13 12 13 12 13 12 13  0  0  0  0  0  0  0  0  9.8 -------------\nMIX  0.0   5.6    0    0 139.0 13 13 12 12 12 13 13 12  0  0  0  0  0  0  0  0  9.6 ------------\nMIX  0.0   6.3    0    0 148.5 13 13 13 12 12 12 13 12  0  0  0  0  0  0  0  0  9.5 ------------\nMIX  0.0   7.0    0    0 158.4 13 13 13 12 12 13 12 13  0  0  0  0  0  0  0  0  9.9 -------------\nMIX  0.0   7.0    0    0 167.7 12 13 13 12 12 13 12 13  0  0  0  0  0  0  0  0  9.3 ------------\nMIX  0.0   7.9    0    0 176.7 13 13 13 13 12 13 12 13  0  0  0  0  0  0  0  0  9.1 ------------\nMIX  0.0   8.7    0    0 186.5 13 12 13 13 12 13 12 13  0  0  0  0  0  0  0  0  9.8 -------------\nMIX  0.0   8.7    0    0 196.0 13 13 13 12 12 12 12 13  0  0  0  0  0  0  0  0  9.5 ------------\nMIX  0.0   3.5    0    0 200.0 10  8 12 15 17 11 15 11  0  0  0  0  0  0  0  0  4.0 -----\nGET  0.0   0.0    0    0 200.0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.0\nGET  0.0   0.6    0    0 206.5 13 13 13 12 10 13 13 13  0  0  0  0  0  0  0  0  6.5 --------\nGET  0.0   0.0    0    0 217.9 13 12 13 13 12 12 12 13  0  0  0  0  0  0  0  0 11.4 ---------------\nGET  0.0   0.0    0    0 229.3 13 12 13 13 13 11 12 13  0  0  0  0  0  0  0  0 11.4 ---------------\nGET  0.0   0.0    0    0 240.6 13 13 13 13 13 12 12 13  0  0  0  0  0  0  0  0 11.3 ---------------\nGET  0.0   0.0    0    0 251.9 13 13 13 12 13 13 10 13  0  0  0  0  0  0  0  0 11.3 ---------------\nGET  0.0   0.0    0    0 263.2 12 12 13 12 13 13 12 13  0  0  0  0  0  0  0  0 11.3 ---------------\nGET  0.0   0.0    0    0 274.4 13 13 13 13 12 13 13 11  0  0  0  0  0  0  0  0 11.2 --------------\nGET  0.0   0.0    0    0 285.9 12 13 13 13 12 12 13 13  0  0  0  0  0  0  0  0 11.5 ---------------\nGET  0.0   0.0    0    0 297.3 12 13 13 13 12 12 13 12  0  0  0  0  0  0  0  0 11.4 ---------------\nGET  0.0   0.0    0    0 300.0  6  9  0 11 22 21 24  6  0  0  0  0  0  0  0  0  2.7 ---\n* MIX is 2% (2000000) del/put, 98% (12100654) get\nDB size: 3.9G   /dev/shm/test-shf-19973.shf\n```\n\n## Performance comparison with LMDB aka Lightning MDB\n\nHere\'s the same test as above but using LMDB instead of SharedHashFile:\n\nNotes:\n\n* Figure out why performance has halved even though the code hasn\'t changed :-(\n* To make the test a more apples to apples hash table comparison:\n* mdb_get() & mdb_put() are used (instead of faster cursor functions) to test LMDB as a hash table.\n* The LMDB DB file is stored in /dev/shm so that disk performance does not effect the results.\n* PUT & MIX disclaimer: LMDB is designed to be fast at reading, not writing.\n* PUT is done using LMDBs transactions (read: global lock?)\n* Pro: Without transactions then PUT only manages about 0.1M per second but all threads get to join in.\n* Con: With transactions then typically only one thread gets to PUT.\n* Con: Transaction locking does not appear to be fair and so although all processes are trying to write a transaction, one thread tends to always win.\n* Con: The PUT write starts off at a healthy 1.1M per second but slowly goes down to 0.2M per second.\n* MIX used only 50% CPU. Presumably due to a heavy weight global lock?\n* GET works very fast at 5.xM per second, but about half the speed of SharedHashFile.\n* LMDB only used 2.6G versus 3.9G for SharedHashFile.\n\n```\n$ perl perf-test-lmdb.pl\n...\nperf testing: LMDB aka Lightning MDB\nrunning tests on: via command: \'cat /proc/cpuinfo | egrep \'model name\' | head -n 1\'\nrunning tests on: `model name   : Intel(R) Core(TM) i7-3720QM CPU @ 2.60GHz`\n-OP MMAP REMAP SHRK PART TOTAL ------PERCENT OPERATIONS PER PROCESS PER SECOND -OPS\n--- -k/s --k/s --/s --/s M-OPS 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 -M/s\nPUT  0.0   0.0    0    0   0.0  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.0\nPUT  0.0   0.0    0    0   1.1  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1.1 -\nPUT  0.0   0.0    0    0   1.9  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.8 -\nPUT  0.0   0.0    0    0   2.6  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.7\nPUT  0.0   0.0    0    0   3.3  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.7\nPUT  0.0   0.0    0    0   3.9  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.6\nPUT  0.0   0.0    0    0   4.4  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.6\nPUT  0.0   0.0    0    0   5.0  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.5\nPUT  0.0   0.0    0    0   5.4  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.5\nPUT  0.0   0.0    0    0   5.9  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.5\nPUT  0.0   0.0    0    0   6.3  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.4\nPUT  0.0   0.0    0    0   6.8  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.4\nPUT  0.0   0.0    0    0   7.2  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.4\nPUT  0.0   0.0    0    0   7.6  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.4\nPUT  0.0   0.0    0    0   7.9  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.4\nPUT  0.0   0.0    0    0   8.3  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.3\nPUT  0.0   0.0    0    0   8.6  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.3\n...\nPUT  0.0   0.0    0    0  72.1  0  0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0.3\nPUT  0.0   0.0    0    0  72.3  5  0 93  2  0  0  0  0  0  0  0  0  0  0  0  0  0.2\n...\nPUT  0.0   0.0    0    0 100.0100  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.2\nMIX  0.0   0.0    0    0 100.0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.0\nMIX  0.0   0.0    0    0 100.3 13 12 12 13 13 12 12 13  0  0  0  0  0  0  0  0  0.3\nMIX  0.0   0.0    0    0 101.3 12 12 12 13 12 12 13 13  0  0  0  0  0  0  0  0  1.0 -\nMIX  0.0   0.0    0    0 102.3 13 12 13 13 12 13 12 12  0  0  0  0  0  0  0  0  1.0 -\n...\nMIX  0.0   0.0    0    0 198.3 13 13 12 13 13 12 12 12  0  0  0  0  0  0  0  0  1.0 -\nMIX  0.0   0.0    0    0 199.4 12 12 12 12 13 13 13 13  0  0  0  0  0  0  0  0  1.1 -\nMIX  0.0   0.0    0    0 200.0 13 27 10  3 17  8 11 11  0  0  0  0  0  0  0  0  0.6\nGET  0.0   0.0    0    0 200.0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0.0\nGET  0.0   0.0    0    0 203.0 13 13 12 13 11 13 12 13  0  0  0  0  0  0  0  0  3.0 ---\nGET  0.0   0.0    0    0 208.1 13 12 13 13 12 13 11 13  0  0  0  0  0  0  0  0  5.2 ------\nGET  0.0   0.0    0    0 213.4 12 11 14 12 13 13 13 11  0  0  0  0  0  0  0  0  5.2 ------\nGET  0.0   0.0    0    0 218.6 13 11 14 12 13 12 13 12  0  0  0  0  0  0  0  0  5.2 ------\nGET  0.0   0.0    0    0 223.8 13 11 13 13 13 13 12 12  0  0  0  0  0  0  0  0  5.3 -------\nGET  0.0   0.0    0    0 229.2 12 12 12 13 14 14 12 12  0  0  0  0  0  0  0  0  5.4 -------\nGET  0.0   0.0    0    0 234.3 12 13 12 12 11 13 13 13  0  0  0  0  0  0  0  0  5.1 ------\nGET  0.0   0.0    0    0 239.6 11 12 14 12 12 13 14 12  0  0  0  0  0  0  0  0  5.3 -------\nGET  0.0   0.0    0    0 244.9 12 12 14 10 13 13 14 13  0  0  0  0  0  0  0  0  5.3 -------\nGET  0.0   0.0    0    0 250.1 11 11 13 13 13 13 14 13  0  0  0  0  0  0  0  0  5.3 -------\nGET  0.0   0.0    0    0 255.3 13 12 12 12 13 12 13 12  0  0  0  0  0  0  0  0  5.2 ------\nGET  0.0   0.0    0    0 260.5 13 12 11 13 12 14 13 11  0  0  0  0  0  0  0  0  5.2 ------\nGET  0.0   0.0    0    0 265.8 13 12 12 11 13 13 14 11  0  0  0  0  0  0  0  0  5.2 ------\nGET  0.0   0.0    0    0 270.8 14 12 12 12 13 13 13 12  0  0  0  0  0  0  0  0  5.1 ------\nGET  0.0   0.0    0    0 275.9 12 14 13 13 13 12 14 10  0  0  0  0  0  0  0  0  5.1 ------\nGET  0.0   0.0    0    0 281.3 12 14 13 12 12 13 14 10  0  0  0  0  0  0  0  0  5.4 -------\nGET  0.0   0.0    0    0 286.4 14 13 12 13 12 13 13 12  0  0  0  0  0  0  0  0  5.2 ------\nGET  0.0   0.0    0    0 291.7 13 12 11 11 13 13 13 13  0  0  0  0  0  0  0  0  5.3 -------\nGET  0.0   0.0    0    0 296.7 12 13 12 13 13 14 11 13  0  0  0  0  0  0  0  0  5.0 ------\nGET  0.0   0.0    0    0 300.0 12 22 11 19 10  0  0 25  0  0  0  0  0  0  0  0  3.2 ----\nGET  0.0   0.0    0    0 300.0  0  0  0  0  0  0  0100  0  0  0  0  0  0  0  0  0.0\n* MIX is 2% (2000000) del/put, 98% (12100654) get\nDB size: 2.6G   /dev/shm/test-lmdb-20848\n```\n\n## TODO\n\n* Add high performance IPC queue notification mechanism and tests based upon eventfd.\n* If using private queue batching for performance, add element crash recovery mechanism.\n* Add performance test for multiplexed logging and compare to e.g. log4cxx.\n* Allow values bigger than 4KB to be their own mmap(); so IPC queue & log addrs never change.\n* Auto dump remaining shared memory log atexit.\n* Extend shf_log() to seemlessly log to a file instead of stdout.\n* Convert shf.log to work with shf_log() instead of slower fopen().\n* Add API documentation via doxygen for log operations.\n* Add API documentation via doxygen for key value operations.\n* Add API documentation via literate programming.\n* Add more tests & enforce 100% code coverage.\n* Support key,value data types other than binary strings with 32bit length.\n* Support in-memory persistence past reboot.\n* Support walking of all key,value pairs in the hash table.\n* Support stack key types, e.g. push, pop, shift, unshift.\n* Add networking layer for distributed hash table.\n* Add command line utility tools.\n* Ensure client can crash at any time without corrupting hash table.\n* Port to Linux-like OSs which do not support mremap().\n* Port to Windows.\n* Test performance on flash drives.\n* Email feedback [@] sharedhashfile [.] com with more wishes!\n\n'