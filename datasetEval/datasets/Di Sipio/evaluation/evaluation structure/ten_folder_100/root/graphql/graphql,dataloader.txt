b'# DataLoader\n\nDataLoader is a generic utility to be used as part of your application\'s data\nfetching layer to provide a simplified and consistent API over various remote\ndata sources such as databases or web services via batching and caching.\n\n[![Build Status](https://travis-ci.org/graphql/dataloader.svg)](https://travis-ci.org/graphql/dataloader)\n[![Coverage Status](https://coveralls.io/repos/graphql/dataloader/badge.svg?branch=master&service=github)](https://coveralls.io/github/graphql/dataloader?branch=master)\n\nA port of the "Loader" API originally developed by [@schrockn][] at Facebook in\n2010 as a simplifying force to coalesce the sundry key-value store back-end\nAPIs which existed at the time. At Facebook, "Loader" became one of the\nimplementation details of the "Ent" framework, a privacy-aware data entity\nloading and caching layer within web server product code. This ultimately became\nthe underpinning for Facebook\'s GraphQL server implementation and type\ndefinitions.\n\nDataLoader is a simplified version of this original idea implemented in\nJavaScript for Node.js services. DataLoader is often used when implementing a\n[graphql-js][] service, though it is also broadly useful in other situations.\n\nThis mechanism of batching and caching data requests is certainly not unique to\nNode.js or JavaScript, it is also the primary motivation for\n[Haxl](https://github.com/facebook/Haxl), Facebook\'s data loading library\nfor Haskell. More about how Haxl works can be read in this [blog post](https://code.facebook.com/posts/302060973291128/open-sourcing-haxl-a-library-for-haskell/).\n\nDataLoader is provided so that it may be useful not just to build GraphQL\nservices for Node.js but also as a publicly available reference implementation\nof this concept in the hopes that it can be ported to other languages. If you\nport DataLoader to another language, please open an issue to include a link from\nthis repository.\n\n\n## Getting Started\n\nFirst, install DataLoader using npm.\n\n```sh\nnpm install --save dataloader\n```\n\nTo get started, create a `DataLoader`. Each `DataLoader` instance represents a\nunique cache. Typically instances are created per request when used within a\nweb-server like [express][] if different users can see different things.\n\n> Note: DataLoader assumes a JavaScript environment with global ES6 `Promise`\nand `Map` classes, available in all supported versions of Node.js.\n\n\n## Batching\n\nBatching is not an advanced feature, it\'s DataLoader\'s primary feature.\nCreate loaders by providing a batch loading function.\n\n```js\nconst DataLoader = require(\'dataloader\')\n\nconst userLoader = new DataLoader(keys => myBatchGetUsers(keys))\n```\n\nA batch loading function accepts an Array of keys, and returns a Promise which\nresolves to an Array of values[<sup>*</sup>](#batch-function).\n\nThen load individual values from the loader. DataLoader will coalesce all\nindividual loads which occur within a single frame of execution (a single tick\nof the event loop) and then call your batch function with all requested keys.\n\n```js\nconst user = await userLoader.load(1)\nconst invitedBy = await userLoader.load(user.invitedByID)\nconsole.log(`User 1 was invited by ${invitedBy}`)\n\n// Elsewhere in your application\nconst user = await userLoader.load(2)\nconst lastInvited = await userLoader.load(user.lastInvitedID)\nconsole.log(`User 2 last invited ${lastInvited}`)\n```\n\nA naive application may have issued four round-trips to a backend for the\nrequired information, but with DataLoader this application will make at most\ntwo.\n\nDataLoader allows you to decouple unrelated parts of your application without\nsacrificing the performance of batch data-loading. While the loader presents an\nAPI that loads individual values, all concurrent requests will be coalesced and\npresented to your batch loading function. This allows your application to safely\ndistribute data fetching requirements throughout your application and maintain\nminimal outgoing data requests.\n\n#### Batch Function\n\nA batch loading function accepts an Array of keys, and returns a Promise which\nresolves to an Array of values or Error instances. The loader itself is provided\nas the `this` context.\n\n```js\nasync function batchFunction(keys) {\n  const results = await db.fetchAllKeys(keys)\n  return keys.map(key => results[key] || new Error(`No result for ${key}`))\n}\n\nconst loader = new DataLoader(batchFunction)\n```\n\nThere are a few constraints this function must uphold:\n\n * The Array of values must be the same length as the Array of keys.\n * Each index in the Array of values must correspond to the same index in the Array of keys.\n\nFor example, if your batch function was provided the Array of keys: `[ 2, 9, 6, 1 ]`,\nand loading from a back-end service returned the values:\n\n```js\n{ id: 9, name: \'Chicago\' }\n{ id: 1, name: \'New York\' }\n{ id: 2, name: \'San Francisco\' }\n```\n\nOur back-end service returned results in a different order than we requested, likely\nbecause it was more efficient for it to do so. Also, it omitted a result for key `6`,\nwhich we can interpret as no value existing for that key.\n\nTo uphold the constraints of the batch function, it must return an Array of values\nthe same length as the Array of keys, and re-order them to ensure each index aligns\nwith the original keys `[ 2, 9, 6, 1 ]`:\n\n```js\n[\n  { id: 2, name: \'San Francisco\' },\n  { id: 9, name: \'Chicago\' },\n  null, // or perhaps `new Error()`\n  { id: 1, name: \'New York\' }\n]\n```\n\n#### Batch Scheduling\n\nBy default DataLoader will coalesce all individual loads which occur within a\nsingle frame of execution before calling your batch function with all requested\nkeys. This ensures no additional latency while capturing many related requests\ninto a single batch. In fact, this is the same behavior used in Facebook\'s\noriginal PHP implementation in 2010. See `enqueuePostPromiseJob` in the\n[source code][] for more details about how this works.\n\nHowever sometimes this behavior is not desirable or optimal. Perhaps you expect\nrequests to be spread out over a few subsequent ticks because of an existing use\nof `setTimeout`, or you just want manual control over dispatching regardless of\nthe run loop. DataLoader allows providing a custom batch scheduler to provide\nthese or any other behaviors.\n\nA custom scheduler is provided as `batchScheduleFn` in options. It must be a\nfunction which is passed a callback and is expected to call that callback in the\nimmediate future to execute the batch request.\n\nAs an example, here is a batch scheduler which collects all requests over a\n100ms window of time (and as a consequence, adds 100ms of latency):\n\n```js\nconst myLoader = new DataLoader(myBatchFn, {\n  batchScheduleFn: callback => setTimeout(callback, 100)\n})\n```\n\nAs another example, here is a manually dispatched batch scheduler:\n\n```js\nfunction createScheduler() {\n  let callbacks = []\n  return {\n    schedule(callback) {\n      callbacks.push(callback)\n    },\n    dispatch() {\n      callbacks.forEach(callback => callback())\n      callbacks = []\n    }\n  }\n}\n\nconst { schedule, dispatch } = createScheduler()\nconst myLoader = new DataLoader(myBatchFn, { batchScheduleFn: schedule })\n\nmyLoader.load(1)\nmyLoader.load(2)\ndispatch()\n```\n\n\n## Caching\n\nDataLoader provides a memoization cache for all loads which occur in a single\nrequest to your application. After `.load()` is called once with a given key,\nthe resulting value is cached to eliminate redundant loads.\n\n#### Caching Per-Request\n\nDataLoader caching *does not* replace Redis, Memcache, or any other shared\napplication-level cache. DataLoader is first and foremost a data loading mechanism,\nand its cache only serves the purpose of not repeatedly loading the same data in\nthe context of a single request to your Application. To do this, it maintains a\nsimple in-memory memoization cache (more accurately: `.load()` is a memoized function).\n\nAvoid multiple requests from different users using the DataLoader instance, which\ncould result in cached data incorrectly appearing in each request. Typically,\nDataLoader instances are created when a Request begins, and are not used once the\nRequest ends.\n\nFor example, when using with [express][]:\n\n```js\nfunction createLoaders(authToken) {\n  return {\n    users: new DataLoader(ids => genUsers(authToken, ids)),\n  }\n}\n\nconst app = express()\n\napp.get(\'/\', function(req, res) {\n  const authToken = authenticateUser(req)\n  const loaders = createLoaders(authToken)\n  res.send(renderPage(req, loaders))\n})\n\napp.listen()\n```\n\n#### Caching and Batching\n\nSubsequent calls to `.load()` with the same key will result in that key not\nappearing in the keys provided to your batch function. *However*, the resulting\nPromise will still wait on the current batch to complete. This way both cached\nand uncached requests will resolve at the same time, allowing DataLoader\noptimizations for subsequent dependent loads.\n\nIn the example below, User `1` happens to be cached. However, because User `1`\nand `2` are loaded in the same tick, they will resolve at the same time. This\nmeans both `user.bestFriendID` loads will also happen in the same tick which\nresults in two total requests (the same as if User `1` had not been cached).\n\n```js\nuserLoader.prime(1, { bestFriend: 3 })\n\nasync function getBestFriend(userID) {\n  const user = await userLoader.load(userID)\n  return await userLoader.load(user.bestFriendID)\n}\n\n// In one part of your application\ngetBestFriend(1)\n\n// Elsewhere\ngetBestFriend(2)\n```\n\nWithout this optimization, if the cached User `1` resolved immediately, this\ncould result in three total requests since each `user.bestFriendID` load would\nhappen at different times.\n\n#### Clearing Cache\n\nIn certain uncommon cases, clearing the request cache may be necessary.\n\nThe most common example when clearing the loader\'s cache is necessary is after\na mutation or update within the same request, when a cached value could be out of\ndate and future loads should not use any possibly cached value.\n\nHere\'s a simple example using SQL UPDATE to illustrate.\n\n```js\n// Request begins...\nconst userLoader = new DataLoader(...)\n\n// And a value happens to be loaded (and cached).\nconst user = await userLoader.load(4)\n\n// A mutation occurs, invalidating what might be in cache.\nawait sqlRun(\'UPDATE users WHERE id=4 SET username="zuck"\')\nuserLoader.clear(4)\n\n// Later the value load is loaded again so the mutated data appears.\nconst user = await userLoader.load(4)\n\n// Request completes.\n```\n\n#### Caching Errors\n\nIf a batch load fails (that is, a batch function throws or returns a rejected\nPromise), then the requested values will not be cached. However if a batch\nfunction returns an `Error` instance for an individual value, that `Error` will\nbe cached to avoid frequently loading the same `Error`.\n\nIn some circumstances you may wish to clear the cache for these individual Errors:\n\n```js\ntry {\n  const user = await userLoader.load(1)\n} catch (error) {\n  if (/* determine if the error should not be cached */) {\n    userLoader.clear(1)\n  }\n  throw error\n}\n```\n\n#### Disabling Cache\n\nIn certain uncommon cases, a DataLoader which *does not* cache may be desirable.\nCalling `new DataLoader(myBatchFn, { cache: false })` will ensure that every\ncall to `.load()` will produce a *new* Promise, and requested keys will not be\nsaved in memory.\n\nHowever, when the memoization cache is disabled, your batch function will\nreceive an array of keys which may contain duplicates! Each key will be\nassociated with each call to `.load()`. Your batch loader should provide a value\nfor each instance of the requested key.\n\nFor example:\n\n```js\nconst myLoader = new DataLoader(keys => {\n  console.log(keys)\n  return someBatchLoadFn(keys)\n}, { cache: false })\n\nmyLoader.load(\'A\')\nmyLoader.load(\'B\')\nmyLoader.load(\'A\')\n\n// > [ \'A\', \'B\', \'A\' ]\n```\n\nMore complex cache behavior can be achieved by calling `.clear()` or `.clearAll()`\nrather than disabling the cache completely. For example, this DataLoader will\nprovide unique keys to a batch function due to the memoization cache being\nenabled, but will immediately clear its cache when the batch function is called\nso later requests will load new values.\n\n```js\nconst myLoader = new DataLoader(keys => {\n  identityLoader.clearAll()\n  return someBatchLoadFn(keys)\n})\n```\n\n#### Custom Cache\n\nAs mentioned above, DataLoader is intended to be used as a per-request cache.\nSince requests are short-lived, DataLoader uses an infinitely growing [Map][] as\na memoization cache. This should not pose a problem as most requests are\nshort-lived and the entire cache can be discarded after the request completes.\n\nHowever this memoization caching strategy isn\'t safe when using a long-lived\nDataLoader, since it could consume too much memory. If using DataLoader in this\nway, you can provide a custom Cache instance with whatever behavior you prefer,\nas long as it follows the same API as [Map][].\n\nThe example below uses an LRU (least recently used) cache to limit total memory\nto hold at most 100 cached values via the [lru_map][] npm package.\n\n```js\nimport { LRUMap } from \'lru_map\'\n\nconst myLoader = new DataLoader(someBatchLoadFn, {\n  cacheMap: new LRUMap(100)\n})\n```\n\nMore specifically, any object that implements the methods `get()`, `set()`,\n`delete()` and `clear()` methods can be provided. This allows for custom Maps\nwhich implement various [cache algorithms][] to be provided.\n\n\n## API\n\n#### class DataLoader\n\nDataLoader creates a public API for loading data from a particular\ndata back-end with unique keys such as the `id` column of a SQL table or\ndocument name in a MongoDB database, given a batch loading function.\n\nEach `DataLoader` instance contains a unique memoized cache. Use caution when\nused in long-lived applications or those which serve many users with different\naccess permissions and consider creating a new instance per web request.\n\n##### `new DataLoader(batchLoadFn [, options])`\n\nCreate a new `DataLoader` given a batch loading function and options.\n\n- *batchLoadFn*: A function which accepts an Array of keys, and returns a\n  Promise which resolves to an Array of values.\n\n- *options*: An optional object of options:\n\n  | Option Key | Type | Default | Description |\n  | ---------- | ---- | ------- | ----------- |\n  | *batch*  | Boolean | `true` | Set to `false` to disable batching, invoking `batchLoadFn` with a single load key. This is equivalent to setting `maxBatchSize` to `1`.\n  | *maxBatchSize* | Number | `Infinity` | Limits the number of items that get passed in to the `batchLoadFn`. May be set to `1` to disable batching.\n  | *batchScheduleFn* | Function | See [Batch scheduling](#batch-scheduling) | A function to schedule the later execution of a batch. The function is expected to call the provided callback in the immediate future.\n  | *cache* | Boolean | `true` | Set to `false` to disable memoization caching, creating a new Promise and new key in the `batchLoadFn` for every load of the same key. This is equivalent to setting `cacheMap` to `null`.\n  | *cacheKeyFn* | Function | `key\xc2\xa0=>\xc2\xa0key` | Produces cache key for a given load key. Useful when objects are keys and two objects should be considered equivalent.\n  | *cacheMap* | Object | `new\xc2\xa0Map()` | Instance of [Map][] (or an object with a similar API) to be used as cache. May be set to `null` to disable caching.\n\n##### `load(key)`\n\nLoads a key, returning a `Promise` for the value represented by that key.\n\n- *key*: A key value to load.\n\n##### `loadMany(keys)`\n\nLoads multiple keys, promising an array of values:\n\n```js\nconst [ a, b ] = await myLoader.loadMany([ \'a\', \'b\' ])\n```\n\nThis is similar to the more verbose:\n\n```js\nconst [ a, b ] = await Promise.all([\n  myLoader.load(\'a\'),\n  myLoader.load(\'b\')\n])\n```\n\nHowever it is different in the case where any load fails. Where\nPromise.all() would reject, loadMany() always resolves, however each result\nis either a value or an Error instance.\n\n```js\nvar [ a, b, c ] = await myLoader.loadMany([ \'a\', \'b\', \'badkey\' ]);\n// c instanceof Error\n```\n\n- *keys*: An array of key values to load.\n\n##### `clear(key)`\n\nClears the value at `key` from the cache, if it exists. Returns itself for\nmethod chaining.\n\n- *key*: A key value to clear.\n\n##### `clearAll()`\n\nClears the entire cache. To be used when some event results in unknown\ninvalidations across this particular `DataLoader`. Returns itself for\nmethod chaining.\n\n##### `prime(key, value)`\n\nPrimes the cache with the provided key and value. If the key already exists, no\nchange is made. (To forcefully prime the cache, clear the key first with\n`loader.clear(key).prime(key, value)`.) Returns itself for method chaining.\n\nTo prime the cache with an error at a key, provide an Error instance.\n\n## Using with GraphQL\n\nDataLoader pairs nicely well with [GraphQL][graphql-js]. GraphQL fields are\ndesigned to be stand-alone functions. Without a caching or batching mechanism,\nit\'s easy for a naive GraphQL server to issue new database requests each time a\nfield is resolved.\n\nConsider the following GraphQL request:\n\n```\n{\n  me {\n    name\n    bestFriend {\n      name\n    }\n    friends(first: 5) {\n      name\n      bestFriend {\n        name\n      }\n    }\n  }\n}\n```\n\nNaively, if `me`, `bestFriend` and `friends` each need to request the backend,\nthere could be at most 13 database requests!\n\nWhen using DataLoader, we could define the `User` type using the\n[SQLite](examples/SQL.md) example with clearer code and at most 4 database requests,\nand possibly fewer if there are cache hits.\n\n```js\nconst UserType = new GraphQLObjectType({\n  name: \'User\',\n  fields: () => ({\n    name: { type: GraphQLString },\n    bestFriend: {\n      type: UserType,\n      resolve: user => userLoader.load(user.bestFriendID)\n    },\n    friends: {\n      args: {\n        first: { type: GraphQLInt }\n      },\n      type: new GraphQLList(UserType),\n      resolve: async (user, { first }) => {\n        const rows = await queryLoader.load([\n          \'SELECT toID FROM friends WHERE fromID=? LIMIT ?\', user.id, first\n        ])\n        return rows.map(row => userLoader.load(row.toID))\n      }\n    }\n  })\n})\n```\n\n\n## Common Patterns\n\n### Creating a new DataLoader per request.\n\nIn many applications, a web server using DataLoader serves requests to many\ndifferent users with different access permissions. It may be dangerous to use\none cache across many users, and is encouraged to create a new DataLoader\nper request:\n\n```js\nfunction createLoaders(authToken) {\n  return {\n    users: new DataLoader(ids => genUsers(authToken, ids)),\n    cdnUrls: new DataLoader(rawUrls => genCdnUrls(authToken, rawUrls)),\n    stories: new DataLoader(keys => genStories(authToken, keys)),\n  }\n}\n\n// When handling an incoming web request:\nconst loaders = createLoaders(request.query.authToken)\n\n// Then, within application logic:\nconst user = await loaders.users.load(4)\nconst pic = await loaders.cdnUrls.load(user.rawPicUrl)\n```\n\nCreating an object where each key is a `DataLoader` is one common pattern which\nprovides a single value to pass around to code which needs to perform\ndata loading, such as part of the `rootValue` in a [graphql-js][] request.\n\n### Loading by alternative keys.\n\nOccasionally, some kind of value can be accessed in multiple ways. For example,\nperhaps a "User" type can be loaded not only by an "id" but also by a "username"\nvalue. If the same user is loaded by both keys, then it may be useful to fill\nboth caches when a user is loaded from either source:\n\n```js\nconst userByIDLoader = new DataLoader(async ids => {\n  const users = await genUsersByID(ids)\n  for (let user of users) {\n    usernameLoader.prime(user.username, user)\n  }\n  return users\n})\n\nconst usernameLoader = new DataLoader(async names => {\n  const users = await genUsernames(names)\n  for (let user of users) {\n    userByIDLoader.prime(user.id, user)\n  }\n  return users\n})\n```\n\n### Freezing results to enforce immutability\n\nSince DataLoader caches values, it\'s typically assumed these values will be\ntreated as if they were immutable. While DataLoader itself doesn\'t enforce\nthis, you can create a higher-order function to enforce immutability\nwith Object.freeze():\n\n```js\nfunction freezeResults(batchLoader) {\n  return keys => batchLoader(keys).then(values => values.map(Object.freeze))\n}\n\nconst myLoader = new DataLoader(freezeResults(myBatchLoader))\n```\n\n### Batch functions which return Objects instead of Arrays\n\nDataLoader expects batch functions which return an Array of the same length as\nthe provided keys. However this is not always a common return format from other\nlibraries. A DataLoader higher-order function can convert from one format to another. The example below converts a `{ key: value }` result to the format\nDataLoader expects.\n\n```js\nfunction objResults(batchLoader) {\n  return keys => batchLoader(keys).then(objValues => keys.map(\n    key => objValues[key] || new Error(`No value for ${key}`)\n  ))\n}\n\nconst myLoader = new DataLoader(objResults(myBatchLoader))\n```\n\n\n## Common Back-ends\n\nLooking to get started with a specific back-end? Try the [loaders in the examples directory](/examples).\n\n## Other Implementations\n\nListed in alphabetical order\n\n* Elixir\n  * [dataloader](https://github.com/absinthe-graphql/dataloader)\n* Golang\n  * [Dataloader](https://github.com/nicksrandall/dataloader)\n* Java\n  * [java-dataloader](https://github.com/graphql-java/java-dataloader)\n* .Net\n  * [GraphQL .NET DataLoader](https://graphql-dotnet.github.io/docs/guides/dataloader/)\n  * [GreenDonut](https://github.com/ChilliCream/greendonut)\n* Perl\n  * [perl-DataLoader](https://github.com/richardjharris/perl-DataLoader)\n* PHP\n  * [DataLoaderPHP](https://github.com/overblog/dataloader-php)\n* Python\n  * [aiodataloader](https://github.com/syrusakbary/aiodataloader)\n* ReasonML\n  * [bs-dataloader](https://github.com/ulrikstrid/bs-dataloader)\n* Ruby\n  * [BatchLoader](https://github.com/exaspark/batch-loader)\n  * [Dataloader](https://github.com/sheerun/dataloader)\n  * [GraphQL Batch](https://github.com/Shopify/graphql-batch)\n* Rust\n  * [Dataloader](https://github.com/cksac/dataloader-rs)\n* Swift\n  * [SwiftDataLoader](https://github.com/kimdv/SwiftDataLoader)\n\n## Video Source Code Walkthrough\n\n**DataLoader Source Code Walkthrough (YouTube):**\n\nA walkthrough of the DataLoader v1 source code. While the source has changed\nsince this video was made, it is still a good overview of the rationale of\nDataLoader and how it works.\n\n<a href="https://youtu.be/OQTnXNCDywA" target="_blank" alt="DataLoader Source Code Walkthrough"><img src="https://img.youtube.com/vi/OQTnXNCDywA/0.jpg" /></a>\n\n\n[@schrockn]: https://github.com/schrockn\n[Map]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map\n[graphql-js]: https://github.com/graphql/graphql-js\n[cache algorithms]: https://en.wikipedia.org/wiki/Cache_algorithms\n[express]: http://expressjs.com/\n[babel/polyfill]: https://babeljs.io/docs/usage/polyfill/\n[lru_map]: https://github.com/rsms/js-lru\n[source code]: https://github.com/graphql/dataloader/blob/master/src/index.js\n'