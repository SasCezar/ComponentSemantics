b'# [Sketch Simplification](https://esslab.jp/~ess/research/sketch/)\n\n![Example result](/example_fig01_eisaku.png?raw=true "Example result of the provided model.")\nExample result of a sketch simplification. Image copyrighted by Eisaku Kubonouchi ([@EISAKUSAKU](https://twitter.com/eisakusaku)) and only non-commercial research usage is allowed.\n\n## Overview\n\nThis code provides pre-trained models used in the research papers:\n\n```\n   "Learning to Simplify: Fully Convolutional Networks for Rough Sketch Cleanup"\n   Edgar Simo-Serra*, Satoshi Iizuka*, Kazuma Sasaki, Hiroshi Ishikawa (* equal contribution)\n   ACM Transactions on Graphics (SIGGRAPH), 2016\n```\n\nand\n\n```\n   "Mastering Sketching: Adversarial Augmentation for Structured Prediction"\n   Edgar Simo-Serra*, Satoshi Iizuka*, Hiroshi Ishikawa (* equal contribution)\n   ACM Transactions on Graphics (TOG), 2018\n```\n\nSee our [project page](https://esslab.jp/~ess/research/sketch_master/) for more detailed information.\n\n## Dependencies\n\n- [PyTorch](http://pytorch.org/) (version 0.4.1)\n  [torchvision](http://pytorch.org/docs/master/torchvision/)\n- [pillow](http://pillow.readthedocs.io/en/latest/index.html)\n\nAll packages should be part of a standard PyTorch install. For information on how to install PyTorch please refer to the [torch website](http://pytorch.org/).\n\n## Usage\n\nBefore the first usage, the models have to be downloaded with:\n\n```\nbash download_models.sh\n```\n\nNext test the models with:\n\n```\npython simplify.py\n```\n\nYou should see a file called `out.png` created with the output of the model.\n\nApplication options can be seen with:\n\n```\npython simplify.py --help\n```\n\n## Pencil Drawing Generation\n\nUsing the same interface it is possible to perform pencil drawing generation. In this case, the input should be a clean line drawing and not a rough sketch, and the line drawings can be generated by:\n\n```\npython simplify.py --img test_line.png --out out_rough.png --model model_pencil2.t7\n```\n\nThis will generate a rough version of `test_line.png` as `out_rough.png`. By changing the model it is possible to change the type of rough sketch being generated.\n\n## Models\n\n- `model_mse.t7`: Model trained using only MSE loss (SIGGRAPH 2016 model).\n- `model_gan.t7`: Model trained with MSE and GAN loss using both supervised and unsupervised training data (TOG 2018 model).\n- `model_pencil1.t7`: Model for pencil drawing generation based on artist 1 (dirty and faded pencil lines).\n- `model_pencil2.t7`: Model for pencil drawing generation based on artist 2 (clearer overlaid pencil lines).\n\n## Reproducing Paper Figures\n\nFor replicability we include code to replicate the figures in the paper. After downloading the models you can run it with:\n\n```\n./figs.sh\n```\n\nThis will convert the input images in `figs/` and save the output in `out/`. We note that there are small differences with the results in the paper due to hardware differences and small differences in the torch/pytorch implementations. Furthermore, results are shown without the post-processing mentioned in the notes at the bottom of this document.\n\nPlease note that we do not have the copyright for all these images and in general only non-commercial research usage is permitted. In particular, `fig16_eisaku.png`, `fig06_eisaku_robo.png`, `fig06_eisaku_joshi.png`, and `fig01_eisaku.png` are copyright by Eisaku Kubonoichi ([@EISAKUSAKU](https://twitter.com/eisakusaku)) and only non-commercial research usage is allowed.\nThe images`fig14_pepper.png` and `fig06_pepper.png` are licensed by David Revoy ([www.davidrevoy.com](http://www.davidrevoy.com/)) under CC-by 4.0.\n\n## Training\n\nPlease see the [training readme](train/TRAIN.md).\n\n## Notes\n\n- Models are in Torch7 format and loaded using the PyTorch legacy code.\n- This was developed and tested on various machines from late 2015 to end of 2016.\n- Provided models are under a non-commercial creative commons license.\n- Post-processing is not performed. You can perform it manually with `convert out.png bmp:- | mkbitmap - -t 0.3 -o - | potrace --svg --group -t 15 -o - > out.svg`.\n\n## Citing\n\nIf you use these models please cite:\n\n```\n@Article{SimoSerraSIGGRAPH2016,\n   author    = {Edgar Simo-Serra and Satoshi Iizuka and Kazuma Sasaki and Hiroshi Ishikawa},\n   title     = {{Learning to Simplify: Fully Convolutional Networks for Rough Sketch Cleanup}},\n   journal   = "ACM Transactions on Graphics (SIGGRAPH)",\n   year      = 2016,\n   volume    = 35,\n   number    = 4,\n}\n```\n\nand\n\n```\n@Article{SimoSerraTOG2018,\n   author    = {Edgar Simo-Serra and Satoshi Iizuka and Hiroshi Ishikawa},\n   title     = {{Mastering Sketching: Adversarial Augmentation for Structured Prediction}},\n   journal   = "ACM Transactions on Graphics (TOG)",\n   year      = 2018,\n   volume    = 37,\n   number    = 1,\n}\n```\n\n## Acknowledgements\n\nThis work was partially supported by JST CREST Grant Number JPMJCR14D1 and JST ACT-I Grant Numbers JPMJPR16UD and JPMJPR16U3.\n\n## License\n\nThis sketch simplification code is  freely available for free non-commercial\nuse, and may be redistributed under these conditions. Please, see the [license](/LICENSE)\nfor further details.\n\n'