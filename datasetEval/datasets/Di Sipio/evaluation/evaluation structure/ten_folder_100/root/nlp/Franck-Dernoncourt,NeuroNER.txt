b'# NeuroNER\n\n[![Build Status](https://travis-ci.org/Franck-Dernoncourt/NeuroNER.svg?branch=master)](https://travis-ci.org/Franck-Dernoncourt/NeuroNER)\n\nNeuroNER is a program that performs named-entity recognition (NER). Website: [neuroner.com](http://neuroner.com).\n\nThis page gives step-by-step instructions to install and use NeuroNER.\n\n\n## Table of Contents\n\n<!-- toc -->\n\n- [Requirements](#requirements)\n- [Installation](#installation)\n- [Using NeuroNER](#using-neuroner)\n  * [Adding a new dataset](#adding-a-new-dataset)\n  * [Using a pretrained model](#using-a-pretrained-model)\n  * [Sharing a pretrained model](#sharing-a-pretrained-model)\n  * [Using TensorBoard](#using-tensorboard)\n- [Citation](#citation)\n\n<!-- tocstop -->\n\n## Requirements\n\nNeuroNER relies on Python 3, TensorFlow 1.0+, and optionally on BRAT:\n\n- Python 3: NeuroNER does not work with Python 2.x. On Windows, it has to be Python 3.6 64-bit or later.\n- TensorFlow is a library for machine learning. NeuroNER uses it for its NER engine, which is based on neural networks. Official website: [https://www.tensorflow.org](https://www.tensorflow.org)\n- BRAT (optional) is a web-based annotation tool. It only needs to be installed if you wish to conveniently create annotations or view the predictions made by NeuroNER. Official website: [http://brat.nlplab.org](http://brat.nlplab.org)\n\n## Installation\n\nFor GPU support, [GPU requirements for Tensorflow](https://www.tensorflow.org/install/) must be satisfied. If your system does not meet these requirements, you should use the CPU version. To install neuroner:\n\n```\n# For CPU support (no GPU support):\npip3 install pyneuroner[cpu]\n\n# For GPU support:\npip3 install pyneuroner[gpu]\n```\n\nYou will also need to download some support packages.\n\n1. The English language module for Spacy:\n\n```\n# Download the SpaCy English module\npython -m spacy download en\n```\n\n2. Download word embeddings from http://neuroner.com/data/word_vectors/glove.6B.100d.zip, unzip them to the folder `./data/word_vectors`\n\n```\n# Get word embeddings\nwget -P data/word_vectors http://neuroner.com/data/word_vectors/glove.6B.100d.zip\nunzip data/word_vectors/glove.6B.100d.zip -d data/word_vectors/\n```\n\n3. Load sample datasets. These can be loaded by calling the `neuromodel.fetch_data()` function from a Python interpreter or with the `--fetch_data` argument at the command line.\n\n```\n# Load a dataset from the command line\nneuroner --fetch_data=conll2003\nneuroner --fetch_data=example_unannotated_texts\nneuroner --fetch_data=i2b2_2014_deid\n```\n\n```\n# Load a dataset from a Python interpreter\nfrom neuroner import neuromodel\nneuromodel.fetch_data(\'conll2003\')\nneuromodel.fetch_data(\'example_unannotated_texts\')\nneuromodel.fetch_data(\'i2b2_2014_deid\')\n```\n\n4. Load a pretrained model. The models can be loaded by calling the `neuromodel.fetch_model()` function from a Python interpreter or with the `--fetch_trained_models` argument at the command line.\n\n```\n# Load a pre-trained model from the command line\nneuroner --fetch_trained_model=conll_2003_en\nneuroner --fetch_trained_model=i2b2_2014_glove_spacy_bioes\nneuroner --fetch_trained_model=i2b2_2014_glove_stanford_bioes\nneuroner --fetch_trained_model=mimic_glove_spacy_bioes\nneuroner --fetch_trained_model=mimic_glove_stanford_bioes\n```\n\n```\n# Load a pre-trained model from a Python interpreter\nfrom neuroner import neuromodel\nneuromodel.fetch_model(\'conll_2003_en\')\nneuromodel.fetch_model(\'i2b2_2014_glove_spacy_bioes\')\nneuromodel.fetch_model(\'i2b2_2014_glove_stanford_bioes\')\nneuromodel.fetch_model(\'mimic_glove_spacy_bioes\')\nneuromodel.fetch_model(\'mimic_glove_stanford_bioes\')\n```\n\n### Installing BRAT (optional) \n\nBRAT is a tool that can be used to create, change or view the BRAT-style annotations. For installation and usage instructions, see the [BRAT website](http://brat.nlplab.org/installation.html).\n\n### Installing Perl (platform dependent)\n\nPerl is required because the official CoNLL-2003 evaluation script is written in this language: http://strawberryperl.com. For Unix and Mac OSX systems, Perl should already be installed. For Windows systems, you may need to install it.\n\n## Using NeuroNER\n\nNeuroNER can either be run from the command line or from a Python interpreter.\n\n### Using NeuroNer from a Python interpreter\n\nTo use NeuroNER from the command line, create an instance of the neuromodel with your desired arguments, and then call the relevant methods. Additional parameters can be set from a `parameters.ini` file in the working directory. For example:\n\n```\nfrom neuroner import neuromodel\nnn = neuromodel.NeuroNER(train_model=False, use_pretrained_model=True)\n```\n\nMore detail to follow.\n\n### Using NeuroNer from the command line\n\nBy default NeuroNER is configured to train and test on the CoNLL-2003 dataset. Running neuroner with the default settings starts training on the CoNLL-2003 dataset (the F1-score on the test set should be around 0.90, i.e. on par with state-of-the-art systems). To start the training:\n\n```\n# To use the CPU if you have installed tensorflow, or use the GPU if you have installed tensorflow-gpu:\nneuroner\n\n# To use the CPU only if you have installed tensorflow-gpu:\nCUDA_VISIBLE_DEVICES="" neuroner\n\n# To use the GPU 1 only if you have installed tensorflow-gpu:\nCUDA_VISIBLE_DEVICES=1 neuroner\n```\n\nIf you wish to change any of NeuroNER parameters, you can modify the [`parameters.ini`](parameters.ini) configuration file in your working directory or specify it as an argument.\n\nFor example, to reduce the number of training epochs and not use any pre-trained token embeddings:\n\n```\nneuroner --maximum_number_of_epochs=2 --token_pretrained_embedding_filepath=""\n```\n\nTo perform NER on some plain texts using a pre-trained model:\n\n```\nneuroner --train_model=False --use_pretrained_model=True --dataset_text_folder=./data/example_unannotated_texts --pretrained_model_folder=./trained_models/conll_2003_en\n```\n\nIf a parameter is specified in both the [`parameters.ini`](parameters.ini) configuration file and as an argument, then the argument takes precedence (i.e., the parameter in [`parameters.ini`](parameters.ini) is ignored). You may specify a different configuration file with the `--parameters_filepath` command line argument. The command line arguments have no default value except for `--parameters_filepath`, which points to [`parameters.ini`](parameters.ini).\n\nNeuroNER has 3 modes of operation:\n\n- training mode (from scratch): the dataset folder must have train and valid sets. Test and deployment sets are optional.\n- training mode (from pretrained model): the dataset folder must have train and valid sets. Test and deployment sets are optional.\n- prediction mode (using pretrained model): the dataset folder must have either a test set or a deployment set.\n\n### Adding a new dataset\n\nA dataset may be provided in either CoNLL-2003 or BRAT format. The dataset files and folders should be organized and named as follows:\n\n- Training set: `train.txt` file (CoNLL-2003 format) or `train` folder (BRAT format). It must contain labels.\n- Validation set: `valid.txt` file (CoNLL-2003 format) or `valid` folder (BRAT format). It must contain labels.\n- Test set: `test.txt` file (CoNLL-2003 format) or `test` folder (BRAT format). It must contain labels.\n- Deployment set: `deploy.txt` file (CoNLL-2003 format) or `deploy` folder (BRAT format). It shouldn\'t contain any label (if it does, labels are ignored).\n\nWe provide several examples of datasets:\n\n- [`data/conll2003/en`](data/conll2003/en): annotated dataset with the CoNLL-2003 format, containing 3 files (`train.txt`, `valid.txt` and  `test.txt`).\n- [`data/example_unannotated_texts`](data/example_unannotated_texts): unannotated dataset with the BRAT format, containing 1 folder (`deploy/`). Note that the BRAT format with no annotation is the same as plain texts.\n\n### Using a pretrained model\n\nIn order to use a pretrained model, the `pretrained_model_folder` parameter in the [`parameters.ini`](parameters.ini) configuration file must be set to the folder containing the pretrained model. The following parameters in the [`parameters.ini`](parameters.ini) configuration file must also be set to the same values as in the configuration file located in the specified `pretrained_model_folder`:\n\n```\nuse_character_lstm\ncharacter_embedding_dimension\ncharacter_lstm_hidden_state_dimension\ntoken_pretrained_embedding_filepath\ntoken_embedding_dimension\ntoken_lstm_hidden_state_dimension\nuse_crf\ntagging_format\ntokenizer\n```\n\n### Sharing a pretrained model\n\nYou are highly encouraged to share a model trained on their own datasets, so that other users can use the pretrained model on other datasets. We provide the [`neuroner/prepare_pretrained_model.py`](neuroner/prepare_pretrained_model.py) script to make it easy to prepare a pretrained model for sharing. In order to use the script, one only needs to specify the `output_folder_name`, `epoch_number`, and `model_name` parameters in the script.\n\nBy default, the only information about the dataset contained in the pretrained model is the list of tokens that appears in the dataset used for training and the corresponding embeddings learned from the dataset.\n\nIf you wish to share a pretrained model without providing any information about the dataset (including the list of tokens appearing in the dataset), you can do so by setting\n\n```delete_token_mappings = True```\n\nwhen running the script. In this case, it is highly recommended to use some external pre-trained token embeddings and freeze them while training the model to obtain high performance. This can be done by specifying the `token_pretrained_embedding_filepath` and setting\n\n```freeze_token_embeddings = True```\n\nin the [`parameters.ini`](parameters.ini) configuration file during training.\n\nIn order to share a pretrained model, please [submit a new issue](https://github.com/Franck-Dernoncourt/NeuroNER/issues/new) on the GitHub repository.\n\n### Using TensorBoard\n\nYou may launch TensorBoard during or after the training phase. To do so, run in the terminal from the NeuroNER folder:\n```\ntensorboard --logdir=output\n```\n\nThis starts a web server that is accessible at http://127.0.0.1:6006 from your web browser.\n\n## Citation\n\nIf you use NeuroNER in your publications, please cite this [paper](https://arxiv.org/abs/1705.05487):\n\n```\n@article{2017neuroner,\n  title={{NeuroNER}: an easy-to-use program for named-entity recognition based on neural networks},\n  author={Dernoncourt, Franck and Lee, Ji Young and Szolovits, Peter},\n  journal={Conference on Empirical Methods on Natural Language Processing (EMNLP)},\n  year={2017}\n}\n```\n\nThe neural network architecture used in NeuroNER is described in this [article](https://arxiv.org/abs/1606.03475):\n\n```\n@article{2016deidentification,\n  title={De-identification of Patient Notes with Recurrent Neural Networks},\n  author={Dernoncourt, Franck and Lee, Ji Young and Uzuner, Ozlem and Szolovits, Peter},\n  journal={Journal of the American Medical Informatics Association (JAMIA)},\n  year={2016}\n}\n```\n'