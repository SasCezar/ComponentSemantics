b'# Lingvo\n\n## What is it?\n\nLingvo is a framework for building neural networks in Tensorflow, particularly\nsequence models.\n\nA list of publications using Lingvo can be found [here](PUBLICATIONS.md).\n\n## Quick start\n\n### Docker\n\nThe easiest way to get started is to use the provided\n[Docker script](docker/dev.dockerfile). If instead you want to install it\ndirectly on your machine, skip to the section below.\n\nFirst,\n[install docker](https://docs.docker.com/install/linux/docker-ce/ubuntu/). Then,\nthe following commands should give you a working shell with Lingvo installed.\n\n```shell\nLINGVO_DIR="/tmp/lingvo"  # (change to the cloned lingvo directory, e.g. "$HOME/lingvo")\nLINGVO_DEVICE="gpu"  # (Leave empty to build and run CPU only docker)\ndocker build --tag tensorflow:lingvo $(test "$LINGVO_DEVICE" = "gpu" && echo "--build-arg base_image=nvidia/cuda:10.0-cudnn7-runtime-ubuntu16.04") - < ${LINGVO_DIR}/docker/dev.dockerfile\ndocker run --rm $(test "$LINGVO_DEVICE" = "gpu" && echo "--runtime=nvidia") -it -v ${LINGVO_DIR}:/tmp/lingvo -v ${HOME}/.gitconfig:/home/${USER}/.gitconfig:ro -p 6006:6006 -p 8888:8888 --name lingvo tensorflow:lingvo bash\nbazel test -c opt --test_output=streamed //lingvo:trainer_test //lingvo:models_test\n```\n\n### Installing directly\n\nThis is an alternative to using Docker as described in the section above.\n\nThe prerequisites are:\n\n*   a TensorFlow 2.0 [installation](https://www.tensorflow.org/install/),\n*   a `C++` compiler (only g++ 7.3 is officially supported), and\n*   the bazel build system.\n\nRefer to [docker/dev.dockerfile](docker/dev.dockerfile) for more specific\ndetails.\n\n### Running the MNIST image model\n\n#### Preparing the input data\n\n```shell\nmkdir -p /tmp/mnist\nbazel run -c opt //lingvo/tools:keras2ckpt -- --dataset=mnist --out=/tmp/mnist/mnist\n```\n\nYou will get the following files in `/tmp/mnist`:\n\n*   `mnist.data-00000-of-00001`: 53MB.\n*   `mnist.index`: 241 bytes.\n\n#### Running the model\n\nTo run the trainer in single-machine mode, use\n\n```shell\nbazel build -c opt //lingvo:trainer\nbazel-bin/lingvo/trainer --run_locally=cpu --mode=sync --model=image.mnist.LeNet5 --logdir=/tmp/mnist/log --logtostderr\n```\n\nAfter a few seconds, the training accuracy should reach `85%` at step 100, as\nseen in the following line.\n\n```\nINFO:tensorflow:step:   100 accuracy:0.85546875 log_pplx:0.46025506 loss:0.46025506 num_preds:256 num_samples_in_batch:256\n```\n\nThe artifacts will be produced in `/tmp/mnist/log/control`:\n\n*   `params.txt`: hyper-parameters.\n*   `model_analysis.txt`: model sizes for each layer.\n*   `train.pbtxt`: the training `tf.GraphDef`.\n*   `events.*`: a tensorboard events file.\n\nIn the `/tmp/mnist/log/train` directory, one will obtain:\n\n*   `ckpt-*`: the checkpoint files.\n*   `checkpoint`: a text file containing information about the checkpoint files.\n\n### Running the machine translation model\n\nTo run a more elaborate model, you\'ll need a cluster with GPUs. Please refer to\n`lingvo/tasks/mt/README.md` for more information.\n\n## Current models\n\n### Automatic Speech Recogition\n\n*   [asr.librispeech.Librispeech960Grapheme](https://github.com/tensorflow/lingvo/blob/master/lingvo/tasks/asr/params/librispeech.py)<sup>1,2</sup>\n*   [asr.librispeech.Librispeech960Wpm](https://github.com/tensorflow/lingvo/blob/master/lingvo/tasks/asr/params/librispeech.py)<sup>1,2</sup>\n\n### Image\n\n*   [image.mnist.LeNet5](https://github.com/tensorflow/lingvo/blob/master/lingvo/tasks/image/params/mnist.py)<sup>3</sup>\n\n### Language Modelling\n\n*   [lm.one_billion_wds.WordLevelOneBwdsSimpleSampledSoftmax](https://github.com/tensorflow/lingvo/blob/master/lingvo/tasks/lm/params/one_billion_wds.py)<sup>4</sup>\n\n### Machine Translation\n\n*   [mt.wmt14_en_de.WmtEnDeTransformerBase](https://github.com/tensorflow/lingvo/blob/master/lingvo/tasks/mt/params/wmt14_en_de.py)<sup>5</sup>\n*   [mt.wmt14_en_de.WmtEnDeRNMT](https://github.com/tensorflow/lingvo/blob/master/lingvo/tasks/mt/params/wmt14_en_de.py)<sup>5</sup>\n*   [mt.wmtm16_en_de.WmtCaptionEnDeTransformer](https://github.com/tensorflow/lingvo/blob/master/lingvo/tasks/mt/params/wmtm16_en_de.py)<sup>5</sup>\n\n<font size="-1">\n\n\\[1]: [Listen, Attend and Spell](https://arxiv.org/pdf/1508.01211.pdf). William\nChan, Navdeep Jaitly, Quoc V. Le, and Oriol Vinyals. ICASSP 2016.\n\n\\[2]: [End-to-end Continuous Speech Recognition using Attention-based Recurrent\nNN: First Results](https://arxiv.org/pdf/1412.1602.pdf). Jan Chorowski, Dzmitry\nBahdanau, Kyunghyun Cho, and Yoshua Bengio. arXiv 2014.\n\n\\[3]:\n[Gradient-based learning applied to document recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf).\nYann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. IEEE 1998.\n\n\\[4]:\n[Exploring the Limits of Language Modeling](https://arxiv.org/pdf/1602.02410.pdf).\nRafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu.\narXiv, 2016.\n\n\\[5]: [The Best of Both Worlds: Combining Recent Advances in Neural Machine\nTranslation](http://aclweb.org/anthology/P18-1008). Mia X. Chen, Orhan Firat,\nAnkur Bapna, Melvin Johnson, Wolfgang Macherey, George Foster, Llion Jones, Mike\nSchuster, Noam Shazeer, Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz\nKaiser, Zhifeng Chen, Yonghui Wu, and Macduff Hughes. ACL 2018.\n\n</font>\n\n## References\n\n*   [API Docs](https://tensorflow.github.io/lingvo/)\n\nPlease cite this [paper](https://arxiv.org/abs/1902.08295) when referencing\nLingvo.\n\n```\n@misc{shen2019lingvo,\n    title={Lingvo: a Modular and Scalable Framework for Sequence-to-Sequence Modeling},\n    author={Jonathan Shen and Patrick Nguyen and Yonghui Wu and Zhifeng Chen and others},\n    year={2019},\n    eprint={1902.08295},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}\n```\n'