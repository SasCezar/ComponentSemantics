b'# BertViz\n\nBertViz is a tool for visualizing attention in the Transformer model, supporting all models from the [transformers](https://github.com/huggingface/transformers) library (BERT, GPT-2, XLNet, RoBERTa, XLM, CTRL, etc.). It extends the [Tensor2Tensor visualization tool](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/visualization) by [Llion Jones](https://medium.com/@llionj) and the [transformers](https://github.com/huggingface/transformers) library from [HuggingFace](https://github.com/huggingface).\n\nBlog posts:\n* [Deconstructing BERT, Part 2: Visualizing the Inner Workings of Attention](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1)\n* [OpenAI GPT-2: Understanding Language Generation through Visualization](https://towardsdatascience.com/openai-gpt-2-understanding-language-generation-through-visualization-8252f683b2f8)\n* [Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters](https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77)\n\n\nPaper:\n* [A Multiscale Visualization of Attention in the Transformer Model](https://arxiv.org/pdf/1906.05714.pdf)\n\n## Attention-head view\n\nThe *attention-head view* visualizes the attention patterns produced by one or more attention heads in a given transformer layer.\n\n![Attention-head view](https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_left.png) ![Attention-head view animated](https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_right.gif)\n\nThe attention view supports all models from the Transformers library, including:<br>\n BERT:\n [[Notebook]](https://github.com/jessevig/bertviz/blob/master/head_view_bert.ipynb)\n  [[Colab]](https://colab.research.google.com/drive/1PEHWRHrvxQvYr9NFRC-E_fr3xDq1htCj)<br>\n GPT-2:\n  [[Notebook]](https://github.com/jessevig/bertviz/blob/master/head_view_gpt2.ipynb)\n[[Colab]](https://colab.research.google.com/drive/1c9kBsbvSqpKkmd62u7nfqVhvWr0W8_Lx)<br>\n XLNet: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/head_view_xlnet.ipynb)<br>\nRoBERTa: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/head_view_roberta.ipynb)<br>\nXLM: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/head_view_xlm.ipynb)<br>\nAlbert: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/head_view_albert.ipynb)<br>\nDistilBert: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/head_view_distilbert.ipynb)<br>\n(and others)\n\n## Model view \n\nThe *model view* provides a birds-eye view of attention across all of the model\xe2\x80\x99s layers  and heads.\n\n![Model view](https://raw.githubusercontent.com/jessevig/bertviz/master/images/model_thumbnail.jpg)\n\nThe model view supports all models from the Transformers library, including:<br>\nBERT: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/model_view_bert.ipynb)\n[[Colab]](https://colab.research.google.com/drive/1c73DtKNdl66B0_HF7QXuPenraDp0jHRS)<br>\nGPT2: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/model_view_gpt2.ipynb)\n[[Colab]](https://colab.research.google.com/drive/1y-wfC95Z0aASawYqA34LQeV0_qC9mOto)<br>\n XLNet: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/model_view_xlnet.ipynb)<br>\nRoBERTa: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/model_view_roberta.ipynb)<br>\nXLM: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/model_view_xlm.ipynb)<br>\nAlbert: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/model_view_albert.ipynb)<br>\nDistilBert: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/model_view_distilbert.ipynb)<br>\n(and others)\n\n## Neuron view \nThe *neuron view* visualizes the individual neurons in the query and key vectors and shows how they are used to compute attention.\n\n![Neuron view](https://raw.githubusercontent.com/jessevig/bertviz/master/images/neuron_thumbnail.png)\n\nThe neuron view supports the following three models:<br>\nBERT: [[Notebook]](https://github.com/jessevig/bertviz/blob/master/neuron_view_bert.ipynb) \n[[Colab]](https://colab.research.google.com/drive/1m37iotFeubMrp9qIf9yscXEL1zhxTN2b)<br>\nGPT-2\n[[Notebook]](https://github.com/jessevig/bertviz/blob/master/neuron_view_gpt2.ipynb) \n[[Colab]](https://colab.research.google.com/drive/1s8XCCyxsKvNRWNzjWi5Nl8ZAYZ5YkLm_)<br>\nRoBERTa\n[[Notebook]](https://github.com/jessevig/bertviz/blob/master/neuron_view_roberta.ipynb) \n\n\n## Requirements\n* [Transformers](https://pypi.org/project/transformers/) (version required depends on models used)\n* [PyTorch](https://pytorch.org/) >=1.0.0 \n* [Jupyter](https://jupyter.org/install)\n* [tqdm](https://pypi.org/project/tqdm/)\n* [boto3](https://pypi.org/project/boto3/)\n* [IPython](https://pypi.org/project/ipython/)\n* [requests](https://pypi.org/project/requests/)\n* [regex](https://pypi.org/project/regex/)\n* [sentencepiece](https://pypi.org/project/sentencepiece/)\n\n(See [requirements.txt](https://github.com/jessevig/bertviz/blob/master/requirements.txt))\n\n## Execution\n\n```\ngit clone https://github.com/jessevig/bertviz.git\ncd bertviz\njupyter notebook\n```\n\n## Authors\n\n* [Jesse Vig](https://github.com/jessevig)\n\n## Citation\n\nWhen referencing BertViz, please cite [this paper](https://arxiv.org/abs/1906.05714).\n\n```\n@article{vig2019transformervis,\n  author    = {Jesse Vig},\n  title     = {A Multiscale Visualization of Attention in the Transformer Model},\n  journal   = {arXiv preprint arXiv:1906.05714},\n  year      = {2019},\n  url       = {https://arxiv.org/abs/1906.05714}\n}\n```\n\n## License\n\nThis project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details\n\n## Acknowledgments\n\nThis project incorporates code from the following repos:\n* https://github.com/tensorflow/tensor2tensor\n* https://github.com/huggingface/pytorch-pretrained-BERT\n'