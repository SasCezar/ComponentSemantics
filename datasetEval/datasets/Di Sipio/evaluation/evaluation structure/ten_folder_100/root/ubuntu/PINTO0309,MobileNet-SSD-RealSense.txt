b'# MobileNet-SSD-RealSense\nRaspberryPi3(Raspbian Stretch) or Ubuntu16.04/UbuntuMate + Neural Compute Stick(NCS/NCS2) + RealSense D435(or USB Camera or PiCamera) + MobileNet-SSD(MobileNetSSD)  \n\n**\xe3\x80\x90Notice\xe3\x80\x91December 19, 2018 OpenVINO has supported RaspberryPi + NCS2 !!  \nhttps://software.intel.com/en-us/articles/OpenVINO-RelNotes#inpage-nav-2-2**  \n  \n**\xe3\x80\x90Dec 31, 2018\xe3\x80\x91 `USB Camera + MultiStick + MultiProcess mode` correspondence with NCS2 is completed.**<br>\n**\xe3\x80\x90Jan 04, 2019\xe3\x80\x91 Tune performance four times. MultiStickSSDwithRealSense_OpenVINO_NCS2.py. Core i7 -> NCS2 x1, 48 FPS**<br>\n**\xe3\x80\x90Nov 12, 2019\xe3\x80\x91 Compatible with OpenVINO 2019 R3 + RaspberryPi3/4 + Raspbian Buster.**<br>\n<br><br>\nMeasure the distance to the object with RealSense D435 while performing object detection by MobileNet-SSD(MobileNetSSD) with RaspberryPi 3 boosted with Intel Movidius Neural Compute Stick.<br>\n"USB Camera mode / PiCamera mode" can not measure the distance, but it operates at high speed.<br>\nAnd, This is support for MultiGraph and FaceDetection, MultiProcessing, Background transparentation.<br>\nAnd, This is support for simple clustering function. (To prevent thermal runaway)<br><br>\n## My blog\n**\xe3\x80\x90Japanese Article1\xe3\x80\x91  \n[RaspberryPi3 (Raspbian Stretch) + Intel Movidius Neural Compute Stick(NCS) + RealSenseD435 + MobileNet-SSD(MobileNetSSD) \xe3\x81\xa7\xe9\xab\x98\xe9\x80\x9f\xe3\x81\xab\xe7\x89\xa9\xe4\xbd\x93\xe6\xa4\x9c\xe5\x87\xba\xe3\x81\x97\xe3\x81\xa4\xe3\x81\xa4\xe6\x82\x9f\xe7\xa9\xba\xe3\x82\x84\xe3\x83\xa2\xe3\x83\x8b\xe3\x82\xbf\xe3\x81\xbe\xe3\x81\xa7\xe3\x81\xae\xe8\xb7\x9d\xe9\x9b\xa2\xe3\x82\x92\xe6\xb8\xac\xe3\x82\x8b](https://qiita.com/PINTO/items/1828f97d95fdda45f57d)**<br>\n**\xe3\x80\x90Japanese / English Article2\xe3\x80\x91  \n[Intel also praised me again \xe3\x83\xbd(\xef\xbe\x9f\xe2\x88\x80\xef\xbe\x9f)\xef\xbe\x89 Yeah MobileNet-SSD(MobileNetSSD) object detection and RealSense distance measurement (640x480) with RaspberryPi3 At least 25FPS playback frame rate + 12FPS prediction rate](https://qiita.com/PINTO/items/40abcf33af3ae7ef579d#-english-article)**<br>\n**\xe3\x80\x90Japanese / English Article3\xe3\x80\x91  \n[Detection rate approx. 30FPS RaspberryPi3 Model B(plus none) is slightly later than TX2, acquires object detection rate of MobilenetSSD and corresponds to MultiModel VOC+WIDER FACE](https://qiita.com/PINTO/items/190daa4fddfd2a21f959#-detection-rate-approx-30fps-raspberrypi3-model-bplus-none-is-slightly-later-than-tx2-acquires-object-detection-rate-of-mobilenetssd-and-corresponds-to-multimodel-vocwider-face)**<br>\n**\xe3\x80\x90Japanese Article4\xe3\x80\x91  \n[RaspberryPi3\xe3\x81\xa7\xe8\xa4\x87\xe6\x95\xb0\xe3\x81\xaeMovidius Neural Compute Stick \xe3\x82\x92\xe3\x82\xb7\xe3\x83\xbc\xe3\x83\xa0\xe3\x83\xac\xe3\x82\xb9\xe3\x81\xab\xe3\x82\xaf\xe3\x83\xa9\xe3\x82\xb9\xe3\x82\xbf\xe5\x88\x87\xe3\x82\x8a\xe6\x9b\xbf\xe3\x81\x88\xe3\x81\x97\xe3\x81\xa6\xe9\xab\x98\xe9\x80\x9f\xe6\x8e\xa8\xe8\xab\x96\xe6\x80\xa7\xe8\x83\xbd\xe3\x82\x92\xe7\xb6\xad\xe6\x8c\x81\xe3\x81\x97\xe3\x81\xa4\xe3\x81\xa4\xe7\x86\xb1\xe6\x9a\xb4\xe8\xb5\xb0(\xe5\x86\x85\xe9\x83\xa8\xe6\xb8\xa9\xe5\xba\xa670\xe2\x84\x83\xe5\x89\x8d\xe5\xbe\x8c)\xe3\x82\x92\xe5\x9b\x9e\xe9\x81\xbf\xe3\x81\x99\xe3\x82\x8b](https://qiita.com/PINTO/items/62859125c5381690623c)**<br>\n**\xe3\x80\x90Japanese Article5\xe3\x80\x91  \n[Caffe\xe3\x81\xa7\xe8\xb6\x85\xe8\xbb\xbd\xe9\x87\x8f\xe3\x81\xaa "Semantic Segmentation" \xe3\x81\xae\xe3\x83\xa2\xe3\x83\x87\xe3\x83\xab\xe3\x82\x92\xe7\x94\x9f\xe6\x88\x90\xe3\x81\x99\xe3\x82\x8b Sparse-Quantized CNN 512x1024_10MB_\xe8\xbb\xbd\xe9\x87\x8f\xe3\x83\xa2\xe3\x83\x87\xe3\x83\xab_\xe3\x81\x9d\xe3\x81\xae\xef\xbc\x91](https://qiita.com/PINTO/items/127c84319822a0776420)**<br>\n**\xe3\x80\x90Japanese / English Article6\xe3\x80\x91  \n[Boost RaspberryPi3 with Neural Compute Stick 2 (1 x NCS2) and feel the explosion performance of MobileNet-SSD\xe3\x80\x80(If it is Core i7, 21 FPS)](https://qiita.com/PINTO/items/fc1fcecce4d5600c20bb#boost-raspberrypi3-with-neural-compute-stick-2-1-x-ncs2-and-feel-the-explosion-performance-of-mobilenet-ssdif-it-is-core-i7-21-fps)**<br>\n**\xe3\x80\x90Japanese / English Article7\xe3\x80\x91  \n[[24 FPS] Boost RaspberryPi3 with four Neural Compute Stick 2 (NCS2) MobileNet-SSD / YoloV3 [48 FPS for Core i7]](https://qiita.com/PINTO/items/94d5557fca9911cc892d#24-fps-boost-raspberrypi3-with-four-neural-compute-stick-2-ncs2-mobilenet-ssd--yolov3-48-fps-for-core-i7)**<br>\n**\xe3\x80\x90Japanese / English Article8\xe3\x80\x91  \n[[24 FPS, 48 FPS] RaspberryPi3 + Neural Compute Stick 2, The day when the true power of one NCS2 was drawn out and "Goku" became a true "super saiya-jin"](https://qiita.com/PINTO/items/cb7ba1dae4bfc74a5966#24-fps-48-fps-raspberrypi3--neural-compute-stick-2-the-day-when-the-true-power-of-one-ncs2-was-drawn-out-and-goku-became-a-true-super-saiya-jin)**<br><br>\n\n## Table of contents\n**1. [Summary](#summary)**  \n\xe3\x80\x80**1.1 [Verification environment NCSDK (1)](#verification-environment-1)**  \n\xe3\x80\x80**1.2 [Result of detection rate NCSDK (1)](#result-of-detection-rate-1)**  \n\xe3\x80\x80**1.3 [Verification environment NCSDK (2)](#verification-environment-2)**  \n\xe3\x80\x80**1.4 [Result of detection rate NCSDK (2)](#result-of-detection-rate-2)**  \n**2. [Performance comparison as a mobile application (Based on sensory comparison)](#performance-comparison-as-a-mobile-application-based-on-sensory-comparison)**  \n**3. [Change history](#change-history)**  \n**4. [Motion image](#motion-image)**  \n\xe3\x80\x80**4-1. NCSDK ver**  \n\xe3\x80\x80\xe3\x80\x80**4-1-1. [RealSense Mode about 6.5 FPS \xef\xbc\x88Synchronous screen drawing\xef\xbc\x89](#realsense-mode-about-65-fps-detection--synchronous-screen-drawing--singlestickssdwithrealsensepy)**  \n\xe3\x80\x80\xe3\x80\x80**4-1-2. [RealSense Mode about 25.0 FPS \xef\xbc\x88Asynchronous screen drawing\xef\xbc\x89](#realsense-mode-about-250-fps-asynchronous-screen-drawing--multistickssdwithrealsensepy)**  \n\xe3\x80\x80\xe3\x80\x80**4-1-3. [USB Camera Mode MultiStick x4 Boosted 16.0 FPS+ \xef\xbc\x88Asynchronous screen drawing\xef\xbc\x89](#usb-camera-mode-multistick-x4-boosted-160-fps-asynchronous-screen-drawing--multistickssdwithrealsensepy)**  \n\xe3\x80\x80\xe3\x80\x80**4-1-4. [RealSense Mode SingleStick about 5.0 FPS\xef\xbc\x88Transparent background / Asynchronous screen drawing](#realsense-mode-singlestick-about-50-fpstransparent-background-in-real-time--asynchronous-screen-drawing--multistickssdwithrealsensepy)**  \n\xe3\x80\x80\xe3\x80\x80**4-1-5. [USB Camera Mode MultiStick x3 Boosted \xef\xbc\x88Asynchronous screen drawing / MultiGraph](#usb-camera-mode-multistick-x3-boosted-asynchronous-screen-drawing--multigraphssdfacedetection--facedetection--multistickssdwithrealsensepy)**  \n\xe3\x80\x80\xe3\x80\x80**4-1-6. [Simple clustering function (MultiStick / MultiCluster / Cluster switch cycle / Cluster switch temperature)](#simple-clustering-function-multistick--multicluster--cluster-switch-cycle--cluster-switch-temperature)**  \n\xe3\x80\x80**4-2. OpenVINO ver**  \n\xe3\x80\x80\xe3\x80\x80**4-2-1. [USB Camera Mode NCS2 x 1 Stick + RaspberryPi3\xef\xbc\x88Synchronous screen drawing\xef\xbc\x89](#usb-camera-mode-ncs2-singlestick--raspberrypi3synchronous-screen-drawing--singlestickssdwithusbcamera_openvino_ncs2py)**  \n\xe3\x80\x80\xe3\x80\x80**4-2-2. [USB Camera Mode NCS2 x 1 Stick + Core i7\xef\xbc\x88Synchronous screen drawing\xef\xbc\x89](#usb-camera-mode-ncs2-singlestick--core-i7synchronous-screen-drawing--singlestickssdwithusbcamera_openvino_ncs2py)**  \n\xe3\x80\x80\xe3\x80\x80**4-2-3. [USB Camera Mode NCS2 x 1 Stick + Core i7\xef\xbc\x88Asynchronous screen drawing\xef\xbc\x89](#usb-camera-mode-ncs2-x-1-stick--core-i7asynchronous-screen-drawing--multistickssdwithrealsense_openvino_ncs2py)**  \n\xe3\x80\x80\xe3\x80\x80**4-2-4. [USB Camera Mode NCS2 x 1 Stick + RaspberryPi3\xef\xbc\x88Asynchronous screen drawing\xef\xbc\x89](#usb-camera-mode-ncs2-x-1-stick--raspberrypi3asynchronous-screen-drawing--multistickssdwithrealsense_openvino_ncs2py)**  \n\xe3\x80\x80\xe3\x80\x80**4-2-5. [USB Camera Mode NCS2 x 1 Stick + LattePanda Alpha\xef\xbc\x88Asynchronous screen drawing\xef\xbc\x8948 FPS](#usb-camera-mode-ncs2-x-1-stick--lattepanda-alphaasynchronous-screen-drawing--multistickssdwithrealsense_openvino_ncs2py48-fps)**  \n\xe3\x80\x80\xe3\x80\x80**4-2-6. [PiCamera Mode NCS2 x 1 Stick + RaspberryPi3\xef\xbc\x88Asynchronous screen drawing\xef\xbc\x89](#picamera-mode-ncs2-x-1-stick--raspberrypi3asynchronous-screen-drawing--multistickssdwithpicamera_openvino_ncs2py)**  \n\xe3\x80\x80\xe3\x80\x80**4-2-7. [USB Camera Mode NCS2 x 1 Stick + RaspberryPi4\xef\xbc\x88Asynchronous screen drawing\xef\xbc\x8940 FPS](#usb-camera-mode-ncs2-x-1-stick--raspberrypi4asynchronous-screen-drawing--multistickssdwithusbcamera_openvino_ncs2py)**  \n**5. [Motion diagram of MultiStick](#motion-diagram-of-multistick)**  \n**6. [Environment](#environment)**  \n**7. [Firmware update with Windows 10 PC](#firmware-update-with-windows-10-pc)**  \n**8. [Work with RaspberryPi3 (or PC + Ubuntu16.04 / RaspberryPi + Ubuntu Mate)](#work-with-raspberrypi3-or-pc--ubuntu1604--raspberrypi--ubuntu-mate)**  \n\xe3\x80\x80**8-1. [NCSDK ver (Not compatible with NCS2)](#1ncsdk-ver-not-compatible-with-ncs2)**  \n\xe3\x80\x80**8-2. [OpenVINO ver (Corresponds to NCS2)](#2openvino-ver-corresponds-to-ncs2)**  \n**9. [Execute the program](#execute-the-program)**  \n**10. [\xe3\x80\x90Reference\xe3\x80\x91 MobileNetv2 Model (Caffe) Great Thanks!!](#reference-mobilenetv2-model-caffe-great-thanks)**  \n**11. [Conversion method from Caffe model to NCS model (NCSDK)](#conversion-method-from-caffe-model-to-ncs-model---ncsdk)**  \n**12. [Conversion method from Caffe model to NCS model (OpenVINO)](#conversion-method-from-caffe-model-to-ncs-model---openvino)**  \n**13. [Construction of learning environment and simple test for model (Ubuntu16.04 x86_64 PC + GPU NVIDIA Geforce)](#construction-of-learning-environment-and-simple-test-for-model-ubuntu1604-x86_64-pc--gpunvidia-geforce)**  \n**14. [Reference articles, thanks](#reference-articles-thanks)**  \n\n## Summary\n**Performance measurement result each number of sticks. (It is Detection rate. It is not a Playback rate.)**<br>\n**The best performance can be obtained with QVGA + 5 Sticks.**<br>\n**However, It is important to use a good quality USB camera.**<br><br>\n### Verification environment (1)\n|No.|Item|Contents|\n|:-:|:-|:-|\n|1|Video device|USB Camera (No RealSense D435) **ELP-USB8MP02G-L75 $70**|\n|2|Auxiliary equipment|(Required) self-powered USB2.0 HUB|\n|3|Input resolution|640x480|\n|4|Output resolution|640x480|\n|5|Execution parameters|$ python3 MultiStickSSDwithRealSense.py -mod 1 -wd 640 -ht 480|\n### Result of detection rate (1)\n|No.|Stick count|FPS|Youtube Movie|Note|\n|:-:|:-|:-|:-|:-|\n|1|1 Stick|6 FPS|**https://youtu.be/lNbhutT8hkA**|base line|\n|2|2 Sticks|12 FPS|**https://youtu.be/zuJOhKWoLwc**|6 FPS increase|\n|3|3 Sticks|16.5 FPS|**https://youtu.be/8UDFIJ1Z4v8**|4.5 FPS increase|\n|4|4 Sticks|16.5 FPS|**https://youtu.be/_2xIZ-IZwZc**|No improvement|\n\n### Verification environment (2)\n|No.|Item|Contents|\n|:-:|:-|:-|\n|1|Video device|USB Camera (No RealSense D435) **PlayStationEye $5**|\n|2|Auxiliary equipment|(Required) self-powered USB2.0 HUB|\n|3|Input resolution|320x240|\n|4|Output resolution|320x240|\n|5|Execution parameters|$ python3 MultiStickSSDwithRealSense.py -mod 1 -wd 320 -ht 240|\n### Result of detection rate (2)\n|No.|Stick count|FPS|Youtube Movie|Note|\n|:-:|:-|:-|:-|:-|\n|1|4 Sticks|\xe3\x80\x80 25 FPS|**https://youtu.be/v-Cei1TW88c**||\n|2|5 Sticks|:star: 30 FPS|**https://youtu.be/CL6PTNgWibI**|best performance|\n\n## Performance comparison as a mobile application (Based on sensory comparison)\n\xe2\x97\xaf=HIGH, \xe2\x96\xb3=MEDIUM, \xc3\x97=LOW  \n\n|No.|Model|Speed|Accuracy|Adaptive distance|\n|:-:|:-|:-:|:-:|:-|\n|1|SSD|\xc3\x97|\xe2\x97\xaf|ALL|\n|2|**[MobileNet-SSD](https://github.com/PINTO0309/MobileNet-SSD-RealSense.git)**|\xe2\x96\xb3|\xe2\x96\xb3|Short distance|\n|3|**[YoloV3](https://github.com/PINTO0309/OpenVINO-YoloV3.git)**|\xc3\x97|\xe2\x97\xaf|ALL|\n|4|**[tiny-YoloV3](https://github.com/PINTO0309/OpenVINO-YoloV3.git)**|\xe2\x97\xaf|\xc3\x97|Long distance|\n\n## Change history\n<details><summary>Change history</summary><div>\n[July 14, 2018]\xe3\x80\x80Corresponds to NCSDK v2.05.00.02<br>\n[July 17, 2018]\xe3\x80\x80Corresponds to OpenCV 3.4.2<br>\n[July 21, 2018]\xe3\x80\x80Support for multiprocessing [MultiStickSSDwithRealSense.py]<br>\n[July 23, 2018]\xe3\x80\x80Support for USB Camera Mode [MultiStickSSDwithRealSense.py]<br>\n[July 29, 2018]\xe3\x80\x80Added steps to build learning environment<br>\n[Aug\xe3\x80\x803, 2018]\xe3\x80\x80Background Multi-transparent mode implementation [MultiStickSSDwithRealSense.py]<br>\n[Aug  11, 2018]\xe3\x80\x80CUDA9.0 + cuDNN7.2 compatible with environment construction procedure<br>\n[Aug 14, 2018]\xe3\x80\x80Reference of MobileNetv2 Model added to README and added Facedetection Model<br>\n[Aug 15, 2018]\xe3\x80\x80Bug Fixed. `MultiStickSSDwithRealSense.py` depth_scale be undefined. Pull Requests merged. Thank you Drunkar!!<br>\n[Aug 19, 2018]\xe3\x80\x80\xe3\x80\x90Experimental\xe3\x80\x91 Update Facedetection model [DeepFace] (graph.facedetectXX)<br>\n[Aug 22, 2018]\xe3\x80\x80Separate environment construction procedure of "Raspbian Stretch" and "Ubuntu16.04"<br>\n[Aug 22, 2018]\xe3\x80\x80\xe3\x80\x90Experimental\xe3\x80\x91 FaceDetection model replaced [resnet] (graph.facedetection)<br>\n[Aug 23, 2018]\xe3\x80\x80Added steps to build NCSDKv2<br>\n[Aug 25, 2018]\xe3\x80\x80Added "Detection FPS View" [MultiStickSSDwithRealSense.py]<br>\n[Sep 01, 2018]\xe3\x80\x80FaceDetection model replaced [Mobilenet] (graph.fullfacedetection / graph.shortfacedetection)<br>\n[Sep 01, 2018]\xe3\x80\x80Added support for MultiGraph and FaceDetection mode [MultiStickSSDwithRealSense.py]<br>\n[Sep 04, 2018]\xe3\x80\x80Performance measurement result with 5 sticks is posted<br>\n[Sep 08, 2018]\xe3\x80\x80To prevent thermal runaway, simple clustering function of stick was implemented.<br>\n[Sep 16, 2018]\xe3\x80\x80\xe3\x80\x90Experimental\xe3\x80\x91 Added Semantic Segmentation model [Tensorflow-UNet] (semanticsegmentation_frozen_person.pb)<br>\n[Sep 20, 2018]\xe3\x80\x80\xe3\x80\x90Experimental\xe3\x80\x91 Updated Semantic Segmentation model [Tensorflow-UNet]<br>\n[Oct 07, 2018]\xe3\x80\x80\xe3\x80\x90Experimental\xe3\x80\x91 Added Semantic Segmentation model [caffe-jacinto] (cityscapes5_jsegnet21v2_iter_60000.caffemodel)<br>\n[Oct 10, 2018]\xe3\x80\x80Corresponds to NCSDK 2.08.01<br>\n[Oct 12, 2018]\xe3\x80\x80\xe3\x80\x90Experimental\xe3\x80\x91 Added Semantic Segmentation model [Tensorflow-ENet] (semanticsegmentation_enet.pb) https://github.com/PINTO0309/TensorFlow-ENet.git<br>\n[Dec 22, 2018]\xe3\x80\x80Only "USB Camera + single thread mode" correspondence with NCS 2 is completed<br>\n[Dec 31, 2018]\xe3\x80\x80"USB Camera + MultiStick + MultiProcess mode" correspondence with NCS2 is completed<br>\n[Jan 04, 2019]\xe3\x80\x80Tune performance four times. MultiStickSSDwithRealSense_OpenVINO_NCS2.py<br>\n[Feb 01, 2019]\xe3\x80\x80Pull request merged. Fix Typo. Thanks, nguyen-alexa!!<br>\n[Feb 09, 2019]\xe3\x80\x80Corresponds to PiCamera.<br>\n[Feb 10, 2019]\xe3\x80\x80Added support for SingleStickSSDwithRealSense_OpenVINO_NCS2.py<br>\n[Feb 10, 2019]\xe3\x80\x80Firmware v5.9.13 -> v5.10.6, RealSenseSDK v2.13.0 -> v2.16.5<br>\n[May 01, 2019]\xe3\x80\x80Corresponds to OpenVINO 2019 R1.0.1<br>\n[Nov 12, 2019]\xe3\x80\x80Corresponds to OpenVINO 2019 R3.0<br>\n</div></details><br><br>\n\n## Motion image\n### **RealSense Mode about 6.5 FPS \xef\xbc\x88Detection + Synchronous screen drawing / SingleStickSSDwithRealSense.py\xef\xbc\x89**<br>\n**\xe3\x80\x90YouTube Movie\xe3\x80\x91 https://youtu.be/77cV9fyqJ1w**<br><br>\n![03](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/03.gif)\n![04](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/04.png)<br><br>\n### **RealSense Mode about 25.0 FPS \xef\xbc\x88Asynchronous screen drawing / MultiStickSSDwithRealSense.py\xef\xbc\x89**<br>\n**However, the prediction rate is fairly low.(about 6.5 FPS)**<br>\n**\xe3\x80\x90YouTube Movie\xe3\x80\x91 https://youtu.be/tAf1u9DKkh4**<br><br>\n![09](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/09.gif)<br><br>\n### **USB Camera Mode MultiStick x4 Boosted 16.0 FPS+ \xef\xbc\x88Asynchronous screen drawing / MultiStickSSDwithRealSense.py\xef\xbc\x89**<br>\n**\xe3\x80\x90YouTube Movie\xe3\x80\x91\xe3\x80\x80https://youtu.be/GedDpAc0JyQ**<br><br>\n![10](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/10.gif) ![11](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/11.png)<br>\n### **RealSense Mode SingleStick about 5.0 FPS\xef\xbc\x88Transparent background in real time / Asynchronous screen drawing / MultiStickSSDwithRealSense.py\xef\xbc\x89**<br>\n**\xe3\x80\x90YouTube Movie\xe3\x80\x91\xe3\x80\x80https://youtu.be/ApyX-mN_dYA**<br><br>\n![12](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/12.gif)<br>\n### **USB Camera Mode MultiStick x3 Boosted \xef\xbc\x88Asynchronous screen drawing / MultiGraph(SSD+FaceDetection) / FaceDetection / MultiStickSSDwithRealSense.py\xef\xbc\x89**<br>\n**\xe3\x80\x90YouTube Movie\xe3\x80\x91\xe3\x80\x80https://youtu.be/fQZpuD8mWok**<br><br>\n![13](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/13.gif)<br>\n### **Simple clustering function (MultiStick / MultiCluster / Cluster switch cycle / Cluster switch temperature)**<br>\n![14](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/14.png)<br>\n**[Execution log]**<br>\n![15](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/15.png)\n### **USB Camera Mode NCS2 SingleStick + RaspberryPi3\xef\xbc\x88Synchronous screen drawing / SingleStickSSDwithUSBCamera_OpenVINO_NCS2.py\xef\xbc\x89**<br>\n**\xe3\x80\x90YouTube Movie\xe3\x80\x91\xe3\x80\x80https://youtu.be/GJNkX-ZBuC8**<br><br>\n![16](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/16.gif)<br>\n### **USB Camera Mode NCS2 SingleStick + Core i7\xef\xbc\x88Synchronous screen drawing / SingleStickSSDwithUSBCamera_OpenVINO_NCS2.py\xef\xbc\x89**<br>\n**\xe3\x80\x90YouTube Movie\xe3\x80\x91\xe3\x80\x80https://youtu.be/1ogge90EuqI**<br><br>\n![17](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/17.gif)<br>\n### **USB Camera Mode NCS2 x 1 Stick + Core i7\xef\xbc\x88Asynchronous screen drawing / MultiStickSSDwithRealSense_OpenVINO_NCS2.py\xef\xbc\x89**<br>\n**\xe3\x80\x90YouTube Movie\xe3\x80\x91\xe3\x80\x80https://youtu.be/Nx_rVDgT8uY**<br>\n```bash\n$ python3 MultiStickSSDwithRealSense_OpenVINO_NCS2.py -mod 1 -numncs 1\n```\n![23](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/23.gif)<br>\n### **USB Camera Mode NCS2 x 1 Stick + RaspberryPi3\xef\xbc\x88Asynchronous screen drawing / MultiStickSSDwithRealSense_OpenVINO_NCS2.py\xef\xbc\x89**<br>\n**\xe3\x80\x90YouTube Movie\xe3\x80\x91\xe3\x80\x80https://youtu.be/Xj2rw_5GwlI**<br>\n```bash\n$ python3 MultiStickSSDwithRealSense_OpenVINO_NCS2.py -mod 1 -numncs 1\n```\n![24](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/24.gif)<br>\n### **USB Camera Mode NCS2 x 1 Stick + LattePanda Alpha\xef\xbc\x88Asynchronous screen drawing / MultiStickSSDwithRealSense_OpenVINO_NCS2.py\xef\xbc\x89[48 FPS]**<br>\n**https://twitter.com/PINTO03091/status/1081575747314057219**<br>\n### **PiCamera Mode NCS2 x 1 Stick + RaspberryPi3\xef\xbc\x88Asynchronous screen drawing / MultiStickSSDwithPiCamera_OpenVINO_NCS2.py\xef\xbc\x89**<br>\n```bash\n$ python3 MultiStickSSDwithPiCamera_OpenVINO_NCS2.py\n```\n![25](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/25.gif)<br>\n### **USB Camera Mode NCS2 x 1 Stick + RaspberryPi4\xef\xbc\x88Asynchronous screen drawing / MultiStickSSDwithUSBCamera_OpenVINO_NCS2.py\xef\xbc\x89**<br>\n```\n$ python3 MultiStickSSDwithUSBCamera_OpenVINO_NCS2.py\n```\n![26](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/26.gif)<br>\n<br>\n<br>\n## Motion diagram of MultiStick\n![20](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/20.png)<br>\n## Environment\n1\xef\xbc\x8eRaspberryPi3 + Raspbian Stretch (USB2.0 Port) or RaspberryPi3 + Ubuntu Mate or PC + Ubuntu16.04<br>\n2\xef\xbc\x8eIntel RealSense D435 (Firmware Ver 5.10.6) or USB Camera or PiCamera [Official stable version firmware](https://realsense.intel.com/intel-realsense-downloads/#firmware)<br>\n3\xef\xbc\x8eIntel Neural Compute Stick v1/v2 x\xef\xbc\x91piece or more<br>\n4-1\xef\xbc\x8eOpenCV 3.4.2 (NCSDK)  \n4-2\xef\xbc\x8eOpenCV 4.1.1-openvino (OpenVINO)  \n5\xef\xbc\x8eVFPV3 or TBB (Intel Threading Building Blocks)<br>\n6\xef\xbc\x8eNumpy<br>\n7\xef\xbc\x8ePython3.5<br>\n8\xef\xbc\x8eNCSDK v2.08.01 (It does not work with NCSDK v1.\xe3\x80\x80[v1 version is here](https://github.com/PINTO0309/MobileNet-SSD-RealSense/tree/v1.0))<br>\n9. OpenVINO 2019 R2.0.1  \n10\xef\xbc\x8eRealSenseSDK v2.16.5 (The latest version is unstable) [Official stable version SDK](https://realsense.intel.com/intel-realsense-downloads/#firmware)<br>\n11\xef\xbc\x8eHDMI Display<br>\n\n## Firmware update with Windows 10 PC\n1\xef\xbc\x8eZIP 2 types [(1) Firmware update tool for Windows 10](https://downloadmirror.intel.com/27514/eng/Intel%20RealSense%20D400%20Series%20DFU%20Tool%20for%20Windows.zip)\xe3\x80\x80[(2) The latest firmware bin file](https://downloadmirror.intel.com/28237/eng/Intel%C2%AE%20RealSense%E2%84%A2D400%20Series%20Signed%20Production%20Firmware%20v5_10_6.zip) Download and decompress<br>\n2\xef\xbc\x8eCopy Signed_Image_UVC_5_10_6_0.bin to the same folder as intel-realsense-dfu.exe<br>\n3\xef\xbc\x8eConnect RealSense D435 to USB port<br>\n4\xef\xbc\x8eWait for completion of installation of device driver<br>\n5\xef\xbc\x8eExecute intel-realsense-dfu.exe<br>\n6\xef\xbc\x8e\xe3\x80\x8c1\xe3\x80\x8d Type and press Enter and follow the instructions on the screen to update<br>\n![01](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/01.png)<br>\n7\xef\xbc\x8eFirmware version check \xe3\x80\x8c2\xe3\x80\x8d<br>\n![02](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/02.png)\n\n## Work with RaspberryPi3 (or PC + Ubuntu16.04 / RaspberryPi + Ubuntu Mate)\n### 1.NCSDK ver (Not compatible with NCS2)\n**Use of Virtualbox is not strongly recommended**<br>\n[Note] Japanese Article<br>\nhttps://qiita.com/akitooo/items/6aee8c68cefd46d2a5dc<br>\nhttps://qiita.com/kikuchi_kentaro/items/280ac68ad24759b4c091<br>\n<br>\n[Post of Official Forum]<br>\nhttps://ncsforum.movidius.com/discussion/950/problems-with-python-multiprocessing-using-sdk-2-0-0-4<br>\nhttps://ncsforum.movidius.com/discussion/comment/3921<br>\nhttps://ncsforum.movidius.com/discussion/comment/4316/#Comment_4316<br><br>\n\n1.Execute the following\n```bash\n$ sudo apt update;sudo apt upgrade\n$ sudo reboot\n```\n2.Extend the SWAP area (RaspberryPi+Raspbian Stretch / RaspberryPi+Ubuntu Mate Only)\n```bash\n$ sudo nano /etc/dphys-swapfile\nCONF_SWAPSIZE=2048\n\n$ sudo /etc/init.d/dphys-swapfile restart;swapon -s\n```\n3.Install NSCDK<br>\n```bash\n$ sudo apt install python-pip python3-pip\n$ sudo pip3 install --upgrade pip\n$ sudo pip2 install --upgrade pip\n\n$ cd ~/ncsdk\n$ make uninstall\n$ cd ~;rm -r -f ncsdk\n#=====================================================================================================\n# [Oct 10, 2018] NCSDK 2.08.01 , Tensorflow 1.9.0\n$ git clone -b ncsdk2 http://github.com/Movidius/ncsdk\n#=====================================================================================================\n$ cd ncsdk\n$ nano ncsdk.conf\n\n#MAKE_NJOBS=1\n\xe2\x86\x93\nMAKE_NJOBS=1\n\n$ sudo apt install cython\n$ sudo -H pip3 install cython\n$ sudo -H pip3 install numpy\n$ sudo -H pip3 install pillow\n$ make install\n\n$ cd ~\n$ wget https://github.com/google/protobuf/releases/download/v3.5.1/protobuf-all-3.5.1.tar.gz\n$ tar -zxvf protobuf-all-3.5.1.tar.gz\n$ cd protobuf-3.5.1\n$ ./configure\n$ sudo make -j1\n$ sudo make install\n$ cd python\n$ export LD_LIBRARY_PATH=../src/.libs\n$ python3 setup.py build --cpp_implementation \n$ python3 setup.py test --cpp_implementation\n$ sudo python3 setup.py install --cpp_implementation\n$ sudo ldconfig\n$ protoc --version\n\n# Before executing "make examples", insert Neural Compute Stick into the USB port of the device.\n$ cd ~/ncsdk\n$ make examples -j1\n```\n**\xe3\x80\x90Reference\xe3\x80\x91https://github.com/movidius/ncsdk**<br>\n\n4.Update udev rule\n```bash\n$ sudo apt install -y git libssl-dev libusb-1.0-0-dev pkg-config libgtk-3-dev\n$ sudo apt install -y libglfw3-dev libgl1-mesa-dev libglu1-mesa-dev\n\n$ cd /etc/udev/rules.d/\n$ sudo wget https://raw.githubusercontent.com/IntelRealSense/librealsense/master/config/99-realsense-libusb.rules\n$ sudo udevadm control --reload-rules && udevadm trigger\n```\n5.Upgrade to "cmake 3.11.4"\n```bash\n$ cd ~\n$ wget https://cmake.org/files/v3.11/cmake-3.11.4.tar.gz\n$ tar -zxvf cmake-3.11.4.tar.gz;rm cmake-3.11.4.tar.gz\n$ cd cmake-3.11.4\n$ ./configure --prefix=/home/pi/cmake-3.11.4\n$ make -j1\n$ sudo make install\n$ export PATH=/home/pi/cmake-3.11.4/bin:$PATH\n$ source ~/.bashrc\n$ cmake --version\ncmake version 3.11.4\n```\n6.Register LD_LIBRARY_PATH\n```bash\n$ nano ~/.bashrc\nexport LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\n\n$ source ~/.bashrc\n```\n7.Install TBB (Intel Threading Building Blocks)\n```bash\n$ cd ~\n$ wget https://github.com/PINTO0309/TBBonARMv7/raw/master/libtbb-dev_2018U2_armhf.deb\n$ sudo dpkg -i ~/libtbb-dev_2018U2_armhf.deb\n$ sudo ldconfig\n```\n8.Uninstall old OpenCV (RaspberryPi Only)<br>\n**[Very Important] The highest performance can not be obtained unless VFPV3 is enabled.**\n```bash\n$ cd ~/opencv-3.x.x/build\n$ sudo make uninstall\n$ cd ~\n$ rm -r -f opencv-3.x.x\n$ rm -r -f opencv_contrib-3.x.x\n```\n9.Build install "OpenCV 3.4.2" or Install by deb package.<br>\n**[Very Important] The highest performance can not be obtained unless VFPV3 is enabled.**<br><br>\n**9.1 Build Install (RaspberryPi Only)**\n```bash\n$ sudo apt update && sudo apt upgrade\n$ sudo apt install build-essential cmake pkg-config libjpeg-dev libtiff5-dev \\\nlibjasper-dev libavcodec-dev libavformat-dev libswscale-dev \\\nlibv4l-dev libxvidcore-dev libx264-dev libgtk2.0-dev libgtk-3-dev \\\nlibcanberra-gtk* libatlas-base-dev gfortran python2.7-dev python3-dev\n\n$ cd ~\n$ wget -O opencv.zip https://github.com/Itseez/opencv/archive/3.4.2.zip\n$ unzip opencv.zip;rm opencv.zip\n$ wget -O opencv_contrib.zip https://github.com/Itseez/opencv_contrib/archive/3.4.2.zip\n$ unzip opencv_contrib.zip;rm opencv_contrib.zip\n$ cd ~/opencv-3.4.2/;mkdir build;cd build\n$ cmake -D CMAKE_CXX_FLAGS="-DTBB_USE_GCC_BUILTINS=1 -D__TBB_64BIT_ATOMICS=0" \\\n        -D CMAKE_BUILD_TYPE=RELEASE \\\n        -D CMAKE_INSTALL_PREFIX=/usr/local \\\n        -D INSTALL_PYTHON_EXAMPLES=OFF \\\n        -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib-3.4.2/modules \\\n        -D BUILD_EXAMPLES=OFF \\\n        -D PYTHON_DEFAULT_EXECUTABLE=$(which python3) \\\n        -D INSTALL_PYTHON_EXAMPLES=OFF \\\n        -D BUILD_opencv_python2=ON \\\n        -D BUILD_opencv_python3=ON \\\n        -D WITH_OPENCL=OFF \\\n        -D WITH_OPENGL=ON \\\n        -D WITH_TBB=ON \\\n        -D BUILD_TBB=OFF \\\n        -D WITH_CUDA=OFF \\\n        -D ENABLE_NEON:BOOL=ON \\\n        -D ENABLE_VFPV3=ON \\\n        -D WITH_QT=OFF \\\n        -D BUILD_TESTS=OFF ..\n$ make -j1\n$ sudo make install\n$ sudo ldconfig\n```\n**9.2 Install by deb package (RaspberryPi Only) [I already activated VFPV3 and built it]**\n```bash\n$ cd ~\n$ sudo apt autoremove libopencv3\n$ wget https://github.com/PINTO0309/OpenCVonARMv7/raw/master/libopencv3_3.4.2-20180709.1_armhf.deb\n$ sudo apt install -y ./libopencv3_3.4.2-20180709.1_armhf.deb\n$ sudo ldconfig\n```\n\n10.Install Intel\xc2\xae RealSense\xe2\x84\xa2 SDK 2.0\n```bash\n$ cd ~\n$ sudo apt update;sudo apt upgrade\n$ sudo apt install -y vulkan-utils libvulkan1 libvulkan-dev\n\n# Ubuntu16.04 Only\n$ sudo apt install -y mesa-utils* libglu1* libgles2-mesa-dev libopenal-dev gtk+-3.0\n\n# The latest version is unstable\n$ cd ~/librealsense/build\n$ sudo make uninstall\n$ cd ~\n$ sudo rm -rf librealsense\n\n$ git clone -b v2.16.5 https://github.com/IntelRealSense/librealsense.git\n$ cd ~/librealsense\n$ git checkout -b v2.16.5\n$ mkdir build;cd build\n\n$ cmake .. -DBUILD_EXAMPLES=true -DCMAKE_BUILD_TYPE=Release\n\n# For RaspberryPi3\n$ make -j1\nor\n# For LaptopPC\n$ make -j8\n\n$ sudo make install\n```\n11.Install Python binding\n```bash\n$ cd ~/librealsense/build\n\n#When using with Python 3.x series\n$ cmake .. -DBUILD_PYTHON_BINDINGS=bool:true -DPYTHON_EXECUTABLE=$(which python3)\n\nOR\n\n#When using with Python 2.x series\n$ cmake .. -DBUILD_PYTHON_BINDINGS=bool:true -DPYTHON_EXECUTABLE=$(which python)\n\n# For RaspberryPi3\n$ make -j1\nor\n# For LaptopPC\n$ make -j8\n\n$ sudo make install\n```\n12.Update PYTHON_PATH\n```bash\n$ nano ~/.bashrc\nexport PYTHONPATH=$PYTHONPATH:/usr/local/lib\n\n$ source ~/.bashrc\n```\n13.RealSense SDK import test\n```bash\n$ python3\nPython 3.5.3 (default, Jan 19 2017, 14:11:04) \n[GCC 6.3.0 20170124] on linux\nType "help", "copyright", "credits" or "license" for more information.\n>>> import pyrealsense2\n>>> exit()\n```\n14.Installing the OpenGL package for Python\n```bash\n$ sudo apt-get install -y python-opengl\n$ sudo -H pip3 install pyopengl\n$ sudo -H pip3 install pyopengl_accelerate\n```\n15.Installation of the imutils package. (For PiCamera)\n```bash\n$ sudo apt-get install -y python3-picamera\n$ sudo -H pip3 install imutils --upgrade\n```\n16.Reduce the SWAP area to the default size (RaspberryPi+Raspbian Stretch / RaspberryPi+Ubuntu Mate Only)\n```bash\n$ sudo nano /etc/dphys-swapfile\nCONF_SWAPSIZE=100\n\n$ sudo /etc/init.d/dphys-swapfile restart;swapon -s\n```\n17.Clone a set of resources\n```bash\n$ git clone https://github.com/PINTO0309/MobileNet-SSD-RealSense.git\n```\n18.[Optional] Create a RAM disk folder for movie file placement\n```bash\n$ cd /etc\n$ sudo cp fstab fstab_org\n$ sudo nano fstab\n\n# Mount "/home/pi/movie" on RAM disk.\n# Add below.\ntmpfs /home/pi/movie tmpfs defaults,size=32m,noatime,mode=0777 0 0\n\n$ sudo reboot\n```\n<br>\n<br>\n\n### 2.OpenVINO ver (Corresponds to NCS2)\n1.Execute the following\n```bash\n$ sudo apt update;sudo apt upgrade\n$ sudo reboot\n```\n2.Extend the SWAP area (RaspberryPi+Raspbian Stretch / RaspberryPi+Ubuntu Mate Only)\n```bash\n$ sudo nano /etc/dphys-swapfile\nCONF_SWAPSIZE=2048\n\n$ sudo /etc/init.d/dphys-swapfile restart;swapon -s\n```\n3.Install OpenVINO\n```bash\n$ curl -sc /tmp/cookie "https://drive.google.com/uc?export=download&id=1rBl_3kU4gsx-x2NG2I5uIhvA3fPqm8uE" > /dev/null\n$ CODE="$(awk \'/_warning_/ {print $NF}\' /tmp/cookie)"\n$ curl -Lb /tmp/cookie "https://drive.google.com/uc?export=download&confirm=${CODE}&id=1rBl_3kU4gsx-x2NG2I5uIhvA3fPqm8uE" -o l_openvino_toolkit_ie_p_2018.5.445.tgz\n$ tar -zxvf l_openvino_toolkit_ie_p_2018.5.445.tgz\n$ rm l_openvino_toolkit_ie_p_2018.5.445.tgz\n$ sed -i "s|<INSTALLDIR>|$(pwd)/inference_engine_vpu_arm|" inference_engine_vpu_arm/bin/setupvars.sh\n$ nano ~/.bashrc\n### Add 1 row below\nsource /home/pi/inference_engine_vpu_arm/bin/setupvars.sh\n\n$ source ~/.bashrc\n### Successful if displayed as below\n[setupvars.sh] OpenVINO environment initialized\n\n$ sudo usermod -a -G users "$(whoami)"\n$ sudo reboot\n\n$ uname -a\nLinux raspberrypi 4.14.79-v7+ #1159 SMP Sun Nov 4 17:50:20 GMT 2018 armv7l GNU/Linux\n\n$ sh inference_engine_vpu_arm/install_dependencies/install_NCS_udev_rules.sh\n### It is displayed as follows\nUpdate udev rules so that the toolkit can communicate with your neural compute stick\n[install_NCS_udev_rules.sh] udev rules installed\n```\n4.Update udev rule\n```bash\n$ sudo apt install -y git libssl-dev libusb-1.0-0-dev pkg-config libgtk-3-dev\n$ sudo apt install -y libglfw3-dev libgl1-mesa-dev libglu1-mesa-dev\n\n$ cd /etc/udev/rules.d/\n$ sudo wget https://raw.githubusercontent.com/IntelRealSense/librealsense/master/config/99-realsense-libusb.rules\n$ sudo udevadm control --reload-rules && udevadm trigger\n```\n5.Upgrade to "cmake 3.11.4"\n```bash\n$ cd ~\n$ wget https://cmake.org/files/v3.11/cmake-3.11.4.tar.gz\n$ tar -zxvf cmake-3.11.4.tar.gz;rm cmake-3.11.4.tar.gz\n$ cd cmake-3.11.4\n$ ./configure --prefix=/home/pi/cmake-3.11.4\n$ make -j1\n$ sudo make install\n$ export PATH=/home/pi/cmake-3.11.4/bin:$PATH\n$ source ~/.bashrc\n$ cmake --version\ncmake version 3.11.4\n```\n6.Register LD_LIBRARY_PATH\n```bash\n$ nano ~/.bashrc\nexport LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\n\n$ source ~/.bashrc\n```\n7.Install Intel\xc2\xae RealSense\xe2\x84\xa2 SDK 2.0\n```bash\n$ cd ~\n$ sudo apt update;sudo apt upgrade\n$ sudo apt install -y vulkan-utils libvulkan1 libvulkan-dev\n\n# Ubuntu16.04 Only\n$ sudo apt install -y mesa-utils* libglu1* libgles2-mesa-dev libopenal-dev gtk+-3.0\n\n# The latest version is unstable\n$ cd ~/librealsense/build\n$ sudo make uninstall\n$ cd ~\n$ sudo rm -rf librealsense\n\n$ git clone -b v2.16.5 https://github.com/IntelRealSense/librealsense.git\n$ cd ~/librealsense\n$ git checkout -b v2.16.5\n$ mkdir build;cd build\n\n$ cmake .. -DBUILD_EXAMPLES=false -DCMAKE_BUILD_TYPE=Release\n\n# For RaspberryPi3\n$ make -j1\nor\n# For LaptopPC\n$ make -j8\n\n$ sudo make install\n```\n8.Install Python binding\n```bash\n$ cd ~/librealsense/build\n\n#When using with Python 3.x series\n$ cmake .. -DBUILD_PYTHON_BINDINGS=bool:true -DPYTHON_EXECUTABLE=$(which python3)\n\nOR\n\n#When using with Python 2.x series\n$ cmake .. -DBUILD_PYTHON_BINDINGS=bool:true -DPYTHON_EXECUTABLE=$(which python)\n\n# For RaspberryPi3\n$ make -j1\nor\n# For LaptopPC\n$ make -j8\n\n$ sudo make install\n```\n9.Update PYTHON_PATH\n```bash\n$ nano ~/.bashrc\nexport PYTHONPATH=$PYTHONPATH:/usr/local/lib\n\n$ source ~/.bashrc\n```\n10.RealSense SDK import test\n```bash\n$ python3\nPython 3.5.3 (default, Jan 19 2017, 14:11:04) \n[GCC 6.3.0 20170124] on linux\nType "help", "copyright", "credits" or "license" for more information.\n>>> import pyrealsense2\n>>> exit()\n```\n11.Installing the OpenGL package for Python\n```bash\n$ sudo apt-get install -y python-opengl\n$ sudo -H pip3 install pyopengl\n$ sudo -H pip3 install pyopengl_accelerate\n```\n12.Installation of the imutils package. (For PiCamera)\n```bash\n$ sudo apt-get install -y python3-picamera\n$ sudo -H pip3 install imutils --upgrade\n```\n13.Reduce the SWAP area to the default size (RaspberryPi+Raspbian Stretch / RaspberryPi+Ubuntu Mate Only)\n```bash\n$ sudo nano /etc/dphys-swapfile\nCONF_SWAPSIZE=100\n\n$ sudo /etc/init.d/dphys-swapfile restart;swapon -s\n```\n14.Clone a set of resources\n```bash\n$ git clone https://github.com/PINTO0309/MobileNet-SSD-RealSense.git\n```\n15.[Optional] Create a RAM disk folder for movie file placement\n```bash\n$ cd /etc\n$ sudo cp fstab fstab_org\n$ sudo nano fstab\n\n# Mount "/home/pi/movie" on RAM disk.\n# Add below.\ntmpfs /home/pi/movie tmpfs defaults,size=32m,noatime,mode=0777 0 0\n\n$ sudo reboot\n```\n<br>\n<br>\n\n## Execute the program\n```\n$ python3 MultiStickSSDwithRealSense.py <option1> <option2> ...\n\n<options>\n -grp MVNC graphs Path. (Default=./)\n -mod Camera Mode. (0:=RealSense Mode, 1:=USB Camera Mode. Defalut=0)\n -wd\xe3\x80\x80Width of the frames in the video stream. (USB Camera Mode Only. Default=320)\n -ht\xe3\x80\x80Height of the frames in the video stream. (USB Camera Mode Only. Default=240)\n -tp\xe3\x80\x80TransparentMode. (RealSense Mode Only. 0:=No background transparent, 1:=Background transparent. Default=0)\n -sd\xe3\x80\x80SSDDetectionMode. (0:=Disabled, 1:=Enabled. Default=1)\n -fd\xe3\x80\x80FaceDetectionMode. (0:=Disabled, 1:=Enabled. Default=0)\n -snc stick_num_of_cluster. Number of sticks to be clustered. (0:=Clustering invalid, n:=Number of sticks Default=0)\n -csc cluster_switch_cycle. Cycle of switching active cluster. (n:=millisecond Default=10000)\n -cst cluster_switch_temperature. Temperature threshold to switch active cluster. (n.n:=temperature(Celsius) Default=65.0)\n```\n(Example0) **[MobileNet-SSD + Neural Compute Stick + RealSense D435 Mode + Syncronous](#realsense-mode-about-65-fps-detection--synchronous-screen-drawing--singlestickssdwithrealsensepy)**\n```\n$ sudo raspi-config\n"7.Advanced Options" - "A7 GL Driver" - "G3 Legacy"\n$ cd ~/MobileNet-SSD-RealSense\n$ python3 SingleStickSSDwithRealSense.py\n```\n\n\n(Example1) **[MobileNet-SSD + Neural Compute Stick + RealSense D435 Mode + Asynchronous](#realsense-mode-about-250-fps-asynchronous-screen-drawing--multistickssdwithrealsensepy)**\n```\n$ sudo raspi-config\n"7.Advanced Options" - "A7 GL Driver" - "G3 Legacy"\n$ cd ~/MobileNet-SSD-RealSense\n$ python3 MultiStickSSDwithRealSense.py\n```\n\n(Example2) **[MobileNet-SSD + Neural Compute Stick + USB Camera Mode + Asynchronous](#usb-camera-mode-multistick-x4-boosted-160-fps-asynchronous-screen-drawing--multistickssdwithrealsensepy)**\n```\n$ sudo raspi-config\n"7.Advanced Options" - "A7 GL Driver" - "G3 Legacy"\n$ cd ~/MobileNet-SSD-RealSense\n$ python3 MultiStickSSDwithRealSense.py -mod 1 -wd 640 -ht 480\n$ python3 MultiStickSSDwithRealSense.py -mod 1 -wd 320 -ht 240\n```\n\n(Example3) **[MobileNet-SSD + Neural Compute Stick + RealSense D435 Mode + Asynchronous + Transparent background in real time](#realsense-mode-singlestick-about-50-fpstransparent-background-in-real-time--asynchronous-screen-drawing--multistickssdwithrealsensepy)**\n```\n$ sudo raspi-config\n"7.Advanced Options" - "A7 GL Driver" - "G3 Legacy"\n$ cd ~/MobileNet-SSD-RealSense\n$ python3 MultiStickSSDwithRealSense.py -tp 1\n```\n\n(Example4) **[MobileNet-SSD + FaceDetection + Neural Compute Stick + USB Camera Mode + Asynchronous ](#usb-camera-mode-multistick-x3-boosted-asynchronous-screen-drawing--multigraphssdfacedetection--facedetection--multistickssdwithrealsensepy)**\n```\n$ sudo raspi-config\n"7.Advanced Options" - "A7 GL Driver" - "G3 Legacy"\n$ cd ~/MobileNet-SSD-RealSense\n$ python3 MultiStickSSDwithRealSense.py -mod 1 -wd 640 -ht 480 -fd 1\n```\n\n(Example5) **To prevent thermal runaway, simple clustering function (2 Stick = 1 Cluster)**<br><br>\nWhen a certain cycle or constant temperature is reached, the active cluster switches seamlessly automatically.<br>\nYou must turn on the clustering enable flag.<br>\nThe default switch period is 10 seconds, the default temperature threshold is 65\xc2\xb0C.<br>\nThe number, cycle, and temperature of sticks constituting one cluster can be specified by the start parameter.<br>\nDepending on your environment, please tune to the optimum parameters yourself.<br><br>\n **[1] Number of all sticks = 5<br>\n [2] stick_num_of_cluster = 2<br>\n [3] cluster_switch_cycle = 10sec (10,000millisec)<br>\n [4] cluster_switch_temperature = 65.0\xe2\x84\x83**<br>\n```\n$ sudo raspi-config\n"7.Advanced Options" - "A7 GL Driver" - "G3 Legacy"\n\n$ cd ~/MobileNet-SSD-RealSense\n$ python3 MultiStickSSDwithRealSense.py -mod 1 -snc 2 -csc 10000 -cst 65.0\n```\n**[Simplified drawing of cluster switching]**<br>\n![14](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/14.png)<br>\n**[Execution log]**<br>\n![15](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/15.png)<br><br>\n\n(Example6)\n```\n$ sudo raspi-config\n"7.Advanced Options" - "A7 GL Driver" - "G2 GL (Fake KMS)"\n$ realsense-viewer\n```\n![05](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/05.gif)\n\n(Example7)\n```\n$ sudo raspi-config\n"7.Advanced Options" - "A7 GL Driver" - "G3 Legacy"\n\n$ cd ~/librealsense/wrappers/opencv/build/grabcuts\n$ rs-grabcuts\n```\n![06](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/06.gif)\n\n(Example8)\n```\n$ sudo raspi-config\n"7.Advanced Options" - "A7 GL Driver" - "G3 Legacy"\n\n$ cd ~/librealsense/wrappers/opencv/build/imshow\n$ rs-imshow\n```\n![07](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/07.gif)\n\n(Example9) MobileNet-SSD(OpenCV-DNN) + RealSense D435 + Without Neural Compute Stick\n```\n$ sudo raspi-config\n"7.Advanced Options" - "A7 GL Driver" - "G3 Legacy"\n\n$ cd ~/librealsense/wrappers/opencv/build/dnn\n$ rs-dnn\n```\n![08](https://github.com/PINTO0309/MobileNet-SSD-RealSense/blob/master/media/08.gif)\n<br>\n<br>\n\n## \xe3\x80\x90Reference\xe3\x80\x91 MobileNetv2 Model (Caffe) Great Thanks!!\n**https://github.com/xufeifeiWHU/Mobilenet-v2-on-Movidius-stick.git**\n\n## Conversion method from Caffe model to NCS model - NCSDK\n```bash\n$ cd ~/MobileNet-SSD-RealSense\n$ mvNCCompile ./caffemodel/MobileNetSSD/deploy.prototxt -w ./caffemodel/MobileNetSSD/MobileNetSSD_deploy.caffemodel -s 12\n$ mvNCCompile ./caffemodel/Facedetection/fullface_deploy.prototxt -w ./caffemodel/Facedetection/fullfacedetection.caffemodel -s 12\n$ mvNCCompile ./caffemodel/Facedetection/shortface_deploy.prototxt -w ./caffemodel/Facedetection/shortfacedetection.caffemodel -s 12\n```\n## Conversion method from Caffe model to NCS model - OpenVINO\n```bash\n$ cd ~/MobileNet-SSD-RealSense\n$ sudo python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n--input_model caffemodel/MobileNetSSD/MobileNetSSD_deploy.caffemodel \\\n--input_proto caffemodel/MobileNetSSD/MobileNetSSD_deploy.prototxt \\\n--data_type FP16 \\\n--batch 1\n```\nor\n```bash\n$ cd ~/MobileNet-SSD-RealSense\n$ sudo python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n--input_model caffemodel/MobileNetSSD/MobileNetSSD_deploy.caffemodel \\\n--input_proto caffemodel/MobileNetSSD/MobileNetSSD_deploy.prototxt \\\n--data_type FP32 \\\n--batch 1\n```\n## Construction of learning environment and simple test for model (Ubuntu16.04 x86_64 PC + GPU[NVIDIA Geforce])\n1.**\xe3\x80\x90Example\xe3\x80\x91** Introduction of NVIDIA-Driver, CUDA and cuDNN to the environment with GPU\n```\n$ sudo apt-get remove nvidia-*\n$ sudo apt-get remove cuda-*\n\n$ apt search "^nvidia-[0-9]{3}$"\n$ sudo apt install cuda-9.0\n$ sudo reboot\n$ nvidia-smi\n\n### Download cuDNN v7.2.1 NVIDIA Home Page\n### libcudnn7_7.2.1.38-1+cuda9.0_amd64.deb\n### libcudnn7-dev_7.2.1.38-1+cuda9.0_amd64.deb\n### cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb\n### cuda-repo-ubuntu1604-9-0-local-cublas-performance-update_1.0-1_amd64.deb\n### cuda-repo-ubuntu1604-9-0-local-cublas-performance-update-2_1.0-1_amd64.deb\n### cuda-repo-ubuntu1604-9-0-local-cublas-performance-update-3_1.0-1_amd64.deb\n### cuda-repo-ubuntu1604-9-0-176-local-patch-4_1.0-1_amd64.deb\n\n$ sudo dpkg -i libcudnn7*\n$ sudo dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb\n$ sudo apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n$ sudo apt update\n$ sudo dpkg -i cuda-repo-ubuntu1604-9*\n$ sudo apt update\n$ rm libcudnn7_7.2.1.38-1+cuda9.0_amd64.deb;rm libcudnn7-dev_7.2.1.38-1+cuda9.0_amd64.deb;rm cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb;rm cuda-repo-ubuntu1604-9-0-local-cublas-performance-update_1.0-1_amd64.deb;rm cuda-repo-ubuntu1604-9-0-local-cublas-performance-update-2_1.0-1_amd64.deb;rm cuda-repo-ubuntu1604-9-0-local-cublas-performance-update-3_1.0-1_amd64.deb;rm cuda-repo-ubuntu1604-9-0-176-local-patch-4_1.0-1_amd64.deb\n\n$ echo \'export PATH=/usr/local/cuda-9.0/bin:${PATH}\' >> ~/.bashrc\n$ echo \'export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64:${LD_LIBRARY_PATH}\' >> ~/.bashrc\n$ source ~/.bashrc\n$ sudo ldconfig\n$ nvcc -V\n$ cd ~;nano cudnn_version.cpp\n\n#include <cudnn.h>\n#include <iostream>\n\nint main(int argc, char** argv) {\n    std::cout << "CUDNN_VERSION: " << CUDNN_VERSION << std::endl;\n    return 0;\n}\n\n$ nvcc cudnn_version.cpp -o cudnn_version\n$ ./cudnn_version\n\n$ sudo pip2 uninstall tensorflow-gpu\n$ sudo pip2 install tensorflow-gpu==1.10.0\n$ sudo pip3 uninstall tensorflow-gpu\n$ sudo pip3 install tensorflow-gpu==1.10.0\n```\n2.**\xe3\x80\x90Example\xe3\x80\x91** Introduction of Caffe to environment with GPU\n```\n$ cd ~\n$ sudo apt install libopenblas-base libopenblas-dev\n$ git clone https://github.com/weiliu89/caffe.git\n$ cd caffe\n$ git checkout ssd\n$ cp Makefile.config.example Makefile.config\n$ nano Makefile.config\n```\n\n```\n# cuDNN acceleration switch (uncomment to build with cuDNN).\n#USE_CUDNN := 1\n\xe2\x86\x93\n# cuDNN acceleration switch (uncomment to build with cuDNN).\nUSE_CUDNN := 1\n\n# Uncomment if you\'re using OpenCV 3\n# OPENCV_VERSION := 3\n\xe2\x86\x93\n# Uncomment if you\'re using OpenCV 3\nOPENCV_VERSION := 3\n\n# CUDA directory contains bin/ and lib/ directories that we need.\nCUDA_DIR := /usr/local/cuda\n\xe2\x86\x93\n# CUDA directory contains bin/ and lib/ directories that we need.\nCUDA_DIR := /usr/local/cuda-9.0\n\n# CUDA architecture setting: going with all of them.\n# For CUDA < 6.0, comment the lines after *_35 for compatibility.\nCUDA_ARCH := -gencode arch=compute_20,code=sm_20 \\\n             -gencode arch=compute_20,code=sm_21 \\\n             -gencode arch=compute_30,code=sm_30 \\\n             -gencode arch=compute_35,code=sm_35 \\\n             -gencode arch=compute_50,code=sm_50 \\\n             -gencode arch=compute_52,code=sm_52 \\\n             -gencode arch=compute_61,code=sm_61\n\xe2\x86\x93\n# CUDA architecture setting: going with all of them.\n# For CUDA < 6.0, comment the lines after *_35 for compatibility.\nCUDA_ARCH := -gencode arch=compute_30,code=sm_30 \\\n             -gencode arch=compute_35,code=sm_35 \\\n             -gencode arch=compute_50,code=sm_50 \\\n             -gencode arch=compute_52,code=sm_52 \\\n             -gencode arch=compute_61,code=sm_61\n\n# NOTE: this is required only if you will compile the python interface.\n# We need to be able to find Python.h and numpy/arrayobject.h.\nPYTHON_INCLUDE := /usr/include/python2.7 \\\n\t\t/usr/lib/python2.7/dist-packages/numpy/core/include\n\xe2\x86\x93\n# NOTE: this is required only if you will compile the python interface.\n# We need to be able to find Python.h and numpy/arrayobject.h.\nPYTHON_INCLUDE := /usr/include/python2.7 \\\n\t\t/usr/lib/python2.7/dist-packages/numpy/core/include \\\n                /usr/local/lib/python2.7/dist-packages/numpy/core/include\n\n\n# Uncomment to support layers written in Python (will link against Python libs)\n# WITH_PYTHON_LAYER := 1\n\xe2\x86\x93\n# Uncomment to support layers written in Python (will link against Python libs)\nWITH_PYTHON_LAYER := 1\n\n# Whatever else you find you need goes here.\nINCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include\nLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib\n\xe2\x86\x93\n# Whatever else you find you need goes here.\nINCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include \\\n                /usr/include/hdf5/serial\nLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib \\\n                /usr/lib/x86_64-linux-gnu/hdf5/serial\n\n# Uncomment to use `pkg-config` to specify OpenCV library paths.\n# (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)\n# USE_PKG_CONFIG := 1\n\xe2\x86\x93\n# Uncomment to use `pkg-config` to specify OpenCV library paths.\n# (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)\nUSE_PKG_CONFIG := 1\n```\n\n```\n$ rm -r -f build\n$ rm -r -f .build_release\n$ make superclean\n$ make all -j4\n$ make test -j4\n$ make distribute -j4\n$ export PYTHONPATH=/home/<username>/caffe/python:$PYTHONPATH\n$ make py\n```\n\n3.Download of VGG model [My Example CAFFE_ROOT PATH = "/home/\\<username\\>/caffe"]\n```\n$ export CAFFE_ROOT=/home/<username>/caffe\n$ cd $CAFFE_ROOT/models/VGGNet\n$ wget http://cs.unc.edu/~wliu/projects/ParseNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel\n```\n\n4.Download VOC 2007 and VOC 2012 datasets\n\n```\n# Download the data.\n$ cd ~;mkdir data;cd data\n$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar #<--- 1.86GB\n$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar #<--- 438MB\n$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar #<--- 430MB\n\n# Extract the data.\n$ tar -xvf VOCtrainval_11-May-2012.tar\n$ tar -xvf VOCtrainval_06-Nov-2007.tar\n$ tar -xvf VOCtest_06-Nov-2007.tar\n$ rm VOCtrainval_11-May-2012.tar;rm VOCtrainval_06-Nov-2007.tar;rm VOCtest_06-Nov-2007.tar\n```\n\n5.Generate lmdb file\n```\n$ export CAFFE_ROOT=/home/<username>/caffe\n$ cd $CAFFE_ROOT\n# Create the trainval.txt, test.txt, and test_name_size.txt in $CAFFE_ROOT/data/VOC0712/\n$ ./data/VOC0712/create_list.sh\n\n# You can modify the parameters in create_data.sh if needed.\n# It will create lmdb files for trainval and test with encoded original image:\n#   - $HOME/data/VOCdevkit/VOC0712/lmdb/VOC0712_trainval_lmdb\n#   - $HOME/data/VOCdevkit/VOC0712/lmdb/VOC0712_test_lmdb\n# and make soft links at examples/VOC0712/\n\n$ ./data/VOC0712/create_data.sh\n```\n\n6.Execution of learning [My Example environment GPU x1, GeForce GT 650M = RAM:2GB]<br><br>\nAdjust according to the number of GPU\n```\n# It will create model definition files and save snapshot models in:\n#   - $CAFFE_ROOT/models/VGGNet/VOC0712/SSD_300x300/\n# and job file, log file, and the python script in:\n#   - $CAFFE_ROOT/jobs/VGGNet/VOC0712/SSD_300x300/\n# and save temporary evaluation results in:\n#   - $HOME/data/VOCdevkit/results/VOC2007/SSD_300x300/\n# It should reach 77.* mAP at 120k iterations.\n\n$ export CAFFE_ROOT=/home/<username>/caffe\n$ export PYTHONPATH=/home/<username>/caffe/python:$PYTHONPATH\n$ cd $CAFFE_ROOT\n$ cp examples/ssd/ssd_pascal.py examples/ssd/BK_ssd_pascal.py\n$ nano examples/ssd/ssd_pascal.py\n```\n\n```\n# Solver parameters.\n# Defining which GPUs to use.\ngpus = "0,1,2,3"\n\xe2\x86\x93\n# Solver parameters.\n# Defining which GPUs to use.\ngpus = "0"\n```\n\nAdjust according to GPU performance (Memory Size) [My Example GeForce GT 650M x1 = RAM:2GB]\n```\n# Divide the mini-batch to different GPUs.\nbatch_size = 32\naccum_batch_size = 32\n\xe2\x86\x93\n# Divide the mini-batch to different GPUs.\nbatch_size = 1\naccum_batch_size = 1\n```\n\nExecution\n- The learned data is generated in "$CAFFE_ROOT/models/VGGNet/VOC0712/SSD_300x300"\n- VGG_VOC0712_SSD_300x300_iter_n.caffemodel\n- VGG_VOC0712_SSD_300x300_iter_n.solverstate\n```\n$ export CAFFE_ROOT=/home/<username>/caffe\n$ export PYTHONPATH=/home/<username>/caffe/python:$PYTHONPATH\n$ cd $CAFFE_ROOT\n$ python examples/ssd/ssd_pascal.py\n```\n\n7.Evaluation of learning data (still image)\n```\n$ export CAFFE_ROOT=/home/<username>/caffe\n$ export PYTHONPATH=/home/<username>/caffe/python:$PYTHONPATH\n$ cd $CAFFE_ROOT\n# If you would like to test a model you trained, you can do:\n$ python examples/ssd/score_ssd_pascal.py\n```\n\n8.Evaluation of learning data (USB camera)\n```\n$ export CAFFE_ROOT=/home/<username>/caffe\n$ export PYTHONPATH=/home/<username>/caffe/python:$PYTHONPATH\n$ cd $CAFFE_ROOT\n# If you would like to attach a webcam to a model you trained, you can do:\n$ python examples/ssd/ssd_pascal_webcam.py\n```\n\n## Reference articles, thanks\nhttps://github.com/movidius/ncappzoo/tree/master/caffe/SSD_MobileNet<br>\nhttps://github.com/FreeApe/VGG-or-MobileNet-SSD<br>\nhttps://github.com/chuanqi305/MobileNet-SSD<br>\nhttps://github.com/avBuffer/MobilenetSSD_caffe<br>\nhttps://github.com/Coldmooon/SSD-on-Custom-Dataset<br>\nhttps://github.com/BVLC/caffe/wiki/Ubuntu-16.04-or-15.10-Installation-Guide#the-gpu-support-prerequisites<br>\nhttps://stackoverflow.com/questions/33962226/common-causes-of-nans-during-training<br>\nhttps://github.com/CongWeilin/mtcnn-caffe<br>\nhttps://github.com/DuinoDu/mtcnn.git<br>\nhttps://www.hackster.io/mjrobot/real-time-face-recognition-an-end-to-end-project-a10826<br>\nhttps://github.com/Mjrovai/OpenCV-Face-Recognition.git<br>\nhttps://github.com/sgxu/face-detection-based-on-caffe.git<br>\nhttps://github.com/RiweiChen/DeepFace.git<br>\nhttps://github.com/KatsunoriWa/eval_faceDetectors<br>\nhttps://github.com/BeloborodovDS/MobilenetSSDFace<br>\nhttps://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/<br>\nhttps://github.com/TimoSaemann/ENet/tree/master/Tutorial<br>\nhttps://blog.amedama.jp/entry/2017/04/03/235901<br>\nhttps://github.com/NVIDIA/nvidia-docker<br>\nhttps://hub.docker.com/r/nvidia/cuda/<br>\nhttps://www.dlology.com/blog/how-to-run-keras-model-on-movidius-neural-compute-stick/<br>\nhttps://ncsforum.movidius.com/discussion/1106/ncs-temperature-issue<br>\nhttps://github.com/opencv/opencv/wiki/Intel%27s-Deep-Learning-Inference-Engine-backend<br>\nhttps://github.com/opencv/opencv/wiki/Intel%27s-Deep-Learning-Inference-Engine-backend#raspbian-stretch<br>\nhttps://github.com/skhameneh/OpenVINO-ARM64<br>\n'