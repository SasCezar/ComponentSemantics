b'# Fast Elixir\n\nThere is a wonderful project in Ruby called [fast-ruby](https://github.com/JuanitoFatas/fast-ruby), from which I got the inspiration for this repo. The idea is to collect various idioms for writing performant code when there is more than one _essentially_ symantically identical way of computing something. There may be slight differences, so please be sure that when you\'re changing something that it doesn\'t change the correctness of your program.\n\nEach idiom has a corresponding code example that resides in [code](code).\n\n**Let\'s write faster code, together! <3**\n\n## Measurement Tool\n\nWe use [benchee](https://github.com/PragTob/benchee).\n\n## Contributing\n\nHelp us collect benchmarks! Please [read the contributing guide](CONTRIBUTING.md).\n\n## Idioms\n\n- [Map Lookup vs. Pattern Matching Lookup](#map-lookup-vs-pattern-matching-lookup-code)\n- [IO Lists vs. String Concatenation](#io-lists-vs-string-concatenation-code)\n- [Combining lists with `|` vs. `++`](#combining-lists-with--vs--code)\n- [Putting into maps with `Map.put` and `put_in`](#putting-into-maps-with-mapput-and-put_in-code)\n- [Splitting Large Strings](#splitting-large-strings-code)\n- [`sort` vs. `sort_by`](#sort-vs-sort_by-code)\n- [Retrieving state from ets tables vs. Gen Servers](#retrieving-state-from-ets-tables-vs-gen-servers-code)\n- [Comparing strings vs. atoms](#comparing-strings-vs-atoms-code)\n- [spawn vs. spawn_link](#spawn-vs-spawn_link-code)\n- [Replacements for Enum.filter_map/3](#replacements-for-enumfilter_map3-code)\n- [Filtering maps](#filtering-maps-code)\n\n#### Map Lookup vs. Pattern Matching Lookup [code](code/general/map_lookup_vs_pattern_matching.exs)\n\nIf you need to lookup static values in a key-value based structure, you might at\nfirst consider assigning a map as a module attribute and looking that up.\nHowever, it\'s significantly faster to use pattern matching to define functions\nthat behave like a key-value based data structure.\n\n```\n$ mix run code/general/map_lookup_vs_pattern_matching.exs\nOperating System: macOS\nCPU Information: Intel(R) Core(TM) i5-4260U CPU @ 1.40GHz\nNumber of Available Cores: 4\nAvailable memory: 8 GB\nElixir 1.6.3\nErlang 20.3\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nparallel: 1\ninputs: none specified\nEstimated total run time: 24 s\n\n\nBenchmarking Map Lookup...\nBenchmarking Pattern Matching...\n\nName                       ips        average  deviation         median         99th %\nPattern Matching      891.15 K        1.12 \xce\xbcs   \xc2\xb1458.04%           1 \xce\xbcs           2 \xce\xbcs\nMap Lookup            671.59 K        1.49 \xce\xbcs   \xc2\xb1385.22%        1.40 \xce\xbcs           3 \xce\xbcs\n\nComparison:\nPattern Matching      891.15 K\nMap Lookup            671.59 K - 1.33x slower\n```\n\n#### IO Lists vs. String Concatenation [code](code/general/io_lists_vs_concatenation.exs)\n\nChances are, eventually you\'ll need to concatenate strings for some sort of\noutput. This could be in a web response, a CLI output, or writing to a file. The\nfaster way to do this is to use IO Lists rather than string concatenation or\ninterpolation.\n\n```\n$ mix run code/general/io_lists_vs_concatenation.exs\nOperating System: macOS\nCPU Information: Intel(R) Core(TM) i5-4260U CPU @ 1.40GHz\nNumber of Available Cores: 4\nAvailable memory: 8 GB\nElixir 1.6.3\nErlang 20.3\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nparallel: 1\ninputs: none specified\nEstimated total run time: 24 s\n\n\nBenchmarking IO List...\nBenchmarking Interpolation...\n\n\nName                    ips        average  deviation         median         99th %\nIO List             17.85 K       56.03 \xce\xbcs   \xc2\xb1472.47%          44 \xce\xbcs         132 \xce\xbcs\nInterpolation       16.25 K       61.53 \xce\xbcs   \xc2\xb1436.51%          47 \xce\xbcs         149 \xce\xbcs\n\nComparison:\nIO List             17.85 K\nInterpolation       16.25 K - 1.10x slower\n```\n\n#### Combining lists with `|` vs. `++` [code](code/general/concat_vs_cons.exs)\n\nAdding two lists together might seem like a simple problem to solve, but in\nElixir there are a couple ways to solve that issue. We can use `++` to\nconcatenate two lists easily: `[1, 2] ++ [3, 4] #=> [1, 2, 3, 4]`, but the\nproblem with that approach is that once you start dealing with larger lists it\nbecomes **VERY** slow! Because of this, when combining two lists, you should try\nand use the cons operator (`|`) whenever possible. This will require you to\nremember to flatten the resulting nested list, but it\'s a huge performance\noptimization on larger lists.\n\n```\n$ mix run code/general/concat_vs_cons.exs\nOperating System: macOS\nCPU Information: Intel(R) Core(TM) i5-4260U CPU @ 1.40GHz\nNumber of Available Cores: 4\nAvailable memory: 8 GB\nElixir 1.6.3\nErlang 20.3\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nparallel: 1\ninputs: Large (30,000 items), Medium (3,000 items), Small (30 items)\nEstimated total run time: 1.80 min\n\n\nBenchmarking Concatenation with input Large (30,000 items)...\nBenchmarking Concatenation with input Medium (3,000 items)...\nBenchmarking Concatenation with input Small (30 items)...\nBenchmarking Cons + Flatten with input Large (30,000 items)...\nBenchmarking Cons + Flatten with input Medium (3,000 items)...\nBenchmarking Cons + Flatten with input Small (30 items)...\nBenchmarking Cons + Reverse + Flatten with input Large (30,000 items)...\nBenchmarking Cons + Reverse + Flatten with input Medium (3,000 items)...\nBenchmarking Cons + Reverse + Flatten with input Small (30 items)...\n\n##### With input Large (30,000 items) #####\nName                               ips        average  deviation         median         99th %\nCons + Flatten                 1050.17        0.95 ms    \xc2\xb121.56%        0.91 ms        1.76 ms\nCons + Reverse + Flatten        963.62        1.04 ms    \xc2\xb120.34%        0.95 ms        1.88 ms\nConcatenation                     1.15      873.22 ms     \xc2\xb17.07%      849.37 ms     1057.06 ms\n\nComparison:\nCons + Flatten                 1050.17\nCons + Reverse + Flatten        963.62 - 1.09x slower\nConcatenation                     1.15 - 917.03x slower\n\n##### With input Medium (3,000 items) #####\nName                               ips        average  deviation         median         99th %\nCons + Flatten                 11.43 K       87.45 \xce\xbcs    \xc2\xb123.38%          79 \xce\xbcs      166.32 \xce\xbcs\nCons + Reverse + Flatten       10.88 K       91.93 \xce\xbcs    \xc2\xb183.54%          82 \xce\xbcs         185 \xce\xbcs\nConcatenation                  0.138 K     7263.24 \xce\xbcs    \xc2\xb114.32%        6884 \xce\xbcs    11724.06 \xce\xbcs\n\nComparison:\nCons + Flatten                 11.43 K\nCons + Reverse + Flatten       10.88 K - 1.05x slower\nConcatenation                  0.138 K - 83.05x slower\n\n##### With input Small (30 items) #####\nName                               ips        average  deviation         median         99th %\nCons + Reverse + Flatten      891.07 K        1.12 \xce\xbcs   \xc2\xb1336.67%           1 \xce\xbcs           2 \xce\xbcs\nCons + Flatten                890.95 K        1.12 \xce\xbcs   \xc2\xb1473.42%           1 \xce\xbcs        2.10 \xce\xbcs\nConcatenation                 717.19 K        1.39 \xce\xbcs  \xc2\xb16508.63%           1 \xce\xbcs           2 \xce\xbcs\n\nComparison:\nCons + Reverse + Flatten      891.07 K\nCons + Flatten                890.95 K - 1.00x slower\nConcatenation                 717.19 K - 1.24x slower\n```\n\n#### Putting into maps with `Map.put` and `put_in` [code](code/general/map_put_vs_put_in.exs)\n\nDo not put data into root of map with `put_in`. It is ~2x slower than `Map.put`. Also `put_in/2` is more effective than `put_in/3`.\n\n```\nOperating System: macOS"\nCPU Information: Intel(R) Core(TM) i7-3520M CPU @ 2.90GHz\nNumber of Available Cores: 4\nAvailable memory: 8 GB\nElixir 1.7.4\nErlang 21.2.2\n\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nmemory time: 0 \xce\xbcs\nparallel: 1\ninputs: Large (30,000 items), Medium (3,000 items), Small (30 items)\nEstimated total run time: 1.80 min\n\n\nBenchmarking Map.put/3 with input Large (30,000 items)...\nBenchmarking Map.put/3 with input Medium (3,000 items)...\nBenchmarking Map.put/3 with input Small (30 items)...\nBenchmarking put_in/2 with input Large (30,000 items)...\nBenchmarking put_in/2 with input Medium (3,000 items)...\nBenchmarking put_in/2 with input Small (30 items)...\nBenchmarking put_in/3 with input Large (30,000 items)...\nBenchmarking put_in/3 with input Medium (3,000 items)...\nBenchmarking put_in/3 with input Small (30 items)...\n\n##### With input Large (30,000 items) #####\nName                ips        average  deviation         median         99th %\nMap.put/3        265.12        3.77 ms    \xc2\xb147.11%        3.33 ms       11.35 ms\nput_in/2         186.31        5.37 ms    \xc2\xb121.17%        5.15 ms        8.67 ms\nput_in/3         158.40        6.31 ms    \xc2\xb134.23%        5.84 ms       14.71 ms\n\nComparison:\nMap.put/3        265.12\nput_in/2         186.31 - 1.42x slower\nput_in/3         158.40 - 1.67x slower\n\n##### With input Medium (3,000 items) #####\nName                ips        average  deviation         median         99th %\nMap.put/3        5.68 K      175.93 \xce\xbcs   \xc2\xb1143.04%         151 \xce\xbcs         476 \xce\xbcs\nput_in/2         2.73 K      366.60 \xce\xbcs    \xc2\xb134.11%         334 \xce\xbcs         829 \xce\xbcs\nput_in/3         2.44 K      409.76 \xce\xbcs    \xc2\xb130.36%         372 \xce\xbcs      854.51 \xce\xbcs\n\nComparison:\nMap.put/3        5.68 K\nput_in/2         2.73 K - 2.08x slower\nput_in/3         2.44 K - 2.33x slower\n\n##### With input Small (30 items) #####\nName                ips        average  deviation         median         99th %\nMap.put/3      677.44 K        1.48 \xce\xbcs  \xc2\xb12879.99%           1 \xce\xbcs           3 \xce\xbcs\nput_in/2       362.48 K        2.76 \xce\xbcs  \xc2\xb11833.30%           2 \xce\xbcs           5 \xce\xbcs\nput_in/3       337.47 K        2.96 \xce\xbcs  \xc2\xb11141.45%           3 \xce\xbcs           5 \xce\xbcs\n\nComparison:\nMap.put/3      677.44 K\nput_in/2       362.48 K - 1.87x slower\nput_in/3       337.47 K - 2.01x slower\n```\n\n#### Splitting Large Strings [code](code/general/string_split_large_strings.exs)\n\nDue to a known issue in Erlang, splitting very large strings can be done faster\nusing Elixir\'s streaming approach rather than using `String.split/2`.\n\n```\n$ mix run code/general/string_split_large_strings.exs\nOperating System: macOS\nCPU Information: Intel(R) Core(TM) i5-4260U CPU @ 1.40GHz\nNumber of Available Cores: 4\nAvailable memory: 8 GB\nElixir 1.6.3\nErlang 20.3\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nparallel: 1\ninputs: Large string (1 Million Numbers), Medium string (10 Thousand Numbers), Small string (1 Hundred Numbers)\nEstimated total run time: 1.20 min\n\n\nBenchmarking split with input Large string (1 Million Numbers)...\nBenchmarking split with input Medium string (10 Thousand Numbers)...\nBenchmarking split with input Small string (1 Hundred Numbers)...\nBenchmarking splitter |> to_list with input Large string (1 Million Numbers)...\nBenchmarking splitter |> to_list with input Medium string (10 Thousand Numbers)...\nBenchmarking splitter |> to_list with input Small string (1 Hundred Numbers)...\n\n##### With input Large string (1 Million Numbers) #####\nName                          ips        average  deviation         median         99th %\nsplitter |> to_list          2.81         0.36 s    \xc2\xb117.24%         0.34 s         0.52 s\nsplit                        0.29         3.48 s     \xc2\xb10.24%         3.49 s         3.49 s\n\nComparison:\nsplitter |> to_list          2.81\nsplit                        0.29 - 9.78x slower\n\n##### With input Medium string (10 Thousand Numbers) #####\nName                          ips        average  deviation         median         99th %\nsplit                      1.73 K        0.58 ms    \xc2\xb134.42%        0.71 ms        0.86 ms\nsplitter |> to_list        0.33 K        3.04 ms    \xc2\xb118.95%        3.11 ms        4.76 ms\n\nComparison:\nsplit                      1.73 K\nsplitter |> to_list        0.33 K - 5.25x slower\n\n##### With input Small string (1 Hundred Numbers) #####\nName                          ips        average  deviation         median         99th %\nsplit                    302.83 K        3.30 \xce\xbcs  \xc2\xb11848.10%           3 \xce\xbcs           6 \xce\xbcs\nsplitter |> to_list       48.08 K       20.80 \xce\xbcs   \xc2\xb1215.29%          18 \xce\xbcs          82 \xce\xbcs\n\nComparison:\nsplit                    302.83 K\nsplitter |> to_list       48.08 K - 6.30x slower\n```\n\n#### `sort` vs. `sort_by` [code](code/general/sort_vs_sort_by.exs)\n\nSorting a list of maps or keyword lists can be done in various ways, given that\nthe key-value you want to sort on is the first one defined in the associative\ndata structure. The speed differences are minimal.\n\n```\n$ mix run code/general/sort_vs_sort_by.exs\nOperating System: macOS\nCPU Information: Intel(R) Core(TM) i5-4260U CPU @ 1.40GHz\nNumber of Available Cores: 4\nAvailable memory: 8 GB\nElixir 1.6.3\nErlang 20.3\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nparallel: 1\ninputs: none specified\nEstimated total run time: 36 s\n\n\nBenchmarking sort/1...\nBenchmarking sort/2...\nBenchmarking sort_by/2...\n\nName                ips        average  deviation         median         99th %\nsort/1           4.93 K      202.65 \xce\xbcs    \xc2\xb121.42%         191 \xce\xbcs         409 \xce\xbcs\nsort/2           4.74 K      210.76 \xce\xbcs    \xc2\xb118.83%         199 \xce\xbcs         394 \xce\xbcs\nsort_by/2        4.53 K      220.71 \xce\xbcs    \xc2\xb134.84%         204 \xce\xbcs         438 \xce\xbcs\n\nComparison:\nsort/1           4.93 K\nsort/2           4.74 K - 1.04x slower\nsort_by/2        4.53 K - 1.09x slower\n```\n\n#### Retrieving state from ets tables vs. Gen Servers [code](code/general/ets_vs_gen_server.exs)\n\nThere are many differences between Gen Servers and ets tables, but many people\nhave often praised ets tables for being extremely fast. For the simple case of\nretrieving information from a key-value store, the ets table is indeed much\nfaster for reads. For more complicated use cases, and for comparisons of writes\ninstead of reads, further benchmarks are needed, but so far ets lives up to its\nreputation for speed.\n\n```\n$ mix run code/general/ets_vs_gen_server.exs\nOperating System: macOS\nCPU Information: Intel(R) Core(TM) i5-4260U CPU @ 1.40GHz\nNumber of Available Cores: 4\nAvailable memory: 8 GB\nElixir 1.6.3\nErlang 20.3\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nparallel: 1\ninputs: none specified\nEstimated total run time: 24 s\n\n\nBenchmarking ets table...\nBenchmarking gen server...\n\nName                 ips        average  deviation         median         99th %\nets table         9.12 M       0.110 \xce\xbcs   \xc2\xb1365.39%       0.100 \xce\xbcs        0.23 \xce\xbcs\ngen server        0.29 M        3.46 \xce\xbcs  \xc2\xb12532.35%           3 \xce\xbcs          10 \xce\xbcs\n\nComparison:\nets table         9.12 M\ngen server        0.29 M - 31.53x slower\n```\n\n#### Comparing strings vs. atoms [code](code/general/comparing_strings_vs_atoms.exs)\n\nBecause atoms are stored in a special table in the BEAM, comparing atoms is\nrather fast compared to comparing strings, where you need to compare each part\nof the list that underlies the string. When you have a choice of what type to\nuse, atoms is the faster choice. However, what you probably should not do is\nto convert strings to atoms solely for the perceived speed benefit, since it\nends up being much slower than just comparing the strings, even dozens of times.\n\n```\nOperating System: macOS\nCPU Information: Intel(R) Core(TM) i5-4260U CPU @ 1.40GHz\nNumber of Available Cores: 4\nAvailable memory: 8 GB\nElixir 1.6.3\nErlang 20.3\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nparallel: 1\ninputs: Large (1-100), Medium (1-50), Small (1-5)\nEstimated total run time: 1.80 min\n\n\nBenchmarking Comparing atoms with input Large (1-100)...\nBenchmarking Comparing atoms with input Medium (1-50)...\nBenchmarking Comparing atoms with input Small (1-5)...\nBenchmarking Comparing strings with input Large (1-100)...\nBenchmarking Comparing strings with input Medium (1-50)...\nBenchmarking Comparing strings with input Small (1-5)...\nBenchmarking Converting to atoms and then comparing with input Large (1-100)...\nBenchmarking Converting to atoms and then comparing with input Medium (1-50)...\nBenchmarking Converting to atoms and then comparing with input Small (1-5)...\n\n##### With input Large (1-100) #####\nName                                             ips        average  deviation         median         99th %\nComparing atoms                               8.12 M       0.123 \xce\xbcs    \xc2\xb154.10%       0.120 \xce\xbcs        0.22 \xce\xbcs\nComparing strings                             6.94 M       0.144 \xce\xbcs    \xc2\xb175.54%       0.140 \xce\xbcs        0.25 \xce\xbcs\nConverting to atoms and then comparing        0.68 M        1.47 \xce\xbcs   \xc2\xb1350.78%           1 \xce\xbcs           2 \xce\xbcs\n\nComparison:\nComparing atoms                               8.12 M\nComparing strings                             6.94 M - 1.17x slower\nConverting to atoms and then comparing        0.68 M - 11.95x slower\n\n##### With input Medium (1-50) #####\nName                                             ips        average  deviation         median         99th %\nComparing atoms                               8.05 M       0.124 \xce\xbcs    \xc2\xb186.21%       0.120 \xce\xbcs        0.23 \xce\xbcs\nComparing strings                             6.91 M       0.145 \xce\xbcs    \xc2\xb176.74%       0.140 \xce\xbcs        0.25 \xce\xbcs\nConverting to atoms and then comparing        1.00 M        1.00 \xce\xbcs   \xc2\xb1441.77%           1 \xce\xbcs           2 \xce\xbcs\n\nComparison:\nComparing atoms                               8.05 M\nComparing strings                             6.91 M - 1.17x slower\nConverting to atoms and then comparing        1.00 M - 8.08x slower\n\n##### With input Small (1-5) #####\nName                                             ips        average  deviation         median         99th %\nComparing atoms                               7.99 M       0.125 \xce\xbcs    \xc2\xb185.13%       0.120 \xce\xbcs        0.22 \xce\xbcs\nComparing strings                             6.83 M       0.146 \xce\xbcs    \xc2\xb178.46%       0.140 \xce\xbcs        0.25 \xce\xbcs\nConverting to atoms and then comparing        2.64 M        0.38 \xce\xbcs    \xc2\xb151.12%        0.37 \xce\xbcs        0.59 \xce\xbcs\n\nComparison:\nComparing atoms                               7.99 M\nComparing strings                             6.83 M - 1.17x slower\nConverting to atoms and then comparing        2.64 M - 3.03x slower\n```\n\n### spawn vs. spawn_link [code](code/general/spawn_vs_spawn_link.exs)\n\nThere are two ways to spawn a process on the BEAM, `spawn` and `spawn_link`.\nBecause `spawn_link` links the child process to the process which spawned it, it\ntakes slightly longer. The way in which processes are spawned is unlikely to be\na bottleneck in most applications, though, and the resiliency benefits of OTP\nsupervision trees vastly outweighs the slightly slower run time of `spawn_link`,\nso that should still be favored in nearly every case in which processes need to\nbe spawned.\n\n```\nOperating System: macOS\nCPU Information: Intel(R) Core(TM) i5-4260U CPU @ 1.40GHz\nNumber of Available Cores: 4\nAvailable memory: 8 GB\nElixir 1.7.1\nErlang 21.0\n\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nmemory time: 2 s\nparallel: 1\ninputs: none specified\nEstimated total run time: 28 s\n\n\nBenchmarking spawn/1...\nBenchmarking spawn_link/1...\n\nName                   ips        average  deviation         median         99th %\nspawn/1           507.24 K        1.97 \xce\xbcs  \xc2\xb11950.75%           2 \xce\xbcs           3 \xce\xbcs\nspawn_link/1      436.03 K        2.29 \xce\xbcs  \xc2\xb11224.66%           2 \xce\xbcs           4 \xce\xbcs\n\nComparison:\nspawn/1           507.24 K\nspawn_link/1      436.03 K - 1.16x slower\n\nMemory usage statistics:\n\nName            Memory usage\nspawn/1                144 B\nspawn_link/1           144 B - 1.00x memory usage\n\n**All measurements for memory usage were the same**\n```\n\n#### Replacements for Enum.filter_map/3 [code](code/general/filter_map.exs)\n\nElixir used to have an `Enum.filter_map/3` function that would filter a list and\nalso apply a function to each element in the list that was not removed, but it\nwas deprecated in version 1.5. Luckily there are still four other ways to do\nthat same thing! They\'re all mostly the same, but if you\'re looking for the\noptions with the best performance your best bet is to use either a `for`\ncomprehension or `Enum.reduce/3` and then `Enum.reverse/1`. Using\n`Enum.filter/2` and then `Enum.map/2` is also a fine choice, but it has higher\nmemory usage than the other two options.\n\nThe one option you should avoid is using `Enum.flat_map/2` as it is both slower\nand has higher memory usage.\n\n```\nOperating System: Linux\nCPU Information: Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz\nNumber of Available Cores: 8\nAvailable memory: 15.39 GB\nElixir 1.8.1\nErlang 21.2.6\n\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nmemory time: 10 ms\nparallel: 1\ninputs: Large, Medium, Small\nEstimated total run time: 2.40 min\n\n\nBenchmarking filter |> map with input Large...\nBenchmarking filter |> map with input Medium...\nBenchmarking filter |> map with input Small...\nBenchmarking flat_map with input Large...\nBenchmarking flat_map with input Medium...\nBenchmarking flat_map with input Small...\nBenchmarking for comprehension with input Large...\nBenchmarking for comprehension with input Medium...\nBenchmarking for comprehension with input Small...\nBenchmarking reduce |> reverse with input Large...\nBenchmarking reduce |> reverse with input Medium...\nBenchmarking reduce |> reverse with input Small...\n\n##### With input Small #####\nName                        ips        average  deviation         median         99th %\nreduce |> reverse      167.19 K        5.98 \xce\xbcs   \xc2\xb1308.23%        5.18 \xce\xbcs       12.07 \xce\xbcs\nfilter |> map          163.15 K        6.13 \xce\xbcs   \xc2\xb1296.65%        5.16 \xce\xbcs       11.98 \xce\xbcs\nfor comprehension      157.76 K        6.34 \xce\xbcs   \xc2\xb1269.05%        5.39 \xce\xbcs       12.38 \xce\xbcs\nflat_map               116.20 K        8.61 \xce\xbcs   \xc2\xb1192.50%        7.69 \xce\xbcs       16.06 \xce\xbcs\n\nComparison:\nreduce |> reverse      167.19 K\nfilter |> map          163.15 K - 1.02x slower\nfor comprehension      157.76 K - 1.06x slower\nflat_map               116.20 K - 1.44x slower\n\nMemory usage statistics:\n\nName                 Memory usage\nreduce |> reverse         1.19 KB\nfilter |> map             1.70 KB - 1.43x memory usage\nfor comprehension         1.19 KB - 1.00x memory usage\nflat_map                  1.59 KB - 1.34x memory usage\n\n**All measurements for memory usage were the same**\n\n##### With input Medium #####\nName                        ips        average  deviation         median         99th %\nreduce |> reverse        1.76 K      569.19 \xce\xbcs    \xc2\xb117.54%      532.00 \xce\xbcs     1035.91 \xce\xbcs\nfor comprehension        1.73 K      579.06 \xce\xbcs    \xc2\xb114.77%      548.57 \xce\xbcs      938.81 \xce\xbcs\nfilter |> map            1.72 K      582.49 \xce\xbcs    \xc2\xb119.98%      536.60 \xce\xbcs     1069.09 \xce\xbcs\nflat_map                 1.21 K      824.01 \xce\xbcs    \xc2\xb118.25%      765.08 \xce\xbcs     1535.27 \xce\xbcs\n\nComparison:\nreduce |> reverse        1.76 K\nfor comprehension        1.73 K - 1.02x slower\nfilter |> map            1.72 K - 1.02x slower\nflat_map                 1.21 K - 1.45x slower\n\nMemory usage statistics:\n\nName                 Memory usage\nreduce |> reverse        57.13 KB\nfor comprehension        57.13 KB - 1.00x memory usage\nfilter |> map           109.15 KB - 1.91x memory usage\nflat_map                117.48 KB - 2.06x memory usage\n\n**All measurements for memory usage were the same**\n\n##### With input Large #####\nName                        ips        average  deviation         median         99th %\nfor comprehension         16.48       60.68 ms    \xc2\xb111.70%       58.62 ms       91.09 ms\nfilter |> map             16.35       61.15 ms    \xc2\xb112.88%       59.24 ms       89.90 ms\nreduce |> reverse         16.20       61.72 ms    \xc2\xb114.36%       57.73 ms       83.17 ms\nflat_map                  11.71       85.43 ms    \xc2\xb113.90%       78.94 ms      113.50 ms\n\nComparison:\nfor comprehension         16.48\nfilter |> map             16.35 - 1.01x slower\nreduce |> reverse         16.20 - 1.02x slower\nflat_map                  11.71 - 1.41x slower\n\nMemory usage statistics:\n\nName                 Memory usage\nfor comprehension         8.16 MB\nfilter |> map            13.34 MB - 1.63x memory usage\nreduce |> reverse         8.16 MB - 1.00x memory usage\nflat_map                 13.64 MB - 1.67x memory usage\n\n**All measurements for memory usage were the same**\n```\n\n#### String.slice/3 vs :binary.part/3 [code](code/general/string_slice.exs)\n\nFrom `String.slice/3` [documentation](https://hexdocs.pm/elixir/String.html#slice/3):\nRemember this function works with Unicode graphemes and considers the slices to represent grapheme offsets. If you want to split on raw bytes, check `Kernel.binary_part/3` instead.\n\n```\nOperating System: macOS\nCPU Information: Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz\nNumber of Available Cores: 12\nAvailable memory: 16 GB\nElixir 1.9.1\nErlang 22.0.7\n\nBenchmark suite executing with the following configuration:\nwarmup: 100 ms\ntime: 2 s\nmemory time: 10 ms\nparallel: 1\ninputs: Large string (10 Thousand Numbers), Small string (10 Numbers)\nEstimated total run time: 12.66 s\n\nBenchmarking :binary.part/3 with input Large string (10 Thousand Numbers)...\nBenchmarking :binary.part/3 with input Small string (10 Numbers)...\nBenchmarking String.slice/3 with input Large string (10 Thousand Numbers)...\nBenchmarking String.slice/3 with input Small string (10 Numbers)...\nBenchmarking binary_part/3 with input Large string (10 Thousand Numbers)...\nBenchmarking binary_part/3 with input Small string (10 Numbers)...\n\n##### With input Large string (10 Thousand Numbers) #####\nName                     ips        average  deviation         median         99th %\nbinary_part/3        17.23 M       58.03 ns  \xc2\xb14513.98%          80 ns         180 ns\n:binary.part/3        3.96 M      252.32 ns  \xc2\xb18577.24%           0 ns         980 ns\nString.slice/3        1.39 M      720.21 ns   \xc2\xb1755.41%         980 ns         980 ns\n\nComparison:\nbinary_part/3        17.23 M\n:binary.part/3        3.96 M - 4.35x slower +194.29 ns\nString.slice/3        1.39 M - 12.41x slower +662.18 ns\n\nMemory usage statistics:\n\nName              Memory usage\nbinary_part/3              0 B\n:binary.part/3             0 B - 1.00x memory usage +0 B\nString.slice/3           880 B - \xe2\x88\x9e x memory usage +880 B\n\n**All measurements for memory usage were the same**\n\n##### With input Small string (10 Numbers) #####\nName                     ips        average  deviation         median         99th %\nbinary_part/3        17.25 M       57.97 ns  \xc2\xb14482.36%          80 ns         180 ns\n:binary.part/3       15.71 M       63.64 ns  \xc2\xb16789.17%          80 ns          80 ns\nString.slice/3        1.38 M      726.17 ns  \xc2\xb11532.43%         980 ns         980 ns\n\nComparison:\nbinary_part/3        17.25 M\n:binary.part/3       15.71 M - 1.10x slower +5.67 ns\nString.slice/3        1.38 M - 12.53x slower +668.20 ns\n\nMemory usage statistics:\n\nName              Memory usage\nbinary_part/3              0 B\n:binary.part/3             0 B - 1.00x memory usage +0 B\nString.slice/3           880 B - \xe2\x88\x9e x memory usage +880 B\n\n**All measurements for memory usage were the same**\n```\n\n#### Filtering maps [code](code/general/filtering_maps.exs)\n\nIf we have a map and want to filter out key-value pairs from that map, there are\nseveral ways to do it. However, because of some optimizations in Erlang,\n`:maps.filter/2` is faster than any of the versions implemented in Elixir.\nIf you look at the benchmark code, you\'ll notice that the function used for\nfiltering takes two arguments (the key and value) instead of one (a tuple with\nthe key and value), and it\'s this difference that is responsible for the\ndecreased execution time and memory usage.\n\n```\nOperating System: macOS\nCPU Information: Intel(R) Core(TM) i7-8750H CPU @ 2.20GHz\nNumber of Available Cores: 12\nAvailable memory: 16 GB\nElixir 1.9.1\nErlang 22.1.2\n\nBenchmark suite executing with the following configuration:\nwarmup: 2 s\ntime: 10 s\nmemory time: 1 s\nparallel: 1\ninputs: Large (10_000), Medium (100), Small (1)\nEstimated total run time: 2.60 min\n\nBenchmarking :maps.filter with input Large (10_000)...\nBenchmarking :maps.filter with input Medium (100)...\nBenchmarking :maps.filter with input Small (1)...\nBenchmarking Enum.filter/2 |> Enum.into/2 with input Large (10_000)...\nBenchmarking Enum.filter/2 |> Enum.into/2 with input Medium (100)...\nBenchmarking Enum.filter/2 |> Enum.into/2 with input Small (1)...\nBenchmarking Enum.filter/2 |> Map.new/1 with input Large (10_000)...\nBenchmarking Enum.filter/2 |> Map.new/1 with input Medium (100)...\nBenchmarking Enum.filter/2 |> Map.new/1 with input Small (1)...\nBenchmarking for with input Large (10_000)...\nBenchmarking for with input Medium (100)...\nBenchmarking for with input Small (1)...\n\n##### With input Large (10_000) #####\nName                                   ips        average  deviation         median         99th %\n:maps.filter                        787.95        1.27 ms    \xc2\xb117.36%        1.24 ms        2.09 ms\nfor                                 734.04        1.36 ms    \xc2\xb124.47%        1.31 ms        1.85 ms\nEnum.filter/2 |> Enum.into/2        712.02        1.40 ms    \xc2\xb129.52%        1.37 ms        1.83 ms\nEnum.filter/2 |> Map.new/1          704.65        1.42 ms    \xc2\xb127.76%        1.38 ms        1.89 ms\n\nComparison:\n:maps.filter                        787.95\nfor                                 734.04 - 1.07x slower +0.0932 ms\nEnum.filter/2 |> Enum.into/2        712.02 - 1.11x slower +0.135 ms\nEnum.filter/2 |> Map.new/1          704.65 - 1.12x slower +0.150 ms\n\nMemory usage statistics:\n\nName                            Memory usage\n:maps.filter                       700.70 KB\nfor                                802.84 KB - 1.15x memory usage +102.14 KB\nEnum.filter/2 |> Enum.into/2       802.86 KB - 1.15x memory usage +102.16 KB\nEnum.filter/2 |> Map.new/1         802.86 KB - 1.15x memory usage +102.16 KB\n\n**All measurements for memory usage were the same**\n\n##### With input Medium (100) #####\nName                                   ips        average  deviation         median         99th %\n:maps.filter                      100.64 K        9.94 \xce\xbcs   \xc2\xb1175.28%           9 \xce\xbcs          26 \xce\xbcs\nEnum.filter/2 |> Map.new/1         85.42 K       11.71 \xce\xbcs   \xc2\xb1110.89%          11 \xce\xbcs          32 \xce\xbcs\nfor                                81.34 K       12.29 \xce\xbcs   \xc2\xb1132.99%          11 \xce\xbcs          32 \xce\xbcs\nEnum.filter/2 |> Enum.into/2       80.41 K       12.44 \xce\xbcs   \xc2\xb1120.11%          12 \xce\xbcs          31 \xce\xbcs\n\nComparison:\n:maps.filter                      100.64 K\nEnum.filter/2 |> Map.new/1         85.42 K - 1.18x slower +1.77 \xce\xbcs\nfor                                81.34 K - 1.24x slower +2.36 \xce\xbcs\nEnum.filter/2 |> Enum.into/2       80.41 K - 1.25x slower +2.50 \xce\xbcs\n\nMemory usage statistics:\n\nName                            Memory usage\n:maps.filter                         5.70 KB\nEnum.filter/2 |> Map.new/1           7.84 KB - 1.38x memory usage +2.15 KB\nfor                                  7.84 KB - 1.38x memory usage +2.15 KB\nEnum.filter/2 |> Enum.into/2         7.84 KB - 1.38x memory usage +2.15 KB\n\n**All measurements for memory usage were the same**\n\n##### With input Small (1) #####\nName                                   ips        average  deviation         median         99th %\n:maps.filter                        2.74 M      365.22 ns  \xc2\xb19695.02%           0 ns        1000 ns\nfor                                 2.05 M      487.50 ns  \xc2\xb16665.49%           0 ns        1000 ns\nEnum.filter/2 |> Map.new/1          1.97 M      508.17 ns  \xc2\xb19786.44%           0 ns        1000 ns\nEnum.filter/2 |> Enum.into/2        1.86 M      536.23 ns \xc2\xb110066.95%           0 ns        1000 ns\n\nComparison:\n:maps.filter                        2.74 M\nfor                                 2.05 M - 1.33x slower +122.28 ns\nEnum.filter/2 |> Map.new/1          1.97 M - 1.39x slower +142.95 ns\nEnum.filter/2 |> Enum.into/2        1.86 M - 1.47x slower +171.01 ns\n\nMemory usage statistics:\n\nName                            Memory usage\n:maps.filter                           136 B\nfor                                    248 B - 1.82x memory usage +112 B\nEnum.filter/2 |> Map.new/1             248 B - 1.82x memory usage +112 B\nEnum.filter/2 |> Enum.into/2           248 B - 1.82x memory usage +112 B\n\n**All measurements for memory usage were the same**\n```\n\n## Something went wrong\n\nSomething look wrong to you? :cry: Have a better example? :heart_eyes: Excellent!\n\n[Please open an Issue](https://github.com/devonestes/fast-elixir/issues/new) or [open a Pull Request](https://github.com/devonestes/fast-elixir/pulls) to fix it.\n\nThank you in advance! :wink: :beer:\n\n## Also Checkout\n\n- [Benchmarking in Practice](https://www.youtube.com/watch?v=7-mE5CKXjkw)\n\n  Talk by [@PragTob](https://github.com/PragTob) from ElixirLive 2016 about benchmarking in Elixir.\n\n- [Credo](https://github.com/rrrene/credo)\n\n  Wonderful static analysis tool by [@rrrene](https://github.com/rrrene). It\'s not _just_ about speed, but it will flag some performance issues.\n\n\nBrought to you by [@devoncestes](https://twitter.com/devoncestes)\n\n## License\n\nThis work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).\n\n## Code License\n\n### CC0 1.0 Universal\n\nTo the extent possible under law, @devonestes has waived all copyright and related or neighboring rights to "fast-elixir".\n\nThis work belongs to the community.\n'