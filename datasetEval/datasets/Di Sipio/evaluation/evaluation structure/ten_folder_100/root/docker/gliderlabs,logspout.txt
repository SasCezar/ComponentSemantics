b'# logspout\n\n[![CircleCI](https://img.shields.io/circleci/project/gliderlabs/logspout/release.svg)](https://circleci.com/gh/gliderlabs/logspout)\n[![Docker pulls](https://img.shields.io/docker/pulls/gliderlabs/logspout.svg)](https://hub.docker.com/r/gliderlabs/logspout/)\n[![IRC Channel](https://img.shields.io/badge/irc-%23gliderlabs-blue.svg)](https://kiwiirc.com/client/irc.freenode.net/#gliderlabs)\n\n> Docker Hub automated builds for `gliderlabs/logspout:latest` and `progrium/logspout:latest` are now pointing to the `release` branch. For `master`, use `gliderlabs/logspout:master`. Individual versions are also available as saved images in [releases](https://github.com/gliderlabs/logspout/releases).\n\nLogspout is a log router for Docker containers that runs inside Docker. It attaches to all containers on a host, then routes their logs wherever you want. It also has an extensible module system.\n\nIt\'s a mostly stateless log appliance. It\'s not meant for managing log files or looking at history. It is just a means to get your logs out to live somewhere else, where they belong.\n\nFor now it only captures stdout and stderr, but a module to collect container syslog is planned.\n\n## Getting logspout\n\nLogspout is a very small Docker container (15.2MB virtual, based on [Alpine](https://github.com/gliderlabs/docker-alpine)). Pull the latest release from the index:\n\n\t$ docker pull gliderlabs/logspout:latest\n\nYou can also download and load a specific version:\n\n\t$ curl -s dl.gliderlabs.com/logspout/v2.tgz | docker load\n\n## Using logspout\n\n#### Route all container output to remote syslog\n\nThe simplest way to use logspout is to just take all logs and ship to a remote syslog. Just pass a syslog URI (or several comma separated URIs) as the command. Here we show use of the `tls` encrypted transport option in the URI. Also, we always mount the Docker Unix socket with `-v` to `/var/run/docker.sock`:\n\n\t$ docker run --name="logspout" \\\n\t\t--volume=/var/run/docker.sock:/var/run/docker.sock \\\n\t\tgliderlabs/logspout \\\n\t\tsyslog+tls://logs.papertrailapp.com:55555\n\nlogspout will gather logs from other containers that are started **without the `-t` option** and are configured with a logging driver that works with `docker logs` (`journald` and `json-file`).\n\nTo see what data is used for syslog messages, see the [syslog adapter](http://github.com/gliderlabs/logspout/blob/master/adapters) docs.\n\nThe container must be able to access the Docker Unix socket to mount it. This is typically a problem when [namespace remapping](https://docs.docker.com/engine/security/userns-remap/) is enabled. To disable remapping for the logspout container, pass the `--userns=host` flag to `docker run`, `.. create`, etc. \n\n#### Ignoring specific containers\n\nYou can tell logspout to ignore specific containers by setting an environment variable when starting your container, like so:-\n\n    $ docker run -d -e \'LOGSPOUT=ignore\' image\n\nOr, by adding a label which you define by setting an environment variable when running logspout:\n\n    $ docker run --name="logspout" \\\n        -e EXCLUDE_LABEL=logspout.exclude \\\n        --volume=/var/run/docker.sock:/var/run/docker.sock \\\n        gliderlabs/logspout\n    $ docker run -d --label logspout.exclude=true image\n\n#### Including specific containers\n\nYou can tell logspout to only include certain containers by setting filter parameters on the URI:\n\n\t$ docker run \\\n\t\t--volume=/var/run/docker.sock:/var/run/docker.sock \\\n\t\tgliderlabs/logspout \\\n\t\traw://192.168.10.10:5000?filter.name=*_db\n\t\n\t$ docker run \\\n\t\t--volume=/var/run/docker.sock:/var/run/docker.sock \\\n\t\tgliderlabs/logspout \\\n\t\traw://192.168.10.10:5000?filter.id=3b6ba57db54a\n\t\n\t$ docker run \\\n\t\t--volume=/var/run/docker.sock:/var/run/docker.sock \\\n\t\tgliderlabs/logspout \\\n\t\traw://192.168.10.10:5000?filter.sources=stdout%2Cstderr\n\t\n\t# Forward logs from containers with both label \'a\' starting with \'x\', and label \'b\' ending in \'y\'.\n\t$ docker run \\\n\t\t--volume=/var/run/docker.sock:/var/run/docker.sock \\\n\t\tgliderlabs/logspout \\\n\t\traw://192.168.10.10:5000?filter.labels=a:x*%2Cb:*y\n\nNote that you must URL-encode parameter values such as the comma in `filter.sources` and `filter.labels`.\n\n#### Multiple logging destinations\n\nYou can route to multiple destinations by comma-separating the URIs:\n\n\t$ docker run \\\n\t\t--volume=/var/run/docker.sock:/var/run/docker.sock \\\n\t\tgliderlabs/logspout \\\n\t\traw://192.168.10.10:5000?filter.name=*_db,syslog+tls://logs.papertrailapp.com:55555?filter.name=*_app\n\n#### Suppressing backlog tail\nYou can tell logspout to only display log entries since container "start" or "restart" event by setting a `BACKLOG=false` environment variable (equivalent to `docker logs --since=0s`):\n\n\t$ docker run -d --name="logspout" \\\n\t\t-e \'BACKLOG=false\' \\\n\t\t--volume=/var/run/docker.sock:/var/run/docker.sock \\\n\t\tgliderlabs/logspout\n\nThe default behaviour is to output all logs since creation of the container (equivalent to `docker logs --tail=all` or simply `docker logs`).\n\n> NOTE: Use of this option **may** cause the first few lines of log output to be missed following a container being started, if the container starts outputting logs before logspout has a chance to see them. If consistent capture of *every* line of logs is critical to your application, you might want to test thoroughly and/or avoid this option (at the expense of getting the entire backlog for every restarting container). This does not affect containers that are removed and recreated.\n\n\n#### Environment variable, TAIL\nWhilst BACKLOG=false restricts the tail by setting the Docker Logs.Options.Since to time.Now(), another mechanism to restrict the tail is to set TAIL=n.  Use of this mechanism avoids parsing the earlier content of the logfile which may have a speed advantage if the tail content is of no interest or has become corrupted.\n\n#### Inspect log streams using curl\n\nUsing the [httpstream module](http://github.com/gliderlabs/logspout/blob/master/httpstream), you can connect with curl to see your local aggregated logs in realtime. You can do this without setting up a route URI.\n\n\t$ docker run -d --name="logspout" \\\n\t\t--volume=/var/run/docker.sock:/var/run/docker.sock \\\n\t\t--publish=127.0.0.1:8000:80 \\\n\t\tgliderlabs/logspout\n\t$ curl http://127.0.0.1:8000/logs\n\nYou should see a nicely colored stream of all your container logs. You can filter by container name and more. You can also get JSON objects, or you can upgrade to WebSocket and get JSON logs in your browser.\n\nSee [httpstream module](http://github.com/gliderlabs/logspout/blob/master/httpstream) for all options.\n\n#### Create custom routes via HTTP\n\nUsing the [routesapi module](http://github.com/gliderlabs/logspout/blob/master/routesapi) logspout can also expose a `/routes` resource to create and manage routes.\n\n\t$ curl $(docker port `docker ps -lq` 8000)/routes \\\n\t\t-X POST \\\n\t\t-d \'{"source": {"filter": "db", "types": ["stderr"]}, "target": {"type": "syslog", "addr": "logs.papertrailapp.com:55555"}}\'\n\nThat example creates a new syslog route to [Papertrail](https://papertrailapp.com) of only `stderr` for containers with `db` in their name.\n\nRoutes are stored on disk, so by default routes are ephemeral. You can mount a volume to `/mnt/routes` to persist them.\n\nSee [routesapi module](http://github.com/gliderlabs/logspout/blob/master/routesapi) for all options.\n\n#### Detecting timeouts in Docker log streams\n\nLogspout relies on the Docker API to retrieve container logs. A failure in the API may cause a log stream to hang. Logspout can detect and restart inactive Docker log streams. Use the environment variable `INACTIVITY_TIMEOUT` to enable this feature. E.g.: `INACTIVITY_TIMEOUT=1m` for a 1-minute threshold.\n\n#### Multiline logging\n\nIn order to enable multiline logging, you must first prefix your adapter with the multiline adapter:\n\n\t$ docker run \\\n\t\t--volume=/var/run/docker.sock:/var/run/docker.sock \\\n\t\tgliderlabs/logspout \\\n\t\tmultiline+raw://192.168.10.10:5000?filter.name=*_db\n\nUsing the the above prefix enables multiline logging on all containers by default. To enable it only to specific containers set MULTILINE_ENABLE_DEFAULT=false for logspout, and use the LOGSPOUT_MULTILINE environment variable on the monitored container:\n\n    $ docker run -d -e \'LOGSPOUT_MULTILINE=true\' image\n\n##### MULTILINE_MATCH\n\nUsing the environment variable `MULTILINE_MATCH`=<first|last|nonfirst|nonlast> (default `nonfirst`) you define, which lines should be matched to the `MULTILINE_PATTERN`.\n* first: match first line only and append following messages until you match another line\n* last: concatenate all messages until the pattern matches the next line\n* nonlast: match a line, append upcoming matching lines, also append first non-matching line and start\n* nonfirst: append all matching lines to first line and start over with the next non-matching line\n\n##### Important!\nIf you use multiline logging with raw, it\'s recommended to json encode the Data to avoid line breaks in the output, eg:\n    \n    "RAW_FORMAT={{ toJSON .Data }}\\n"\n\n#### Environment variables\n\n* `ALLOW_TTY` - include logs from containers started with `-t` or `--tty` (i.e. `Allocate a pseudo-TTY`)\n* `BACKLOG` - suppress container tail backlog\n* `TAIL` - specify the number of lines in the log tail to capture when logspout starts (default `all`)\n* `DEBUG` - emit debug logs\n* `EXCLUDE_LABEL` - exclude containers with a given label. The label can have a value of true or a custom value matched with : after the label name like label_name:label_value.\n* `INACTIVITY_TIMEOUT` - detect hang in Docker API (default 0)\n* `HTTP_BIND_ADDRESS` - configure which interface address to listen on (default 0.0.0.0)\n* `PORT` or `HTTP_PORT` - configure which port to listen on (default 80)\n* `RAW_FORMAT` - log format for the raw adapter (default `{{.Data}}\\n`)\n* `RETRY_COUNT` - how many times to retry a broken socket (default 10)\n* `ROUTESPATH` - path to routes (default `/mnt/routes`)\n* `SYSLOG_DATA` - datum for data field (default `{{.Data}}`)\n* `SYSLOG_FORMAT` - syslog format to emit, either `rfc3164` or `rfc5424` (default `rfc5424`)\n* `SYSLOG_HOSTNAME` - datum for hostname field (default `{{.Container.Config.Hostname}}`)\n* `SYSLOG_PID` - datum for pid field (default `{{.Container.State.Pid}}`)\n* `SYSLOG_PRIORITY` - datum for priority field (default `{{.Priority}}`)\n* `SYSLOG_STRUCTURED_DATA` - datum for structured data field\n* `SYSLOG_TAG` - datum for tag field (default `{{.ContainerName}}+route.Options["append_tag"]`)\n* `SYSLOG_TIMESTAMP` - datum for timestamp field (default `{{.Timestamp}}`)\n* `MULTILINE_ENABLE_DEFAULT` - enable multiline logging for all containers when using the multiline adapter (default `true`)\n* `MULTILINE_MATCH` - determines which lines the pattern should match, one of first|last|nonfirst|nonlast, for details see: [MULTILINE_MATCH](#multiline_match) (default `nonfirst`)\n* `MULTILINE_PATTERN` - pattern for multiline logging, see: [MULTILINE_MATCH](#multiline_match) (default: `^\\s`)\n* `MULTILINE_FLUSH_AFTER` - maximum time between the first and last lines of a multiline log entry in milliseconds (default: 500)\n* `MULTILINE_SEPARATOR` - separator between lines for output (default: `\\n`)\n\n#### Raw Format\n\nThe raw adapter has a function `toJSON` that can be used to format the message/fields to generate JSON-like output in a simple way, or full JSON output.\n\nUse examples:\n\n##### Mixed JSON + generic:\n```\n{{ .Time.Format "2006-01-02T15:04:05Z07:00" }} { "container" : "{{ .Container.Name }}", "labels": {{ toJSON .Container.Config.Labels }}, "timestamp": "{{ .Time.Format "2006-01-02T15:04:05Z07:00" }}", "source" : "{{ .Source }}", "message": {{ toJSON .Data }} }\n```\n\n```\n2017-10-26T11:59:32Z { "container" : "/catalogo_worker_1", "image": "sha256:e9bce6c17c80c603c4c8dbac2ad2285982d218f6ea0332f8b0fb84572941b773", "labels": {"com.docker.compose.config-hash":"4f9c3d3bfb2f65e29a4bc8a4a1b3f0a1c8a42323106a5e9106fe9279f8031321","com.docker.compose.container-number":"1","com.docker.compose.oneoff":"False","com.docker.compose.project":"catalogo","com.docker.compose.service":"worker","com.docker.compose.version":"1.16.1","logging":"true"}, "timestamp": "2017-10-26T11:59:32Z", "source" : "stdout", "message": "2017-10-26 11:59:32,950 INFO success: command_bus_0 entered RUNNING state, process has stayed up for \\u003e than 1 seconds (startsecs)" }\n```\n\n##### Full JSON like:\n\n```\n{ "container" : "{{ .Container.Name }}", "labels": {{ toJSON .Container.Config.Labels }}, "timestamp": "{{ .Time.Format "2006-01-02T15:04:05Z07:00" }}", "source" : "{{ .Source }}", "message": {{ toJSON .Data }} }\n```\n\n```json\n{\n  "container": "/a_container",\n  "image": "sha256:e9bce6c17c80c603c4c8dbac2ad2285982d218f6ea0332f8b0fb84572941b773",\n  "labels": {\n    "com.docker.compose.config-hash": "4f9c3d3bfb2f65e29a4bc8a4a1b3f0a1c8a42323106a5e9106fe9279f8031321",\n    "com.docker.compose.container-number": "1",\n    "com.docker.compose.oneoff": "False",\n    "com.docker.compose.project": "a_project",\n    "com.docker.compose.service": "worker",\n    "com.docker.compose.version": "1.16.1",\n    "logging": "true"\n  },\n  "timestamp": "2017-10-26T11:59:32Z",\n  "source": "stdout",\n  "message": "2017-10-26 11:59:32,950 INFO success: command_bus_0 entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)"\n}\n\n```\n\n#### Using Logspout in a swarm\n\nIn a swarm, logspout is best deployed as a global service.  When running logspout with \'docker run\', you can change the value of the hostname field using the `SYSLOG_HOSTNAME` environment variable as explained above. However, this does not work in a compose file because the value for `SYSLOG_HOSTNAME` will be the same for all logspout "tasks", regardless of the docker host on which they run. To support this mode of deployment, the syslog adapter will look for the file `/etc/host_hostname` and, if the file exists and it is not empty, will configure the hostname field with the content of this file. You can then use a volume mount to map a file on the docker hosts with the file `/etc/host_hostname` in the container.  The sample compose file below illustrates how this can be done\n\n```\nversion: "3"\nnetworks:\n  logging:\nservices:\n  logspout:\n    image: gliderlabs/logspout:latest\n    networks:\n      - logging\n    volumes:\n      - /etc/hostname:/etc/host_hostname:ro\n      - /var/run/docker.sock:/var/run/docker.sock\n    command:\n      syslog://svt2-logger.am2.cloudra.local:514\n    deploy:\n      mode: global\n      resources:\n        limits:\n          cpus: \'0.20\'\n          memory: 256M\n        reservations:\n          cpus: \'0.10\'\n          memory: 128M\n```\n\nlogspout can then be deployed as a global service in the swarm with the following command\n\n```bash\ndocker stack deploy --compose-file <name of your compose file> STACK\n```\n\nMore information about services and their mode of deployment can be found here:\nhttps://docs.docker.com/engine/swarm/how-swarm-mode-works/services/ \n\n### TLS Settings\nlogspout supports modification of the client TLS settings via environment variables described below:\n\n| Environment Variable  | Description |\n| :---                  |  :---       |\n| `LOGSPOUT_TLS_DISABLE_SYSTEM_ROOTS` | when set to `true` it disables loading the system trust store into the trust store of logspout |\n| `LOGSPOUT_TLS_CA_CERTS` | a comma seperated list of filesystem paths to pem encoded CA certificates that should be added to logsput\'s TLS trust store. Each pem file can contain more than one certificate |\n| `LOGSPOUT_TLS_CLIENT_CERT` | filesytem path to pem encoded x509 client certificate to load when TLS mutual authentication is desired |\n| `LOGSPOUT_TLS_CLIENT_KEY` | filesytem path to pem encoded client private key to load when TLS mutual authentication is desired |\n| `LOGSPOUT_TLS_HARDENING` | when set to `true` it enables stricter client TLS settings designed to mitigate some known TLS vulnerabilities |\n\n#### Example TLS settings\nThe following settings cover some common use cases.\nWhen running docker, use the `-e` flag to supply environment variables\n\n**add your own CAs to the list of trusted authorities**\n```\nexport LOGSPOUT_TLS_CA_CERTS="/opt/tls/ca/myRootCA1.pem,/opt/tls/ca/myRootCA2.pem"\n```\n\n**force logspout to ONLY trust your own CA**\n```\nexport LOGSPOUT_TLS_DISABLE_SYSTEM_ROOTS=true\nexport LOGSPOUT_TLS_CA_CERTS="/opt/tls/ca/myRootCA1.pem"\n```\n\n**configure client authentication**\n```\nexport LOGSPOUT_TLS_CLIENT_CERT="/opt/tls/client/myClient.pem"\nexport LOGSPOUT_TLS_CLIENT_KEY="/opt/tls/client/myClient-key.pem"\n```\n\n**highest possible security settings (paranoid mode)**\n```\nexport LOGSPOUT_TLS_DISABLE_SYSTEM_ROOTS=true\nexport LOGSPOUT_TLS_HARDENING=true\nexport LOGSPOUT_TLS_CA_CERTS="/opt/tls/ca/myRootCA1.pem"\nexport LOGSPOUT_TLS_CLIENT_CERT="/opt/tls/client/myClient.pem"\nexport LOGSPOUT_TLS_CLIENT_KEY="/opt/tls/client/myClient-key.pem"\n```\n\n## Modules\n\nThe standard distribution of logspout comes with all modules defined in this repository. You can remove or add new modules with custom builds of logspout. In the `custom` dir, edit the `modules.go` file and do a `docker build`.\n\n### Builtin modules\n\n * adapters/raw\n * adapters/syslog\n * transports/tcp\n * transports/tls\n * transports/udp\n * httpstream\n * routesapi\n\n### Third-party modules\n\n * [logspout-kafka](https://github.com/dylanmei/logspout-kafka)\n * logspout-redis...\n * [logspout-logstash](https://github.com/looplab/logspout-logstash)\n * [logspout-redis-logstash](https://github.com/rtoma/logspout-redis-logstash)\n * [logspout-gelf](https://github.com/micahhausler/logspout-gelf) for Graylog\n\n### Loggly support\n\nUse logspout to stream your docker logs to Loggly via the [Loggly syslog endpoint](https://www.loggly.com/docs/streaming-syslog-without-using-files/).\n```\n$ docker run --name logspout -d --volume=/var/run/docker.sock:/var/run/docker.sock \\\n    -e SYSLOG_STRUCTURED_DATA="<Loggly API Key>@41058 tag=\\"some tag name\\"" \\\n    gliderlabs/logspout \\\n    syslog+tcp://logs-01.loggly.com:514\n```\n\n## Contributing\n\nAs usual, pull requests are welcome. You can also propose releases by opening a PR against the `release` branch from `master`. Please be sure to bump the version and update `CHANGELOG.md` and include your changelog text in the PR body.\n\nDiscuss logspout development with us on Freenode in `#gliderlabs`.\n\n## Sponsor\n\nThis project was made possible by [DigitalOcean](http://digitalocean.com) and [Deis](http://deis.io).\n\n## License\n\nBSD\n<img src="https://ga-beacon.appspot.com/UA-58928488-2/logspout/readme?pixel" />\n'