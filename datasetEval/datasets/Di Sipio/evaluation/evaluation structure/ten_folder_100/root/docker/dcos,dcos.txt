b'# DC/OS - The Datacenter Operating System\n\nThe easiest way to run microservices, big data, and containers in production.\n\n\n# What is DC/OS?\n\nLike traditional operating systems, DC/OS is system software that manages computer hardware and software resources and provides common services for computer programs.\n\nUnlike traditional operating systems, DC/OS spans multiple machines within a network, aggregating their resources to maximize utilization by distributed applications.\n\nTo learn more, see the [DC/OS Overview](https://dcos.io/docs/latest/overview/).\n\n\n# How Do I...?\n\n- Learn More - <https://dcos.io/>\n- Find the Docs - <https://dcos.io/docs/>\n- Install - <https://dcos.io/install/>\n- Get Started - <https://dcos.io/get-started/>\n- Get Help - <http://chat.dcos.io/>\n- Join the Discussion - <https://groups.google.com/a/dcos.io/d/forum/users>\n- Report an Issue - <https://jira.dcos.io>\n- Contribute - <https://dcos.io/contribute/>\n\n\n# Releases\n\nDC/OS releases are publicly available on <http://dcos.io/releases/>\n\nRelease artifacts are managed by Mesosphere on Amazon S3, using a CloudFront cache.\n\nTo find the git SHA of any given release, check the latest commit in the versioned branches on GitHub: <https://github.com/dcos/dcos/branches/>\n\n| Release Type | URL Pattern |\n|--------------|--------------------|\n| Latest Stable| `https://downloads.dcos.io/dcos/stable/dcos_generate_config.sh` |\n| Latest Master | `https://downloads.dcos.io/dcos/testing/master/dcos_generate_config.sh` |\n| Specific PR, Latest Build\t| `https://downloads.dcos.io/dcos/testing/pull/<github-pr-number>/dcos_generate_config.sh` |\n\n\n# Development Environment\n\n**Linux is required for building and testing DC/OS.**\n\n1. Linux distribution:\n    - Docker doesn\'t have all the features needed on OS X or Windows\n    - `tar` needs to be GNU tar for the set of flags used\n    - `unzip` needs to be installed\n1. [tox](https://tox.readthedocs.org/en/latest/)\n1. git 1.8.5+\n1. Docker 1.11+\n    - [Install Instructions for various distributions](https://docs.docker.com/engine/installation/). Docker needs to be configured so your user can run docker containers. The command `docker run alpine  /bin/echo \'Hello, World!\'` when run at a new terminal as your user should just print `"Hello, World!"`. If it says something like "Unable to find image \'alpine:latest\' locally" then re-run and the message should go away.\n1. Python 3.6\n    - Arch Linux: `sudo pacman -S python`\n    - Fedora 23 Workstation: Already installed by default / no steps\n    - Ubuntu 16.04 LTS:\n        - [pyenv-installer](https://github.com/yyuu/pyenv-installer)\n        - Python dependencies: `sudo apt-get install make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils liblzma-dev python3-venv`\n        - Install Python 3.6.3: `pyenv install 3.6.3`\n        - Create DC/OS virtualenv: `pyenv virtualenv 3.6.3 dcos`\n        - Activate environment: `pyenv activate dcos`\n1. Over 10GB of free disk space and 8GB of RAM\n    - The build makes use of hard links, so if you\'re using VirtualBox the disk space cannot be a synced folder.\n1. _Optional_ pxz (speeds up package and bootstrap compression)\n    - ArchLinux: [pxz-git in the AUR](https://aur.archlinux.org/packages/pxz-git). The pxz package corrupts tarballs fairly frequently.\n    - Fedora 23: `sudo dnf install pxz`\n\n# Unit Tests\n\nUnit tests can be run locally but require the [development environment](#development-environment) specified above.\n\n```\ntox\n```\n\n[Tox](https://tox.readthedocs.io/en/latest/) is used to run the codebase unit tests, as well as coding standard checks. The config is in `tox.ini`.\n\n\n# Integration Tests\n\nIntegration tests can be run on any deployed DC/OS cluster. For installation instructions, see <https://dcos.io/install/>.\n\nIntegration tests are installed via the [dcos-integration-test](./packages/dcos-integration-test/) Pkgpanda package.\n\nIntegration test files are stored on the DC/OS master node at `/opt/mesosphere/active/dcos-integration-test`.\nTherefore, in order to test changes to test files, move files from `packages/dcos-integration-test/extra/` in your checkout to `/opt/mesosphere/active/dcos-integration-test` on the master node.\n\nThe canonical source of the test suite\'s results is the continuous integration system.\nThere may be differences between the results of running the integration tests as described in this document and the results given by the continuous integration system.\nIn particular, some tests may pass on the continuous integration system and fail locally or vice versa.\n\n## Minimum Requirements\n\n- 1 master node\n- 2 private agent nodes\n- 1 public agent node\n- Task resource allocation is currently insignificantly small\n- DC/OS itself requires at least 2 (virtual) cpu cores on each node\n\n## Instructions\n\n1. SSH into a master node\nThe tests can be run via Pytest while SSH\'d as root into a master node of the cluster to be tested.\n\n1. Switch to root\n\n    ```\n    sudo su -\n    ```\n\n1. Add the test user\n\n    ```\n    dcos-shell python /opt/mesosphere/bin/dcos_add_user.py albert@bekstil.net\n    ```\n\n    Running the above mentioned command will result in an output\n\n    ```\n    User albert@bekstil.net successfully added\n    ```\n\n    This test user has a known login token with far future expiration. DO NOT USE IN PRODUCTION.\n    After the test, remember to delete the test user.\n\n    For more information, see [User Management](https://docs.mesosphere.com/latest/security/oss/user-management/).\n\n\n2. Run the tests using pytest in the cluster.\n\n    ```\n    cd /opt/mesosphere/active/dcos-integration-test\n    dcos-shell pytest\n    ```\n\n## Using a Docker Cluster with miniDC/OS\n\nOne way to run the integration tests is to use the [miniDC/OS CLI](https://minidcos.readthedocs.io/en/latest/).\n\nThis lets you create, run and manage clusters in test environments.\nEach DC/OS node is represented by a Docker container.\n\n1. Setup DC/OS in containers using the [miniDC/OS CLI](http://minidcos.readthedocs.io/en/latest/).\n\nFor example, after [installing the miniDC/OS CLI](http://minidcos.readthedocs.io/en/latest/#installation), create a cluster:\n\n```\nminidcos docker download-installer\nminidcos docker create /tmp/dcos_generate_config.sh \\\n    --masters 1 \\\n    --agents 2 \\\n    --public-agents 1 \\\n    --cluster-id default\n```\n\n2. Run `minidcos docker wait`\n\nWait for DC/OS to start.\nRunning wait command allows to make sure that the cluster is set up properly before any other actions that could otherwise cause errors in `pytest` command in the next step.\n\n3. Run `pytest` on a master node.\n\nFor example:\n\n```\nminidcos docker run --test-env pytest\n```\n\n4. Destroy the cluster.\n\n```\nminidcos docker destroy\n```\n\n# Build\n\nDC/OS can be built locally but requires the [development environment](#development-environment) specified above.\n\nDC/OS builds are packaged as a self-extracting Docker image wrapped in a bash script called `dcos_generate_config.sh`.\n\n**WARNING**: Building a release from scratch the first time on a modern dev machine (4 cores / 8 hyper threads, SSD, reasonable internet bandwidth) takes about 1 hour.\n\n## Instructions\n\n```\n./build_local.sh\n```\n\nThat will run a simple local build, and output the resulting DC/OS installers to `./packages/cache/dcos_generate_config.sh`:\n\n```\n$ ./packages/cache/dcos_generate_config.sh\n```\n\nSee the section on [running in Docker](#using-a-docker-cluster-with-minidcos) to test the installer.\n\n## Build Details\n\nIf you look inside of the bash script `build_local.sh` there are the commands with descriptions of each.\n\nThe general flow is to:\n 1. Check the environment is reasonable\n 2. Write a `release` tool configuration if one doesn\'t exist\n 3. Setup a python virtualenv where we can install the DC/OS python tools to in order to run them\n 4. Install the DC/OS python tools to the virtualenv\n 5. Build the release using the `release` tool\n\nThese steps can all be done by hand and customized / tweaked like standard python projects. You can hand create a virtualenvironment, and then do an editable pip install (`pip install -e`) to have a "live" working environment (as you change code you can run the tool and see the results).\n\n## Release Tool Configuration\n\nThis release tool always loads the config in `dcos-release.config.yaml` in the current directory.\n\nThe config is [YAML](http://yaml.org/). Inside it has two main sections. `storage` which contains a dictionary of different storage providers which the built artifacts should be sent to, and `options` which sets general DC/OS build configuration options.\n\nConfig values can either be specified directly, or you may use $ prefixed environment variables (the env variable must set the whole value).\n\n### Storage Providers\n\nAll the available storage providers are in [release/storage](./release/storage/). The configuration is a dictionary of a reference name for the storage provider (local, aws, my_azure), to the configuration.\n\nEach storage provider (ex: aws.py) is an available kind prefix. The dictionary `factories` defines the suffix for a particular kind. For instance `kind: aws_s3` would map to the S3StorageProvider.\n\nThe configuration options for a storage provider are the storage provider\'s constructor parameters.\n\nSample config storage that will save to my home directory (/home/cmaloney):\n```yaml\nstorage:\n  local:\n    kind: local_path\n    path: /home/cmaloney/dcos-artifacts\n```\n\nSample config that will store to a local archive path as well as AWS S3. To authenticate with AWS S3, reference the [boto3 docs](http://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials) to learn how to configure access.\n```yaml\nstorage:\n  aws:\n    kind: aws_s3\n    bucket: downloads.dcos.io\n    object_prefix: dcos\n    download_url: https://downloads.dcos.io/dcos/\n  local:\n    kind: local_path\n    path: /mnt/big_artifact_store/dcos/\n```\n\n# Repo Structure\n\nDC/OS itself is composed of many individual components precisely configured to work together in concert.\n\nThis repo contains the release and package building tools necessary to produce installers for various on-premises and cloud platforms.\n\n| Directory | Contents |\n| --------- | -------- |\n| *cloud_images*       | Base OS image building tools\n| *config*             | Release configuration\n| *docs*               | Documentation\n| *flake8_dcos_lint*   | Flake8 plugin for testing code quality\n| *dcos_installer*     | Backend for Web, SSH, and some bits of the Advanced installer. Code is being cleaned up\n| *gen*                | Python library for rendering yaml config files for various platforms into packages, with utilities to do things like make "late binding" config set by CloudFormation\n| *packages*           | Packages which make up DC/OS (Mesos, Marathon, AdminRouter, etc). These packages are built by pkgpanda, and combined into a "bootstrap" tarball for deployment.\n| *pkgpanda*           | DC/OS baseline/host package management system. Tools for building, deploying, upgrading, and bundling packages together which live on the root filesystem of a machine / underneath Mesos.\n| *release*            | Release tools for DC/OS. (Building releases, building installers for releases, promoting between channels)\n| *ssh*                | AsyncIO based parallel ssh library used by the installer\n| *test_util*          | various scripts, utilities to help with integration testing\n\n\n# Pull Requests Statuses\n\nPull requests automatically trigger a new DC/OS build and run several tests. These are the details on the various status checks against a DC/OS Pull Request.\n\n| Status Check                                   | Purpose                                                                                                                 | Source and Dependencies                                                                                |\n|------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|\n| continuous-integration/jenkins/pr-head         | Admin Router Endpoint tests                                                                                             | [dcos/dcos/packages/adminrouter/extra/src/test-harness](https://github.com/dcos/dcos/tree/master/packages/adminrouter/extra/src/test-harness) Docker Dependency: [dcos/dcos/packages/adminrouter](https://github.com/dcos/dcos/blob/master/packages/adminrouter/buildinfo.json) |\n| mergebot/enterprise/build-status/aggregate     | EE Test Enforcement                                                                                                     | Private [mesosphere/dcos-enterprise](https://github.com/mesosphere/dcos-enterprise) repo is tested against the SHA.|\n| mergebot/enterprise/has_ship-it                | Code Review Enforcement                                                                                                 | Private [Mergebot](https://github.com/mesosphere/mergebot) service in prod cluster                     |\n| mergebot/enterprise/review/approved/min_2      | Code Review Enforcement                                                                                                 | Mergebot service in prod cluster                                                                       |\n| mergebot/has_ship-it                           | Code Review Enforcement                                                                                                 | Mergebot service in prod cluster                                                                       |\n| mergebot/review/approved/min_2                 | Code Review Enforcement                                                                                                 | Mergebot service in prod cluster                                                                       |\n| teamcity/dcos/build/dcosWindows                | Builds for DC/OS Windows                                                                                                | [Windows Packages](https://github.com/dcos/dcos/blob/master/packages/windows.treeinfo.json)            |\n| teamcity/dcos/build/dcos                       | Builds DCOS Image (dcos_generate_config.sh)                                                                             | [gen/build_deploy/bash.py](https://github.com/dcos/dcos/blob/master/gen/build_deploy/bash.py)          |\n| teamcity/dcos/build/tox                        | Runs check-style, unit-tests                                                                                            | [tox.ini](https://github.com/dcos/dcos/blob/master/tox.ini)                                            |\n| teamcity/dcos/build/tox/windows                | Runs tox for the Windows Build                                                                                          | [azure-ci-dependencies](https://github.com/dcos/azure-ci-dependencies/blob/master/scripts/dcos-windows-tox-tests.ps1) |\n| teamcity/dcos/test/aws/cloudformation/simple   | Deployment using single-master-cloudformation.json and runs integration tests                                           | [gen/build_deploy/aws.py](https://github.com/dcos/dcos/blob/master/gen/build_deploy/aws.py),           |\n| teamcity/dcos/test/terraform/aws/onprem/static/group{1..n}  | Installation via dcos_generation_config.sh and runs Integration Tests                                                | [gen/build_deploy/bash.py](https://github.com/dcos/dcos/blob/master/gen/build_deploy/bash.py), |\n| teamcity/dcos/test/test-e2e/group{1..n}        | End to End Tests. Each Test launches a cluster, exercises a functionality.                                              | [test-e2e](https://github.com/dcos/dcos/tree/master/test-e2e)\n\n### Required vs Non-Required Status checks\n\nA PR status check may be marked as **Required** or **Not-Required** (Default). The required status checks are necessary for applying a ship-it label, which makes the PR eligible for merge.\nA non-required status check is completely informational, and the success or the failure of the status check does not, in any way, impact the merge of the PR.\n\nThe required status checks are encoded in the repo\'s megebot-config (For .e.g: https://github.com/dcos/dcos/blob/master/mergebot-config.json#L38)\nand are enforced by mergebot.\n'