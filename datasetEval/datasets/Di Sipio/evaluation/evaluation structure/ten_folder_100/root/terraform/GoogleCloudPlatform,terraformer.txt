b'# Terraformer\n\n[![Build Status](https://travis-ci.com/GoogleCloudPlatform/terraformer.svg?branch=master)](https://travis-ci.com/GoogleCloudPlatform/terraformer)\n[![Go Report Card](https://goreportcard.com/badge/github.com/GoogleCloudPlatform/terraformer)](https://goreportcard.com/report/github.com/GoogleCloudPlatform/terraformer)\n[![AUR package](https://img.shields.io/aur/version/terraformer)](https://aur.archlinux.org/packages/terraformer/)\n\nA CLI tool that generates `tf` and `tfstate` files based on existing infrastructure\n(reverse Terraform).\n\n*   Disclaimer: This is not an official Google product\n*   Created by: Waze SRE\n\n![Waze SRE logo](docs/waze-sre-logo.png)\n\n# Table of Contents\n\n- [Capabilities](#capabilities)\n- [Installation](#installation)\n- [Supported Providers](/providers)\n    * Major Cloud\n        * [Google Cloud](#use-with-gcp)\n        * [AWS](#use-with-aws)\n        * [Azure](#use-with-azure)\n        * [AliCloud](#use-with-alicloud)\n    * Cloud\n        * [DigitalOcean](#use-with-digitalocean)\n        * [Heroku](#use-with-heroku)\n        * [Linode](#use-with-linode)\n        * [OpenStack](#use-with-openstack)\n        * [Vultr](#use-with-vultr)\n    * Infrastructure Software\n        * [Kubernetes](#use-with-kubernetes)\n        * [RabbitMQ](#use-with-rabbitmq)\n    * Network\n        * [Cloudflare](#use-with-cloudflare)\n    * VCS\n        * [GitHub](#use-with-github)\n    * Monitoring & System Management\n        * [Datadog](#use-with-datadog)\n        * [New Relic](#use-with-new-relic)\n    * Community\n        * [Logz.io](#use-with-logzio)\n        * [Commercetools](#use-with-commercetools)\n- [Contributing](#contributing)\n- [Developing](#developing)\n- [Infrastructure](#infrastructure)\n\n## Capabilities\n\n1.  Generate `tf` + `tfstate` files from existing infrastructure for all\n    supported objects by resource.\n2.  Remote state can be uploaded to a GCS bucket.\n3.  Connect between resources with `terraform_remote_state` (local and bucket).\n4.  Save `tf` files using a custom folder tree pattern.\n5.  Import by resource name and type.\n6.  Support terraform 0.12 (for terraform 0.11 use v0.7.9).\n\nTerraformer uses Terraform providers and is designed to easily support newly added resources.\nTo upgrade resources with new fields, all you need to do is upgrade the relevant Terraform providers.\n```\nImport current state to Terraform configuration from Google Cloud\n\nUsage:\n   import google [flags]\n   import google [command]\n\nAvailable Commands:\n  list        List supported resources for google provider\n\nFlags:\n  -b, --bucket string         gs://terraform-state\n  -c, --connect                (default true)\n  -\xd0\xa1, --compact                (default false)\n  -f, --filter strings        google_compute_firewall=id1:id2:id4\n  -h, --help                  help for google\n  -o, --path-output string     (default "generated")\n  -p, --path-pattern string   {output}/{provider}/ (default "{output}/{provider}/{service}/")\n      --projects strings\n  -z, --regions strings       europe-west1, (default [global])\n  -r, --resources strings     firewalls,networks\n  -s, --state string          local or bucket (default "local")\n\nUse " import google [command] --help" for more information about a command.\n```\n#### Permissions\n\nRead-only permissions\n\n#### Filtering\n\nFilters are a way to choose which resources `terraformer` imports. It\'s possible to filter resources by its identifiers or attributes. Multiple filtering values are separated by `:`. If an identifier contains this symbol, value should be wrapped in `\'` e.g. `--filter=resource=id1:\'project:dataset_id\'`. Identifier based filters will be executed before Terraformer will try to refresh remote state.\n\n##### Resource ID\n\nFiltering is based on Terraform resource ID patterns. To find valid ID patterns for your resource, check the import part of the [Terraform documentation][terraform-providers].\n\n[terraform-providers]: https://www.terraform.io/docs/providers/\n\nExample usage:\n\n```\nterraformer import aws --resources=vpc,subnet --filter=aws_vpc=myvpcid --regions=eu-west-1\n```\nWill only import the vpc with id `myvpcid`. This form of filters can help when it\'s necessary to select resources by its identifiers.\n\n#### Planning\n\nThe `plan` command generates a planfile that contains all the resources set to be imported. By modifying the planfile before running the `import` command, you can rename or filter the resources you\'d like to import.\n\nThe rest of subcommands and parameters are identical to the `import` command.\n\n```\n$ terraformer plan google --resources=networks,firewalls --projects=my-project --zone=europe-west1-d\n(snip)\n\nSaving planfile to generated/google/my-project/terraformer/plan.json\n```\n\nAfter reviewing/customizing the planfile, begin the import by running `import plan`.\n\n```\n$ terraformer import plan generated/google/my-project/terraformer/plan.json\n```\n\n### Resource structure\n\nTerraformer by default separates each resource into a file, which is put into a given service directory.\n\nThe default path for resource files is `{output}/{provider}/{service}/{resource}.tf` and can vary for each provider.\n\nIt\'s possible to adjust the generated structure by:\n1. Using `--compact` parameter to group resource files within a single service into one `resources.tf` file\n2. Adjusting the `--path-pattern` parameter and passing e.g. `--path-pattern {output}/{provider}/` to generate resources for all services in one directory\n\nIt\'s possible to combine `--compact` `--path-pattern` parameters together.\n\n### Installation\n\nFrom source:\n1.  Run `git clone <terraformer repo>`\n2.  Run `GO111MODULE=on go mod vendor`\n3.  Run `go build -v` for all providers OR build with one provider `go run build/main.go {google,aws,azure,kubernetes and etc}`\n4.  Run ```terraform init``` against an ```init.tf``` file to install the plugins required for your platform. For example, if you need plugins for the google provider, ```init.tf``` should contain:\n```\nprovider "google" {}\n```\nOr alternatively\n\n4.  Copy your Terraform provider\'s plugin(s) to folder\n    `~/.terraform.d/plugins/{darwin,linux}_amd64/`, as appropriate.\n\nFrom Releases:\n\n* Linux\n```\nexport PROVIDER={all,google,aws,kubernetes}\ncurl -LO https://github.com/GoogleCloudPlatform/terraformer/releases/download/$(curl -s https://api.github.com/repos/GoogleCloudPlatform/terraformer/releases/latest | grep tag_name | cut -d \'"\' -f 4)/terraformer-${PROVIDER}-linux-amd64\nchmod +x terraformer-${PROVIDER}-linux-amd64\nsudo mv terraformer-${PROVIDER}-linux-amd64 /usr/local/bin/terraformer\n```\n* MacOS\n```\nexport PROVIDER={all,google,aws,kubernetes}\ncurl -LO https://github.com/GoogleCloudPlatform/terraformer/releases/download/$(curl -s https://api.github.com/repos/GoogleCloudPlatform/terraformer/releases/latest | grep tag_name | cut -d \'"\' -f 4)/terraformer-${PROVIDER}-darwin-amd64\nchmod +x terraformer-${PROVIDER}-darwin-amd64\nsudo mv terraformer-${PROVIDER}-darwin-amd64 /usr/local/bin/terraformer\n```\n\n#### Using a package manager\n\nIf you want to use a package manager:\n\n- [Homebrew](https://brew.sh/) users can use `brew install terraformer`.\n\nLinks to download Terraform Providers:\n* Major Cloud\n    * Google Cloud provider >2.11.0 - [here](https://releases.hashicorp.com/terraform-provider-google/)\n    * AWS provider >2.25.0 - [here](https://releases.hashicorp.com/terraform-provider-aws/)\n    * Azure provider >1.35.0 - [here](https://releases.hashicorp.com/terraform-provider-azurerm/)\n    * Alicloud provider >1.57.1 - [here](https://releases.hashicorp.com/terraform-provider-alicloud/)\n* Cloud\n    * DigitalOcean provider >1.9.1 - [here](https://releases.hashicorp.com/terraform-provider-digitalocean/)\n    * Heroku provider >2.2.1 - [here](https://releases.hashicorp.com/terraform-provider-heroku/)\n    * Linode provider >1.8.0 - [here](https://releases.hashicorp.com/terraform-provider-linode/)\n    * OpenStack provider >1.21.1 - [here](https://releases.hashicorp.com/terraform-provider-openstack/)\n    * Vultr provider >1.0.5 - [here](https://releases.hashicorp.com/terraform-provider-vultr/)\n* Infrastructure Software\n    * Kubernetes provider >=1.9.0 - [here](https://releases.hashicorp.com/terraform-provider-kubernetes/)\n    * RabbitMQ provider >=1.1.0 - [here](https://releases.hashicorp.com/terraform-provider-rabbitmq/)\n* Network\n    * Cloudflare provider >1.16 - [here](https://releases.hashicorp.com/terraform-provider-cloudflare/)\n* VCS\n    * GitHub provider >=2.2.1 - [here](https://releases.hashicorp.com/terraform-provider-github/)\n* Monitoring & System Management\n    * Datadog provider >2.1.0 - [here](https://releases.hashicorp.com/terraform-provider-datadog/)\n    * New Relic provider >1.5.0 - [here](https://releases.hashicorp.com/terraform-provider-newrelic/)\n* Community\n    * Logz.io provider >=1.1.1 - [here](https://github.com/jonboydell/logzio_terraform_provider/)\n    * Commercetools provider >= 0.19.0 - [here](https://github.com/labd/terraform-provider-commercetools)\n\nInformation on provider plugins:\nhttps://www.terraform.io/docs/configuration/providers.html\n\n### Use with GCP\n\n[![asciicast](https://asciinema.org/a/243961.svg)](https://asciinema.org/a/243961)\n\nExample:\n\n```\nterraformer import google --resources=gcs,forwardingRules,httpHealthChecks --connect=true --regions=europe-west1,europe-west4 --projects=aaa,fff\nterraformer import google --resources=gcs,forwardingRules,httpHealthChecks --filter=google_compute_firewall=rule1:rule2:rule3 --regions=europe-west1 --projects=aaa,fff\n```\n\nList of supported GCP services:\n\n*   `addresses`\n    * `google_compute_address`\n*   `autoscalers`\n    * `google_compute_autoscaler`\n*   `backendBuckets`\n    * `google_compute_backend_bucket`\n*   `backendServices`\n    * `google_compute_backend_service`\n*   `bigQuery`\n    * `google_bigquery_dataset`\n    * `google_bigquery_table`\n*   `cloudFunctions`\n    * `google_cloudfunctions_function`\n*   `cloudsql`\n    * `google_sql_database_instance`\n    * `google_sql_database`\n*   `dataProc`\n    * `google_dataproc_cluster`\n*   `disks`\n    * `google_compute_disk`\n*   `dns`\n    * `google_dns_managed_zone`\n    * `google_dns_record_set`\n*   `firewalls`\n    * `google_compute_firewall`\n*   `forwardingRules`\n    * `google_compute_forwarding_rule`\n*   `gcs`\n    * `google_storage_bucket`\n    * `google_storage_bucket_acl`\n    * `google_storage_default_object_acl`\n    * `google_storage_bucket_iam_binding`\n    * `google_storage_bucket_iam_member`\n    * `google_storage_bucket_iam_policy`\n    * `google_storage_notification`\n*   `gke`\n    * `google_container_cluster`\n    * `google_container_node_pool`\n*   `globalAddresses`\n    * `google_compute_global_address`\n*   `globalForwardingRules`\n    * `google_compute_global_forwarding_rule`\n*   `healthChecks`\n    * `google_compute_health_check`\n*   `httpHealthChecks`\n    * `google_compute_http_health_check`\n*   `httpsHealthChecks`\n    * `google_compute_https_health_check`\n*   `images`\n    * `google_compute_image`\n*   `instanceGroupManagers`\n    * `google_compute_instance_group_manager`\n*   `instanceGroups`\n    * `google_compute_instance_group`\n*   `instanceTemplates`\n    * `google_compute_instance_template`\n*   `instances`\n    * `google_compute_instance`\n*   `interconnectAttachments`\n    * `google_compute_interconnect_attachment`\n*   `kms`\n    * `google_kms_key_ring`\n    * `google_kms_crypto_key`\n*   `logging`\n    * `google_logging_metric`\n*   `memoryStore`\n    * `google_redis_instance`\n*   `monitoring`\n    * `google_monitoring_alert_policy`\n    * `google_monitoring_group`\n    * `google_monitoring_notification_channel`\n    * `google_monitoring_uptime_check_config`\n*   `networks`\n    * `google_compute_network`\n*   `nodeGroups`\n    * `google_compute_node_group`\n*   `nodeTemplates`\n    * `google_compute_node_template`\n*   `project`\n    * `google_project`\n*   `pubsub`\n    * `google_pubsub_subscription`\n    * `google_pubsub_topic`\n*   `regionAutoscalers`\n    * `google_compute_region_autoscaler`\n*   `regionBackendServices`\n    * `google_compute_region_backend_service`\n*   `regionDisks`\n    * `google_compute_region_disk`\n*   `regionInstanceGroupManagers`\n    * `google_compute_region_instance_group_manager`\n*   `routers`\n    * `google_compute_router`\n*   `routes`\n    * `google_compute_route`\n*   `schedulerJobs`\n    * `google_cloud_scheduler_job`\n*   `securityPolicies`\n    * `google_compute_security_policy`\n*   `sslPolicies`\n    * `google_compute_ssl_policy`\n*   `subnetworks`\n    * `google_compute_subnetwork`\n*   `targetHttpProxies`\n    * `google_compute_target_http_proxy`\n*   `targetHttpsProxies`\n    * `google_compute_target_https_proxy`\n*   `targetInstances`\n    * `google_compute_target_instance`\n*   `targetPools`\n    * `google_compute_target_pool`\n*   `targetSslProxies`\n    * `google_compute_target_ssl_proxy`\n*   `targetTcpProxies`\n    * `google_compute_target_tcp_proxy`\n*   `targetVpnGateways`\n    * `google_compute_vpn_gateway`\n*   `urlMaps`\n    * `google_compute_url_map`\n*   `vpnTunnels`\n    * `google_compute_vpn_tunnel`\n\nYour `tf` and `tfstate` files are written by default to\n`generated/gcp/zone/service`.\n\n### Use with AWS\n\nExample:\n\n```\n terraformer import aws --resources=vpc,subnet --connect=true --regions=eu-west-1 --profile=prod --debug\n terraformer import aws --resources=vpc,subnet --filter=aws_vpc=vpc_id1:vpc_id2:vpc_id3 --regions=eu-west-1\n```\n\nTo turn on HTTP request/response debugging, you can use `--debug` parameter.\n\n#### Profiles support\n\nTo load profiles from the shared AWS configuration file (typically `~/.aws/config`), set the `AWS_SDK_LOAD_CONFIG` to `true`:\n\n```\nAWS_SDK_LOAD_CONFIG=true terraformer import aws --resources=vpc,subnet --regions=eu-west-1 --profile=prod\n```\n\nYou can also provide no regions when importing resources:\n```\nterraformer import aws --resources=cloudfront --profile=prod\n```\nIn that case terraformer will not know with which region resources are associated with and will not assume any region. That scenario is useful in case of global resources (e.g. CloudFront distributions or Route 53 records) and when region is passed implicitly through environmental variables or metadata service.\n\n#### Supported services\n\n*   `acm`\n    * `aws_acm_certificate`\n*   `alb` (supports ALB and NLB)\n    * `aws_lb`\n    * `aws_lb_listener`\n    * `aws_lb_listener_rule`\n    * `aws_lb_listener_certificate`\n    * `aws_lb_target_group`\n    * `aws_lb_target_group_attachment`\n*   `auto_scaling`\n    * `aws_autoscaling_group`\n    * `aws_launch_configuration`\n    * `aws_launch_template`\n*   `budgets`\n    * `aws_budgets_budget`\n*   `cloud9`\n    * `aws_cloud9_environment_ec2`\n*   `cloudfront`\n    * `aws_cloudfront_distribution`\n*   `cloudformation`\n    * `aws_cloudformation_stack`\n    * `aws_cloudformation_stack_set`\n    * `aws_cloudformation_stack_set_instance`\n*   `cloudtrail`\n    * `aws_cloudtrail`\n*   `dynamodb`\n    * `aws_dynamodb_table`\n*   `ec2_instance`\n    * `aws_instance`\n*   `eip`\n    * `aws_eip`\n*   `elasticache`\n    * `aws_elasticache_cluster`\n    * `aws_elasticache_parameter_group`\n    * `aws_elasticache_subnet_group`\n    * `aws_elasticache_replication_group`\n*   `ebs`\n    * `aws_ebs_volume`\n    * `aws_volume_attachment`\n*   `ecs`\n    * `aws_ecs_cluster`\n    * `aws_ecs_service`\n    * `aws_ecs_task_definition`\n*   `eks`\n    * `aws_eks_cluster`\n*   `elb`\n    * `aws_elb`\n*   `es`\n    * `aws_elasticsearch_domain`\n*   `firehose`\n    * `aws_kinesis_firehose_delivery_stream`\n*   `glue`\n    * `glue_crawler`\n    * `aws_glue_catalog_database`\n    * `aws_glue_catalog_table`\n*   `iam`\n    * `aws_iam_role`\n    * `aws_iam_role_policy`\n    * `aws_iam_user`\n    * `aws_iam_user_group_membership`\n    * `aws_iam_user_policy`\n    * `aws_iam_policy_attachment`\n    * `aws_iam_policy`\n    * `aws_iam_group`\n    * `aws_iam_group_membership`\n    * `aws_iam_group_policy`\n*   `igw`\n    * `aws_internet_gateway`\n*   `kinesis`\n    * `aws_kinesis_stream`\n*   `msk`\n    * `aws_msk_cluster`\n*   `nat`\n    * `aws_nat_gateway`\n*   `nacl`\n    * `aws_network_acl`\n*   `organization`\n    * `aws_organizations_account`\n    * `aws_organizations_organization`\n    * `aws_organizations_organizational_unit`\n    * `aws_organizations_policy`\n    * `aws_organizations_policy_attachment`\n*   `rds`\n    * `aws_db_instance`\n    * `aws_db_parameter_group`\n    * `aws_db_subnet_group`\n    * `aws_db_option_group`\n    * `aws_db_event_subscription`\n*   `route53`\n    * `aws_route53_zone`\n    * `aws_route53_record`\n*   `route_table`\n    * `aws_route_table`\n    * `aws_main_route_table_association`\n    * `aws_route_table_association`\n*   `s3`\n    * `aws_s3_bucket`\n    * `aws_s3_bucket_policy`\n*   `sg`\n    * `aws_security_group`\n*   `sns`\n    * `aws_sns_topic`\n    * `aws_sns_topic_subscription`\n*   `sqs`\n    * `aws_sqs_queue`\n*   `subnet`\n    * `aws_subnet`\n*   `vpc`\n    * `aws_vpc`\n*   `vpc_peering`\n    * `aws_vpc_peering_connection`\n*   `vpn_connection`\n    * `aws_vpn_connection`\n*   `vpn_gateway`\n    * `aws_vpn_gateway`\n\n#### Global services\n\nAWS services that are global will be imported without specified region even if several regions will be passed. It is to ensure only one representation of an AWS resource is imported.\n\nList of global AWS services:\n*   `budgets`\n*   `cloudfront`\n*   `iam`\n*   `organization`\n*   `route53`\n\n#### Attribute filters\n\nAttribute filters allow filtering across different resource types by its attributes.\n\n```\nterraformer import aws --resources=ec2_instance,ebs --filter=Name=tags.costCenter;Value=20000:\'20001:1\' --regions=eu-west-1\n```\nWill only import AWS EC2 instances along with EBS volumes annotated with tag `costCenter` with values `20000` or `20001:1`. Attribute filters are by default applicable to all resource types although it\'s possible to specify to what resource type a given filter should be applicable to by providing `Type=<type>` parameter. For example:\n```\nterraformer import aws --resources=ec2_instance,ebs --filter=Type=ec2_instance;Name=tags.costCenter;Value=20000:\'20001:1\' --regions=eu-west-1\n```\nWill work as same as example above with a change the filter will be applicable only to `ec2_instance` resources.\n\n#### SQS queues retrieval\n\nTerraformer uses AWS [ListQueues](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_ListQueues.html) API call to fetch available queues. The API is able to return only up to 1000 queues and an additional name prefix should be passed to filter the list results. It\'s possible to pass `QueueNamePrefix` parameter by environmental variable `SQS_PREFIX`.\n\n### Use with Azure\n\nExample:\n\n```\nexport ARM_CLIENT_ID=[CLIENT_ID]\nexport ARM_CLIENT_SECRET=[CLIENT_SECRET]\nexport ARM_SUBSCRIPTION_ID=[SUBSCRIPTION_ID]\nexport ARM_TENANT_ID=[TENANT_ID]\n\nexport AZURE_CLIENT_ID=[CLIENT_ID]\nexport AZURE_CLIENT_SECRET=[CLIENT_SECRET]\nexport AZURE_TENANT_ID=[TENANT_ID]\n\n./terraformer import azure -r resource_group\n```\n\nList of supported Azure resources:\n\n*   `disk`\n    * `azurerm_managed_disk`\n*   `network_interface`\n    * `azurerm_network_interface`\n*   `network_security_group`\n    * `azurerm_network_security_group`\n*   `resource_group`\n    * `azurerm_resource_group`\n*   `storage_account`\n    * `azurerm_storage_account`\n*   `virtual_machine`\n    * `azurerm_virtual_machine`\n*   `virtual_network`\n    * `azurerm_virtual_network`\n\n### Use with AliCloud\n\nYou can either edit your alicloud config directly, (usually it is `~/.aliyun/config.json`)\nor run `aliyun configure` and enter the credentials when prompted.\n\nTerraformer will pick up the profile name specified in the `--profile` parameter.\nIt defaults to the first config in the config array.\n\n```sh\nterraformer import alicloud --resources=ecs --regions=ap-southeast-3 --profile=default\n```\n\nFor all *supported* resources, you can do\n\n```sh\n# https://unix.stackexchange.com/a/114948/203870\nexport ALL_SUPPORTED_ALICLOUD_RESOURCES=$(terraformer import alicloud list | sed -e \'H;1h;$!d;x;y/\\n/,/\')\nterraformer import alicloud --resources=$ALL_SUPPORTED_ALICLOUD_RESOURCES --regions=ap-southeast-3\n```\n\nList of supported AliCloud resources:\n\n* `dns`\n  * `alicloud_dns`\n  * `alicloud_dns_record`\n* `ecs`\n  * `alicloud_instance`\n* `keypair`\n  * `alicloud_key_pair`\n* `nat`\n  * `alicloud_nat_gateway`\n* `pvtz`\n  * `alicloud_pvtz_zone`\n  * `alicloud_pvtz_zone_attachment`\n  * `alicloud_pvtz_zone_record`\n* `ram`\n  * `alicloud_ram_role`\n  * `alicloud_ram_role_policy_attachment`\n* `rds`\n  * `alicloud_db_instance`\n* `sg`\n  * `alicloud_security_group`\n  * `alicloud_security_group_rule`\n* `slb`\n  * `alicloud_slb`\n  * `alicloud_slb_server_group`\n  * `alicloud_slb_listener`\n* `vpc`\n  * `alicloud_vpc`\n* `vswitch`\n  * `alicloud_vswitch`\n\n### Use with DigitalOcean\n\nExample:\n\n```\nexport DIGITALOCEAN_TOKEN=[DIGITALOCEAN_TOKEN]\n./terraformer import digitalocean -r project,droplet\n```\n\nList of supported DigitalOcean resources:\n\n*   `cdn`\n    * `digitalocean_cdn`\n*   `certificate`\n    * `digitalocean_certificate`\n*   `database_cluster`\n    * `digitalocean_database_cluster`\n*   `domain`\n    * `digitalocean_domain`\n*   `droplet`\n    * `digitalocean_droplet`\n*   `droplet_snapshot`\n    * `digitalocean_droplet_snapshot`\n*   `firewall`\n    * `digitalocean_firewall`\n*   `floating_ip`\n    * `digitalocean_floating_ip`\n*   `kubernetes_cluster`\n    * `digitalocean_kubernetes_cluster`\n*   `loadbalancer`\n    * `digitalocean_loadbalancer`\n*   `project`\n    * `digitalocean_project`\n*   `ssh_key`\n    * `digitalocean_ssh_key`\n*   `tag`\n    * `digitalocean_tag`\n*   `volume`\n    * `digitalocean_volume`\n*   `volume_snapshot`\n    * `digitalocean_volume_snapshot`\n\n### Use with Heroku\n\nExample:\n\n```\nexport HEROKU_EMAIL=[HEROKU_EMAIL]\nexport HEROKU_API_KEY=[HEROKU_API_KEY]\n./terraformer import heroku -r app,addon\n```\n\nList of supported Heroku resources:\n\n*   `account_feature`\n    * `heroku_account_feature`\n*   `addon`\n    * `heroku_addon`\n*   `addon_attachment`\n    * `heroku_addon_attachment`\n*   `app`\n    * `heroku_app`\n*   `app_config_association`\n    * `heroku_app_config_association`\n*   `app_feature`\n    * `heroku_app_feature`\n*   `app_webhook`\n    * `heroku_app_webhook`\n*   `build`\n    * `heroku_build`\n*   `cert`\n    * `heroku_cert`\n*   `domain`\n    * `heroku_domain`\n*   `drain`\n    * `heroku_drain`\n*   `formation`\n    * `heroku_formation`\n*   `pipeline`\n    * `heroku_pipeline`\n*   `pipeline_coupling`\n    * `heroku_pipeline_coupling`\n*   `team_collaborator`\n    * `heroku_team_collaborator`\n*   `team_member`\n    * `heroku_team_member`\n\n### Use with Linode\n\nExample:\n\n```\nexport LINODE_TOKEN=[LINODE_TOKEN]\n./terraformer import linode -r instance\n```\n\nList of supported Linode resources:\n\n*   `domain`\n    * `linode_domain`\n    * `linode_domain_record`\n*   `image`\n    * `linode_image`\n*   `instance`\n    * `linode_instance`\n*   `nodebalancer`\n    * `linode_nodebalancer`\n    * `linode_nodebalancer_config`\n    * `linode_nodebalancer_node`\n*   `rdns`\n    * `linode_rdns`\n*   `sshkey`\n    * `linode_sshkey`\n*   `stackscript`\n    * `linode_stackscript`\n*   `token`\n    * `linode_token`\n*   `volume`\n    * `linode_volume`\n\n### Use with OpenStack\n\nExample:\n\n```\n terraformer import openstack --resources=compute,networking --regions=RegionOne\n```\n\nList of supported OpenStack services:\n\n*   `blockstorage`\n    * `openstack_blockstorage_volume_v1`\n    * `openstack_blockstorage_volume_v2`\n    * `openstack_blockstorage_volume_v3`\n*   `compute`\n    * `openstack_compute_instance_v2`\n*   `networking`\n    * `openstack_networking_secgroup_v2`\n    * `openstack_networking_secgroup_rule_v2`\n\n### Use with Vultr\n\nExample:\n\n```\nexport VULTR_API_KEY=[VULTR_API_KEY]\n./terraformer import vultr -r server\n```\n\nList of supported Vultr resources:\n\n*   `bare_metal_server`\n    * `vultr_bare_metal_server`\n*   `block_storage`\n    * `vultr_block_storage`\n*   `dns_domain`\n    * `vultr_dns_domain`\n*   `firewall_group`\n    * `vultr_firewall_group`\n*   `network`\n    * `vultr_network`\n*   `reserved_ip`\n    * `vultr_reserved_ip`\n*   `server`\n    * `vultr_server`\n*   `snapshot`\n    * `vultr_snapshot`\n*   `ssh_key`\n    * `vultr_ssh_key`\n*   `startup_script`\n    * `vultr_startup_script`\n*   `user`\n    * `vultr_user`\n\n### Use with Kubernetes\n\nExample:\n\n```\n terraformer import kubernetes --resources=deployments,services,storageclasses\n terraformer import kubernetes --resources=deployments,services,storageclasses --filter=kubernetes_deployment=name1:name2:name3\n```\n\nAll Kubernetes resources that are currently supported by the Kubernetes provider, are also supported by this module. Here is the list of resources which are currently supported by Kubernetes provider v.1.4:\n\n*   `clusterrolebinding`\n    * `kubernetes_cluster_role_binding`\n*   `configmaps`\n    * `kubernetes_config_map`\n*   `deployments`\n    * `kubernetes_deployment`\n*   `horizontalpodautoscalers`\n    * `kubernetes_horizontal_pod_autoscaler`\n*   `limitranges`\n    * `kubernetes_limit_range`\n*   `namespaces`\n    * `kubernetes_namespace`\n*   `persistentvolumes`\n    * `kubernetes_persistent_volume`\n*   `persistentvolumeclaims`\n    * `kubernetes_persistent_volume_claim`\n*   `pods`\n    * `kubernetes_pod`\n*   `replicationcontrollers`\n    * `kubernetes_replication_controller`\n*   `resourcequotas`\n    * `kubernetes_resource_quota`\n*   `secrets`\n    * `kubernetes_secret`\n*   `services`\n    * `kubernetes_service`\n*   `serviceaccounts`\n    * `kubernetes_service_account`\n*   `statefulsets`\n    * `kubernetes_stateful_set`\n*   `storageclasses`\n    * `kubernetes_storage_class`\n\n#### Known issues\n\n* Terraform Kubernetes provider is rejecting resources with ":" characters in their names (as they don\'t meet DNS-1123), while it\'s allowed for certain types in Kubernetes, e.g. ClusterRoleBinding.\n* Because Terraform flatmap uses "." to detect the keys for unflattening the maps, some keys with "." in their names are being considered as the maps.\n* Since the library assumes empty strings to be empty values (not "0"), there are some issues with optional integer keys that are restricted to be positive.\n\n### Use with RabbitMQ\n\nExample:\n\n```\n export RABBITMQ_SERVER_URL=http://foo.bar.localdomain:15672\n export RABBITMQ_USERNAME=[RABBITMQ_USERNAME]\n export RABBITMQ_PASSWORD=[RABBITMQ_PASSWORD]\n\n terraformer import rabbitmq --resources=vhosts,queues,exchanges\n terraformer import rabbitmq --resources=vhosts,queues,exchanges --filter=rabbitmq_vhost=name1:name2:name3\n```\n\nAll RabbitMQ resources that are currently supported by the RabbitMQ provider, are also supported by this module. Here is the list of resources which are currently supported by RabbitMQ provider v.1.1.0:\n\n*   `bindings`\n    * `rabbitmq_binding`\n*   `exchanges`\n    * `rabbitmq_exchange`\n*   `permissions`\n    * `rabbitmq_permissions`\n*   `policies`\n    * `rabbitmq_policy`\n*   `queues`\n    * `rabbitmq_queue`\n*   `users`\n    * `rabbitmq_user`\n*   `vhosts`\n    * `rabbitmq_vhost`\n\n### Use with Cloudflare\n\nExample:\n```\nCLOUDFLARE_TOKEN=[CLOUDFLARE_API_TOKEN]\nCLOUDFLARE_EMAIL=[CLOUDFLARE_EMAIL]\n ./terraformer import cloudflare --resources=firewall,dns\n```\n\nList of supported Cloudflare services:\n\n* `access`\n  * `cloudflare_access_application`\n* `dns`\n  * `cloudflare_zone`\n  * `cloudflare_record`\n* `firewall`\n  * `cloudflare_access_rule`\n  * `cloudflare_filter`\n  * `cloudflare_firewall_rule`\n  * `cloudflare_zone_lockdown`\n\n### Use with GitHub\n\nExample:\n\n```\n ./terraformer import github --organizations=YOUR_ORGANIZATION --resources=repositories --token=YOUR_TOKEN // or GITHUB_TOKEN in env\n ./terraformer import github --organizations=YOUR_ORGANIZATION --resources=repositories --filter=github_repository=id1:id2:id4 --token=YOUR_TOKEN // or GITHUB_TOKEN in env\n```\n\nSupports only organizational resources. List of supported resources:\n\n*   `members`\n    * `github_membership`\n*   `organization_webhooks`\n    * `github_organization_webhook`\n*   `repositories`\n    * `github_repository`\n    * `github_repository_webhook`\n    * `github_branch_protection`\n    * `github_repository_collaborator`\n    * `github_repository_deploy_key`\n*   `teams`\n    * `github_team`\n    * `github_team_membership`\n    * `github_team_repository`\n\nNotes:\n* Terraformer can\'t get webhook secrets from the GitHub API. If you use a secret token in any of your webhooks, running `terraform plan` will result in a change being detected:\n=> `configuration.#: "1" => "0"` in tfstate only.\n\n### Use with Datadog\n\nExample:\n\n```\n ./terraformer import datadog --resources=monitor --api-key=YOUR_DATADOG_API_KEY // or DATADOG_API_KEY in env --app-key=YOUR_DATADOG_APP_KEY // or DATADOG_APP_KEY in env\n ./terraformer import datadog --resources=monitor --filter=datadog_monitor=id1:id2:id4 --api-key=YOUR_DATADOG_API_KEY // or DATADOG_API_KEY in env --app-key=YOUR_DATADOG_APP_KEY // or DATADOG_APP_KEY in env\n```\n\nList of supported Datadog services:\n\n*   `dashboard`\n    * `datadog_dashboard`\n*   `downtime`\n    * `datadog_downtime`\n*   `monitor`\n    * `datadog_monitor`\n*   `screenboard`\n    * `datadog_screenboard`\n*   `synthetics`\n    * `datadog_synthetics_test`\n*   `timeboard`\n    * `datadog_timeboard`\n*   `user`\n    * `datadog_user`\n\n### Use with New Relic\n\nExample:\n\n```\nNEWRELIC_API_KEY=[API-KEY]\n./terraformer import newrelic -r alert,dashboard,infra,synthetics\n```\n\nList of supported New Relic resources:\n\n*   `alert`\n    * `newrelic_alert_channel`\n    * `newrelic_alert_condition`\n    * `newrelic_alert_policy`\n*   `dashboard`\n    * `newrelic_dashboard`\n*   `infra`\n    * `newrelic_infra_alert_condition`\n*   `synthetics`\n    * `newrelic_synthetics_monitor`\n    * `newrelic_synthetics_alert_condition`\n\n### Use with Logz.io\n\nExample:\n\n```\n LOGZIO_API_TOKEN=foobar LOGZIO_BASE_URL=https://api-eu.logz.io ./terraformer import logzio -r=alerts,alert_notification_endpoints // Import Logz.io alerts and alert notification endpoints\n```\n\nList of supported Logz.io resources:\n\n*   `alerts`\n    * `logzio_alert`\n*   `alert_notification_endpoints`\n    * `logzio_endpoint`\n\n### Use with [Commercetools](https://commercetools.com/de/)\n\nThis provider use the [terraform-provider-commercetools](https://github.com/labd/terraform-provider-commercetools). The terraformer provider was build by [Dustin Deus](https://github.com/StarpTech).\n\nExample:\n\n```\nCTP_CLIENT_ID=foo CTP_CLIENT_SCOPE=scope CTP_CLIENT_SECRET=bar CTP_PROJECT_KEY=key ./terraformer plan commercetools -r=types // Only planning\nCTP_CLIENT_ID=foo CTP_CLIENT_SCOPE=scope CTP_CLIENT_SECRET=bar CTP_PROJECT_KEY=key ./terraformer import commercetools -r=types // Import commercetools types\n```\n\nList of supported [commercetools](https://commercetools.com/de/) resources:\n\n*   `types`\n    * `commercetools_type`\n*   `product_type`\n    * `commercetools_product_type`\n*   `store`\n    * `commercetools_store`\n*   `api_extension`\n    * `commercetools_api_extension`\n*   `channel`\n    * `commercetools_channel`\n*   `subscription`\n    * `commercetools_subscription`\n*   `shipping_zone`\n    * `commercetools_shipping_zone`\n*   `state`\n    * `commercetools_state`\n*   `tax_category`\n    * `commercetools_tax_category`\n\n## Contributing\n\nIf you have improvements or fixes, we would love to have your contributions.\nPlease read CONTRIBUTING.md for more information on the process we would like\ncontributors to follow.\n\n## Developing\n\nTerraformer was built so you can easily add new providers of any kind.\n\nProcess for generating `tf` + `tfstate` files:\n\n1.  Call GCP/AWS/other api and get list of resources.\n2.  Iterate over resources and take only the ID (we don\'t need mapping fields!).\n3.  Call to provider for readonly fields.\n4.  Call to infrastructure and take tf + tfstate.\n\n## Infrastructure\n\n1.  Call to provider using the refresh method and get all data.\n2.  Convert refresh data to go struct.\n3.  Generate HCL file - `tf` files.\n4.  Generate `tfstate` files.\n\nAll mapping of resource is made by providers and Terraform. Upgrades are needed only\nfor providers.\n\n##### GCP compute resources\n\nFor GCP compute resources, use generated code from\n`providers/gcp/gcp_compute_code_generator`.\n\nTo regenerate code:\n\n```\ngo run providers/gcp/gcp_compute_code_generator/*.go\n```\n\n### Similar projects\n\n#### [terraforming](https://github.com/dtan4/terraforming)\n\n##### Terraformer Benefits\n\n* Simpler to add new providers and resources - already supports AWS, GCP, GitHub, Kubernetes, and Openstack. Terraforming supports only AWS.\n* Better support for HCL + tfstate, including updates for Terraform 0.12.\n* If a provider adds new attributes to a resource, there is no need change Terraformer code - just update the Terraform provider on your laptop.\n* Automatically supports connections between resources in HCL files.\n\n##### Comparison\n\nTerraforming gets all attributes from cloud APIs and creates HCL and tfstate files with templating. Each attribute in the API needs to map to attribute in Terraform. Generated files from templating can be broken with illegal syntax. When a provider adds new attributes the terraforming code needs to be updated.\n\nTerraformer instead uses Terraform provider files for mapping attributes, HCL library from Hashicorp, and Terraform code.\n\nLook for S3 support in terraforming here and official S3 support\nTerraforming lacks full coverage for resources - as an example you can see that 70% of S3 options are not supported:\n\n* terraforming - https://github.com/dtan4/terraforming/blob/master/lib/terraforming/template/tf/s3.erb\n* official S3 support - https://www.terraform.io/docs/providers/aws/r/s3_bucket.html\n'