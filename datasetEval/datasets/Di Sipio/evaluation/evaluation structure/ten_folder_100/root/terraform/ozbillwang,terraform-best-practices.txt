b'# terraform-best-practices\n\nTerraform Best Practices for AWS users.\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON\'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n**Table of Contents**  \n\n- [Run terraform command with var-file](#run-terraform-command-with-var-file)\n- [Manage s3 backend for tfstate files](#manage-s3-backend-for-tfstate-files)\n  - [Notes](#notes)\n- [Manage multiple Terraform modules and environments easily with Terragrunt](#manage-multiple-terraform-modules-and-environments-easily-with-terragrunt)\n- [Retrieve state meta data from a remote backend](#retrieve-state-meta-data-from-a-remote-backend)\n- [Turn on debug when you need do troubleshooting.](#turn-on-debug-when-you-need-do-troubleshooting)\n- [Use shared modules](#use-shared-modules)\n  - [Notes](#notes-1)\n- [Isolate environment](#isolate-environment)\n- [Use terraform import to include as many resources you can](#use-terraform-import-to-include-as-many-resources-you-can)\n- [Avoid hard coding the resources](#avoid-hard-coding-the-resources)\n- [validate and format terraform code](#validate-and-format-terraform-code)\n- [Enable version control on terraform state files bucket](#enable-version-control-on-terraform-state-files-bucket)\n- [Generate README for each module with input and output variables](#generate-readme-for-each-module-with-input-and-output-variables)\n- [Update terraform version](#update-terraform-version)\n- [Run terraform in docker container](#run-terraform-in-docker-container)\n- [Run test](#run-test)\n  - [Quick start](#quick-start)\n  - [Run test within docker container](#run-test-within-docker-container)\n- [Minimum AWS permissions necessary for a Terraform run](#minimum-aws-permissions-necessary-for-a-terraform-run)\n- [Tips to deal with lambda functions](#tips-to-deal-with-lambda-functions)\n  - [explanation](#explanation)\n  - [Notes](#notes-2)\n- [usage of variable "self"](#usage-of-variable-self)\n  - [One more use case](#one-more-use-case)\n- [Use pre-installed Terraform plugins](#use-pre-installed-terraform-plugins)\n- [Tips to upgrade to terraform 0.12](#tips-to-upgrade-to-terraform-012)\n- [Useful documents you should read](#useful-documents-you-should-read)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n>the READM for terraform version 0.11 and less has been renamed to [README.0.11.md](README.0.11.md)\n\n## Run terraform command with var-file\n\n```\n$ cat config/dev.tfvars\n\nname = "dev-stack"\ns3_terraform_bucket = "dev-stack-terraform"\ntag_team_name = "hello-world"\n \n$ terraform plan -var-file=config/dev.tfvars\n```\n\nWith `var-file`, you can easily manage environment (dev/stag/uat/prod) variables.\n\nWith `var-file`, you avoid running terraform with long list of key-value pairs ( `-var foo=bar` )\n\n## Manage s3 backend for tfstate files\n\nTerraform doesn\'t support [Interpolated variables in terraform backend config](https://github.com/hashicorp/terraform/pull/12067), normally you write a seperate script to define s3 backend bucket name for different environments, but I recommend to hard code it directly as below\n\nAdd below code in terraform configuration files.\n```\n$ cat main.tf\n\nterraform {\n  required_version = "~> 0.12"\n\n  backend "s3" {\n    encrypt = true\n  }\n}\n```\n\nDefine backend variables for particular environment\n```\n$ cat config/backend-dev.conf\nbucket  = "<unique_bucket_name>-terraform-development"\nkey     = "development/service-1.tfstate"\nencrypt = true\nregion  = "ap-southeast-2"\nkms_key_id = "alias/terraform"\ndynamodb_table = "terraform-lock"\n```\n\n### Notes\n\n- bucket - s3 bucket name, has to be globally unique.\n- key - Set some meaningful names for different services and applications, such as vpc.tfstate, application_name.tfstate, etc\n- dynamodb_table - optional when you want to enable [State Locking](https://www.terraform.io/docs/state/locking.html)\n\nAfter you set `config/backend-dev.conf` and `config/dev.tfvars` properly (for each environment). You can easily run terraform as below:\n\n```\nenv=dev\nterraform get -update=true\nterraform init -backend-config=config/backend-${env}.conf\nterraform plan -var-file=config/${env}.tfvars\nterraform apply -var-file=config/${env}.tfvars\n```\n\n## Manage multiple Terraform modules and environments easily with Terragrunt\n\nTerragrunt is a thin wrapper for Terraform that provides extra tools for working with multiple Terraform modules. https://www.gruntwork.io\n\nSample for reference: https://github.com/gruntwork-io/terragrunt-infrastructure-live-example\n\nIts README is too long, if you need a quick start, follow below steps:\n\n```\n# Install terraform and terragrunt\n# Make sure you are in right aws account\n$ aws s3 ls\n# use terragrunt to deploy\n$ git clone https://github.com/gruntwork-io/terragrunt-infrastructure-live-example.git\n$ cd terragrunt-infrastructure-live-example\n# for example, you want to deploy mysql in stage non-prod at region us-east-1\n$ cd non-prod/us-east-1/stage/mysql\n$ terragrunt plan\n# Confirm everything works\n$ terragrunt apply\n```\n\nSo if you followed the setting in terragrunt properly, you don\'t need to care about the backend state files and variable file path in different environments, even more, you can run `terragrunt plan-all` to plan all modules together.\n\n## Retrieve state meta data from a remote backend\n\nNormally we have several layers to manage terraform resources, such as network, database, application layers. After you create the basic network resources, such as vpc, security group, subnets, nat gateway in vpc stack. Your database layer and applications layer should always refer the resource from vpc layer directly via `terraform_remote_state` data srouce. \n\n>Notes: in Terraform v0.12+, you need add extra `outputs` to reference the attributes, otherwise you will get error message of [Unsupported attribute](https://github.com/hashicorp/terraform/issues/21442)\n\n```\ndata "terraform_remote_state" "vpc" {\n  backend = "s3"\n  config = {\n    bucket = var.s3_terraform_bucket\n    key    = "${var.environment}/vpc.tfstate"\n    region = var.aws_region\n  }\n}\n \n# Retrieves the vpc_id and subnet_ids directly from remote backend state files.\nresource "aws_xx_xxxx" "main" {\n  # ...\n  subnet_ids = split(",", data.terraform_remote_state.vpc.data_subnets)\n  vpc_id     = data.terraform_remote_state.vpc.outputs.vpc_id\n}\n```\n\n## Turn on debug when you need do troubleshooting.\n\n```\nTF_LOG=DEBUG terraform <command>\n\n# or if you run with terragrunt\nTF_LOG=DEBUG terragrunt <command>\n```\n\n## Use shared modules\n\nManage terraform resource with shared modules, this will save a lot of coding time. No need re-invent the wheel!\n\nYou can start from below links: \n\n[terraform module usage](https://www.terraform.io/docs/modules/usage.html)\n\n[Terraform Module Registry](https://registry.terraform.io/)\n\n[Terraform aws modules](https://github.com/terraform-aws-modules)\n\n### Notes\n\nterraform modules don\'t support `count` parameter currently. You can follow up this ticket for updates: https://github.com/hashicorp/terraform/issues/953\n\n## Isolate environment\n\nSometimes, developers like to create a security group and share it to all non-prod (dev/qa) environments. Don\'t do that, create resources with different name for each environment and each resource.\n\n```\nvariable "application" {\n  description = "application name"\n  default = "<replace_with_your_project_or_application_name>"\n}\n\nvariable "environment" {\n  description = "environment name"\n}\n\nlocals {\n  name_prefix    = "${var.application}-${var.environment}"\n}\n\nresource "<any_resource>" {\n  name = "${local.name_prefix}-<resource_name>"\n  ...\n}\n```\nWith that, you will easily define the resource with a meaningful and unique name, and you can build more of the same application stack for different developers without change a lot. For example, you update the environment to dev, staging, uat, prod, etc.\n\n>Tips: some aws resource names have length limits, such as less than 24 characters, so when you define variables of application and environment name, use short name.\n\n## Use terraform import to include as many resources you can\n\nSometimes developers manually created resources. You need to mark these resource and use `terraform import` to include them in codes.\n\n[terraform import](https://www.terraform.io/docs/import/usage.html)\n\n## Avoid hard coding the resources\n\nA sample:\n```\naccount_number=\xe2\x80\x9c123456789012"\naccount_alias="mycompany"\nregion="us-east-2"\n```\n\nThe current aws account id, account alias and current region can be input directly via [data sources](https://www.terraform.io/docs/providers/aws/).\n\n```\n# The attribute `${data.aws_caller_identity.current.account_id}` will be current account number. \ndata "aws_caller_identity" "current" {}\n\n# The attribue `${data.aws_iam_account_alias.current.account_alias}` will be current account alias\ndata "aws_iam_account_alias" "current" {}\n\n# The attribute `${data.aws_region.current.name}` will be current region\ndata "aws_region" "current" {}\n\n# Set as [local values](https://www.terraform.io/docs/configuration/locals.html)\nlocals {\n  account_id    = data.aws_caller_identity.current.account_id\n  account_alias = data.aws_iam_account_alias.current.account_alias\n  region        = data.aws_region.current.name\n}\n```\n\n## validate and format terraform code\n\nAlways run `terraform fmt` to format terraform configuration files and make them neat.\n\nI used below code in Travis CI pipeline (you can re-use it in any pipelines) to validate and format check the codes before you can merge it to master branch.\n\n      - terraform validate\n      - terraform fmt -check=true -write=false -diff=true\n\nOne more check [tflint](https://github.com/wata727/tflint)  you can add\n\n      - docker run --rm -v $(pwd):/data -t wata727/tflint\n\n## Enable version control on terraform state files bucket\n\nAlways set backend to s3 and enable version control on this bucket. \n\nIf you\'d like to manage terraform state bucket as well, I recommend using this repostory I wrote [tf_aws_tfstate_bucket](https://github.com/BWITS/tf_aws_tfstate_bucket) to create the bucket and replicate to other regions automatically. \n\n## Generate README for each module with input and output variables\n\nYou needn\'t manually manage `USAGE` about input variables and outputs. A tool named `terraform-docs` can do the job for you.\n\n>Currently original terraform-docs doesn\'t support terraform 0.12+, follow this issue (https://github.com/segmentio/terraform-docs/issues/62) for updating.\n\nNow we have a work around.\n\n```\n# [Terraform >= 0.12]\ndocker run --rm \\\n  -v $(pwd):/data \\\n  cytopia/terraform-docs \\\n  terraform-docs-012 --sort-inputs-by-required --with-aggregate-type-defaults md . > README.md\n```\n\nFor details on how to run `terraform-docs`, check this repository: https://github.com/cytopia/docker-terraform-docs\n\nThere is a simple sample for you to start [tf_aws_acme](https://github.com/BWITS/tf_aws_acme), the README is generatd by `terraform-docs`\n\n## Update terraform version\n\nHashicorp doesn\'t have a good qa/build/release process for their software and does not follow semantic versioning rules.\n\nFor example, `terraform init` isn\'t compatible between 0.9 and 0.8. Now they are going to split providers and use "init" to install providers as plugin in coming version 0.10\n\nSo recommend to keep updating to latest terraform version\n\n## Run terraform in docker container\n\nTerraform releases official docker containers that you can easily control which version you can run.\n\nRecommend to run terraform docker container, when you set your build job in CI/CD pipeline.\n\n```\nTERRAFORM_IMAGE=hashicorp/terraform:0.12.3\nTERRAFORM_CMD="docker run -ti --rm -w /app -v ${HOME}/.aws:/root/.aws -v ${HOME}/.ssh:/root/.ssh -v `pwd`:/app -w /app ${TERRAFORM_IMAGE}"\n${TERRAFORM_CMD} init\n${TERRAFORM_CMD} plan\n```\n\nOr with `terragrunt`\n\n```\n# (1) must mount the local folder to /apps in container.\n# (2) must mount the aws credentials and ssh config folder in container.\n$ docker run -ti --rm -v $HOME/.aws:/root/.aws -v ${HOME}/.ssh:/root/.ssh -v `pwd`:/apps alpine/terragrunt:0.12.3 bash\n# cd to terragrunt configuration directory, if required.\n$ terragrunt plan-all\n$ terragrunt apply-all\n```\n\n## Run test\n\nRecommend to add [awspec](https://github.com/k1LoW/awspec) tests through [kitchen](https://kitchen.ci/) and [kitchen-terraform](https://newcontext-oss.github.io/kitchen-terraform/).\n\n### Quick start\n\nReference: repo [terraform-aws-modules/terraform-aws-eks](https://github.com/terraform-aws-modules/terraform-aws-eks#testing)\n\n### Run test within docker container\n\nReference: [README for terraform awspec container](https://github.com/alpine-docker/bundle-terraform-awspec)\n\n## Minimum AWS permissions necessary for a Terraform run\n\nThere will be no answer for this. But with below iam policy you can easily get started.\n```json\n{\n    "Version": "2012-10-17",\n    "Statement": [\n        {\n            "Sid": "AllowSpecifics",\n            "Action": [\n                "lambda:*",\n                "apigateway:*",\n                "ec2:*",\n                "rds:*",\n                "s3:*",\n                "sns:*",\n                "states:*",\n                "ssm:*",\n                "sqs:*",\n                "iam:*",\n                "elasticloadbalancing:*",\n                "autoscaling:*",\n                "cloudwatch:*",\n                "cloudfront:*",\n                "route53:*",\n                "ecr:*",\n                "logs:*",\n                "ecs:*",\n                "application-autoscaling:*",\n                "logs:*",\n                "events:*",\n                "elasticache:*",\n                "es:*",\n                "kms:*",\n                "dynamodb:*"\n            ],\n            "Effect": "Allow",\n            "Resource": "*"\n        },\n        {\n            "Sid": "DenySpecifics",\n            "Action": [\n                "iam:*User*",\n                "iam:*Login*",\n                "iam:*Group*",\n                "iam:*Provider*",\n                "aws-portal:*",\n                "budgets:*",\n                "config:*",\n                "directconnect:*",\n                "aws-marketplace:*",\n                "aws-marketplace-management:*",\n                "ec2:*ReservedInstances*"\n            ],\n            "Effect": "Deny",\n            "Resource": "*"\n        }\n    ]\n}\n```\n\nDepend on your company or project requirement, you can easily update the resources in `Allow` session which terraform commands should have, and add deny policies in `Deny` session if some of permissions are not required.\n\n## Tips to deal with lambda functions\n\nHeadache to save python packages from `pip install` into source codes and generate lambda zip file manually? Here is full codes with solution.\n\nThe folder [lambda](./lambda) includes all codes, here is the explanation.\n\n```\n$ tree\n.\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 lambda.tf              # terraform HCL to deal with lambda\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 pip.sh                 # script to install python packages with pip.\n\xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 source\n    \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 .gitignore         # Ignore all other files\n    \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 main.py            # Lambda function, replace with yours\n    \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 requirements.txt   # python package list, replace with yours.\n    \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 setup.cfg          # Useful for mac users who installed python using Homebrew\n```\n\nReplace `main.py` and `requirements.txt` with your applications.\n\n### explanation\n\nAfter you run `terraform apply`, it will:\n\n1. install all pip packages into source folder\n2. zip the source folder to `source.zip`\n3. deploy lambda function with `source.zip`\n4. because of `source/.gitignore`, it will ignore all new installed pip packages in git source codes.\n\nThis solution is reference from the comments in [Ability to zip AWS Lambda function on the fly](https://github.com/hashicorp/terraform/issues/8344#issuecomment-345807204))\n\nYou should be fine to do the same for lambda functions using nodejs (`npm install`) or other languages with this tip.\n\n### Notes\n\nYou need have python/pip installed when run terraform commands, if you run in terraform container, make sure you install python/pip in it.\n\n## usage of variable "self"\n\nQuote from terraform documents:\n>Attributes of your own resource\n\n>The syntax is self.ATTRIBUTE. For example ${self.private_ip} will interpolate that resource\'s private IP address.\n\n>Note: The self.ATTRIBUTE syntax is only allowed and valid within provisioners.\n\n### One more use case\n```\nresource "aws_ecr_repository" "jenkins" {\n  name = var.image_name\n  provisioner "local-exec" {\n    command = "./deploy-image.sh ${self.repository_url} ${var.jenkins_image_name}"\n  }\n}\n\nvariable "jenkins_image_name" {\n  default = "mycompany/jenkins"\n  description = "Jenkins image name."\n}\n```\nYou can easily define ecr image url (`<account_id>.dkr.ecr.<aws_region>.amazonaws.com/<image_name>`) with ${self.repository_url}\n\nAny attributes in this resource can be self referenced by this way.\n\nReference: https://github.com/shuaibiyy/terraform-ecs-jenkins/blob/master/docker/main.tf\n\n## Use pre-installed Terraform plugins\n\nThere is a way to use pre-installed Terraform plugins instead of downloading them with `terraform init`, the accepted answer below gives the detail:\n\n[Use pre-installed Terraform plugins instead of downloading them with terraform init](https://stackoverflow.com/questions/50944395/use-pre-installed-terraform-plugins-instead-of-downloading-them-with-terraform-i?rq=1)\n\n## Tips to upgrade to terraform 0.12\n\nIf you have any codes older than 0.12, please go through official documents first,\n\n* [terraform Input Variables](https://www.terraform.io/docs/configuration/variables.html), a lot of new features you have to know.\n* [Upgrading to Terraform v0.12](https://www.terraform.io/upgrade-guides/0-12.html)\n* [terraform command 0.12upgrade](https://www.terraform.io/docs/commands/0.12upgrade.html)\n* [Announcing Terraform 0.12](https://www.hashicorp.com/blog/announcing-terraform-0-12)\n\nThen here are extra tips for you.\n\n* upgrade to terraform 0.11 first, if you have any.\n* upgrade terraform moudles to 0.12 first, because terraform 0.12 can\'t work with 0.11 modules.\n* define `type` for each variable, otherwise you will get weird error messages.\n \n## Useful documents you should read\n\n[terraform tips & tricks: loops, if-statements, and gotchas](https://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9)\n'