b'# MetalPetal\n\n[![Platform](https://img.shields.io/badge/platform-iOS%209.0%2B%20%7C%20macOS%2010.13%2B-blue.svg?style=flat-square)](#)\n[![Version](https://img.shields.io/cocoapods/v/MetalPetal.svg?style=flat-square)](#)\n[![License](https://img.shields.io/cocoapods/l/MetalPetal.svg?style=flat-square)](#)\n\nAn image processing framework based on Metal.\n\n<!-- TOC depthFrom:2 -->\n\n- [Design Overview](#design-overview)\n    - [Goals](#goals)\n    - [Core Components](#core-components)\n        - [MTIContext](#mticontext)\n        - [MTIImage](#mtiimage)\n        - [MTIFilter](#mtifilter)\n        - [MTIKernel](#mtikernel)\n    - [Alpha Type Handling](#alpha-type-handling)\n    - [Optimizations](#optimizations)\n    - [Concurrency Considerations](#concurrency-considerations)\n    - [Advantages over Core Image](#advantages-over-core-image)\n    - [Extensions](#extensions)\n        - [Working with SceneKit](#working-with-scenekit)\n        - [Working with JavaScript](#working-with-javascript)\n        - [Texture Loader](#texture-loader)\n- [Builtin Filters](#builtin-filters)\n- [Example Code](#example-code)\n    - [Create a `MTIImage`](#create-a-mtiimage)\n    - [Create a Filtered Image](#create-a-filtered-image)\n    - [Render a `MTIImage`](#render-a-mtiimage)\n- [Quick Look Debug Support](#quick-look-debug-support)\n- [Best Practices](#best-practices)\n- [Build Custom Filter](#build-custom-filter)\n    - [Shader Function Arguments Encoding](#shader-function-arguments-encoding)\n    - [Simple Single Input / Output Filters](#simple-single-input--output-filters)\n    - [Fully Custom Filters](#fully-custom-filters)\n    - [Multiple Draw Calls in One Render Pass](#multiple-draw-calls-in-one-render-pass)\n    - [Custom Vertex Data](#custom-vertex-data)\n    - [Custom Processing Module](#custom-processing-module)\n- [Install](#install)\n- [iOS Simulator Support](#ios-simulator-support)\n- [Trivia](#trivia)\n- [Contribute](#contribute)\n- [License](#license)\n\n<!-- /TOC -->\n\n## Design Overview\n\nMetalPetal is an image processing framework based on [Metal](https://developer.apple.com/metal/) designed to provide real-time processing for still image and video with easy to use programming interfaces.\n\nThis chapter covers the key concepts of MetalPetal, and will help you to get a better understanding of its design, implementation, performance implications and best practices.\n\n### Goals\n\nMetalPetal is designed with the following goals in mind.\n\n- Easy to use API\n\n    Provides convenience APIs and avoids common pitfalls.\n\n- Performance\n\n    Use CPU, GPU and memory efficiently.\n\n- Extensibility\n\n    Easy to create custom filters as well as plugin your custom image processing unit.\n\n- Swifty\n\n    Provides a fluid experience for Swift programmers.\n\n### Core Components\n\nSome of the core concepts of MetalPetal are very similar to those in Apple\'s Core Image framework.\n\n#### MTIContext\n\nProvides an evaluation context for rendering `MTIImage`s. It also stores a lot of caches and state information, so it\'s more efficient to reuse a context whenever possible.\n\n#### MTIImage\n\n A `MTIImage` object is a representation of an image to be processed or produced. It does directly represent image bitmap data instead it has all the information necessary to produce an image or more precisely a `MTLTexture`. It consists of two parts, a recipe of how to produce the texture (`MTIImagePromise`) and other information such as how a context caches the image (`cachePolicy`), and how the texture should be sampled (`samplerDescriptor`).\n\n#### MTIFilter\n\nA `MTIFilter` represents an image processing effect and any parameters that control that effect. It produces a `MTIImage` object as output. To use a filter, you create a filter object, set its input images and parameters, and then access its output image. Typically, a filter class owns a static kernel (`MTIKernel`), when you access its `outputImage` property, it asks the kernel with the input images and parameters to produce an output `MTIImage`. \n\n#### MTIKernel\n\nA `MTIKernel` represents an image processing routine. `MTIKernel` is responsible for creating the cooresponding render or compute pipeline state for the filter, as well as building the `MTIImagePromise` for a `MTIImage`.\n\n### Alpha Type Handling\n\nIf an alpha channel is used in an image, there are two common representations that are available: unpremultiplied (straight/unassociated) alpha, and premultiplied (associated) alpha.\n\nWith unpremultiplied alpha, the RGB components represent the color of the pixel, disregarding its opacity.\n\nWith premultiplied alpha, the RGB components represent the color of the pixel, adjusted for its opacity by multiplication.\n\nMost of the filters in MetalPetal accept unpremultiplied alpha and opaque images and output unpremultiplied alpha images. Some filters, such as  `MTIMultilayerCompositingFilter` accepts both unpremultiplied/premultiplied alpha images.\n\nMetalPetal handles alpha type explicitly. You are responsible for providing the correct alpha type during image creation.\n\nThere are three alpha types in MetalPetal.\n\n`MTIAlphaType.nonPremultiplied`: the alpha value in the image is not premultiplied.\n\n`MTIAlphaType.premultiplied`: the alpha value in the image is premultiplied.\n\n`MTIAlphaType.alphaIsOne`: there\'s no alpha channel in the image or the image is opaque.\n\nTypically, `CGImage`, `CVPixelBuffer`, `CIImage` objects have premultiplied alpha channel. `MTIAlphaType.alphaIsOne` is strongly recommanded if the image is opaque, e.g. a `CVPixelBuffer` from camera feed, or a `CGImage` loaded from a `jpg` file.\n\nYou can call `unpremultiplyingAlpha()` or `premultiplyingAlpha()` on a `MTIImage` to convert the alpha type of the image.\n\nFor performance reasons, alpha type validation only happens in debug build.\n\n### Optimizations\n\nMetalPetal does a lot of optimizations for you under the hood.\n\nIt automatically caches functions, kernel states, samplers, etc.\n\nBefore rendering, MetalPetal can look into your image render graph and figure out the minimal number of intermedinate textures needed to do the rendering, saving memory, energy and time.\n\nIt can also re-organize the image render graph if multiple \xe2\x80\x9crecipes\xe2\x80\x9d can be concatenated to eliminate redundant render passes. (`MTIContext.isRenderGraphOptimizationEnabled`)\n\n### Concurrency Considerations\n\n`MTIImage` objects are immutable, which means they can be shared safely among threads.\n\nHowever, `MTIFilter` objects are mutable and thus cannot be shared safely among threads.\n\nA `MTIContext` contains a lot of states and caches. There\'s a thread-safe mechanism for `MTIContext` objects, making it safe to share a `MTIContext` object among threads.\n\n### Advantages over Core Image\n\n- Fully customizable vertex and fragment functions.\n\n- MRT (Multiple Render Targets) support.\n\n- Generally better performance. (Detailed benchmark data needed)\n\n### Extensions\n\n#### Working with SceneKit\n\nYou can use `MTISCNSceneRenderer` to generate `MTIImage`s from a `SCNScene`. You may want to handle the SceneKit renderer\'s linear RGB color space, see issue [#76 The image from SceneKit is darker than normal](https://github.com/MetalPetal/MetalPetal/issues/76).\n\n#### Working with JavaScript\n\nSee [MetalPetalJS](https://github.com/MetalPetal/MetalPetalJS)\n\nWith MetalPetalJS you can create render pipelines and filters using JavaScript, making it possible to download your filters/renderers from "the cloud".\n\n#### Texture Loader\n\nMetalPetal, by default, uses `MTKTextureLoader` to load `CGImage`s, images from `URL`, and named images.\n\nYou can custom this behavior by implementing the `MTITextureLoader` protocol. Then assign your texture loader class to `MTIContextOptions.textureLoaderClass` when creating a `MTIContext`.\n\nThe `MTKTextureLoader` on iOS 9 loads images with the bottom-left origin by default. MetalPetal provides a custom texture loader to resolve this issue. You can add the following code if you\'d like MetalPetal to use the `MTITextureLoaderForiOS9WithImageOrientationFix` on iOS 9. Releated issue(s): [#67 MTIColorLookupFilter error result](https://github.com/MetalPetal/MetalPetal/issues/67)\n\n```\nif (NSFoundationVersionNumber <= NSFoundationVersionNumber_iOS_9_x_Max) {\n    MTIContextOptions.defaultTextureLoaderClass = MTITextureLoaderForiOS9WithImageOrientationFix.class;\n}\n```\n\n## Builtin Filters\n\n- Color Matrix\n\n- Color Lookup\n\n    Uses an color lookup table to remap the colors in an image.\n\n- Opacity\n\n- Exposure\n\n- Saturation\n\n- Brightness\n\n- Contrast\n\n- Color Invert\n\n- Vibrance\n\n    Adjusts the saturation of an image while keeping pleasing skin tones.\n\n- RGB Tone Curve\n\n- Blend Modes\n\n    - Normal\n    - Multiply\n    - Overlay\n    - Screen\n    - Hard Light\n    - Soft Light\n    - Darken\n    - Lighten\n    - Color Dodge\n    - Add (Linear Dodge)\n    - Color Burn\n    - Linear Burn\n    - Lighter Color\n    - Darker Color\n    - Vivid Light\n    - Linear Light\n    - Pin Light\n    - Hard Mix\n    - Difference\n    - Exclusion\n    - Subtract\n    - Divide\n    - Hue\n    - Saturation\n    - Color\n    - Luminosity\n    - ColorLookup512x512\n\n- Blend with Mask\n\n- Transform\n\n- Crop\n\n- Pixellate\n\n- Multilayer Composite\n\n- MPS Convolution\n\n- MPS Gaussian Blur\n\n- MPS Definition\n\n- MPS Sobel\n\n- MPS Unsharp Mask\n\n- MPS Box Blur\n\n- [High Pass Skin Smoothing](https://github.com/YuAo/YUCIHighPassSkinSmoothing)\n\n- [CLAHE (Contrast-Limited Adaptive Histogram Equalization)](https://github.com/YuAo/Accelerated-CLAHE)\n\n- [Lens Blur (Hexagonal Bokeh Blur)](https://github.com/YuAo/HexagonalBokehBlur)\n\n- [Surface Blur](https://github.com/MetalPetal/SurfaceBlur)\n\n- Bulge Distortion\n\n- Chroma Key Blend\n\n- Color Halftone\n\n- Dot Screen\n\n## Example Code\n\n### Create a `MTIImage`\n\n```Swift\nlet imageFromCGImage = MTIImage(cgImage: cgImage, options: [.SRGB: false])\n\nlet imageFromCIImage = MTIImage(ciImage: ciImage)\n\nlet imageFromCoreVideoPixelBuffer = MTIImage(cvPixelBuffer: pixelBuffer, alphaType: .alphaIsOne)\n\nlet imageFromContentsOfURL = MTIImage(contentsOf: url, options: [.SRGB: false])\n\n// unpremultiply alpha if needed\nlet unpremultipliedAlphaImage = image.unpremultiplyingAlpha()\n```\n\n### Create a Filtered Image\n\n```Swift\nlet inputImage = ...\n\nlet filter = MTISaturationFilter()\nfilter.saturation = 0\nfilter.inputImage = inputImage\n\nlet outputImage = filter.outputImage\n```\n\n### Render a `MTIImage`\n\n```Swift\nlet options = MTIContextOptions()\n\nguard let device = MTLCreateSystemDefaultDevice(), let context = try? MTIContext(device: device, options: options) else {\n    return\n}\n\nlet image: MTIImage = ...\n\ndo {\n    try context.render(image, to: pixelBuffer) \n    \n    //context.makeCIImage(from: image)\n    \n    //context.makeCGImage(from: image)\n} catch {\n    print(error)\n}\n```\n\n## Quick Look Debug Support\n\nIf you do a Quick Look on a `MTIImage`, it\'ll show you the image graph that you constructed to produce that image.\n\n![Quick Look Debug Preview](Assets/quick_look_debug_preview.jpg)\n\n## Best Practices\n\n- Reuse a `MTIContext` whenever possible.\n\n    Contexts are heavyweight objects, so if you do create one, do so as early as possible, and reuse it each time you need to render an image.\n\n- Use `MTIImage.cachePolicy` wisely.\n    \n    Use `MTIImageCachePolicyTransient` when you do not want to preserve the render result of a image, for example when the image is just an intermediate result in a filter chain, so the underlying texture of the render result can be reused. It is the most memory efficient option. However, when you ask the context to render a previously rendered image, it may re-render that image since its underlying texture has been reused.\n    \n    By default, a filter\'s output image has the `transient` policy.\n\n    Use `MTIImageCachePolicyPersistent` when you want to prevent the underlying texture from being reused.\n    \n    By default, images created from external sources have the `persistent` policy.\n\n- Understand that `MTIFilter.outputImage` is a compute property.\n\n    Each time you ask a filter for its output image, the filter may give you a new output image object even if the inputs are identical with the previous call. So reuse output images whenever possible.\n    \n    For example,\n\n     ```Swift\n    //          \xe2\x95\xad\xe2\x86\x92 filterB\n    // filterA \xe2\x94\x80\xe2\x94\xa4\n    //          \xe2\x95\xb0\xe2\x86\x92 filterC\n    // \n    // filterB and filterC use filterA\'s output as their input.\n    ```\n    In this situation, the following solution:\n    \n    ```Swift\n    let filterOutputImage = filterA.outputImage\n    filterB.inputImage = filterOutputImage\n    filterC.inputImage = filterOutputImage\n    ```\n    \n    is better than:\n\n    ```Swift\n    filterB.inputImage = filterA.outputImage\n    filterC.inputImage = filterA.outputImage\n    ```\n\n## Build Custom Filter\n\nIf you want to include the `MTIShaderLib.h` in your `.metal` file, you need to add the path of `MTIShaderLib.h` file to the `Metal Compiler - Header Search Paths` (`MTL_HEADER_SEARCH_PATHS`) setting.\n\nFor example, if you use CocoaPods you can set the `MTL_HEADER_SEARCH_PATHS` to  `${PODS_CONFIGURATION_BUILD_DIR}/MetalPetal/MetalPetal.framework/Headers` or `${PODS_ROOT}/MetalPetal/Frameworks/MetalPetal/Shaders`.\n\n### Shader Function Arguments Encoding\n\nMetalPetal has a built-in mechanism to encode shader function arguments for you. You can pass the shader function arguments as `name: value` dictionaries to the `MTIRenderPipelineKernel.apply(toInputImages:parameters:outputDescriptors:)`, `MTIRenderCommand(kernel:geometry:images:parameters:)`, etc.\n\nFor example, the parameter dictionary for the metal function `vibranceAdjust` can be:\n\n```Swift\n// Swift\nlet amount: Float = 1.0\nlet vibranceVector = float4(1, 1, 1, 1)\nlet parameters = ["amount": amount,\n                  "vibranceVector": MTIVector(value: vibranceVector),\n                  "avoidsSaturatingSkinTones": true,\n                  "grayColorTransform": MTIVector(value: float3(0,0,0))]\n```\n\n```Metal\n// vibranceAdjust metal function\nfragment float4 vibranceAdjust(...,\n                constant float & amount [[ buffer(0) ]],\n                constant float4 & vibranceVector [[ buffer(1) ]],\n                constant bool & avoidsSaturatingSkinTones [[ buffer(2) ]],\n                constant float3 & grayColorTransform [[ buffer(3) ]])\n{\n    ...\n}\n\n```\n\nThe shader function argument types and the coorresponding types to use in a parameter dictionary is listed below.\n\n| Shader Function Argument Type | Swift | Objective-C | \n| :--- | :--- | :--- |\n| float | Float | float |\n| int | Int32 | int |\n| uint | UInt32 | uint |\n| bool | Bool | bool |\n| simd (float2,float4,float4x4,int4, etc.) | MTIVector | MTIVector |\n| struct | Data / MTIDataBuffer | NSData / MTIDataBuffer |\n| other (float *, struct *, etc.) immutable | Data / MTIDataBuffer | NSData / MTIDataBuffer |\n| other (float *, struct *, etc.) mutable | MTIDataBuffer | MTIDataBuffer |\n\n### Simple Single Input / Output Filters\n\nTo build a custom unary filter, you can subclass `MTIUnaryImageRenderingFilter` and override the methods in the `SubclassingHooks` category. Examples: `MTIPixellateFilter`, `MTIVibranceFilter`, `MTIUnpremultiplyAlphaFilter`, `MTIPremultiplyAlphaFilter`, etc.\n\n```ObjectiveC\n//Objective-C\n\n@interface MTIPixellateFilter : MTIUnaryImageRenderingFilter\n\n@property (nonatomic) float fractionalWidthOfAPixel;\n\n@end\n\n@implementation MTIPixellateFilter\n\n- (instancetype)init {\n    if (self = [super init]) {\n        _fractionalWidthOfAPixel = 0.05;\n    }\n    return self;\n}\n\n+ (MTIFunctionDescriptor *)fragmentFunctionDescriptor {\n    return [[MTIFunctionDescriptor alloc] initWithName:@"pixellateEffect" libraryURL:[bundle URLForResource:@"default" withExtension:@"metallib"]];\n}\n\n- (NSDictionary<NSString *,id> *)parameters {\n    return @{@"fractionalWidthOfAPixel": @(self.fractionalWidthOfAPixel)};\n}\n\n@end\n```\n\n```Swift\n//Swift\n\nclass MTIPixellateFilter: MTIUnaryImageRenderingFilter {\n    \n    var fractionalWidthOfAPixel: Float = 0.05\n\n    override var parameters: [String : Any] {\n        return ["fractionalWidthOfAPixel": fractionalWidthOfAPixel]\n    }\n    \n    override class func fragmentFunctionDescriptor() -> MTIFunctionDescriptor {\n        return MTIFunctionDescriptor(name: "pixellateEffect", libraryURL: MTIDefaultLibraryURLForBundle(Bundle.main))\n    }\n}\n```\n\n### Fully Custom Filters\n\nTo build more complex filters, all you need to do is create a kernel (`MTIRenderPipelineKernel`/`MTIComputePipelineKernel`/`MTIMPSKernel`), then apply the kernel to the input image(s). Examples: `MTIChromaKeyBlendFilter`, `MTIBlendWithMaskFilter`, `MTIColorLookupFilter`, etc.\n\n```ObjectiveC\n\n@interface MTIChromaKeyBlendFilter : NSObject <MTIFilter>\n\n@property (nonatomic, strong, nullable) MTIImage *inputImage;\n\n@property (nonatomic, strong, nullable) MTIImage *inputBackgroundImage;\n\n@property (nonatomic) float thresholdSensitivity;\n\n@property (nonatomic) float smoothing;\n\n@property (nonatomic) MTIColor color;\n\n@end\n\n@implementation MTIChromaKeyBlendFilter\n\n@synthesize outputPixelFormat = _outputPixelFormat;\n\n+ (MTIRenderPipelineKernel *)kernel {\n    static MTIRenderPipelineKernel *kernel;\n    static dispatch_once_t onceToken;\n    dispatch_once(&onceToken, ^{\n        kernel = [[MTIRenderPipelineKernel alloc] initWithVertexFunctionDescriptor:[[MTIFunctionDescriptor alloc] initWithName:MTIFilterPassthroughVertexFunctionName] fragmentFunctionDescriptor:[[MTIFunctionDescriptor alloc] initWithName:@"chromaKeyBlend"]];\n    });\n    return kernel;\n}\n\n- (instancetype)init {\n    if (self = [super init]) {\n        _thresholdSensitivity = 0.4;\n        _smoothing = 0.1;\n        _color = MTIColorMake(0.0, 1.0, 0.0, 1.0);\n    }\n    return self;\n}\n\n- (MTIImage *)outputImage {\n    if (!self.inputImage || !self.inputBackgroundImage) {\n        return nil;\n    }\n    return [self.class.kernel applyToInputImages:@[self.inputImage, self.inputBackgroundImage]\n                                      parameters:@{@"color": [MTIVector vectorWithFloat4:(simd_float4){self.color.red, self.color.green, self.color.blue,self.color.alpha}],\n                                    @"thresholdSensitivity": @(self.thresholdSensitivity),\n                                               @"smoothing": @(self.smoothing)}\n                         outputTextureDimensions:MTITextureDimensionsMake2DFromCGSize(self.inputImage.size)\n                               outputPixelFormat:self.outputPixelFormat];\n}\n\n@end\n```\n\n### Multiple Draw Calls in One Render Pass\n\nYou can use `MTIRenderCommand` to issue multiple draw calls in one render pass.\n\n```Swift\n// Create a draw call with kernelA, geometryA, and imageA.\nlet renderCommandA = MTIRenderCommand(kernel: self.kernelA, geometry: self.geometryA, images: [imageA], parameters: [:])\n\n// Create a draw call with kernelB, geometryB, and imageB.\nlet renderCommandB = MTIRenderCommand(kernel: self.kernelB, geometry: self.geometryB, images: [imageB], parameters: [:])\n\n// Create an output descriptor\nlet outputDescriptor = MTIRenderPassOutputDescriptor(dimensions: MTITextureDimensions(width: outputWidth, height: outputHeight, depth: 1), pixelFormat: .bgra8Unorm, loadAction: .clear, storeAction: .store)\n\n// Get the output images, the output image count is equal to the output descriptor count.\nlet images = MTIRenderCommand.images(byPerforming: [renderCommandA, renderCommandB], outputDescriptors: [outputDescriptor])\n```\n\nYou can also create multiple output descriptors to output multiple images in one render pass (MRT, See https://en.wikipedia.org/wiki/Multiple_Render_Targets).\n\n### Custom Vertex Data\n\nWhen `MTIVertex` cannot fit your needs, you can implement the `MTIGeometry` protocol to provide your custom vertex data to the command encoder.\n\nUse the `MTIRenderCommand` API to issue draw calls and pass your custom `MTIGeometry`.\n\n### Custom Processing Module\n\nIn rare scenarios, you may want to access the underlying texture directly, use multiple MPS kernels in one render pass, do 3D rendering, or encode the render commands yourself.\n\n`MTIImagePromise` protocol provides direct access to the underlying texture and the render context for a step in MetalPetal.\n\nYou can create new input sources or fully custom processing unit by implementing `MTIImagePromise` protocol. You will need to import an additional module to do so. For Swift: `import MetalPetal.Extension`, Objective-C: `@import MetalPetal.Extension;`.\n\nSee the implementation of `MTIComputePipelineKernel`, `MTICLAHELUTRecipe` or `MTIImage` for example.\n\n## Install\n\nYou can use [CocoaPods](https://cocoapods.org/) to install the lastest version.\n\n```\nuse_frameworks!\n\npod \'MetalPetal\'\n\n# Swift extensions (optional).\npod \'MetalPetal/Swift\'\n\n```\n\nWe also provide a script to generate dynamic `.framework`s for you. You need to first install [CocoaPods/Rome](https://github.com/CocoaPods/Rome), then run [Rome/build_frameworks.sh](Rome/build_frameworks.sh)\n\n## iOS Simulator Support\n\nMetalPetal can run on Simulator with Xcode 11+ and macOS 10.15+.\n\n`MetalPerformanceShaders.framework` is not available on Simulator, so filters relies on `MetalPerformanceShaders`, such as `MTIMPSGaussianBlurFilter`, `MTICLAHEFilter`, do not work.\n\nSimulator supports fewer features or different implementation limits than an actual Apple GPU. See [Developing Metal Apps that Run in Simulator](https://developer.apple.com/documentation/metal/developing_metal_apps_that_run_in_simulator) for detail.\n\n## Trivia\n\n[Why Objective-C?](https://github.com/MetalPetal/MetalPetal/issues/52)\n\n## Contribute\n\nThank you for considering contributing to MetalPetal. Please read our [Contributing Guidelines](CONTRIBUTING.md).\n\n## License\n\nMetalPetal is MIT-licensed. [LICENSE](LICENSE)\n\nThe files in the `/MetalPetalDemo` directory are licensed under a separate license. [LICENSE.md](MetalPetalDemo/LICENSE.md)\n\nDocumentation is licensed CC-BY-4.0.\n'