b'# Serverless WarmUp Plugin \xe2\x99\xa8\n[![Serverless][serverless-badge]](serverless-badge-url)\n[![npm version][npm-version-badge]][npm-version-badge-url]\n[![npm monthly downloads][npm-downloads-badge]][npm-version-badge-url]\n[![Build Status][travis-badge]][travis-badge-url]\n[![Coverage Status][coveralls-badge]][coveralls-badge-url]\n[![Dependency Status][dev-badge]][dev-badge-url]\n[![license](https://img.shields.io/npm/l/serverless-plugin-warmup.svg)](https://raw.githubusercontent.com/FidelLimited/serverless-plugin-warmup/master/LICENSE)\n\nKeep your lambdas warm during winter.\n\n**Requirements:**\n* Serverless *v1.12.x* or higher (Recommended *v1.33.x* or higher because of [this](https://github.com/FidelLimited/serverless-plugin-warmup/pull/69)).\n* AWS provider\n\n## How it works\n\nWarmUp solves *cold starts* by creating a scheduled lambda that invokes all the selected service\'s lambdas in a configured time interval (default: 5 minutes) and forcing your containers to stay warm.\n\n## Installation\n\nInstall via npm in the root of your Serverless service:\n\n```sh\nnpm install --save-dev serverless-plugin-warmup\n```\n\nAdd the plugin to the `plugins` array in your Serverless `serverless.yaml`:\n\n```yaml\nplugins:\n  - serverless-plugin-warmup\n```\n\n## Configuration\n\nMost options are set under `custom.warmup` in the `serverless.yaml` file.\n\n* **folderName** Folder to temporarily store the generated code (defaults to `_warmup`)\n* **cleanFolder** Whether to automatically delete the generated code folder. You might want to keep it if you are doing some custom packaging (defaults to `true`)\n* **name** Name of the generated warmer lambda (defaults to `${service}-${stage}-warmup-plugin`)\n* **role** Role to apply to the warmer lambda (defaults to the role in the provider)\n* **tags** Tag to apply to the generated warmer lambda (defaults to the serverless default tags)\n* **vpc** The VPC and subnets in which to deploy. Can be any [Serverless VPC configuration](https://serverless.com/framework/docs/providers/aws/guide/functions#vpc-configuration) or be set to `false` in order to deploy the warmup function outside of a VPC (defaults to the vpc in the provider)\n* **memorySize** The memory to be assigned to the warmer lambda (defaults to `128`)\n* **events** The event that triggers the warmer lambda. Can be any [Serverless event](https://serverless.com/framework/docs/providers/aws/events/) (defaults to `- schedule: rate(5 minutes)`)\n* **package** The package configuration. Can be any [Serverless package configuration](https://serverless.com/framework/docs/providers/aws/guide/packaging#package-configuration) (defaults to `{ individually: true, exclude: [\'**\'], include: [\'_warmup/**\'] }`)\n* **timeout** How many seconds until the warmer lambda times out. (defaults to `10`)\n* **environment** Can be used to set environment variables in the warmer lambda. You can also unset variables configured at the provider by setting them to undefined. However, you should almost never have to change the default. (defaults to unset all package level environment variables. )\n* **prewarm** If set to true, it warms up your lambdas right after deploying (defaults to `false`)\n\nThere are also some options which can be set under `custom.warmup` to be applied to all your lambdas or under `yourLambda.warmup` to  overridde the global configuration for that particular lambda.\n\n* **enabled** Whether your lambda should be warmed up or not. Can be a boolean, a stage for which the lambda will be warmed up or a list of stages for which your lambda will be warmed up (defaults to `false`)\n* **payload** The payload to send to your lambda. This helps your lambda identify when the call comes from this plugin (defaults to `{ "source": "serverless-plugin-warmup" }`, )\n* **payloadRaw** Whether to leave the payload as-is. If false, the payload will be stringified into JSON. (defaults to `false`)\n* **concurrency** The number of times that each of your lambda functions will be called in parallel. This can be used in a best-effort attempt to force AWS to spin up more parallel containers for your lambda. (defaults to `1`)\n\n```yaml\ncustom:\n  warmup:\n    enabled: true # Whether to warm up functions by default or not\n    folderName: \'_warmup\' # Name of the folder created for the generated warmup \n    cleanFolder: false\n    memorySize: 256\n    name: \'make-them-pop\'\n    role: myCustRole0\n    tags:\n      Project: foo\n      Owner: bar \n    vpc: false\n    events:\n      - schedule: \'cron(0/5 8-17 ? * MON-FRI *)\' # Run WarmUp every 5 minutes Mon-Fri between 8:00am and 5:55pm (UTC)\n    package:\n      individually: true\n      exclude: # exclude additional binaries that are included at the serverless package level\n        - ../**\n        - ../../**\n      include:\n        - ./**\n    timeout: 20\n    prewarm: true # Run WarmUp immediately after a deploymentlambda\n    payload: \n      source: my-custom-source\n      other: 20\n    payloadRaw: true # Won\'t JSON.stringify() the payload, may be necessary for Go/AppSync deployments\n    concurrency: 5 # Warm up 5 concurrent instances\n    \nfunctions:\n  myColdfunction:\n    handler: \'myColdfunction.handler\'\n    events:\n      - http:\n          path: my-cold-function\n          method: post\n    warmup:\n      enabled: false\n\n  myLowConcurrencyFunction:\n    handler: \'myLowConcurrencyFunction.handler\'\n    events:\n      - http:\n          path: my-low-concurrency-function\n          method: post\n    warmup:\n      payload: different-source-only-for-this-lambda\n      concurrency: 1\n   \n  myProductionOnlyFunction:\n    handler: \'myProductionOnlyFunction.handler\'\n    events:\n      - http:\n          path: my-production-only-function\n          method: post\n    warmup:\n      enabled: prod\n      \n   myDevAndStagingOnlyFunction:\n    handler: \'myDevAndStagingOnlyFunction.handler\'\n    events:\n      - http:\n          path: my-dev-and-staging-only-function\n          method: post\n    warmup:\n      enabled:\n        - dev\n        - staging\n```\n\n##### Options should be tweaked depending on:\n\n* Number of lambdas to warm up\n* Day cold periods\n* Desire to avoid cold lambdas after a deployment\n\n#### Runtime Configuration\nConcurrency can be modified post-deployment at runtime by setting the warmer lambda environment variables.  \nTwo configuration options exist:\n* Globally set the concurrency for all lambdas on the stack (overriding the deployment-time configuration):  \n  Set the environment variable `WARMUP_CONCURRENCY`\n* Individually set the concurrency per lambda  \n  Set the environment variable `WARMUP_CONCURRENCY_YOUR_FUNCTION_NAME`. Must be all uppercase and hyphens (-) must be replaced with underscores (_). If present for one of your lambdas, it overrides the global concurrency setting. \n\n#### Legacy options\n\nOver time some options have been removed from the plugin.\nFor now, we keep backwards compatibility so they still work.\nHowever, they are listed here only to facilitate upgrading the plugin and we strongly recommend switching to the options defined above as soon as possible.\n\n* **default** Has been renamed to `enabled`\n* **schedule** `schedule: rate(5 minutes)` is equivalent to `events: - schedule: rate(5 minutes)`.\n* **source** Has been renamed to `payload`\n* **sourceRaw** Has been renamed to `payloadRaw`\n\n### Permissions\n\nWarmUp requires some permissions to be able to `invoke` your lambdas.\n\n```yaml\ncustom:\n  warmup:\n    folderName: \'_warmup\' # Name of the folder created for the generated warmup \n    cleanFolder: false\n    memorySize: 256\n    name: \'make-them-pop\'\n    role:  myCustRole0\n    events:\n      - schedule: \'cron(0/5 8-17 ? * MON-FRI *)\' # Run WarmUp every 5 minutes Mon-Fri between 8:00am and 5:55pm (UTC)\n    timeout: 20\n    prewarm: true # Run WarmUp immediately after a deployment\n    tags:\n      Project: foo\n      Owner: bar\n\n.....\n\nresources:\n  Resources:\n    myCustRole0:\n      Type: AWS::IAM::Role\n      Properties:\n        Path: /my/cust/path/\n        RoleName: MyCustRole0\n        AssumeRolePolicyDocument:\n          Version: \'2012-10-17\'\n          Statement:\n            - Effect: Allow\n              Principal:\n                Service:\n                  - lambda.amazonaws.com\n              Action: sts:AssumeRole\n        Policies:\n          - PolicyName: myPolicyName\n            PolicyDocument:\n              Version: \'2012-10-17\'\n              Statement:\n                - Effect: Allow # Warmer lambda to send logs to CloudWatch\n                  Action:\n                    - logs:CreateLogGroup\n                    - logs:CreateLogStream\n                    - logs:PutLogEvents\n                  Resource: \n                    - \'Fn::Join\':\n                      - \':\'\n                      -\n                        - \'arn:aws:logs\'\n                        - Ref: \'AWS::Region\'\n                        - Ref: \'AWS::AccountId\'\n                        - \'log-group:/aws/lambda/*:*:*\'\n                - Effect: Allow # Warmer lambda to manage ENIS (only needed if deploying to VPC, https://docs.aws.amazon.com/lambda/latest/dg/vpc.html)\n                  Action:\n                    - ec2:CreateNetworkInterface\n                    - ec2:DescribeNetworkInterfaces\n                    - ec2:DetachNetworkInterface\n                    - ec2:DeleteNetworkInterface\n                  Resource: "*"\n                - Effect: \'Allow\' # Warmer lambda to invoke the functions to be warmed\n                  Action:\n                    - \'lambda:InvokeFunction\'\n                  Resource:\n                  - Fn::Join:\n                    - \':\'\n                    - - arn:aws:lambda\n                      - Ref: AWS::Region\n                      - Ref: AWS::AccountId\n                      - function:${self:service}-${opt:stage, self:provider.stage}-*\n```\n\nThe permissions can also be added to all lambdas using `iamRoleStatements` under `provider` (see https://serverless.com/framework/docs/providers/aws/guide/functions/#permissions):\n\n```yaml\nprovider:\n  name: aws\n  runtime: nodejs10.x\n  iamRoleStatements:\n    - Effect: \'Allow\'\n      Action:\n        - \'lambda:InvokeFunction\'\n      Resource:\n      - Fn::Join:\n        - \':\'\n        - - arn:aws:lambda\n          - Ref: AWS::Region\n          - Ref: AWS::AccountId\n          - function:${self:service}-${opt:stage, self:provider.stage}-*\n```\nIf using pre-warm, the deployment user also needs a similar policy so it can run the warmer lambda.\n\n\n## On the function side\n\nWhen invoked by WarmUp, your lambdas will have the event source `serverless-plugin-warmup` (unless otherwise specified using the `payload` option):\n\n```json\n{\n  "Event": {\n    "source": "serverless-plugin-warmup"\n  }\n}\n```\n\nTo minimize cost and avoid running your lambda unnecessarily, you should add an early return call before your lambda logic when that payload is received.\n\n### Javascript\n```javascript\n// Using the Promise style\nmodule.exports.lambdaToWarm = async function(event, context) {\n  /** Immediate response for WarmUp plugin */\n  if (event.source === \'serverless-plugin-warmup\') {\n    console.log(\'WarmUp - Lambda is warm!\');\n    return \'Lambda is warm!\';\n  }\n\n  ... add lambda logic after\n}\n\n// Using the Callback style\nmodule.exports.lambdaToWarm = function(event, context, callback) {\n  /** Immediate response for WarmUp plugin */\n  if (event.source === \'serverless-plugin-warmup\') {\n    console.log(\'WarmUp - Lambda is warm!\')\n    return callback(null, \'Lambda is warm!\')\n  }\n\n  ... add lambda logic after\n}\n\n// Using context.\n// This could be useful if you are handling the raw input and output streams.\nmodule.exports.lambdaToWarm = async function(event, context) {\n  /** Immediate response for WarmUp plugin */\n  if (context.custom.source === \'serverless-plugin-warmup\') {\n    console.log(\'WarmUp - Lambda is warm!\');\n    return \'Lambda is warm!\';\n  }\n\n  ... add lambda logic after\n}\n```\n\nIf you\'re using the `concurrency` option you might want to add a slight delay before returning on warmup calls to ensure that your function doesn\'t return before all concurrent requests have been started:\n\n```javascript\nmodule.exports.lambdaToWarm = async (event, context) => {\n  if (event.source === \'serverless-plugin-warmup\') {\n    console.log(\'WarmUp - Lambda is warm!\');\n    /** Slightly delayed (25ms) response \n    \tto ensure concurrent invocation */\n    await new Promise(r => setTimeout(r, 25));\n    return \'Lambda is warm!\';\n    \n  }\n\n  ... add lambda logic after\n}\n```\n\n### Python\n\n```python\ndef lambda_handler(event, context):\n    # early return call when the function is called by warmup plugin\n    if event.get("source") in ["aws.events", "serverless-plugin-warmup"]:\n        print(\'Lambda is warm!\')\n        return {}\n\n    # function logic here\n    ...\n```\n\n## Deployment\n\nWarmUp supports `serverless deploy`.\n\n## Packaging\n\nWarmUp supports `serverless package`.\n\nBy default, the WarmUp function is packaged individually and it uses a folder named `_warmup` to store duiring the packaging process, which is deleted at the end of the process.\n\nIf you are doing your own [package artifact](https://serverless.com/framework/docs/providers/aws/guide/packaging#artifact) you can set the `cleanFolder` option to `false` and include the `_warmup` folder in your custom artifact.\n\n## Gotchas\n\nThe WarmUp function use normal calls to the AWS SDK in order to keep your lambdas warm.\nBy deafult, the WarmUp function is deployed outside of any VPC so it can reach AWS API.\nIf you use the VPC option to deploy your WarmUp function to a VPC subnet it will need internet access. You can do it by using an [Internet Gateway](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html) or a [Network Address Translation (NAT) gateway](http://docs.aws.amazon.com/lambda/latest/dg/vpc.html). \n\n## Cost\n\nYou can check the Lambda [pricing](https://aws.amazon.com/lambda/pricing/) and CloudWatch [pricing](https://aws.amazon.com/cloudwatch/pricing/) or can use the [AWS Lambda Pricing Calculator](https://s3.amazonaws.com/lambda-tools/pricing-calculator.html) to estimate the monthly cost\n\n#### Example\n\nIf you want to warm 10 functions, each with `memorySize = 1024` and `duration = 10`, using the default settings (and we ignore the free tier):\n\n* WarmUp: runs 8640 times per month = $0.18\n* 10 warm lambdas: each invoked 8640 times per month = $14.4\n* Total = $14.58\n\nCloudWatch costs are not in this example because they are very low.\n\n## Contribute\n\nHelp us making this plugin better and future proof.\n\n* Clone the code\n* Install the dependencies with `npm install`\n* Create a feature branch `git checkout -b new_feature`\n* Add your code and add tests if you implement a new feature\n* Validate your changes `npm run lint` and `npm test` (or `npm run test-with-coverage`)\n\n## License\n\nThis software is released under the MIT license. See [the license file](LICENSE) for more details.\n\n[serverless-badge]: http://public.serverless.com/badges/v3.svg\n[serverless-badge-url]: http://www.serverless.com\n[npm-version-badge]: https://badge.fury.io/js/serverless-plugin-warmup.svg\n[npm-version-badge-url]: https://www.npmjs.com/package/serverless-plugin-warmup\n[npm-downloads-badge]: https://img.shields.io/npm/dm/serverless-plugin-warmup.svg\n[travis-badge]: https://travis-ci.org/FidelLimited/serverless-plugin-warmup.svg\n[travis-badge-url]: https://travis-ci.org/FidelLimited/serverless-plugin-warmup\n[coveralls-badge]: https://coveralls.io/repos/FidelLimited/serverless-plugin-warmup/badge.svg?branch=master\n[coveralls-badge-url]: https://coveralls.io/r/FidelLimited/serverless-plugin-warmup?branch=master\n[dev-badge]: https://david-dm.org/FidelLimited/serverless-plugin-warmup.svg\n[dev-badge-url]: https://david-dm.org/FidelLimited/serverless-plugin-warmup\n'