b'# Serverless Python Requirements\n\n[![serverless](http://public.serverless.com/badges/v3.svg)](http://www.serverless.com)\n[![CircleCI](https://circleci.com/gh/UnitedIncome/serverless-python-requirements.svg?style=shield)](https://circleci.com/gh/UnitedIncome/serverless-python-requirements)\n[![appveyor](https://ci.appveyor.com/api/projects/status/biel93xc535nxvi2?svg=true)](https://ci.appveyor.com/project/dschep/serverless-python-requirements)\n[![npm](https://img.shields.io/npm/v/serverless-python-requirements.svg)](https://www.npmjs.com/package/serverless-python-requirements)\n[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg)](https://github.com/prettier/prettier)\n\nA Serverless v1.x plugin to automatically bundle dependencies from\n`requirements.txt` and make them available in your `PYTHONPATH`.\n\n**Requires Serverless >= v1.34**\n\n## Install\n\n```\nsls plugin install -n serverless-python-requirements\n```\n\nThis will automatically add the plugin to your project\'s `package.json` and the plugins section of its\n`serverless.yml`. That\'s all that\'s needed for basic use! The plugin will now bundle your python\ndependencies specified in your `requirements.txt` or `Pipfile` when you run `sls deploy`.\n\nFor a more in depth introduction on how to use this plugin, check out\n[this post on the Serverless Blog](https://serverless.com/blog/serverless-python-packaging/)\n\nIf you\'re on a mac, check out [these notes](#applebeersnake-mac-brew-installed-python-notes) about using python installed by brew.\n\n\n## Cross compiling!\nCompiling non-pure-Python modules or fetching their manylinux wheels is\nsupported on non-linux OSs via the use of Docker and the\n[docker-lambda](https://github.com/lambci/docker-lambda) image.\nTo enable docker usage, add the following to your `serverless.yml`:\n```yaml\ncustom:\n  pythonRequirements:\n    dockerizePip: true\n```\nThe dockerizePip option supports a special case in addition to booleans of `\'non-linux\'` which makes\nit dockerize only on non-linux environments.\n\n\nTo utilize your own Docker container instead of the default, add the following to your `serverless.yml`:\n```yaml\ncustom:\n  pythonRequirements:\n    dockerImage: <image name>:tag\n```\nThis must be the full image name and tag to use, including the runtime specific tag if applicable.\n\nAlternatively, you can define your Docker image in your own Dockerfile and add the following to your `serverless.yml`:\n```yaml\ncustom:\n  pythonRequirements:\n    dockerFile: ./path/to/Dockerfile\n```\nWith `Dockerfile` the path to the Dockerfile that must be in the current folder (or a subfolder).\nPlease note the `dockerImage` and the `dockerFile` are mutually exclusive.\n\nTo install requirements from private git repositories, add the following to your `serverless.yml`:\n```yaml\ncustom:\n  pythonRequirements:\n    dockerizePip: true\n    dockerSsh: true\n```\nThe `dockerSsh` option will mount your `$HOME/.ssh/id_rsa` and `$HOME/.ssh/known_hosts` as a\nvolume in the docker container. If your SSH key is password protected, you can use `ssh-agent`\nbecause `$SSH_AUTH_SOCK` is also mounted & the env var set.\nIt is important that the host of your private repositories has already been added in your\n`$HOME/.ssh/known_hosts` file, as the install process will fail otherwise due to host authenticity\nfailure.\n\nYou can also pass environment variables to docker by specifying them in `dockerEnv`\noption:\n```yaml\ncustom:\n  pythonRequirements:\n    dockerEnv:\n      - https_proxy\n```\n\n[:checkered_flag: Windows notes](#checkered_flag-windows-dockerizepip-notes)\n\n## Pipenv support :sparkles::cake::sparkles:\nIf you include a `Pipfile` and have `pipenv` installed instead of a `requirements.txt` this will use\n`pipenv lock -r` to generate them. It is fully compatible with all options such as `zip` and\n`dockerizePip`. If you don\'t want this plugin to generate it for you, set the following option:\n```yaml\ncustom:\n  pythonRequirements:\n    usePipenv: false\n```\n\n\n## Poetry support :sparkles::pencil::sparkles:\nNOTE: Only poetry version 1 supports the required `export` command for this\nfeature. As of the point this feature was added, poetry 1.0.0 was in preview\nand requires that poetry is installed with the --preview flag.\n\nTL;DR Install poetry with the `--preview` flag.\n\nIf you include a `pyproject.toml` and have `poetry` installed instead of a `requirements.txt` this will use\n`poetry export --without-hashes -f requirements.txt` to generate them. It is fully compatible with all options such as `zip` and\n`dockerizePip`. If you don\'t want this plugin to generate it for you, set the following option:\n```yaml\ncustom:\n  pythonRequirements:\n    usePoetry: false\n```\n\n### Poetry with git dependencies\nPoetry by default generates the exported requirements.txt file with `-e` and that breaks pip with `-t` parameter\n(used to install all requirements in a specific folder). In order to fix that we remove all `-e ` from the generated file but,\nfor that to work you need to add the git dependencies in a specific way.\n\nInstead of:\n```toml\n[tool.poetry.dependencies]\nbottle = {git = "git@github.com/bottlepy/bottle.git", tag = "0.12.16"}\n```\nUse:\n```toml\n[tool.poetry.dependencies]\nbottle = {git = "https://git@github.com/bottlepy/bottle.git", tag = "0.12.16"}\n```\nOr, if you have an SSH key configured:\n```toml\n[tool.poetry.dependencies]\nbottle = {git = "ssh://git@github.com/bottlepy/bottle.git", tag = "0.12.16"}\n```\n\n## Dealing with Lambda\'s size limitations\nTo help deal with potentially large dependencies (for example: `numpy`, `scipy`\nand `scikit-learn`) there is support for compressing the libraries. This does\nrequire a minor change to your code to decompress them.  To enable this add the\nfollowing to your  `serverless.yml`:\n```yaml\ncustom:\n  pythonRequirements:\n    zip: true\n```\n\nand add this to your handler module before any code that imports your deps:\n```python\ntry:\n  import unzip_requirements\nexcept ImportError:\n  pass\n```\n### Slim Package\n_Works on non \'win32\' environments: Docker, WSL are included_\nTo remove the tests, information and caches from the installed packages,\nenable the `slim` option. This will: `strip` the `.so` files, remove `__pycache__`\nand `dist-info` directories as well as `.pyc` and `.pyo` files.\n```yaml\ncustom:\n  pythonRequirements:\n    slim: true\n```\n#### Custom Removal Patterns\nTo specify additional directories to remove from the installed packages,\ndefine a list of patterns in the serverless config using the `slimPatterns`\noption and glob syntax. These paterns will be added to the default ones (`**/*.py[c|o]`, `**/__pycache__*`, `**/*.dist-info*`).\nNote, the glob syntax matches against whole paths, so to match a file in any\ndirectory, start your pattern with `**/`.\n```yaml\ncustom:\n  pythonRequirements:\n    slim: true\n    slimPatterns:\n      - "**/*.egg-info*"\n```\nTo overwrite the default patterns set the option `slimPatternsAppendDefaults` to `false` (`true` by default).\n```yaml\ncustom:\n  pythonRequirements:\n    slim: true\n    slimPatternsAppendDefaults: false\n    slimPatterns:\n      - "**/*.egg-info*"\n```\nThis will remove all folders within the installed requirements that match\nthe names in `slimPatterns`\n\n#### Option not to strip binaries\n\nIn some cases, stripping binaries leads to problems like "ELF load command address/offset not properly aligned", even when done in the Docker environment. You can still slim down the package without `*.so` files with\n```yaml\ncustom:\n  pythonRequirements:\n    slim: true\n    strip: false\n```\n\n### Lambda Layer\nAnother method for dealing with large dependencies is to put them into a\n[Lambda Layer](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html).\nSimply add the `layer` option to the configuration.\n```yaml\ncustom:\n  pythonRequirements:\n    layer: true\n```\nThe requirements will be zipped up and a layer will be created automatically.\nNow just add the reference to the functions that will use the layer.\n```yaml\nfunctions:\n  hello:\n    handler: handler.hello\n    layers:\n      - {Ref: PythonRequirementsLambdaLayer}\n```\nIf the layer requires additional or custom configuration, add them onto the `layer` option.\n```yaml\ncustom:\n  pythonRequirements:\n    layer:\n      name: ${self:provider.stage}-layerName\n      description: Python requirements lambda layer\n      compatibleRuntimes:\n        - python3.7\n      licenseInfo: GPLv3\n      allowedAccounts:\n        - \'*\'\n```\n## Omitting Packages\nYou can omit a package from deployment with the `noDeploy` option. Note that\ndependencies of omitted packages must explicitly be omitted too.\n\nThis example makes it instead omit pytest:\n```yaml\ncustom:\n  pythonRequirements:\n    noDeploy:\n      - pytest\n```\n\n## Extra Config Options\n### Caching\nYou can enable two kinds of caching with this plugin which are currently both ENABLED by default.  First, a download cache that will cache downloads that pip needs to compile the packages.  And second, a what we call "static caching" which caches output of pip after compiling everything for your requirements file.  Since generally requirements.txt files rarely change, you will often see large amounts of speed improvements when enabling the static cache feature.  These caches will be shared between all your projects if no custom cacheLocation is specified (see below).\n\n _**Please note:** This has replaced the previously recommended usage of "--cache-dir" in the pipCmdExtraArgs_\n```yaml\ncustom:\n  pythonRequirements:\n    useDownloadCache: true\n    useStaticCache: true\n```\n_Additionally, In future versions of this plugin, both caching features will probably be enabled by default_\n\n### Other caching options...\nThere are two additional options related to caching.  You can specify where in your system that this plugin caches with the `cacheLocation` option.  By default it will figure out automatically where based on your username and your OS to store the cache via the [appdirectory](https://www.npmjs.com/package/appdirectory) module.  Additionally, you can specify how many max static caches to store with `staticCacheMaxVersions`, as a simple attempt to limit disk space usage for caching.  This is DISABLED (set to 0) by default.  Example:\n```yaml\ncustom:\n  pythonRequirements:\n    useStaticCache: true\n    useDownloadCache: true\n    cacheLocation: \'/home/user/.my_cache_goes_here\'\n    staticCacheMaxVersions: 10\n\n```\n\n### Extra pip arguments\nYou can specify extra arguments [supported by pip](https://pip.pypa.io/en/stable/reference/pip_install/#options) to be passed to pip like this:\n```yaml\ncustom:\n  pythonRequirements:\n      pipCmdExtraArgs:\n          - --compile\n```\n\n### Extra Docker arguments\n\nYou can specify extra arguments to be passed to [docker build](https://docs.docker.com/engine/reference/commandline/build/) during the build step, and [docker run](https://docs.docker.com/engine/reference/run/) during the dockerized pip install step:\n\n```yaml\ncustom:\n  pythonRequirements:\n    dockerizePip: true\n    dockerBuildCmdExtraArgs: ["--build-arg", "MY_GREAT_ARG=123"]\n    dockerRunCmdExtraArgs: ["-v", "${env:PWD}:/my-app"]\n```\n\n\n### Customize requirements file name\n[Some `pip` workflows involve using requirements files not named\n`requirements.txt`](https://www.kennethreitz.org/essays/a-better-pip-workflow).\nTo support these, this plugin has the following option:\n\n```yaml\ncustom:\n  pythonRequirements:\n    fileName: requirements-prod.txt\n```\n\n### Per-function requirements\nIf you have different python functions, with different sets of requirements, you can avoid\nincluding all the unecessary dependencies of your functions by using the following structure:\n```\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 serverless.yml\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 function1\n\xe2\x94\x82      \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 requirements.txt\n\xe2\x94\x82      \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 index.py\n\xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 function2\n       \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 requirements.txt\n       \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 index.py\n```\nWith the content of your `serverless.yml` containing:\n```yml\npackage:\n  individually: true\n\nfunctions:\n  func1:\n    handler: index.handler\n    module: function1\n  func2:\n    handler: index.handler\n    module: function2\n```\nThe result is 2 zip archives, with only the requirements for function1 in the first one, and only\nthe requirements for function2 in the second one.\n\nQuick notes on the config file:\n * The `module` field must be used to tell the plugin where to find the `requirements.txt` file for\neach function.\n * The `handler` field must not be prefixed by the folder name (already known through `module`) as\nthe root of the zip artifact is already the path to your function.\n\n### Customize Python executable\nSometimes your Python executable isn\'t available on your `$PATH` as `python2.7`\nor `python3.6` (for example, windows or using pyenv).\nTo support this, this plugin has the following option:\n```yaml\ncustom:\n  pythonRequirements:\n    pythonBin: /opt/python3.6/bin/python\n```\n\n### Vendor library directory\nFor certain libraries, default packaging produces too large an installation,\neven when zipping. In those cases it may be necessary to tailor make a version\nof the module. In that case you can store them in a directory and use the\n`vendor` option, and the plugin will copy them along with all the other\ndependencies to install:\n```yaml\ncustom:\n  pythonRequirements:\n    vendor: ./vendored-libraries\nfunctions:\n  hello:\n    handler: hello.handler\n    vendor: ./hello-vendor # The option is also available at the function level\n```\n\n\n\n\n## Manual invocations\n\nThe `.requirements` and `requirements.zip`(if using zip support) files are left\nbehind to speed things up on subsequent deploys. To clean them up, run\n`sls requirements clean`. You can also create them (and `unzip_requirements` if\nusing zip support) manually with `sls requirements install`.\n\n## Invalidate requirements caches on package\n\nIf you are using your own Python library, you have to cleanup\n`.requirements` on any update. You can use the following option to cleanup\n`.requirements` everytime you package.\n\n```\ncustom:\n  pythonRequirements:\n    invalidateCaches: true\n```\n\n## :apple::beer::snake: Mac Brew installed Python notes\n[Brew wilfully breaks the `--target` option with no seeming intention to fix it](https://github.com/Homebrew/brew/pull/821)\nwhich causes issues since this uses that option. There are a few easy workarounds for this:\n* Install Python from [python.org](https://www.python.org/downloads/) and specify it with the\n[`pythonBin` option](#customize-python-executable).\n\nOR\n\n* Create a virtualenv and activate it while using serverless.\n\nOR\n\n* [Install Docker](https://docs.docker.com/docker-for-mac/install/) and use the [`dockerizePip` option](#cross-compiling).\n\nAlso, [brew seems to cause issues with pipenv](https://github.com/dschep/lambda-decorators/issues/4#event-1418928080),\nso make sure you install pipenv using pip.\n\n## :checkered_flag: Windows `dockerizePip` notes\nFor usage of `dockerizePip` on Windows do Step 1 only if running serverless on windows, or do both Step 1 & 2 if running serverless inside WSL.\n\n1. [Enabling shared volume in Windows Docker Taskbar settings](https://forums.docker.com/t/docker-data-volumes-and-windows-mounts/31499/2)\n1. [Installing the Docker client on Windows Subsystem for Linux (Ubuntu)](https://medium.com/@sebagomez/installing-the-docker-client-on-ubuntus-windows-subsystem-for-linux-612b392a44c4)\n\n\n## Native Code Dependencies During Build\n\nSome Python packages require extra OS dependencies to build successfully. To deal with this, replace the default image (`lambci/lambda:python3.6`) with a `Dockerfile` like:\n\n```dockerfile\nFROM lambci/lambda:build-python3.6\n\n# Install your dependencies\nRUN yum -y install mysql-devel\n```\n\nThen update your `serverless.yml`:\n\n```yaml\ncustom:\n  pythonRequirements:\n    dockerFile: Dockerfile\n```\n\n## Native Code Dependencies During Runtime\n\nSome Python packages require extra OS libraries (`*.so` files) at runtime. You need to manually include these files in the root directory of your Serverless package. The simplest way to do this is to use the `dockerExtraFiles` option.\n\nFor instance, the `mysqlclient` package requires `libmysqlclient.so.1020`. If you use the Dockerfile from the previous section, add an item to the `dockerExtraFiles` option in your `serverless.yml`:\n\n```yaml\ncustom:\n  pythonRequirements:\n    dockerExtraFiles:\n      - /usr/lib64/mysql57/libmysqlclient.so.1020\n```\n\nThen verify the library gets included in your package:\n\n```bash\nsls package\nzipinfo .serverless/xxx.zip\n```\n\nIf you can\'t see the library, you might need to adjust your package include/exclude configuration in `serverless.yml`.\n\n## Optimising packaging time\n\nIf you wish to exclude most of the files in your project, and only include the source files of your lambdas and their dependencies you may well use an approach like this:\n\n```yaml\npackage:\n  individually: false\n  include:\n    - "./src/lambda_one/**"\n    - "./src/lambda_two/**"\n  exclude:\n    - "**"\n```\n\nThis will be very slow. Serverless adds a default `"&ast;&ast;"` include. If you are using the `cacheLocation` parameter to this plugin, this will result in all of the cached files\' names being loaded and then subsequently discarded because of the exclude pattern. To avoid this happening you can add a negated include pattern, as is observed in https://github.com/serverless/serverless/pull/5825.\n\nUse this approach instead:\n\n```yaml\npackage:\n  individually: false\n  include:\n    - "!./**"\n    - "./src/lambda_one/**"\n    - "./src/lambda_two/**"\n  exclude:\n    - "**"\n```\n\n## Contributors\n * [@dschep](https://github.com/dschep) - Lead developer & maintainer\n * [@azurelogic](https://github.com/azurelogic) - logging & documentation fixes\n * [@abetomo](https://github.com/abetomo) - style & linting\n * [@angstwad](https://github.com/angstwad) - `deploy --function` support\n * [@mather](https://github.com/mather) - the cache invalidation option\n * [@rmax](https://github.com/rmax) - the extra pip args option\n * [@bsamuel-ui](https://github.com/bsamuel-ui) - Python 3 support\n * [@suxor42](https://github.com/suxor42) - fixing permission issues with Docker on Linux\n * [@mbeltran213](https://github.com/mbeltran213) - fixing docker linux -u option bug\n * [@Tethik](https://github.com/Tethik) - adding usePipenv option\n * [@miketheman](https://github.com/miketheman) - fixing bug with includes when using zip option\n * [@wattdave](https://github.com/wattdave) - fixing bug when using `deploymentBucket`\n * [@heri16](https://github.com/heri16) - fixing Docker support in Windows\n * [@ryansb](https://github.com/ryansb) - package individually support\n * [@cgrimal](https://github.com/cgrimal) - Private SSH Repo access in Docker, `dockerFile` option\n  to build a custom docker image, real per-function requirements, and the\n  `vendor` option\n * [@kichik](https://github.com/kichik) - Imposed windows & `noDeploy` support,\n   switched to adding files straight to zip instead of creating symlinks, and\n   improved pip cache support when using docker.\n * [@dee-me-tree-or-love](https://github.com/dee-me-tree-or-love) - the `slim` package option\n * [@alexjurkiewicz](https://github.com/alexjurkiewicz) - [docs about docker workflows](#native-code-dependencies-during-build)\n * [@andrewfarley](https://github.com/andrewfarley) - Implemented download caching and static caching\n * [@bweigel](https://github.com/bweigel) - adding the `slimPatternsAppendDefaults` option & fixing per-function packaging when some functions don\'t have requirements & Porting tests from bats to js!\n * [@squaresurf](https://github.com/squaresurf) - adding usePoetry option\n * [@david-mk-lawrence](https://github.com/david-mk-lawrence) - added Lambda Layer support\n'