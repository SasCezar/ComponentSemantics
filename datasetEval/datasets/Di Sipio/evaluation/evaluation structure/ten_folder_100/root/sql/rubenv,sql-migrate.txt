b'# sql-migrate\n\n> SQL Schema migration tool for [Go](http://golang.org/). Based on [gorp](https://github.com/go-gorp/gorp) and [goose](https://bitbucket.org/liamstask/goose).\n\n[![Build Status](https://travis-ci.org/rubenv/sql-migrate.svg?branch=master)](https://travis-ci.org/rubenv/sql-migrate) [![GoDoc](https://godoc.org/github.com/rubenv/sql-migrate?status.png)](https://godoc.org/github.com/rubenv/sql-migrate)\n\nUsing [modl](https://github.com/jmoiron/modl)? Check out [modl-migrate](https://github.com/rubenv/modl-migrate).\n\n## Features\n\n* Usable as a CLI tool or as a library\n* Supports SQLite, PostgreSQL, MySQL, MSSQL and Oracle databases (through [gorp](https://github.com/go-gorp/gorp))\n* Can embed migrations into your application\n* Migrations are defined with SQL for full flexibility\n* Atomic migrations\n* Up/down migrations to allow rollback\n* Supports multiple database types in one project\n* Works great with other libraries such as [sqlx](http://jmoiron.github.io/sqlx/)\n\n## Installation\n\nTo install the library and command line program, use the following:\n\n```bash\ngo get -v github.com/rubenv/sql-migrate/...\n```\n\n## Usage\n\n### As a standalone tool\n\n```\n$ sql-migrate --help\nusage: sql-migrate [--version] [--help] <command> [<args>]\n\nAvailable commands are:\n    down      Undo a database migration\n    new       Create a new migration\n    redo      Reapply the last migration\n    status    Show migration status\n    up        Migrates the database to the most recent version available\n```\n\nEach command requires a configuration file (which defaults to `dbconfig.yml`, but can be specified with the `-config` flag). This config file should specify one or more environments:\n\n```yml\ndevelopment:\n    dialect: sqlite3\n    datasource: test.db\n    dir: migrations/sqlite3\n\nproduction:\n    dialect: postgres\n    datasource: dbname=myapp sslmode=disable\n    dir: migrations/postgres\n    table: migrations\n```\n\n(See more examples for different set ups [here](test-integration/dbconfig.yml))\n\nAlso one can obtain env variables in datasource field via `os.ExpandEnv` embedded call for the field.\nThis may be useful if one doesn\'t want to store credentials in file:\n\n```yml\nproduction:\n    dialect: postgres\n    datasource: host=prodhost dbname=proddb user=${DB_USER} password=${DB_PASSWORD} sslmode=required\n    dir: migrations\n    table: migrations\n```\n\nThe `table` setting is optional and will default to `gorp_migrations`.\n\nThe environment that will be used can be specified with the `-env` flag (defaults to `development`).\n\nUse the `--help` flag in combination with any of the commands to get an overview of its usage:\n\n```\n$ sql-migrate up --help\nUsage: sql-migrate up [options] ...\n\n  Migrates the database to the most recent version available.\n\nOptions:\n\n  -config=dbconfig.yml   Configuration file to use.\n  -env="development"     Environment.\n  -limit=0               Limit the number of migrations (0 = unlimited).\n  -dryrun                Don\'t apply migrations, just print them.\n```\n\nThe `new` command creates a new empty migration template using the following pattern `<current time>-<name>.sql`.\n\nThe `up` command applies all available migrations. By contrast, `down` will only apply one migration by default. This behavior can be changed for both by using the `-limit` parameter.\n\nThe `redo` command will unapply the last migration and reapply it. This is useful during development, when you\'re writing migrations.\n\nUse the `status` command to see the state of the applied migrations:\n\n```bash\n$ sql-migrate status\n+---------------+-----------------------------------------+\n|   MIGRATION   |                 APPLIED                 |\n+---------------+-----------------------------------------+\n| 1_initial.sql | 2014-09-13 08:19:06.788354925 +0000 UTC |\n| 2_record.sql  | no                                      |\n+---------------+-----------------------------------------+\n```\n\n#### Running Test Integrations\nYou can see how to run setups for different setups by executing the `.sh` files in [test-integration](test-integration/)\n\n```bash\n# Run mysql-env.sh example (you need to be in the project root directory)\n\n./test-integration/mysql-env.sh\n```\n\n### MySQL Caveat\n\nIf you are using MySQL, you must append `?parseTime=true` to the `datasource` configuration. For example:\n\n```yml\nproduction:\n    dialect: mysql\n    datasource: root@/dbname?parseTime=true\n    dir: migrations/mysql\n    table: migrations\n```\n\nSee [here](https://github.com/go-sql-driver/mysql#parsetime) for more information.\n\n### As a library\n\nImport sql-migrate into your application:\n\n```go\nimport "github.com/rubenv/sql-migrate"\n```\n\nSet up a source of migrations, this can be from memory, from a set of files or from bindata (more on that later):\n\n```go\n// Hardcoded strings in memory:\nmigrations := &migrate.MemoryMigrationSource{\n    Migrations: []*migrate.Migration{\n        &migrate.Migration{\n            Id:   "123",\n            Up:   []string{"CREATE TABLE people (id int)"},\n            Down: []string{"DROP TABLE people"},\n        },\n    },\n}\n\n// OR: Read migrations from a folder:\nmigrations := &migrate.FileMigrationSource{\n    Dir: "db/migrations",\n}\n\n// OR: Use migrations from a packr box\nmigrations := &migrate.PackrMigrationSource{\n    Box: packr.New("migrations", "./migrations"),\n}\n\n// OR: Use migrations from bindata:\nmigrations := &migrate.AssetMigrationSource{\n    Asset:    Asset,\n    AssetDir: AssetDir,\n    Dir:      "migrations",\n}\n```\n\nThen use the `Exec` function to upgrade your database:\n\n```go\ndb, err := sql.Open("sqlite3", filename)\nif err != nil {\n    // Handle errors!\n}\n\nn, err := migrate.Exec(db, "sqlite3", migrations, migrate.Up)\nif err != nil {\n    // Handle errors!\n}\nfmt.Printf("Applied %d migrations!\\n", n)\n```\n\nNote that `n` can be greater than `0` even if there is an error: any migration that succeeded will remain applied even if a later one fails.\n\nCheck [the GoDoc reference](https://godoc.org/github.com/rubenv/sql-migrate) for the full documentation.\n\n## Writing migrations\nMigrations are defined in SQL files, which contain a set of SQL statements. Special comments are used to distinguish up and down migrations.\n\n```sql\n-- +migrate Up\n-- SQL in section \'Up\' is executed when this migration is applied\nCREATE TABLE people (id int);\n\n\n-- +migrate Down\n-- SQL section \'Down\' is executed when this migration is rolled back\nDROP TABLE people;\n```\n\nYou can put multiple statements in each block, as long as you end them with a semicolon (`;`).\n\nYou can alternatively set up a separator string that matches an entire line by setting `sqlparse.LineSeparator`. This\ncan be used to imitate, for example, MS SQL Query Analyzer functionality where commands can be separated by a line with\ncontents of `GO`. If `sqlparse.LineSeparator` is matched, it will not be included in the resulting migration scripts.\n\nIf you have complex statements which contain semicolons, use `StatementBegin` and `StatementEnd` to indicate boundaries:\n\n```sql\n-- +migrate Up\nCREATE TABLE people (id int);\n\n-- +migrate StatementBegin\nCREATE OR REPLACE FUNCTION do_something()\nreturns void AS $$\nDECLARE\n  create_query text;\nBEGIN\n  -- Do something here\nEND;\n$$\nlanguage plpgsql;\n-- +migrate StatementEnd\n\n-- +migrate Down\nDROP FUNCTION do_something();\nDROP TABLE people;\n```\n\nThe order in which migrations are applied is defined through the filename: sql-migrate will sort migrations based on their name. It\'s recommended to use an increasing version number or a timestamp as the first part of the filename.\n\nNormally each migration is run within a transaction in order to guarantee that it is fully atomic. However some SQL commands (for example creating an index concurrently in PostgreSQL) cannot be executed inside a transaction. In order to execute such a command in a migration, the migration can be run using the `notransaction` option:\n\n```sql\n-- +migrate Up notransaction\nCREATE UNIQUE INDEX people_unique_id_idx CONCURRENTLY ON people (id);\n\n-- +migrate Down\nDROP INDEX people_unique_id_idx;\n```\n\n## Embedding migrations with [packr](https://github.com/gobuffalo/packr)\n\nIf you like your Go applications self-contained (that is: a single binary): use [packr](https://github.com/gobuffalo/packr) to embed the migration files.\n\nJust write your migration files as usual, as a set of SQL files in a folder.\n\nImport the packr package into your application:\n\n```go\nimport "github.com/gobuffalo/packr/v2"\n```\n\nUse the `PackrMigrationSource` in your application to find the migrations:\n\n```go\nmigrations := &migrate.PackrMigrationSource{\n    Box: packr.New("migrations", "./migrations"),\n}\n```\n\nIf you already have a box and would like to use a subdirectory:\n\n```go\nmigrations := &migrate.PackrMigrationSource{\n    Box: myBox,\n    Dir: "./migrations",\n}\n```\n\n## Embedding migrations with [bindata](https://github.com/shuLhan/go-bindata)\n\nAs an alternative, but slightly less maintained, you can use [bindata](https://github.com/shuLhan/go-bindata) to embed the migration files.\n\nJust write your migration files as usual, as a set of SQL files in a folder.\n\nThen use bindata to generate a `.go` file with the migrations embedded:\n\n```bash\ngo-bindata -pkg myapp -o bindata.go db/migrations/\n```\n\nThe resulting `bindata.go` file will contain your migrations. Remember to regenerate your `bindata.go` file whenever you add/modify a migration (`go generate` will help here, once it arrives).\n\nUse the `AssetMigrationSource` in your application to find the migrations:\n\n```go\nmigrations := &migrate.AssetMigrationSource{\n    Asset:    Asset,\n    AssetDir: AssetDir,\n    Dir:      "db/migrations",\n}\n```\n\nBoth `Asset` and `AssetDir` are functions provided by bindata.\n\nThen proceed as usual.\n\n## Extending\n\nAdding a new migration source means implementing `MigrationSource`.\n\n```go\ntype MigrationSource interface {\n    FindMigrations() ([]*Migration, error)\n}\n```\n\nThe resulting slice of migrations will be executed in the given order, so it should usually be sorted by the `Id` field.\n\n## Usage with [sqlx](http://jmoiron.github.io/sqlx/)\n\nThis library is compatible with sqlx. When calling migrate just dereference the DB from your `*sqlx.DB`:\n\n```\nn, err := migrate.Exec(db.DB, "sqlite3", migrations, migrate.Up)\n                    //   ^^^ <-- Here db is a *sqlx.DB, the db.DB field is the plain sql.DB\nif err != nil {\n    // Handle errors!\n}\n```\n\n## License\n\nThis library is distributed under the [MIT](LICENSE) license.\n'