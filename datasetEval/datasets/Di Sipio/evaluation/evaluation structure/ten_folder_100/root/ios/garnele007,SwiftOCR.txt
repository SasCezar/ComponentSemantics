b'![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)\n![CocoaPods Compatible](https://img.shields.io/cocoapods/v/SwiftOCR.svg)\n![Platform](https://img.shields.io/cocoapods/p/SwiftOCR.svg?style=flat)\n\n# SwiftOCR\n\nSwiftOCR is a fast and simple OCR library written in Swift. It uses a neural network for image recognition.\nAs of now, SwiftOCR is optimized for recognizing short, one line long alphanumeric codes (e.g. DI4C9CM). We currently support iOS and OS X.\n\n## Features\n- [x] Easy to use training class\n- [x] High accuracy\n- [x] Great default image preprocessing\n- [x] Fast and accurate character segmentation algorithm\n- [x] Add support for lowercase characters\n- [x] Add support for connected character segmentation\n\n## Why should I choose SwiftOCR instead of Tesseract?\n\nThis is a really good question. \n\nIf you want to recognize normal text like a poem or a news article, go with Tesseract, but if you want to recognize short, alphanumeric codes (e.g. gift cards), I would advise you to choose SwiftOCR because that\'s where it exceeds.\n\nTesseract is written in C++ and over 30 years old. To use it you first have to write a Objective-C++ wrapper for it. The main issue that\'s slowing down Tesseract is the way memory is managed. Too many memory allocations and releases slow it down.\n\nI did some testing on over 50 difficult images containing alphanumeric codes. The results where astonishing. SwiftOCR beat Tesseract in every category.\n\n|          | SwiftOCR  | Tesseract |\n| -------- | :-------: | :-------: |\n| Speed    | 0.08 sec. | 0.63 sec. |\n| Accuracy | 97.7%     | 45.2%     |\n| CPU      | ~30%      | ~90%      |\n| Memory   | 45 MB     | 73 MB     |\n\n\n## How does it work?\n\n1) Input image is thresholded (binarized).\n2) Characters are extracted from the image, using a technique called [Connected-component labeling](https://en.wikipedia.org/wiki/Connected-component_labeling).\n3) Separated characters are converted into numbers, which are then fed into the neural network.\n\n## How to use it?\n\nSwiftOCR is available through CocoaPods. To install it, simply add the following line to your Podfile:\n\n`pod \'SwiftOCR\'`\n\nIf you ever used Tesseract you know how exhausting it can be to implement OCR into your project. \nSwiftOCR is the exact opposite of Tesseract. It can be implemented using **just 6 lines of code**. \n\n```swift\nimport SwiftOCR\n\nlet swiftOCRInstance = SwiftOCR()\n    \nswiftOCRInstance.recognize(myImage) { recognizedString in\n    print(recognizedString)\n}\n```\n\nTo improve your experience with SwiftOCR you should set your Build Configuration to `Release`.\n\n#### Training\n\nTraining SwiftOCR is pretty easy. There are only a few steps you have to do, before it can recognize a new font.\n\nThe easiest way to train SwiftOCR is using the training app that can be found under `/example/OS X/SwiftOCR Training`. First select the fonts you want to train from the list. After that, you can change the characters you want to train in the text field. Finally, you have to press the `Start Testing` button. The only thing that\'s left now, is waiting. Depending on your settings, this can take between a half and two minutes. After about two minutes you may manually stop the training.\nPressing the `Save` button will save trained network to your desktop.\nThe `Test` button is used for evaluating the accuracy of the trained neural network.\n\n## Examples\n\nHere is an example image. SwiftOCR has no problem recognizing it. If you try to recognize the same image using Tesseract the output is \'LABMENSW\' ?!?!?.\n\n![Image 1](https://github.com/garnele007/SwiftOCR/blob/master/example/OS%20X/SwiftOCR%20Example%20OS%20X/SwiftOCR%20Example%20OS%20X/images/Test%202.png?raw=true)\n\nThis image is difficult to recognize because of two reasons:\n- The lighting is uneven. This problem is solved by the innovative preprocessing algorithm of SwiftOCR.\n- The text in this image is distorted. Since SwiftOCR uses a neural network for the recognition, this isn\'t a real problem. A NN is flexible like a human brain and can recognize even the most distorted image (most of the time).\n\n## TODO\n\n- [ ] Port to [GPUImage 2](https://github.com/BradLarson/GPUImage2)\n\n## Dependencies\n\n* [Swift-AI](https://github.com/collinhundley/Swift-AI)\n* [GPUImage](https://github.com/BradLarson/GPUImage)\n* [Union-Find](https://github.com/hollance/swift-algorithm-club/tree/master/Union-Find)\n\n## License\n\n    The code in this repository is licensed under the Apache License, Version 2.0 (the "License");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an "AS IS" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n\n**NOTE**: This software depends on other packages that may be licensed under different open source licenses.\n'